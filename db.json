{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/indigo/source/css/style.less","path":"css/style.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.min.js","path":"js/main.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.min.js","path":"js/search.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/cc.png","path":"img/cc.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/brand.jpg","path":"img/brand.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/loader.js","path":"js/cloudTie/loader.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/mobile.min.js","path":"js/cloudTie/mobile.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/loader.min.js","path":"js/cloudTie/loader.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/cloudTie/mobile.less","path":"css/cloudTie/mobile.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/cloudTie/pc.less","path":"css/cloudTie/pc.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/wechat.jpg","path":"img/wechat.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/mobile.js","path":"js/cloudTie/mobile.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/pc.min.js","path":"js/cloudTie/pc.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/pc.js","path":"js/cloudTie/pc.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/indigo/.editorconfig","hash":"67a03b88eadd7810f2e01866e73814074ecd3b87","modified":1498811961439},{"_id":"themes/indigo/.gitignore","hash":"01ded238bb1d5a6738431f2c7c0409deb5423fa1","modified":1499422085959},{"_id":"themes/indigo/LICENSE","hash":"9dd0f70bc72c9d575447655526aded395bb93754","modified":1498811961450},{"_id":"themes/indigo/README.md","hash":"480f6efbd0fcf50308b22bc3af7a8c79e56601f8","modified":1498811961451},{"_id":"themes/indigo/package.json","hash":"7154332fa35990cfe4fa82ad7857c781ce6ddbb4","modified":1498811961528},{"_id":"source/_posts/difference-between-stringbuilder-and-stringbuffer.md","hash":"8b271730b246af6a01e5ff8b52ce3010f1c2c408","modified":1498811961402},{"_id":"themes/indigo/_config.yml","hash":"82a636ba8ffc5c4ecd62123efc565130ef456d8d","modified":1499736915170},{"_id":"source/_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","hash":"7482656191402a2d7fda927fcd226f42f1ee9b10","modified":1498811961402},{"_id":"source/_posts/introduction-to-actor-model.md","hash":"549a3571fc8a624e3ac4430a2ddd3383819fad3d","modified":1498811961426},{"_id":"source/links/index.md","hash":"1bbaa83362bf5846782bed96a4e02a15fdb90c3c","modified":1500624586830},{"_id":"source/_posts/introduction-to-galera-cluster-for-mysql.md","hash":"b71c4c8f7c7c8a2127d094f0e77faf147263722e","modified":1498811961426},{"_id":"source/_posts/general-concepts-concurrency-parallelism-process-thread-coroutine.md","hash":"3594c35da091c9d11b9ede233489d48cd980c019","modified":1498811961425},{"_id":"source/_posts/nested-lists-and-deep-copies.md","hash":"0ba6d17c139a9211c8e95555ebd7a6dcd784883b","modified":1498811961427},{"_id":"source/_posts/python-introduction-to-decorators-with-examples.md","hash":"e7bc436da83ff70f6d9f7b492d245e04a63be58a","modified":1505892478748},{"_id":"source/_posts/mongodb-crashed-with-the-Got-signal-6-Aborted.md","hash":"2c579ab34743b192e202bb57a4074a0dc79a263b","modified":1498811961427},{"_id":"source/_posts/mongodb-connecttimeout-and-sockettimeout.md","hash":"d39f183e2f29b1e82c1f57b7d9d3a4452710f4b8","modified":1498811961426},{"_id":"source/_posts/packing-and-unpacking-tuples.md","hash":"4619e512901721f534241494b4891758947a33b8","modified":1498811961428},{"_id":"source/_posts/一个成功的Git分支模型.md","hash":"df0404690e3faf499afbb7c4ca9d6790781f267e","modified":1498811961428},{"_id":"source/_posts/为CentOS6-5安装Kernel3-10.md","hash":"13db155cd009b89e283ecc2370c5e0de46b55707","modified":1498811961429},{"_id":"source/_posts/使用Logrotate管理MongoDB日志-后记.md","hash":"9aecb9a8660f9b404bc41e269465c3b3aac5f822","modified":1498811961429},{"_id":"source/_posts/introduction-to-trove.md","hash":"eb50d66732a5b73f2a594654a1e8a2413c606cf1","modified":1500970484040},{"_id":"source/_posts/使用Logrotate管理MongoDB日志.md","hash":"edcd29ba2c948df979046f7ff68c55f09c91bde4","modified":1498811961429},{"_id":"source/_posts/基于Redis的Tomcat集群Session共享.md","hash":"27fba5918ad2bebca1c15bf4549267fb9bd62adb","modified":1498811961430},{"_id":"source/_posts/如何在CentOS7上安装和配置VNCServer.md","hash":"7e9ed8b71146e195d9510740768f7c3c8bfd80c9","modified":1498811961430},{"_id":"source/tags/index.md","hash":"8cd4bb27b82c3174f45565ea5b8a17cab3c370b5","modified":1499422085958},{"_id":"source/_posts/开山第一篇.md","hash":"2beac7e8f1d38c9eabcfeb06c7080bb6667c78c1","modified":1498811961437},{"_id":"source/_posts/英雄联盟中的随机行为优化.md","hash":"5ce6504499852d2c9744551b4ff81d844c8d6d7f","modified":1498811961438},{"_id":"themes/indigo/languages/en.yml","hash":"ba78def0453d08172248e220a1f9e145e99b4f23","modified":1498811961456},{"_id":"themes/indigo/languages/zh-CN.yml","hash":"6806e4c305facf19cbe4e37ccc5d6b00cb56e199","modified":1498811961456},{"_id":"themes/indigo/languages/zh-TW.yml","hash":"9b8bdd9c8b68716f364503926dca6ba8571ee5ff","modified":1498811961456},{"_id":"themes/indigo/scripts/plugins.js","hash":"00ea278ea77733f546439aed507ce69a298da362","modified":1498700659842},{"_id":"source/_posts/python-generators-and-yield-keyword.md","hash":"d0d3d2fd441afff87969008697428c5e3651ff74","modified":1505729126680},{"_id":"themes/indigo/layout/category.ejs","hash":"e5ba5cc2e092c199285b8097ef12ffe70bf84c91","modified":1498700659842},{"_id":"themes/indigo/layout/index.ejs","hash":"772c1985c7743e101598b4eddc253f9174c5605b","modified":1498794106444},{"_id":"themes/indigo/layout/layout.ejs","hash":"770af84fff104c398ce8b6c995130cddd3e9a1e9","modified":1498700659842},{"_id":"themes/indigo/layout/post.ejs","hash":"efc3352828351f8574c51e8a93dc56c66660c3b1","modified":1498700659842},{"_id":"themes/indigo/layout/tag.ejs","hash":"90a231dea3a364b329a740e5d6c49c8cf5664fe9","modified":1498802368757},{"_id":"themes/indigo/layout/tags.ejs","hash":"1fc0461e9602b53899ec756e4361beb8cce74740","modified":1498802452709},{"_id":"themes/indigo/layout/categories.ejs","hash":"efae06b4d83aaf73ab93260381e891825bf404ac","modified":1498700659842},{"_id":"themes/indigo/layout/page.ejs","hash":"567c42b978da4c39b8b4982df19b940c26bc32a4","modified":1498700659842},{"_id":"themes/indigo/layout/archive.ejs","hash":"6897178ba358379d6a4b7c0ba1bc2ab97ad5303a","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/after-footer.ejs","hash":"1351dbfca311f0d50a939f9e1a91c4f65bbcdf5f","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/archive.ejs","hash":"c294c98617ce14082f9b3d5eec83328f480f5597","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/footer.ejs","hash":"4369f8b97bd25053bdbb64c9cd5f23e6a25b371d","modified":1498806819453},{"_id":"themes/indigo/source/css/style.less","hash":"27dc4b93b93e92824d748f66b85de343b6a68f71","modified":1498813568502},{"_id":"themes/indigo/layout/_partial/loading.ejs","hash":"8b3e037dd5f3d4564012689c5cd6f63caf73df0f","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/header.ejs","hash":"648db446567a81371b8a29d719d13636aa157012","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/paginator.ejs","hash":"886826704c92f8756818430becaab7e176850ed8","modified":1498794103963},{"_id":"themes/indigo/layout/_partial/head.ejs","hash":"fca3d18413c21ef65d384bdf26004a2c38c9ed19","modified":1498809985892},{"_id":"themes/indigo/layout/_partial/menu.ejs","hash":"ea6aded24a68de0914f24b3760f766b5e1c9835a","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/index-item.ejs","hash":"af249dd23a69b9d9807198cdd9de5c3450338cad","modified":1498804816609},{"_id":"themes/indigo/layout/_partial/search.ejs","hash":"752109904304fdb8e988ee1254df2af9c0701466","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/script.ejs","hash":"31052bc524a10abd6871aed2415448ce585faff2","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post.ejs","hash":"20597ac0d547aea37680ecf195eb129fe5ee19d8","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/tags-bar.ejs","hash":"30ec74f081cc4c273a7bcd5d57da99072e9f0755","modified":1498700659826},{"_id":"themes/indigo/source/js/main.js","hash":"69766ad2f40957e2bf1088327a047aaa8304cefd","modified":1498700659889},{"_id":"themes/indigo/source/js/main.min.js","hash":"dcec14830cf056fbbab82313ecd5886a03cdf580","modified":1498700659889},{"_id":"themes/indigo/source/js/search.min.js","hash":"c0c3d048af0d6b840f6f1dfda08911c7bfdb5dc1","modified":1498700659889},{"_id":"themes/indigo/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1458891514496},{"_id":"themes/indigo/source/js/search.js","hash":"e9075b0dd68bce7750fb32a1e3c46f81fdcca6f6","modified":1498700659889},{"_id":"themes/indigo/source/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1458891514496},{"_id":"themes/indigo/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1458891514496},{"_id":"themes/indigo/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1458891514497},{"_id":"themes/indigo/source/css/_partial/gotop.less","hash":"bad63006b3bd4849bf53ad38482af0d9971061d3","modified":1498813568486},{"_id":"themes/indigo/source/css/_partial/archives.less","hash":"382fc22cd5cc073e881768a65600d97eba9f1d21","modified":1498813568484},{"_id":"themes/indigo/source/css/_partial/article.less","hash":"6944b67d793b3e1a645e9d61de766f74b38eb600","modified":1498813568484},{"_id":"themes/indigo/source/css/_partial/layout.less","hash":"b0695de88dc4f1053dfd977dfc24805886a2b1d5","modified":1498813568487},{"_id":"themes/indigo/source/css/_partial/lightbox.less","hash":"38419aaf3c1832e84ade331f051f110fdc8b960f","modified":1498813568488},{"_id":"themes/indigo/source/css/_partial/highlight.less","hash":"99e48793dc0b4ffb66ecaf2d1315145872f9bb98","modified":1498813568487},{"_id":"themes/indigo/source/css/_partial/header.less","hash":"880b4a28e97d556ed15b07642d25115f9b6ba4f6","modified":1498813568486},{"_id":"themes/indigo/source/css/_partial/loading.less","hash":"85157ddf3877b5c58e8f1d737dda3dfb1bfd540b","modified":1498813568488},{"_id":"themes/indigo/source/css/_partial/reward.less","hash":"e690327ce648f8b7920c82f28df2e6333b8d6462","modified":1498813568490},{"_id":"themes/indigo/source/css/_partial/postlist.less","hash":"df2f01c2514e060f2a6f3aca819bdf1e94ea8a4c","modified":1498813568489},{"_id":"themes/indigo/source/css/_partial/search.less","hash":"dbc23e77e586ee682a21475f5eb568628ea6720f","modified":1498813568491},{"_id":"themes/indigo/source/css/_partial/roboto.less","hash":"3e457942995da8840e7662fa6cb551a7e12ea294","modified":1498813568490},{"_id":"themes/indigo/source/css/_partial/share.less","hash":"a683c96a59470efd35722b763c55149a46e35156","modified":1498813568492},{"_id":"themes/indigo/source/css/_partial/tags.less","hash":"01eb7f84193180928a6ed4796ee8802f6c1628e7","modified":1498813568492},{"_id":"themes/indigo/source/css/_partial/variable.less","hash":"89124f48aed2a61a4c8ab1f207f1d4c6df129abd","modified":1498813568493},{"_id":"themes/indigo/source/css/_partial/waves.less","hash":"a02eaa601887f947257f6016679b62dc96a61c0c","modified":1498813568494},{"_id":"themes/indigo/layout/_partial/plugins/disqus.ejs","hash":"86fe837ab16cb60754b0a73bb9efa38b04f3023f","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/gitment.ejs","hash":"5f6ceb7f4b9b579e8e3f87894447f556a53f9385","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/google-analytics.ejs","hash":"b5b87761751a897949e085a8f1ace78b0b8babd5","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/dynamic-title.ejs","hash":"3b877868c4a6fc217ea6f3314544830280a77472","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/baidu.ejs","hash":"da1355eea131952031e54c45560555e6d3aa5a33","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/mathjax.ejs","hash":"3a5c9f7d22d30cd8ffa4e83a8d3976db22815994","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/page-visit.ejs","hash":"bb9deb32c54ea6820f622b923e62592915e9f21f","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/site-visit.ejs","hash":"a2c247c2e32016563dd6a22c21474072d93f4dbd","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/plugins/tajs.ejs","hash":"ef9c77d8c6e004b014c83c5f9333e7174f8bafa3","modified":1498700659826},{"_id":"themes/indigo/source/img/alipay.jpg","hash":"815d6b304af810accce4bf2cbbe05a00758d71e9","modified":1498806328866},{"_id":"themes/indigo/layout/_partial/plugins/uyan.ejs","hash":"ddf290e90dc1c779f42a48e1bd852ca932148dfb","modified":1498700659826},{"_id":"themes/indigo/source/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1458891514495},{"_id":"themes/indigo/layout/_partial/plugins/wangyi-ygt.ejs","hash":"7660c57324984fdbfeddc4d5b72b1d4b2c077866","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/category.ejs","hash":"c08e44cbd7315dec7afb6054b04d3c7b82c3bde8","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/copyright.ejs","hash":"ffd06f34b6d29d5306d1bb8965fcca0e41cdd5f7","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/comment.ejs","hash":"fead9e41d2c1c9fbbb922c30193eb12fe11215f5","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/head-meta.ejs","hash":"f137c126672769e9571be2bb0a70ea8dda644b0e","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/date.ejs","hash":"c5adcec8db1506c378d39855a697e1bb1165646c","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/reward-btn.ejs","hash":"9777c348d76f0a809b20add7d55bf61d3bfb5fb8","modified":1498806500148},{"_id":"themes/indigo/layout/_partial/post/tag.ejs","hash":"412894001b1ac6e63012b26b1109a0856651c076","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/share-fab.ejs","hash":"2ec7de870988cfbc8ea9872cddf7e4076ac64a57","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/title.ejs","hash":"eaad7af7888bddd7095243a43ff38f55ad8c494a","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/share.ejs","hash":"7d79a67b3e5e6989f22fb0e0904fa540bfca5fcc","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/updated.ejs","hash":"00fedf7971c0bda0623d968bc0614e512d19a985","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/toc.ejs","hash":"0d8f0a4ab14c227cd52802095fc4974b6a7aae67","modified":1498700659826},{"_id":"themes/indigo/layout/_partial/post/reward.ejs","hash":"66f0dae33519e64fedb6456bb605fefc4076d2a4","modified":1498806894413},{"_id":"themes/indigo/layout/_partial/post/nav.ejs","hash":"8209ed8fa67f1a094565eaf28b1eea7046f506c9","modified":1498805201928},{"_id":"themes/indigo/source/css/_partial/page.less","hash":"d411248ac382d20cf5d851463795bd3b28510694","modified":1499422085960},{"_id":"themes/indigo/source/js/cloudTie/loader.js","hash":"b69e12df49584d551668192c1870c7f3e4ab9883","modified":1498700659889},{"_id":"themes/indigo/source/js/cloudTie/mobile.min.js","hash":"90edd9177e8beb2083b803bbe9a84e45c2c55aa6","modified":1498700659889},{"_id":"themes/indigo/source/css/cloudTie/_joinCount.less","hash":"e251746eb432d5597a2883fe01dd2307ef1a231f","modified":1498813568495},{"_id":"themes/indigo/source/css/cloudTie/_reset.less","hash":"2e8ff3e47dadac5259f5ac7218e31edc88df8aff","modified":1498813568496},{"_id":"themes/indigo/source/js/cloudTie/loader.min.js","hash":"e73fcd885be2c4585f154861c9969e3c955d03e3","modified":1498700659889},{"_id":"themes/indigo/source/css/cloudTie/_inputBox.less","hash":"c7d7c8eaf26fbc878b0170b64318c8e04066b26a","modified":1498813568494},{"_id":"themes/indigo/source/css/cloudTie/_share.less","hash":"adc02184e9a9dabc72beeebc9ce8f9b3c7ee826e","modified":1498813568496},{"_id":"themes/indigo/source/css/cloudTie/mobile.less","hash":"8a00d06f62b937a2c7c38249f877f709dc1ae27b","modified":1498813568497},{"_id":"themes/indigo/source/css/cloudTie/pc.less","hash":"fcb5bb53f9211ac845d8e52b985099bf2a7f4a85","modified":1498813568498},{"_id":"themes/indigo/source/css/_partial/fontawesome.less","hash":"907c10fa4388b7ae7e141b026fb98cc9f758d785","modified":1498813568485},{"_id":"themes/indigo/source/img/wechat.jpg","hash":"b77bf94cae10f3e15c927a1871003c567c3d6fcc","modified":1498806341768},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1498700659889},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1498700659873},{"_id":"themes/indigo/source/js/cloudTie/mobile.js","hash":"0a9ea82684b59a4985270fc89eb9f7e19993418c","modified":1498700659889},{"_id":"themes/indigo/source/js/cloudTie/pc.min.js","hash":"abc6cd3b05a563aa3aa5569cd881735ed36c6e94","modified":1498700659889},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1498700659889},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1498700659889},{"_id":"themes/indigo/source/img/avatar.jpg","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1458891514494},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1498700659889},{"_id":"themes/indigo/source/js/cloudTie/pc.js","hash":"e11f2a346da54ff420e3d8a7911e121e514482c1","modified":1498700659889},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1498700659857},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1498700659873},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1498700659857},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1498813568501},{"_id":"public/content.json","hash":"477d2202813edad6a83d22c93ccb57263a9e88c8","modified":1505892564931},{"_id":"public/links/index.html","hash":"a5bc8ba63410fd90048bf3a2922bb46961a3a1f9","modified":1505892253469},{"_id":"public/archives/2016/03/index.html","hash":"05bef7a74bc21e48f2639979728a3aa4f2fe5e8b","modified":1505892253812},{"_id":"public/archives/2016/04/index.html","hash":"f90e9ea199ea896b477eb6e5575ed7243bbb5250","modified":1505892253825},{"_id":"public/archives/2016/page/2/index.html","hash":"cccdafb39d4bb64a35428fa8140a5127e6cdb16a","modified":1505892253825},{"_id":"public/archives/2016/06/index.html","hash":"431cc59a92920cc840586b085f43b6953a19b9af","modified":1505892253826},{"_id":"public/archives/2016/07/index.html","hash":"c7cbfca62a7f86370c88b48681b5a7df444b684c","modified":1505892253826},{"_id":"public/archives/2016/09/index.html","hash":"3d83edaaca7330d06601a79d36bc23b7b6a29f03","modified":1505892253826},{"_id":"public/archives/2016/12/index.html","hash":"f35d8cf5531e02c531b97b27961ef681b1716fe3","modified":1505892253826},{"_id":"public/archives/2017/06/index.html","hash":"05c0f36e6fe3831c2147de58739f39dc48772ea0","modified":1505892253826},{"_id":"public/archives/2017/03/index.html","hash":"16a5deb898b5c9f834ba64b254cb52deea60d9bd","modified":1505892253826},{"_id":"public/archives/2017/01/index.html","hash":"4db623b2786c1177ab76012a4365cc4ad8309823","modified":1505892253826},{"_id":"public/archives/2017/09/index.html","hash":"b001518af86d0430ab8f56ef44fa26fe5252adf1","modified":1505892565295},{"_id":"public/tags/Java/index.html","hash":"6294700d9a80595f56d0469e1810a6c2fb9d73f4","modified":1505892253826},{"_id":"public/tags/Actor-Model/index.html","hash":"092f496f80611f321c98d1f78e40b0921f503b5c","modified":1505892253826},{"_id":"public/archives/2017/07/index.html","hash":"0735517df5885aac4850ccd5bf67878622893f8a","modified":1505892253826},{"_id":"public/tags/Galera-Cluster/index.html","hash":"4075943047df5b156635f1b3e9a2430420be0b60","modified":1505892253826},{"_id":"public/tags/Parallelism/index.html","hash":"6a3a30b46594a9c0533ab66f56a07433c31a8d80","modified":1505892253826},{"_id":"public/tags/Concurrency/index.html","hash":"21f9c164c58a10d94cbc907a9ede537be8d8168a","modified":1505892253826},{"_id":"public/tags/MySQL/index.html","hash":"f1db820789f3e608d1033a4c2ebf12e0743e650a","modified":1505892253826},{"_id":"public/tags/Deep-Copy/index.html","hash":"354ff62b7a28c88086229551a93b3062a92b94f5","modified":1505892253826},{"_id":"public/tags/DB/index.html","hash":"795e74cac2afbfc9cd3983081498e94d2a4168bd","modified":1505892253826},{"_id":"public/tags/Coroutine/index.html","hash":"a53968c90ea986f0a7ec479498d17e79bb713248","modified":1505892253827},{"_id":"public/tags/Tuple/index.html","hash":"e681fb131579d338ccca4a92acf863917fdbbaeb","modified":1505892253827},{"_id":"public/tags/Git/index.html","hash":"0ad357848be5333e6ecbf1090a40ada2aa1b194d","modified":1505892253827},{"_id":"public/tags/Linux/index.html","hash":"4aaf5d802b1a63cd5aa3ef810c7f0db1b0d4870d","modified":1505892253827},{"_id":"public/tags/Logrotate/index.html","hash":"3cd0622bcb81619bf5febb698ee18492b51587b7","modified":1505892253827},{"_id":"public/tags/Shallow-Copy/index.html","hash":"8062b2ec765caa934273a9c85355df6be86d3be9","modified":1505892253827},{"_id":"public/tags/CentOS6-5/index.html","hash":"0271e4b240f2a2f32a207038cfb6b30c76887e84","modified":1505892253827},{"_id":"public/tags/OpenStack/index.html","hash":"7d418333cee8ed564f901cc1e3ece35197e42091","modified":1505892253827},{"_id":"public/tags/Trove/index.html","hash":"c79bdc0515d8186d1e755706f3d3ae70920a186f","modified":1505892253827},{"_id":"public/tags/Reids/index.html","hash":"2afc590b171b77f933874146632b23ab9a4c7729","modified":1505892253827},{"_id":"public/tags/Translation/index.html","hash":"97ce727ebde90adfc918c6f4116e1fcc96f48f3e","modified":1505892253827},{"_id":"public/tags/Tomcat/index.html","hash":"7cd648f4cdeebbd114d5859d23e9568ae42e8504","modified":1505892253827},{"_id":"public/tags/翻译/index.html","hash":"6ae469981bab5d14c94d6de5e9722b27a390738a","modified":1505892253827},{"_id":"public/tags/杂/index.html","hash":"b9a31b2a289d0620ea8fe33ad8406b1b019c314c","modified":1505892253827},{"_id":"public/tags/yield/index.html","hash":"bb7519a5c5a8b2d6eee24a59d828d1f58146fe29","modified":1505892253827},{"_id":"public/tags/CentOS7/index.html","hash":"4787ff2f142d0fe597e68cfbea9bf3168a1db63c","modified":1505892253827},{"_id":"public/2017/09/18/python-generators-and-yield-keyword/index.html","hash":"140d8c5ec3adee39af44aa771a88473a728ea17c","modified":1505892565297},{"_id":"public/tags/index.html","hash":"b537f655775b31d0bd2353db947bc5a3c4337cf3","modified":1505892565297},{"_id":"public/2017/03/30/packing-and-unpacking-tuples/index.html","hash":"8ad760e2955d7689cef544065907a280d7218908","modified":1505892253827},{"_id":"public/2017/06/28/mongodb-connecttimeout-and-sockettimeout/index.html","hash":"c063a987bb4421dc35c039ad026522bc7d387642","modified":1505892253827},{"_id":"public/2017/06/23/mongodb-crashed-with-the-Got-signal-6-Aborted/index.html","hash":"2afca5992c370dc3c605290ca6391d0933e5664e","modified":1505892253827},{"_id":"public/2017/01/21/introduction-to-actor-model/index.html","hash":"93062f5d1bbd859cd8826263cb4cc786b135f8d8","modified":1505892253827},{"_id":"public/2017/03/29/nested-lists-and-deep-copies/index.html","hash":"b17a1d133762354802f99d0a66d1b3f7807fb940","modified":1505892253827},{"_id":"public/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/index.html","hash":"66c76242ae4a5b9ebe90966d6e901b16ad2e50a6","modified":1505892253827},{"_id":"public/2016/12/28/introduction-to-galera-cluster-for-mysql/index.html","hash":"f35f01533241c8da4d6ba46f2498828e33fbc7a1","modified":1505892253827},{"_id":"public/2016/09/05/difference-between-stringbuilder-and-stringbuffer/index.html","hash":"987862df367edc3bb5962434bf02fcbe8826133b","modified":1505892253827},{"_id":"public/2016/07/01/使用Logrotate管理MongoDB日志-后记/index.html","hash":"7b6e901b1da39a4856596f473f4715cc89b17315","modified":1505892253828},{"_id":"public/2016/06/30/使用Logrotate管理MongoDB日志/index.html","hash":"965c12cead02a7701cdd38da91b02cd4d8f92846","modified":1505892253828},{"_id":"public/2016/04/27/MongoDB复制集Secondary节点持续Recovering状态解决办法/index.html","hash":"204868933bb351bfbf66855d697e6716f26f67f6","modified":1505892253828},{"_id":"public/2016/03/12/为CentOS6-5安装Kernel3-10/index.html","hash":"f6adffb128e6f57e57bb9ec4a067aff50626764b","modified":1505892253828},{"_id":"public/2016/03/10/基于Redis的Tomcat集群Session共享/index.html","hash":"15a8d4dacfa700294ee46f393f83fa527d2dc251","modified":1505892253828},{"_id":"public/2016/03/09/如何在CentOS7上安装和配置VNCServer/index.html","hash":"948ca57b8ea48ee65222f6bdefa3f61d6da64596","modified":1505892253828},{"_id":"public/2016/03/03/开山第一篇/index.html","hash":"5bf0d44f843c6128b62f0ba17f9c51bc44078542","modified":1505892253828},{"_id":"public/archives/index.html","hash":"ba18260940cd4470a3d97f8030c98c3988adecec","modified":1505892565297},{"_id":"public/2016/03/07/英雄联盟中的随机行为优化/index.html","hash":"ed795b73a3230ad1f1227134399e074bcb8272df","modified":1505892253828},{"_id":"public/archives/page/2/index.html","hash":"683c79a97405f94e33a62d7866a65a3704af2b1d","modified":1505892253828},{"_id":"public/2016/03/08/一个成功的Git分支模型/index.html","hash":"85ce65533da94a4a9b9fe09cc17d3d7c15f661d8","modified":1505892253828},{"_id":"public/2017/07/25/introduction-to-trove/index.html","hash":"a60e4c98697b2cadf58eb1608f14be6c32c370fb","modified":1505892253828},{"_id":"public/archives/2016/index.html","hash":"836def90066a12d4003a7eebccd72e2d8fc4bbd0","modified":1505892253828},{"_id":"public/archives/2017/index.html","hash":"904968012af7de6c9fa90b2625f28d42465b48cc","modified":1505892565297},{"_id":"public/index.html","hash":"b057ab78a1587331c6e7480f7388a42af4cd6ee9","modified":1505892565297},{"_id":"public/page/2/index.html","hash":"8161299aa5504118cd1d9238c0cb447941f22e74","modified":1505892253828},{"_id":"public/tags/MongoDB/index.html","hash":"57ec80d00e8d96400dfe2465437e9707faa6d37c","modified":1505892253828},{"_id":"public/tags/Python/index.html","hash":"46d23328d44dce7bf7f3fa89da8f5dcb4708b54c","modified":1505892565297},{"_id":"public/tags/decorator/index.html","hash":"b1d4dd03d6accc2f7034b4d769052f329627627f","modified":1505892565296},{"_id":"public/2017/09/20/python-introduction-to-decorators-with-examples/index.html","hash":"3beb95a960f31eb8accd8ab2e33001aa78808718","modified":1505892565297},{"_id":"public/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1505892253838},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1505892253838},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1505892253838},{"_id":"public/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1505892253838},{"_id":"public/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1505892253838},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1505892253839},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1505892253839},{"_id":"public/img/alipay.jpg","hash":"815d6b304af810accce4bf2cbbe05a00758d71e9","modified":1505892253898},{"_id":"public/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1505892253899},{"_id":"public/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1505892253901},{"_id":"public/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1505892253901},{"_id":"public/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1505892253901},{"_id":"public/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1505892253901},{"_id":"public/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1505892253902},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1505892253902},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1505892253902},{"_id":"public/js/search.js","hash":"c3f80dee3bab6bd4895b55b849085c8af7d1e647","modified":1505892253906},{"_id":"public/js/main.min.js","hash":"dcec14830cf056fbbab82313ecd5886a03cdf580","modified":1505892253906},{"_id":"public/js/search.min.js","hash":"c0c3d048af0d6b840f6f1dfda08911c7bfdb5dc1","modified":1505892253906},{"_id":"public/css/cloudTie/mobile.css","hash":"0e594542785c389dcf320d615b607b6b91195d16","modified":1505892253907},{"_id":"public/js/cloudTie/loader.js","hash":"299d58e74946a2aeb8db74d3e4b6b5adfe694e15","modified":1505892253907},{"_id":"public/js/cloudTie/loader.min.js","hash":"e73fcd885be2c4585f154861c9969e3c955d03e3","modified":1505892253907},{"_id":"public/js/main.js","hash":"26688338ac55bed772e630099d2ce1ed69ef1431","modified":1505892253907},{"_id":"public/js/cloudTie/mobile.min.js","hash":"859e3efb15db88cedfd18f8523ecfd21f3a22324","modified":1505892253907},{"_id":"public/js/cloudTie/mobile.js","hash":"67a0a31ee1e491635369b0401d629e97fccd4d94","modified":1505892253907},{"_id":"public/js/cloudTie/pc.min.js","hash":"aea28510192fb36a36bf174716a39afd1ca20240","modified":1505892253907},{"_id":"public/js/cloudTie/pc.js","hash":"25d4ae345f8122f8c7e8e48959d37523dd1e4abb","modified":1505892253907},{"_id":"public/img/wechat.jpg","hash":"b77bf94cae10f3e15c927a1871003c567c3d6fcc","modified":1505892253907},{"_id":"public/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1505892253907},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1505892253908},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1505892253909},{"_id":"public/img/avatar.jpg","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1505892253909},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1505892254054},{"_id":"public/css/style.css","hash":"7ddcda3f8e046108463d0a648d6e4871edcf452b","modified":1505892254222},{"_id":"public/css/cloudTie/pc.css","hash":"1c6dd9b04c4a1617d3b3c3349c873a12ae5bb7d7","modified":1505892254222}],"Category":[],"Data":[],"Page":[{"noDate":true,"comments":1,"reward":false,"title":"Links","_content":"\n| Friends | Links |\n|:--------|:------|\n|郭建祥|[guojianxiang.com](http://guojianxiang.com/)|\n|浩哥|[iyeele.com](http://www.iyeele.com/)|\n|高文|[wencst.com](http://www.wencst.com/)|\n|壮壮|[l-zz.cn](http://l-zz.cn)|\n|dwon|[bt91.net](http://www.bt91.net/)|\n|董桐|[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)|\n|LYang|[ly798.github.io/](http://ly798.github.io/)|\n|王昱森|[imys.net](http://imys.net)|\n|blkart|[blog.blkart.org](http://blog.blkart.org/)|\n\n\n>排名不分先后，欢迎各位看官交换链接 :)\n\n","source":"links/index.md","raw":"---\nnoDate: true\ncomments: true\nreward: false\ntitle: Links\n---\n\n| Friends | Links |\n|:--------|:------|\n|郭建祥|[guojianxiang.com](http://guojianxiang.com/)|\n|浩哥|[iyeele.com](http://www.iyeele.com/)|\n|高文|[wencst.com](http://www.wencst.com/)|\n|壮壮|[l-zz.cn](http://l-zz.cn)|\n|dwon|[bt91.net](http://www.bt91.net/)|\n|董桐|[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)|\n|LYang|[ly798.github.io/](http://ly798.github.io/)|\n|王昱森|[imys.net](http://imys.net)|\n|blkart|[blog.blkart.org](http://blog.blkart.org/)|\n\n\n>排名不分先后，欢迎各位看官交换链接 :)\n\n","date":"2017-07-21T08:09:46.830Z","updated":"2017-07-21T08:09:46.830Z","path":"links/index.html","layout":"page","_id":"cj7spd66z0001nshlhvzukktl","content":"<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Friends</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">郭建祥</td>\n<td style=\"text-align:left\"><a href=\"http://guojianxiang.com/\" target=\"_blank\" rel=\"external\">guojianxiang.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">浩哥</td>\n<td style=\"text-align:left\"><a href=\"http://www.iyeele.com/\" target=\"_blank\" rel=\"external\">iyeele.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">高文</td>\n<td style=\"text-align:left\"><a href=\"http://www.wencst.com/\" target=\"_blank\" rel=\"external\">wencst.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">壮壮</td>\n<td style=\"text-align:left\"><a href=\"http://l-zz.cn\" target=\"_blank\" rel=\"external\">l-zz.cn</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dwon</td>\n<td style=\"text-align:left\"><a href=\"http://www.bt91.net/\" target=\"_blank\" rel=\"external\">bt91.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">董桐</td>\n<td style=\"text-align:left\"><a href=\"http://www.cnblogs.com/ytu2010dt/\" target=\"_blank\" rel=\"external\">www.cnblogs.com/ytu2010dt</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">LYang</td>\n<td style=\"text-align:left\"><a href=\"http://ly798.github.io/\" target=\"_blank\" rel=\"external\">ly798.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">王昱森</td>\n<td style=\"text-align:left\"><a href=\"http://imys.net\" target=\"_blank\" rel=\"external\">imys.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">blkart</td>\n<td style=\"text-align:left\"><a href=\"http://blog.blkart.org/\" target=\"_blank\" rel=\"external\">blog.blkart.org</a></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>排名不分先后，欢迎各位看官交换链接 :)</p>\n</blockquote>\n","excerpt":"","more":"<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Friends</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">郭建祥</td>\n<td style=\"text-align:left\"><a href=\"http://guojianxiang.com/\">guojianxiang.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">浩哥</td>\n<td style=\"text-align:left\"><a href=\"http://www.iyeele.com/\">iyeele.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">高文</td>\n<td style=\"text-align:left\"><a href=\"http://www.wencst.com/\">wencst.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">壮壮</td>\n<td style=\"text-align:left\"><a href=\"http://l-zz.cn\">l-zz.cn</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dwon</td>\n<td style=\"text-align:left\"><a href=\"http://www.bt91.net/\">bt91.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">董桐</td>\n<td style=\"text-align:left\"><a href=\"http://www.cnblogs.com/ytu2010dt/\">www.cnblogs.com/ytu2010dt</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">LYang</td>\n<td style=\"text-align:left\"><a href=\"http://ly798.github.io/\">ly798.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">王昱森</td>\n<td style=\"text-align:left\"><a href=\"http://imys.net\">imys.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">blkart</td>\n<td style=\"text-align:left\"><a href=\"http://blog.blkart.org/\">blog.blkart.org</a></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>排名不分先后，欢迎各位看官交换链接 :)</p>\n</blockquote>\n"},{"noDate":true,"comments":0,"reward":false,"layout":"tags","_content":"","source":"tags/index.md","raw":"noDate: true\ncomments: false\nreward: false\nlayout: tags\n---","date":"2017-07-07T10:08:05.958Z","updated":"2017-07-07T10:08:05.958Z","path":"tags/index.html","title":"","_id":"cj7spd68l001onshlhs177shi","content":"","excerpt":"","more":""}],"Post":[{"title":"简述StringBuilder和StringBuffer的区别","date":"2016-09-05T06:36:37.000Z","_content":"\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/difference-between-stringbuilder-and-stringbuffer.md","raw":"---\ntitle: 简述StringBuilder和StringBuffer的区别\ndate: 2016-09-05 14:36:37\ntags: [Java]\n---\n\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","slug":"difference-between-stringbuilder-and-stringbuffer","published":1,"updated":"2017-06-30T08:39:21.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd66u0000nshlz16g0w33","content":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\" target=\"_blank\" rel=\"external\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛<a id=\"more\"></a>，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\" target=\"_blank\" rel=\"external\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\" target=\"_blank\" rel=\"external\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\" target=\"_blank\" rel=\"external\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\" target=\"_blank\" rel=\"external\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\" target=\"_blank\" rel=\"external\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>\n","excerpt":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛","more":"，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>"},{"title":"MongoDB复制集Secondary节点持续Recovering状态解决办法","date":"2016-04-26T21:51:27.000Z","_content":"\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","source":"_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","raw":"---\ntitle: MongoDB复制集Secondary节点持续Recovering状态解决办法\ndate: 2016-04-27 05:51:27\ntags: [MongoDB]\n---\n\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","slug":"MongoDB复制集Secondary节点持续Recovering状态解决办法","published":1,"updated":"2017-06-30T08:39:21.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd6710002nshl4wi8ch0f","content":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\" target=\"_blank\" rel=\"external\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<a id=\"more\"></a>当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\" target=\"_blank\" rel=\"external\">官方文档</a>，这里就不赘述了。</p>\n","excerpt":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……","more":"当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\">官方文档</a>，这里就不赘述了。</p>"},{"title":"并发编程模型之Actor模型","date":"2017-01-21T09:30:30.000Z","_content":"\n\n上一篇文章[《几个概念：并发、并行、进程、线程和协程》](https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/)中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。\n\n<!--more-->\n\n## 两种并发编程模型\n\n并发编程中有两类常见的模型：共享内存和消息传递。\n\n### 共享内存模型\n\n![](http://elbarco.eos.eayun.com/imgs/shared-memory.png)\n\n在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。\n\n共享内存模型的其他示例：\n* A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存\n* A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写\n* A、B是同一Java程序中的两个线程，共享相同的Java对象。\n\n### 消息传递模型\n\n![](http://elbarco.eos.eayun.com/imgs/message-passing.png)\n\n在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。\n\n消息传递模型的示例还有：\n* A和B是通网络中的两台计算机，通过网络通讯\n* A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A\n\n## Actor模型\n\n### 认识Actor模型\n\n上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：\n* 将有限数量的消息传递给其他的actor\n* 产生有限数量的新的actor\n* 当下一个传入的消息被处理时，改变自己的内部行为\n\nactor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，\n\nactor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。\n\n支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。\n\n## 写在后面\n\n本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。\n\n\n## 参考资料\n\n[1].MIT.6.005.[Reading 17:Concurrency](http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/)\n[2].Wikipedia.[Actor Model](https://en.wikipedia.org/wiki/Actor_model)\n[3].Ruben Vermeersch.[Concurrency in Erlang and Scala](https://rocketeer.be/articles/concurrency-in-erlang-scala/)\n[4].Marko Dvečko.[Introduction to Concurrent Programming](https://www.toptal.com/software/introduction-to-concurrent-programming)\n","source":"_posts/introduction-to-actor-model.md","raw":"---\ntitle: 并发编程模型之Actor模型\ndate: 2017-01-21 17:30:30\ntags: [Concurrency, Actor Model]\n---\n\n\n上一篇文章[《几个概念：并发、并行、进程、线程和协程》](https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/)中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。\n\n<!--more-->\n\n## 两种并发编程模型\n\n并发编程中有两类常见的模型：共享内存和消息传递。\n\n### 共享内存模型\n\n![](http://elbarco.eos.eayun.com/imgs/shared-memory.png)\n\n在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。\n\n共享内存模型的其他示例：\n* A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存\n* A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写\n* A、B是同一Java程序中的两个线程，共享相同的Java对象。\n\n### 消息传递模型\n\n![](http://elbarco.eos.eayun.com/imgs/message-passing.png)\n\n在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。\n\n消息传递模型的示例还有：\n* A和B是通网络中的两台计算机，通过网络通讯\n* A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A\n\n## Actor模型\n\n### 认识Actor模型\n\n上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：\n* 将有限数量的消息传递给其他的actor\n* 产生有限数量的新的actor\n* 当下一个传入的消息被处理时，改变自己的内部行为\n\nactor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，\n\nactor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。\n\n支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。\n\n## 写在后面\n\n本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。\n\n\n## 参考资料\n\n[1].MIT.6.005.[Reading 17:Concurrency](http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/)\n[2].Wikipedia.[Actor Model](https://en.wikipedia.org/wiki/Actor_model)\n[3].Ruben Vermeersch.[Concurrency in Erlang and Scala](https://rocketeer.be/articles/concurrency-in-erlang-scala/)\n[4].Marko Dvečko.[Introduction to Concurrent Programming](https://www.toptal.com/software/introduction-to-concurrent-programming)\n","slug":"introduction-to-actor-model","published":1,"updated":"2017-06-30T08:39:21.426Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd6770004nshl5sibmcyn","content":"<p>上一篇文章<a href=\"https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/\">《几个概念：并发、并行、进程、线程和协程》</a>中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。</p>\n<a id=\"more\"></a>\n<h2 id=\"两种并发编程模型\"><a href=\"#两种并发编程模型\" class=\"headerlink\" title=\"两种并发编程模型\"></a>两种并发编程模型</h2><p>并发编程中有两类常见的模型：共享内存和消息传递。</p>\n<h3 id=\"共享内存模型\"><a href=\"#共享内存模型\" class=\"headerlink\" title=\"共享内存模型\"></a>共享内存模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/shared-memory.png\" alt=\"\"></p>\n<p>在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。</p>\n<p>共享内存模型的其他示例：</p>\n<ul>\n<li>A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存</li>\n<li>A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写</li>\n<li>A、B是同一Java程序中的两个线程，共享相同的Java对象。</li>\n</ul>\n<h3 id=\"消息传递模型\"><a href=\"#消息传递模型\" class=\"headerlink\" title=\"消息传递模型\"></a>消息传递模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/message-passing.png\" alt=\"\"></p>\n<p>在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。</p>\n<p>消息传递模型的示例还有：</p>\n<ul>\n<li>A和B是通网络中的两台计算机，通过网络通讯</li>\n<li>A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A</li>\n</ul>\n<h2 id=\"Actor模型\"><a href=\"#Actor模型\" class=\"headerlink\" title=\"Actor模型\"></a>Actor模型</h2><h3 id=\"认识Actor模型\"><a href=\"#认识Actor模型\" class=\"headerlink\" title=\"认识Actor模型\"></a>认识Actor模型</h3><p>上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：</p>\n<ul>\n<li>将有限数量的消息传递给其他的actor</li>\n<li>产生有限数量的新的actor</li>\n<li>当下一个传入的消息被处理时，改变自己的内部行为</li>\n</ul>\n<p>actor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，</p>\n<p>actor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。</p>\n<p>支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。</p>\n<h2 id=\"写在后面\"><a href=\"#写在后面\" class=\"headerlink\" title=\"写在后面\"></a>写在后面</h2><p>本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1].MIT.6.005.<a href=\"http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/\" target=\"_blank\" rel=\"external\">Reading 17:Concurrency</a><br>[2].Wikipedia.<a href=\"https://en.wikipedia.org/wiki/Actor_model\" target=\"_blank\" rel=\"external\">Actor Model</a><br>[3].Ruben Vermeersch.<a href=\"https://rocketeer.be/articles/concurrency-in-erlang-scala/\" target=\"_blank\" rel=\"external\">Concurrency in Erlang and Scala</a><br>[4].Marko Dvečko.<a href=\"https://www.toptal.com/software/introduction-to-concurrent-programming\" target=\"_blank\" rel=\"external\">Introduction to Concurrent Programming</a></p>\n","excerpt":"<p>上一篇文章<a href=\"https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/\">《几个概念：并发、并行、进程、线程和协程》</a>中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。</p>","more":"<h2 id=\"两种并发编程模型\"><a href=\"#两种并发编程模型\" class=\"headerlink\" title=\"两种并发编程模型\"></a>两种并发编程模型</h2><p>并发编程中有两类常见的模型：共享内存和消息传递。</p>\n<h3 id=\"共享内存模型\"><a href=\"#共享内存模型\" class=\"headerlink\" title=\"共享内存模型\"></a>共享内存模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/shared-memory.png\" alt=\"\"></p>\n<p>在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。</p>\n<p>共享内存模型的其他示例：</p>\n<ul>\n<li>A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存</li>\n<li>A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写</li>\n<li>A、B是同一Java程序中的两个线程，共享相同的Java对象。</li>\n</ul>\n<h3 id=\"消息传递模型\"><a href=\"#消息传递模型\" class=\"headerlink\" title=\"消息传递模型\"></a>消息传递模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/message-passing.png\" alt=\"\"></p>\n<p>在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。</p>\n<p>消息传递模型的示例还有：</p>\n<ul>\n<li>A和B是通网络中的两台计算机，通过网络通讯</li>\n<li>A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A</li>\n</ul>\n<h2 id=\"Actor模型\"><a href=\"#Actor模型\" class=\"headerlink\" title=\"Actor模型\"></a>Actor模型</h2><h3 id=\"认识Actor模型\"><a href=\"#认识Actor模型\" class=\"headerlink\" title=\"认识Actor模型\"></a>认识Actor模型</h3><p>上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：</p>\n<ul>\n<li>将有限数量的消息传递给其他的actor</li>\n<li>产生有限数量的新的actor</li>\n<li>当下一个传入的消息被处理时，改变自己的内部行为</li>\n</ul>\n<p>actor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，</p>\n<p>actor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。</p>\n<p>支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。</p>\n<h2 id=\"写在后面\"><a href=\"#写在后面\" class=\"headerlink\" title=\"写在后面\"></a>写在后面</h2><p>本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1].MIT.6.005.<a href=\"http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/\">Reading 17:Concurrency</a><br>[2].Wikipedia.<a href=\"https://en.wikipedia.org/wiki/Actor_model\">Actor Model</a><br>[3].Ruben Vermeersch.<a href=\"https://rocketeer.be/articles/concurrency-in-erlang-scala/\">Concurrency in Erlang and Scala</a><br>[4].Marko Dvečko.<a href=\"https://www.toptal.com/software/introduction-to-concurrent-programming\">Introduction to Concurrent Programming</a></p>"},{"title":"Galera Cluster for MySQL介绍","date":"2016-12-28T06:27:53.000Z","_content":"## 关于数据库复制\n\n数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——\n<!--more-->\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png)\n* Master/Slave Replication\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png)\n* Multi-master Replication\n\n对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。\n而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。\n\n无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——\n* Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。\n* Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。\n\n目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。\n\n为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：\n1. 同步复制，主备无延迟\n2. 支持多主同时读写，保证数据一致性\n3. 集群中各个节点保存全量数据\n4. 节点添加或删除，集群具备自动监测和配置\n5. 行级锁并行复制\n6. 不需要写binlog\n\n## Galera Cluster for MySQL架构\n\n使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png)\n\n当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个`write-set`中，紧接着，数据库节点就会将`write-set`发送到所有的其他节点。\n\n之后，`write-set`会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用`write-set`。如果验证未通过，则节点丢掉`write-set`并且集群回滚；如果验证通过，则事务提交，并且`write-set`会被应用到集群的其他节点。\n\n上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。\n\n那么Galera Cluster内部又是如何工作的呢？\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png)\n\n如上图所示，Galera Cluster有四个组件组成：\n* DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB\n* wsrep API  \n* Galera Replication Plugin\n* Group Communication plugins\n\n这里就不一一展开具体解释了，详细的可以参见[Replication API](http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api)\n\n\n## 部分关键字解释\n\n### Primary Componet\n\n除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。\n\nPrimary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png)\n\n如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。\n\n所以为了能够实现自动故障转移，需要至少三个节点——\n* 单交换器的集群应该至少具备3个节点\n* 跨交换机的集群应该至少具备3个交换机\n* 跨网络的集群应该至少具备3个网络\n* 跨数据中心的集群应该至少具备3个数据中心\n\n\n### Replication Configuration\n\n* wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。\n* wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。\n* wsrep_node_name - 节点名称。\n* wsrep_node_address - 每个节点自己的IP地址。\n* wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过`find / -name libgalera_smm.so` 来查找。\n* wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：`gcache.size`，表示节点缓存`write-sets`集合的磁盘空间，默认值是128M；`gcache.page_size`表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。\n* wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有`mysqldump`和`rsync`两种，在大数据集的场景中，后者比前者更快。\n\n上面是我们`/etc/my.cnf.d/wsrep.cnf`文件中几个配置项的解释，更多的详细内容，请参见[http://galeracluster.com/documentation-webpages/reference.html](http://galeracluster.com/documentation-webpages/reference.html)。\n","source":"_posts/introduction-to-galera-cluster-for-mysql.md","raw":"---\ntitle: Galera Cluster for MySQL介绍\ndate: 2016-12-28 14:27:53\ntags: [MySQL, Galera Cluster, DB]\n---\n## 关于数据库复制\n\n数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——\n<!--more-->\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png)\n* Master/Slave Replication\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png)\n* Multi-master Replication\n\n对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。\n而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。\n\n无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——\n* Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。\n* Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。\n\n目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。\n\n为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：\n1. 同步复制，主备无延迟\n2. 支持多主同时读写，保证数据一致性\n3. 集群中各个节点保存全量数据\n4. 节点添加或删除，集群具备自动监测和配置\n5. 行级锁并行复制\n6. 不需要写binlog\n\n## Galera Cluster for MySQL架构\n\n使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png)\n\n当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个`write-set`中，紧接着，数据库节点就会将`write-set`发送到所有的其他节点。\n\n之后，`write-set`会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用`write-set`。如果验证未通过，则节点丢掉`write-set`并且集群回滚；如果验证通过，则事务提交，并且`write-set`会被应用到集群的其他节点。\n\n上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。\n\n那么Galera Cluster内部又是如何工作的呢？\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png)\n\n如上图所示，Galera Cluster有四个组件组成：\n* DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB\n* wsrep API  \n* Galera Replication Plugin\n* Group Communication plugins\n\n这里就不一一展开具体解释了，详细的可以参见[Replication API](http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api)\n\n\n## 部分关键字解释\n\n### Primary Componet\n\n除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。\n\nPrimary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png)\n\n如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。\n\n所以为了能够实现自动故障转移，需要至少三个节点——\n* 单交换器的集群应该至少具备3个节点\n* 跨交换机的集群应该至少具备3个交换机\n* 跨网络的集群应该至少具备3个网络\n* 跨数据中心的集群应该至少具备3个数据中心\n\n\n### Replication Configuration\n\n* wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。\n* wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。\n* wsrep_node_name - 节点名称。\n* wsrep_node_address - 每个节点自己的IP地址。\n* wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过`find / -name libgalera_smm.so` 来查找。\n* wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：`gcache.size`，表示节点缓存`write-sets`集合的磁盘空间，默认值是128M；`gcache.page_size`表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。\n* wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有`mysqldump`和`rsync`两种，在大数据集的场景中，后者比前者更快。\n\n上面是我们`/etc/my.cnf.d/wsrep.cnf`文件中几个配置项的解释，更多的详细内容，请参见[http://galeracluster.com/documentation-webpages/reference.html](http://galeracluster.com/documentation-webpages/reference.html)。\n","slug":"introduction-to-galera-cluster-for-mysql","published":1,"updated":"2017-06-30T08:39:21.426Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd6780005nshlwcdcsl2u","content":"<h2 id=\"关于数据库复制\"><a href=\"#关于数据库复制\" class=\"headerlink\" title=\"关于数据库复制\"></a>关于数据库复制</h2><p>数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——<br><a id=\"more\"></a></p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png\" alt=\"\"></p>\n<ul>\n<li>Master/Slave Replication</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png\" alt=\"\"></p>\n<ul>\n<li>Multi-master Replication</li>\n</ul>\n<p>对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。<br>而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。</p>\n<p>无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——</p>\n<ul>\n<li>Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。</li>\n<li>Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。</li>\n</ul>\n<p>目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。</p>\n<p>为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：</p>\n<ol>\n<li>同步复制，主备无延迟</li>\n<li>支持多主同时读写，保证数据一致性</li>\n<li>集群中各个节点保存全量数据</li>\n<li>节点添加或删除，集群具备自动监测和配置</li>\n<li>行级锁并行复制</li>\n<li>不需要写binlog</li>\n</ol>\n<h2 id=\"Galera-Cluster-for-MySQL架构\"><a href=\"#Galera-Cluster-for-MySQL架构\" class=\"headerlink\" title=\"Galera Cluster for MySQL架构\"></a>Galera Cluster for MySQL架构</h2><p>使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png\" alt=\"\"></p>\n<p>当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个<code>write-set</code>中，紧接着，数据库节点就会将<code>write-set</code>发送到所有的其他节点。</p>\n<p>之后，<code>write-set</code>会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用<code>write-set</code>。如果验证未通过，则节点丢掉<code>write-set</code>并且集群回滚；如果验证通过，则事务提交，并且<code>write-set</code>会被应用到集群的其他节点。</p>\n<p>上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。</p>\n<p>那么Galera Cluster内部又是如何工作的呢？</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png\" alt=\"\"></p>\n<p>如上图所示，Galera Cluster有四个组件组成：</p>\n<ul>\n<li>DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB</li>\n<li>wsrep API  </li>\n<li>Galera Replication Plugin</li>\n<li>Group Communication plugins</li>\n</ul>\n<p>这里就不一一展开具体解释了，详细的可以参见<a href=\"http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api\" target=\"_blank\" rel=\"external\">Replication API</a></p>\n<h2 id=\"部分关键字解释\"><a href=\"#部分关键字解释\" class=\"headerlink\" title=\"部分关键字解释\"></a>部分关键字解释</h2><h3 id=\"Primary-Componet\"><a href=\"#Primary-Componet\" class=\"headerlink\" title=\"Primary Componet\"></a>Primary Componet</h3><p>除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。</p>\n<p>Primary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png\" alt=\"\"></p>\n<p>如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。</p>\n<p>所以为了能够实现自动故障转移，需要至少三个节点——</p>\n<ul>\n<li>单交换器的集群应该至少具备3个节点</li>\n<li>跨交换机的集群应该至少具备3个交换机</li>\n<li>跨网络的集群应该至少具备3个网络</li>\n<li>跨数据中心的集群应该至少具备3个数据中心</li>\n</ul>\n<h3 id=\"Replication-Configuration\"><a href=\"#Replication-Configuration\" class=\"headerlink\" title=\"Replication Configuration\"></a>Replication Configuration</h3><ul>\n<li>wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。</li>\n<li>wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。</li>\n<li>wsrep_node_name - 节点名称。</li>\n<li>wsrep_node_address - 每个节点自己的IP地址。</li>\n<li>wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过<code>find / -name libgalera_smm.so</code> 来查找。</li>\n<li>wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：<code>gcache.size</code>，表示节点缓存<code>write-sets</code>集合的磁盘空间，默认值是128M；<code>gcache.page_size</code>表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。</li>\n<li>wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有<code>mysqldump</code>和<code>rsync</code>两种，在大数据集的场景中，后者比前者更快。</li>\n</ul>\n<p>上面是我们<code>/etc/my.cnf.d/wsrep.cnf</code>文件中几个配置项的解释，更多的详细内容，请参见<a href=\"http://galeracluster.com/documentation-webpages/reference.html\" target=\"_blank\" rel=\"external\">http://galeracluster.com/documentation-webpages/reference.html</a>。</p>\n","excerpt":"<h2 id=\"关于数据库复制\"><a href=\"#关于数据库复制\" class=\"headerlink\" title=\"关于数据库复制\"></a>关于数据库复制</h2><p>数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——<br>","more":"</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png\" alt=\"\"></p>\n<ul>\n<li>Master/Slave Replication</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png\" alt=\"\"></p>\n<ul>\n<li>Multi-master Replication</li>\n</ul>\n<p>对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。<br>而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。</p>\n<p>无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——</p>\n<ul>\n<li>Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。</li>\n<li>Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。</li>\n</ul>\n<p>目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。</p>\n<p>为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：</p>\n<ol>\n<li>同步复制，主备无延迟</li>\n<li>支持多主同时读写，保证数据一致性</li>\n<li>集群中各个节点保存全量数据</li>\n<li>节点添加或删除，集群具备自动监测和配置</li>\n<li>行级锁并行复制</li>\n<li>不需要写binlog</li>\n</ol>\n<h2 id=\"Galera-Cluster-for-MySQL架构\"><a href=\"#Galera-Cluster-for-MySQL架构\" class=\"headerlink\" title=\"Galera Cluster for MySQL架构\"></a>Galera Cluster for MySQL架构</h2><p>使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png\" alt=\"\"></p>\n<p>当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个<code>write-set</code>中，紧接着，数据库节点就会将<code>write-set</code>发送到所有的其他节点。</p>\n<p>之后，<code>write-set</code>会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用<code>write-set</code>。如果验证未通过，则节点丢掉<code>write-set</code>并且集群回滚；如果验证通过，则事务提交，并且<code>write-set</code>会被应用到集群的其他节点。</p>\n<p>上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。</p>\n<p>那么Galera Cluster内部又是如何工作的呢？</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png\" alt=\"\"></p>\n<p>如上图所示，Galera Cluster有四个组件组成：</p>\n<ul>\n<li>DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB</li>\n<li>wsrep API  </li>\n<li>Galera Replication Plugin</li>\n<li>Group Communication plugins</li>\n</ul>\n<p>这里就不一一展开具体解释了，详细的可以参见<a href=\"http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api\">Replication API</a></p>\n<h2 id=\"部分关键字解释\"><a href=\"#部分关键字解释\" class=\"headerlink\" title=\"部分关键字解释\"></a>部分关键字解释</h2><h3 id=\"Primary-Componet\"><a href=\"#Primary-Componet\" class=\"headerlink\" title=\"Primary Componet\"></a>Primary Componet</h3><p>除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。</p>\n<p>Primary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png\" alt=\"\"></p>\n<p>如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。</p>\n<p>所以为了能够实现自动故障转移，需要至少三个节点——</p>\n<ul>\n<li>单交换器的集群应该至少具备3个节点</li>\n<li>跨交换机的集群应该至少具备3个交换机</li>\n<li>跨网络的集群应该至少具备3个网络</li>\n<li>跨数据中心的集群应该至少具备3个数据中心</li>\n</ul>\n<h3 id=\"Replication-Configuration\"><a href=\"#Replication-Configuration\" class=\"headerlink\" title=\"Replication Configuration\"></a>Replication Configuration</h3><ul>\n<li>wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。</li>\n<li>wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。</li>\n<li>wsrep_node_name - 节点名称。</li>\n<li>wsrep_node_address - 每个节点自己的IP地址。</li>\n<li>wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过<code>find / -name libgalera_smm.so</code> 来查找。</li>\n<li>wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：<code>gcache.size</code>，表示节点缓存<code>write-sets</code>集合的磁盘空间，默认值是128M；<code>gcache.page_size</code>表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。</li>\n<li>wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有<code>mysqldump</code>和<code>rsync</code>两种，在大数据集的场景中，后者比前者更快。</li>\n</ul>\n<p>上面是我们<code>/etc/my.cnf.d/wsrep.cnf</code>文件中几个配置项的解释，更多的详细内容，请参见<a href=\"http://galeracluster.com/documentation-webpages/reference.html\">http://galeracluster.com/documentation-webpages/reference.html</a>。</p>"},{"title":"几个概念：并发、并行、进程、线程和协程","date":"2017-01-20T02:11:19.000Z","_content":"\n“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书[《不一样的技术创新》](https://102.alibaba.com/newsInfo.htm?newsId=28&channel=127)中看到这样一句话。<!-- more -->看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如[Akka](http://akka.io/)起一个头。\n\n## 并发和并行\n\n在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。\n\n### 并发（Concurrency）\n\n并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png)\n\n比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。\n\n### 并行（Parallelism）\n\n并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png)\n\n比如吃饭的同时，我还能打电话，这就是并行。\n\n### 对比\n\n由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。\n\n另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。\n\n并发与顺序相对，而并行是并发的子集。\n\n这里还有一个更形象的例子：\n![](http://elbarco.eos.eayun.com/imgs/con_and_par.jpg)\n\n\n## 进程、线程和协程\n\n### 进程（Process）\n\n是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。\n\n### 线程（Thread）\n\n线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。\n\n### 协程（Coroutine, Fiber）\n\n协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考[廖雪峰的文章](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000)，举个例子：\n如果有两个子程序A和B：\n```python\ndef A():\n    print '1'\n    print '2'\n    print '3'\n\ndef B():\n    print 'x'\n    print 'y'\n    print 'z'\n```\n\n对于这两个子程序，一次调用，一次返回，返回结果很有可能是：\n```\n1\n2\n3\nx\ny\nz\n```\n而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：\n```\n1\n2\nx\ny\n3\nz\n```\n有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。\n\n### Java与协程\n\nJava语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。\n\n\n\n\n\n","source":"_posts/general-concepts-concurrency-parallelism-process-thread-coroutine.md","raw":"---\ntitle: 几个概念：并发、并行、进程、线程和协程\ndate: 2017-01-20 10:11:19\ntags: [Concurrency, Parallelism, Coroutine]\n---\n\n“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书[《不一样的技术创新》](https://102.alibaba.com/newsInfo.htm?newsId=28&channel=127)中看到这样一句话。<!-- more -->看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如[Akka](http://akka.io/)起一个头。\n\n## 并发和并行\n\n在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。\n\n### 并发（Concurrency）\n\n并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png)\n\n比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。\n\n### 并行（Parallelism）\n\n并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png)\n\n比如吃饭的同时，我还能打电话，这就是并行。\n\n### 对比\n\n由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。\n\n另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。\n\n并发与顺序相对，而并行是并发的子集。\n\n这里还有一个更形象的例子：\n![](http://elbarco.eos.eayun.com/imgs/con_and_par.jpg)\n\n\n## 进程、线程和协程\n\n### 进程（Process）\n\n是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。\n\n### 线程（Thread）\n\n线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。\n\n### 协程（Coroutine, Fiber）\n\n协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考[廖雪峰的文章](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000)，举个例子：\n如果有两个子程序A和B：\n```python\ndef A():\n    print '1'\n    print '2'\n    print '3'\n\ndef B():\n    print 'x'\n    print 'y'\n    print 'z'\n```\n\n对于这两个子程序，一次调用，一次返回，返回结果很有可能是：\n```\n1\n2\n3\nx\ny\nz\n```\n而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：\n```\n1\n2\nx\ny\n3\nz\n```\n有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。\n\n### Java与协程\n\nJava语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。\n\n\n\n\n\n","slug":"general-concepts-concurrency-parallelism-process-thread-coroutine","published":1,"updated":"2017-06-30T08:39:21.425Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67a0007nshlmrwhiin9","content":"<p>“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书<a href=\"https://102.alibaba.com/newsInfo.htm?newsId=28&amp;channel=127\" target=\"_blank\" rel=\"external\">《不一样的技术创新》</a>中看到这样一句话。<a id=\"more\"></a>看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如<a href=\"http://akka.io/\" target=\"_blank\" rel=\"external\">Akka</a>起一个头。</p>\n<h2 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h2><p>在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。</p>\n<h3 id=\"并发（Concurrency）\"><a href=\"#并发（Concurrency）\" class=\"headerlink\" title=\"并发（Concurrency）\"></a>并发（Concurrency）</h3><p>并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png\" alt=\"\"></p>\n<p>比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。</p>\n<h3 id=\"并行（Parallelism）\"><a href=\"#并行（Parallelism）\" class=\"headerlink\" title=\"并行（Parallelism）\"></a>并行（Parallelism）</h3><p>并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png\" alt=\"\"></p>\n<p>比如吃饭的同时，我还能打电话，这就是并行。</p>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h3><p>由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。</p>\n<p>另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。</p>\n<p>并发与顺序相对，而并行是并发的子集。</p>\n<p>这里还有一个更形象的例子：<br><img src=\"http://elbarco.eos.eayun.com/imgs/con_and_par.jpg\" alt=\"\"></p>\n<h2 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h2><h3 id=\"进程（Process）\"><a href=\"#进程（Process）\" class=\"headerlink\" title=\"进程（Process）\"></a>进程（Process）</h3><p>是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。</p>\n<h3 id=\"线程（Thread）\"><a href=\"#线程（Thread）\" class=\"headerlink\" title=\"线程（Thread）\"></a>线程（Thread）</h3><p>线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。</p>\n<h3 id=\"协程（Coroutine-Fiber）\"><a href=\"#协程（Coroutine-Fiber）\" class=\"headerlink\" title=\"协程（Coroutine, Fiber）\"></a>协程（Coroutine, Fiber）</h3><p>协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考<a href=\"http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000\" target=\"_blank\" rel=\"external\">廖雪峰的文章</a>，举个例子：<br>如果有两个子程序A和B：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">A</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'1'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'2'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'3'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">B</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'x'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'y'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'z'</span></span><br></pre></td></tr></table></figure></p>\n<p>对于这两个子程序，一次调用，一次返回，返回结果很有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">3</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。</p>\n<h3 id=\"Java与协程\"><a href=\"#Java与协程\" class=\"headerlink\" title=\"Java与协程\"></a>Java与协程</h3><p>Java语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。</p>\n","excerpt":"<p>“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书<a href=\"https://102.alibaba.com/newsInfo.htm?newsId=28&amp;channel=127\">《不一样的技术创新》</a>中看到这样一句话。","more":"看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如<a href=\"http://akka.io/\">Akka</a>起一个头。</p>\n<h2 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h2><p>在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。</p>\n<h3 id=\"并发（Concurrency）\"><a href=\"#并发（Concurrency）\" class=\"headerlink\" title=\"并发（Concurrency）\"></a>并发（Concurrency）</h3><p>并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png\" alt=\"\"></p>\n<p>比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。</p>\n<h3 id=\"并行（Parallelism）\"><a href=\"#并行（Parallelism）\" class=\"headerlink\" title=\"并行（Parallelism）\"></a>并行（Parallelism）</h3><p>并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png\" alt=\"\"></p>\n<p>比如吃饭的同时，我还能打电话，这就是并行。</p>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h3><p>由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。</p>\n<p>另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。</p>\n<p>并发与顺序相对，而并行是并发的子集。</p>\n<p>这里还有一个更形象的例子：<br><img src=\"http://elbarco.eos.eayun.com/imgs/con_and_par.jpg\" alt=\"\"></p>\n<h2 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h2><h3 id=\"进程（Process）\"><a href=\"#进程（Process）\" class=\"headerlink\" title=\"进程（Process）\"></a>进程（Process）</h3><p>是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。</p>\n<h3 id=\"线程（Thread）\"><a href=\"#线程（Thread）\" class=\"headerlink\" title=\"线程（Thread）\"></a>线程（Thread）</h3><p>线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。</p>\n<h3 id=\"协程（Coroutine-Fiber）\"><a href=\"#协程（Coroutine-Fiber）\" class=\"headerlink\" title=\"协程（Coroutine, Fiber）\"></a>协程（Coroutine, Fiber）</h3><p>协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考<a href=\"http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000\">廖雪峰的文章</a>，举个例子：<br>如果有两个子程序A和B：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">A</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'1'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'2'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'3'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">B</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'x'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'y'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'z'</span></span><br></pre></td></tr></table></figure></p>\n<p>对于这两个子程序，一次调用，一次返回，返回结果很有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">3</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。</p>\n<h3 id=\"Java与协程\"><a href=\"#Java与协程\" class=\"headerlink\" title=\"Java与协程\"></a>Java与协程</h3><p>Java语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。</p>"},{"title":"从Python中内嵌列表复制说起","date":"2017-03-29T02:00:31.000Z","_content":"\n## 写在前面\n\n在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。\n<!--more-->\n## 内嵌列表和列表拷贝中的问题\n\nPython中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：\n```python\n>>> m = [[0, 1, 2], [10, 11, 12], [20, 21, 22]]\n>>> m[0]\n[0, 1, 2]\n>>> m[0][1]\n1\n>>> m[2]\n[20, 21, 22]\n>>> m[2][2]\n22\n```\n当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。\n\n大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。\n\n\n创建一个含有内嵌列表的列表`original`：\n```python\n>>> nested = [0]\n>>> original = [nested, 1]\n>>> original\n[[0], 1]\n```\n列表`original`的第一个元素指向了列表`nested`，如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-01.png)\n\n列表`nested`的修改可以通过直接修改其本身，也可以通过修改列表`original`来实现，即：\n```python\n>>> nested[0] = 'zero'\n>>> original\n[['zero'], 1]\n>>> original[0][0] = 0\n>>> nested\n[0]\n>>> original\n[[0], 1]\n```\n\n如果我们将`nested`赋值为其他列表，则`nested`和`original`之间的连接就会断掉，即：\n```python\n>>> nested = [2]\n>>> original\n[[0], 1]\n```\n如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-02.png)\n\n除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——\n* 全切片(full slice)\n```python\n>>> x = [0, 1, 2]\n>>> y = x[:]\n>>> y\n[0, 1, 2]\n```\n* `+`或`*`运算符\n```python\n>>> x = [0, 1, 2]\n>>> y = x + []\n>>> y\n[0, 1, 2]\n>>> z = x * 1\n>>> z\n[0, 1, 2]\n```\n\n但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即*shallow copy*，与之相对的，是“深拷贝”，即*deep copy*。\n\n## 对列表的深拷贝\n\n对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用`copy`模块的`deepcopy`功能。\n\n```python\n>>> original = [[0], 1]\n>>> shallow = original[:]\n>>> import copy\n>>> deep = copy.deepcopy(original)\n```\n复制后两个列表的构成其实如下图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-03.png)\n\n在得到列表`shallow`和列表`deep`后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：\n```python\n>>> shallow[1]=2 #更改列表中非内嵌列表的值，原列表值不变\n>>> shallow\n[[0], 2]\n>>> original\n[[0], 1]\n>>> shallow[0][0]='zero' #更改内嵌列表的值，原列表内嵌列表值改变\n>>> shallow\n[['zero'], 2]\n>>> original\n[['zero'], 1]\n>>> \n>>> \n>>> deep[0][0]=5 #对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表\n>>> deep\n[[5], 1]\n>>> original\n[['zero'], 1]\n>>> \n```\n\n此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。\n\n## 总结和引申思考\n\n首先，明确一点，*deep copy*和*shallow copy*并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。\n\n根据维基百科中的[Object copying](https://en.wikipedia.org/wiki/Object_copying)中的描述，我们总结如下：\n\n![](http://elbarco.eos.eayun.com/imgs/shallow-copy.png)\n\n我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。\n\n![](http://elbarco.eos.eayun.com/imgs/deep-copy.png)\n\n我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。\n\n其他语言，如Java，可以参见StackOverFlow上的这一个讨论：[How do I copy an object in Java](http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java)，后面有机会再详细的梳理一下。\n\n\n\n## 参考\n\n1.[What's the difference between a deep copy and a shallow copy](http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy)\n2.[Object copying](https://en.wikipedia.org/wiki/Object_copying)\n3.[Shallow and deep copy](http://www.python-course.eu/deep_copy.php)\n4.[The Quick Python Book, 2nd Edition. Chapter 5.6](https://item.jd.com/19176803.html)\n\n\n\n\n\n\n\n","source":"_posts/nested-lists-and-deep-copies.md","raw":"---\ntitle: 从Python中内嵌列表复制说起\ndate: 2017-03-29 10:00:31\ntags: [Python, Deep Copy, Shallow Copy]\n---\n\n## 写在前面\n\n在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。\n<!--more-->\n## 内嵌列表和列表拷贝中的问题\n\nPython中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：\n```python\n>>> m = [[0, 1, 2], [10, 11, 12], [20, 21, 22]]\n>>> m[0]\n[0, 1, 2]\n>>> m[0][1]\n1\n>>> m[2]\n[20, 21, 22]\n>>> m[2][2]\n22\n```\n当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。\n\n大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。\n\n\n创建一个含有内嵌列表的列表`original`：\n```python\n>>> nested = [0]\n>>> original = [nested, 1]\n>>> original\n[[0], 1]\n```\n列表`original`的第一个元素指向了列表`nested`，如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-01.png)\n\n列表`nested`的修改可以通过直接修改其本身，也可以通过修改列表`original`来实现，即：\n```python\n>>> nested[0] = 'zero'\n>>> original\n[['zero'], 1]\n>>> original[0][0] = 0\n>>> nested\n[0]\n>>> original\n[[0], 1]\n```\n\n如果我们将`nested`赋值为其他列表，则`nested`和`original`之间的连接就会断掉，即：\n```python\n>>> nested = [2]\n>>> original\n[[0], 1]\n```\n如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-02.png)\n\n除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——\n* 全切片(full slice)\n```python\n>>> x = [0, 1, 2]\n>>> y = x[:]\n>>> y\n[0, 1, 2]\n```\n* `+`或`*`运算符\n```python\n>>> x = [0, 1, 2]\n>>> y = x + []\n>>> y\n[0, 1, 2]\n>>> z = x * 1\n>>> z\n[0, 1, 2]\n```\n\n但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即*shallow copy*，与之相对的，是“深拷贝”，即*deep copy*。\n\n## 对列表的深拷贝\n\n对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用`copy`模块的`deepcopy`功能。\n\n```python\n>>> original = [[0], 1]\n>>> shallow = original[:]\n>>> import copy\n>>> deep = copy.deepcopy(original)\n```\n复制后两个列表的构成其实如下图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-03.png)\n\n在得到列表`shallow`和列表`deep`后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：\n```python\n>>> shallow[1]=2 #更改列表中非内嵌列表的值，原列表值不变\n>>> shallow\n[[0], 2]\n>>> original\n[[0], 1]\n>>> shallow[0][0]='zero' #更改内嵌列表的值，原列表内嵌列表值改变\n>>> shallow\n[['zero'], 2]\n>>> original\n[['zero'], 1]\n>>> \n>>> \n>>> deep[0][0]=5 #对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表\n>>> deep\n[[5], 1]\n>>> original\n[['zero'], 1]\n>>> \n```\n\n此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。\n\n## 总结和引申思考\n\n首先，明确一点，*deep copy*和*shallow copy*并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。\n\n根据维基百科中的[Object copying](https://en.wikipedia.org/wiki/Object_copying)中的描述，我们总结如下：\n\n![](http://elbarco.eos.eayun.com/imgs/shallow-copy.png)\n\n我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。\n\n![](http://elbarco.eos.eayun.com/imgs/deep-copy.png)\n\n我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。\n\n其他语言，如Java，可以参见StackOverFlow上的这一个讨论：[How do I copy an object in Java](http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java)，后面有机会再详细的梳理一下。\n\n\n\n## 参考\n\n1.[What's the difference between a deep copy and a shallow copy](http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy)\n2.[Object copying](https://en.wikipedia.org/wiki/Object_copying)\n3.[Shallow and deep copy](http://www.python-course.eu/deep_copy.php)\n4.[The Quick Python Book, 2nd Edition. Chapter 5.6](https://item.jd.com/19176803.html)\n\n\n\n\n\n\n\n","slug":"nested-lists-and-deep-copies","published":1,"updated":"2017-06-30T08:39:21.427Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67c0009nshlqo7bst5q","content":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。<br><a id=\"more\"></a></p>\n<h2 id=\"内嵌列表和列表拷贝中的问题\"><a href=\"#内嵌列表和列表拷贝中的问题\" class=\"headerlink\" title=\"内嵌列表和列表拷贝中的问题\"></a>内嵌列表和列表拷贝中的问题</h2><p>Python中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m = [[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>]</span><br><span class=\"line\">[<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"number\">22</span></span><br></pre></td></tr></table></figure></p>\n<p>当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。</p>\n<p>大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。</p>\n<p>创建一个含有内嵌列表的列表<code>original</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [nested, <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>列表<code>original</code>的第一个元素指向了列表<code>nested</code>，如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-01.png\" alt=\"\"></p>\n<p>列表<code>nested</code>的修改可以通过直接修改其本身，也可以通过修改列表<code>original</code>来实现，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested[<span class=\"number\">0</span>] = <span class=\"string\">'zero'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested</span><br><span class=\"line\">[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如果我们将<code>nested</code>赋值为其他列表，则<code>nested</code>和<code>original</code>之间的连接就会断掉，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-02.png\" alt=\"\"></p>\n<p>除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——</p>\n<ul>\n<li><p>全切片(full slice)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>+</code>或<code>*</code>运算符</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x + []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x * <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即<em>shallow copy</em>，与之相对的，是“深拷贝”，即<em>deep copy</em>。</p>\n<h2 id=\"对列表的深拷贝\"><a href=\"#对列表的深拷贝\" class=\"headerlink\" title=\"对列表的深拷贝\"></a>对列表的深拷贝</h2><p>对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用<code>copy</code>模块的<code>deepcopy</code>功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow = original[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep = copy.deepcopy(original)</span><br></pre></td></tr></table></figure>\n<p>复制后两个列表的构成其实如下图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-03.png\" alt=\"\"></p>\n<p>在得到列表<code>shallow</code>和列表<code>deep</code>后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">1</span>]=<span class=\"number\">2</span> <span class=\"comment\">#更改列表中非内嵌列表的值，原列表值不变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"string\">'zero'</span> <span class=\"comment\">#更改内嵌列表的值，原列表内嵌列表值改变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"number\">5</span> <span class=\"comment\">#对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep</span><br><span class=\"line\">[[<span class=\"number\">5</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。</p>\n<h2 id=\"总结和引申思考\"><a href=\"#总结和引申思考\" class=\"headerlink\" title=\"总结和引申思考\"></a>总结和引申思考</h2><p>首先，明确一点，<em>deep copy</em>和<em>shallow copy</em>并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。</p>\n<p>根据维基百科中的<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"external\">Object copying</a>中的描述，我们总结如下：</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/shallow-copy.png\" alt=\"\"></p>\n<p>我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/deep-copy.png\" alt=\"\"></p>\n<p>我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。</p>\n<p>其他语言，如Java，可以参见StackOverFlow上的这一个讨论：<a href=\"http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java\" target=\"_blank\" rel=\"external\">How do I copy an object in Java</a>，后面有机会再详细的梳理一下。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy\" target=\"_blank\" rel=\"external\">What’s the difference between a deep copy and a shallow copy</a><br>2.<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"external\">Object copying</a><br>3.<a href=\"http://www.python-course.eu/deep_copy.php\" target=\"_blank\" rel=\"external\">Shallow and deep copy</a><br>4.<a href=\"https://item.jd.com/19176803.html\" target=\"_blank\" rel=\"external\">The Quick Python Book, 2nd Edition. Chapter 5.6</a></p>\n","excerpt":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。<br>","more":"</p>\n<h2 id=\"内嵌列表和列表拷贝中的问题\"><a href=\"#内嵌列表和列表拷贝中的问题\" class=\"headerlink\" title=\"内嵌列表和列表拷贝中的问题\"></a>内嵌列表和列表拷贝中的问题</h2><p>Python中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m = [[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>]</span><br><span class=\"line\">[<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"number\">22</span></span><br></pre></td></tr></table></figure></p>\n<p>当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。</p>\n<p>大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。</p>\n<p>创建一个含有内嵌列表的列表<code>original</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [nested, <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>列表<code>original</code>的第一个元素指向了列表<code>nested</code>，如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-01.png\" alt=\"\"></p>\n<p>列表<code>nested</code>的修改可以通过直接修改其本身，也可以通过修改列表<code>original</code>来实现，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested[<span class=\"number\">0</span>] = <span class=\"string\">'zero'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested</span><br><span class=\"line\">[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如果我们将<code>nested</code>赋值为其他列表，则<code>nested</code>和<code>original</code>之间的连接就会断掉，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-02.png\" alt=\"\"></p>\n<p>除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——</p>\n<ul>\n<li><p>全切片(full slice)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>+</code>或<code>*</code>运算符</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x + []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x * <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即<em>shallow copy</em>，与之相对的，是“深拷贝”，即<em>deep copy</em>。</p>\n<h2 id=\"对列表的深拷贝\"><a href=\"#对列表的深拷贝\" class=\"headerlink\" title=\"对列表的深拷贝\"></a>对列表的深拷贝</h2><p>对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用<code>copy</code>模块的<code>deepcopy</code>功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow = original[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep = copy.deepcopy(original)</span><br></pre></td></tr></table></figure>\n<p>复制后两个列表的构成其实如下图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-03.png\" alt=\"\"></p>\n<p>在得到列表<code>shallow</code>和列表<code>deep</code>后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">1</span>]=<span class=\"number\">2</span> <span class=\"comment\">#更改列表中非内嵌列表的值，原列表值不变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"string\">'zero'</span> <span class=\"comment\">#更改内嵌列表的值，原列表内嵌列表值改变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"number\">5</span> <span class=\"comment\">#对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep</span><br><span class=\"line\">[[<span class=\"number\">5</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。</p>\n<h2 id=\"总结和引申思考\"><a href=\"#总结和引申思考\" class=\"headerlink\" title=\"总结和引申思考\"></a>总结和引申思考</h2><p>首先，明确一点，<em>deep copy</em>和<em>shallow copy</em>并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。</p>\n<p>根据维基百科中的<a href=\"https://en.wikipedia.org/wiki/Object_copying\">Object copying</a>中的描述，我们总结如下：</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/shallow-copy.png\" alt=\"\"></p>\n<p>我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/deep-copy.png\" alt=\"\"></p>\n<p>我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。</p>\n<p>其他语言，如Java，可以参见StackOverFlow上的这一个讨论：<a href=\"http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java\">How do I copy an object in Java</a>，后面有机会再详细的梳理一下。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy\">What’s the difference between a deep copy and a shallow copy</a><br>2.<a href=\"https://en.wikipedia.org/wiki/Object_copying\">Object copying</a><br>3.<a href=\"http://www.python-course.eu/deep_copy.php\">Shallow and deep copy</a><br>4.<a href=\"https://item.jd.com/19176803.html\">The Quick Python Book, 2nd Edition. Chapter 5.6</a></p>"},{"title":"Python中的装饰器——初识篇","date":"2017-09-20T06:53:15.000Z","_content":"\n## 认识装饰器 \n\n装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<!--more-->（或称为callable，比如一个对象具有__call__方法），并且对被装饰的函数做些处理。举个例子：\n```python\ndef decorated_by(func):\n    func.__doc__ += '\\nDecorated by decorated_by.'\n    return func\n\n\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    add = decorated_by(add)\n    print add.__doc__\n\n# output \nReturn the sum of x and y.\nDecorated by decorated_by.\n\n```\n大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：\n```python\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\n# output\nReturn the sum of x and y.\nDecorated by decorated_by.\n```\n添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。\n\n## 装饰器应用的顺序\n\n当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：\n我们有另外的一个函数叫做also_decorated_by，也是在func.__doc__后面添加一段话，然后对add函数应用该装饰器：\n```python\ndef also_decorated_by(func):\n    func.__doc__ += '\\nAlso decorated by also_decorated_by.'\n    return func\n\n\n@also_decorated_by\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n```\n按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：\n```python\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\nReturn the sum of x and y.\nDecorated by decorated_by.\nAlso decorated by also_decorated_by.\n```\n## 装饰器的应用场景\n\n标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。\n常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。\n\n## 为什么要使用装饰器\n\n 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。\n在Python应用程序和模块中编写装饰器有几个非常好的用例——\n* 附加功能 - 在被装饰的方法前后执行额外的附加功能\n* 数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints\n* 功能注册\n \n## 动手写几个装饰器\n\n纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。\n\n### 功能注册\n\n先上代码打个样：\n\n```python\nclass Registry(object):\n    def __init__(self):\n        self._functions = []\n\n    def register(self, decorated):\n        self._functions.append(decorated)\n        return decorated\n\n    def run_all(self, *args, **kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args, **kwargs))\n        return return_values\n\n\na = Registry()\nb = Registry()\n\n\n@a.register\ndef foo(x=3):\n    return x\n\n\n@b.register\ndef bar(x=5):\n    return x\n\n\n@a.register\n@b.register\ndef baz(x=7):\n    return x\n\na_r = a.run_all() \t# [3, 7]\nb_r = b.run_all() \t# [5, 7]\na_r = a.run_all(x=4) \t# [4, 4]\n\n```\n\n### 运行时封装代码（wrap code）\n\n上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：\n\n#### 类型检查\n\n```python\ndef requires_int(decorated):\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n        for arg in list(args) + kwarg_values:\n            if not isinstance(arg, int):\n                raise TypeError('%s only accepts integers as arguments.' %\n                                decorated.__name__)\n        return decorated(*args, **kwargs)\n\n    return inner\n\n@requires_int\ndef foo(x,y):\n    \"\"\" Return the sum of x and y\"\"\"\n    return x+y\n\nif __name__ == '__main__':\n    print foo(1,y='a')\n\n# output \nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 17, in <module>\n    print foo(1,y='a')\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 7, in inner\n    decorated.__name__)\nTypeError: foo only accepts integers as arguments.\n\n```\n上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。\n\n如果此时我们执行help(foo)会发现，得到的结果是：\n```python\nHelp on function inner in module __main__:\n\ninner(*args, **kwargs)\n    Get any values that may have been sent as keyword arguments.\n```\n很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(*args, **kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。\n\n#### 保留原函数的帮助信息\n\n经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：\n```python\nimport functools\n\ndef requires_int(decorated):\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n...\n\n```\n那么此时查看help(foo)，我们得到的输出结果是：\n```python\nHelp on function foo in module __main__:\n\nfoo(*args, **kwargs)\n    Return the sum of x and y\n```\n> 注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是`foo(x, y)`。\n\n#### 用户校验\n\n```python\nimport functools\n\n\nclass User(object):\n    def __init__(self, username, email):\n        self.username = username\n        self.email = email\n\n\nclass AnonymousUser(User):\n    def __init__(self):\n        self.username = None\n        self.email = None\n\n    def __nonzero__(self):\n        return False\n\n\ndef require_user(func):\n    @functools.wraps(func)\n    def inner(user, *args, **kwargs):\n        if user and isinstance(user, User):\n            return func(user, *args, **kwargs)\n        else:\n            raise ValueError('A valid user is required to run this.')\n    return inner\n\n@require_user\ndef foo(user):\n    if user.username and user.email:\n        print user.username + ',' + user.email\n    else:\n        print 'None'\n\nif __name__ == '__main__':\n    user = User('Tom','tom.smith@tom.com')\n    a_user = AnonymousUser()\n    foo(user)\n    foo(a_user)\n\n# output\nTom,tom.smith@tom.com\nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/user.py\", line 39, in <module>\n    foo(a_user)\n  File \"F:/Test/PyTest/decorators/user.py\", line 25, in inner\n    raise ValueError('A valid user is required to run this.')\nValueError: A valid user is required to run this.\n```\n我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了__nonzero__方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了__nonzero__返回False，所以这里就没有办法通过if检查，从而rasie了异常。\n\n#### 格式化输出\n\n除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。\n\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(decorated):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        try:\n            result = decorated(*args, **kwargs)\n        except JSONOutputError as ex:\n            result = {\n                'status': 'error',\n                'message': str(ex),\n            }\n        return json.dumps(result)\n    return inner\n\n\n@json_output\ndef do_nothing():\n    return {'status': 'done'}\n\n\n@json_output\ndef error():\n    raise JSONOutputError('This function is erratic')\n\n\n@json_output\ndef other_error():\n    raise ValueError('The grass is always greener..')\n\nif __name__ == '__main__':\n    # print do_nothing()\n    print error()\n\n# output\n{\"status\": \"error\", \"message\": \"This function is erratic\"}\n```\n\n#### 打印日志\n\n最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：\n```python\nimport functools\nimport logging\nimport time\n\nlogging.basicConfig(evel=logging.DEBUG)\nLOG = logging.getLogger(__name__)\n\n\ndef logged(method):\n    @functools.wraps(method)\n    def inner(*args, **kwargs):\n        start = time.time()\n        return_value = method(*args, **kwargs)\n        end = time.time()\n        delta = end - start\n        LOG.warn('Called method %s at %.02f; execution time %.02f '\n                 'seconds; result %r.' %\n                 (method.__name__, start, delta, return_value))\n        return return_value\n\n    return inner\n\n\n@logged\ndef sleep_and_return(return_value):\n    time.sleep(2)\n    return return_value\n\n\nif __name__ == '__main__':\n    print sleep_and_return(27)\n\n# output \nWARNING:__main__:Called method sleep_and_return at 1505889774.61; execution time 2.00 seconds; result 27.\n27\n\n```\n\n## 小节结语\n\n本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。\n\n目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。\n","source":"_posts/python-introduction-to-decorators-with-examples.md","raw":"---\ntitle: Python中的装饰器——初识篇\ndate: 2017-09-20 14:53:15\ntags: [Python, decorator]\n---\n\n## 认识装饰器 \n\n装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<!--more-->（或称为callable，比如一个对象具有__call__方法），并且对被装饰的函数做些处理。举个例子：\n```python\ndef decorated_by(func):\n    func.__doc__ += '\\nDecorated by decorated_by.'\n    return func\n\n\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    add = decorated_by(add)\n    print add.__doc__\n\n# output \nReturn the sum of x and y.\nDecorated by decorated_by.\n\n```\n大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：\n```python\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\n# output\nReturn the sum of x and y.\nDecorated by decorated_by.\n```\n添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。\n\n## 装饰器应用的顺序\n\n当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：\n我们有另外的一个函数叫做also_decorated_by，也是在func.__doc__后面添加一段话，然后对add函数应用该装饰器：\n```python\ndef also_decorated_by(func):\n    func.__doc__ += '\\nAlso decorated by also_decorated_by.'\n    return func\n\n\n@also_decorated_by\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n```\n按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：\n```python\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\nReturn the sum of x and y.\nDecorated by decorated_by.\nAlso decorated by also_decorated_by.\n```\n## 装饰器的应用场景\n\n标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。\n常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。\n\n## 为什么要使用装饰器\n\n 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。\n在Python应用程序和模块中编写装饰器有几个非常好的用例——\n* 附加功能 - 在被装饰的方法前后执行额外的附加功能\n* 数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints\n* 功能注册\n \n## 动手写几个装饰器\n\n纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。\n\n### 功能注册\n\n先上代码打个样：\n\n```python\nclass Registry(object):\n    def __init__(self):\n        self._functions = []\n\n    def register(self, decorated):\n        self._functions.append(decorated)\n        return decorated\n\n    def run_all(self, *args, **kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args, **kwargs))\n        return return_values\n\n\na = Registry()\nb = Registry()\n\n\n@a.register\ndef foo(x=3):\n    return x\n\n\n@b.register\ndef bar(x=5):\n    return x\n\n\n@a.register\n@b.register\ndef baz(x=7):\n    return x\n\na_r = a.run_all() \t# [3, 7]\nb_r = b.run_all() \t# [5, 7]\na_r = a.run_all(x=4) \t# [4, 4]\n\n```\n\n### 运行时封装代码（wrap code）\n\n上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：\n\n#### 类型检查\n\n```python\ndef requires_int(decorated):\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n        for arg in list(args) + kwarg_values:\n            if not isinstance(arg, int):\n                raise TypeError('%s only accepts integers as arguments.' %\n                                decorated.__name__)\n        return decorated(*args, **kwargs)\n\n    return inner\n\n@requires_int\ndef foo(x,y):\n    \"\"\" Return the sum of x and y\"\"\"\n    return x+y\n\nif __name__ == '__main__':\n    print foo(1,y='a')\n\n# output \nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 17, in <module>\n    print foo(1,y='a')\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 7, in inner\n    decorated.__name__)\nTypeError: foo only accepts integers as arguments.\n\n```\n上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。\n\n如果此时我们执行help(foo)会发现，得到的结果是：\n```python\nHelp on function inner in module __main__:\n\ninner(*args, **kwargs)\n    Get any values that may have been sent as keyword arguments.\n```\n很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(*args, **kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。\n\n#### 保留原函数的帮助信息\n\n经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：\n```python\nimport functools\n\ndef requires_int(decorated):\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n...\n\n```\n那么此时查看help(foo)，我们得到的输出结果是：\n```python\nHelp on function foo in module __main__:\n\nfoo(*args, **kwargs)\n    Return the sum of x and y\n```\n> 注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是`foo(x, y)`。\n\n#### 用户校验\n\n```python\nimport functools\n\n\nclass User(object):\n    def __init__(self, username, email):\n        self.username = username\n        self.email = email\n\n\nclass AnonymousUser(User):\n    def __init__(self):\n        self.username = None\n        self.email = None\n\n    def __nonzero__(self):\n        return False\n\n\ndef require_user(func):\n    @functools.wraps(func)\n    def inner(user, *args, **kwargs):\n        if user and isinstance(user, User):\n            return func(user, *args, **kwargs)\n        else:\n            raise ValueError('A valid user is required to run this.')\n    return inner\n\n@require_user\ndef foo(user):\n    if user.username and user.email:\n        print user.username + ',' + user.email\n    else:\n        print 'None'\n\nif __name__ == '__main__':\n    user = User('Tom','tom.smith@tom.com')\n    a_user = AnonymousUser()\n    foo(user)\n    foo(a_user)\n\n# output\nTom,tom.smith@tom.com\nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/user.py\", line 39, in <module>\n    foo(a_user)\n  File \"F:/Test/PyTest/decorators/user.py\", line 25, in inner\n    raise ValueError('A valid user is required to run this.')\nValueError: A valid user is required to run this.\n```\n我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了__nonzero__方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了__nonzero__返回False，所以这里就没有办法通过if检查，从而rasie了异常。\n\n#### 格式化输出\n\n除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。\n\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(decorated):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        try:\n            result = decorated(*args, **kwargs)\n        except JSONOutputError as ex:\n            result = {\n                'status': 'error',\n                'message': str(ex),\n            }\n        return json.dumps(result)\n    return inner\n\n\n@json_output\ndef do_nothing():\n    return {'status': 'done'}\n\n\n@json_output\ndef error():\n    raise JSONOutputError('This function is erratic')\n\n\n@json_output\ndef other_error():\n    raise ValueError('The grass is always greener..')\n\nif __name__ == '__main__':\n    # print do_nothing()\n    print error()\n\n# output\n{\"status\": \"error\", \"message\": \"This function is erratic\"}\n```\n\n#### 打印日志\n\n最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：\n```python\nimport functools\nimport logging\nimport time\n\nlogging.basicConfig(evel=logging.DEBUG)\nLOG = logging.getLogger(__name__)\n\n\ndef logged(method):\n    @functools.wraps(method)\n    def inner(*args, **kwargs):\n        start = time.time()\n        return_value = method(*args, **kwargs)\n        end = time.time()\n        delta = end - start\n        LOG.warn('Called method %s at %.02f; execution time %.02f '\n                 'seconds; result %r.' %\n                 (method.__name__, start, delta, return_value))\n        return return_value\n\n    return inner\n\n\n@logged\ndef sleep_and_return(return_value):\n    time.sleep(2)\n    return return_value\n\n\nif __name__ == '__main__':\n    print sleep_and_return(27)\n\n# output \nWARNING:__main__:Called method sleep_and_return at 1505889774.61; execution time 2.00 seconds; result 27.\n27\n\n```\n\n## 小节结语\n\n本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。\n\n目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。\n","slug":"python-introduction-to-decorators-with-examples","published":1,"updated":"2017-09-20T07:27:58.748Z","_id":"cj7spd67f000anshlysxng9r0","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"认识装饰器\"><a href=\"#认识装饰器\" class=\"headerlink\" title=\"认识装饰器\"></a>认识装饰器</h2><p>装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<a id=\"more\"></a>（或称为callable，比如一个对象具有<strong>call</strong>方法），并且对被装饰的函数做些处理。举个例子：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nDecorated by decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    add = decorated_by(add)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。</p>\n<h2 id=\"装饰器应用的顺序\"><a href=\"#装饰器应用的顺序\" class=\"headerlink\" title=\"装饰器应用的顺序\"></a>装饰器应用的顺序</h2><p>当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：<br>我们有另外的一个函数叫做also_decorated_by，也是在func.<strong>doc</strong>后面添加一段话，然后对add函数应用该装饰器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">also_decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nAlso decorated by also_decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@also_decorated_by</span></span><br><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br></pre></td></tr></table></figure></p>\n<p>按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br><span class=\"line\">Also decorated by also_decorated_by.</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"装饰器的应用场景\"><a href=\"#装饰器的应用场景\" class=\"headerlink\" title=\"装饰器的应用场景\"></a>装饰器的应用场景</h2><p>标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。<br>常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。</p>\n<h2 id=\"为什么要使用装饰器\"><a href=\"#为什么要使用装饰器\" class=\"headerlink\" title=\"为什么要使用装饰器\"></a>为什么要使用装饰器</h2><p> 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。<br>在Python应用程序和模块中编写装饰器有几个非常好的用例——</p>\n<ul>\n<li>附加功能 - 在被装饰的方法前后执行额外的附加功能</li>\n<li>数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints</li>\n<li>功能注册</li>\n</ul>\n<h2 id=\"动手写几个装饰器\"><a href=\"#动手写几个装饰器\" class=\"headerlink\" title=\"动手写几个装饰器\"></a>动手写几个装饰器</h2><p>纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。</p>\n<h3 id=\"功能注册\"><a href=\"#功能注册\" class=\"headerlink\" title=\"功能注册\"></a>功能注册</h3><p>先上代码打个样：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Registry</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self._functions = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, decorated)</span>:</span></span><br><span class=\"line\">        self._functions.append(decorated)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_all</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        return_values = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> func <span class=\"keyword\">in</span> self._functions:</span><br><span class=\"line\">            return_values.append(func(*args, **kwargs))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_values</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">a = Registry()</span><br><span class=\"line\">b = Registry()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x=<span class=\"number\">3</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bar</span><span class=\"params\">(x=<span class=\"number\">5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">baz</span><span class=\"params\">(x=<span class=\"number\">7</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">a_r = a.run_all() \t<span class=\"comment\"># [3, 7]</span></span><br><span class=\"line\">b_r = b.run_all() \t<span class=\"comment\"># [5, 7]</span></span><br><span class=\"line\">a_r = a.run_all(x=<span class=\"number\">4</span>) \t<span class=\"comment\"># [4, 4]</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"运行时封装代码（wrap-code）\"><a href=\"#运行时封装代码（wrap-code）\" class=\"headerlink\" title=\"运行时封装代码（wrap code）\"></a>运行时封装代码（wrap code）</h3><p>上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：</p>\n<h4 id=\"类型检查\"><a href=\"#类型检查\" class=\"headerlink\" title=\"类型检查\"></a>类型检查</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span><br><span class=\"line\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> list(args) + kwarg_values:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(arg, int):</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> TypeError(<span class=\"string\">'%s only accepts integers as arguments.'</span> %</span><br><span class=\"line\">                                decorated.__name__)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated(*args, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@requires_int</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" Return the sum of x and y\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x+y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">17</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">7</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    decorated.__name__)</span><br><span class=\"line\">TypeError: foo only accepts integers <span class=\"keyword\">as</span> arguments.</span><br></pre></td></tr></table></figure>\n<p>上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。</p>\n<p>如果此时我们执行help(foo)会发现，得到的结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function inner <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">inner(*args, **kwargs)</span><br><span class=\"line\">    Get any values that may have been sent <span class=\"keyword\">as</span> keyword arguments.</span><br></pre></td></tr></table></figure></p>\n<p>很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(<em>args, *</em>kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。</p>\n<h4 id=\"保留原函数的帮助信息\"><a href=\"#保留原函数的帮助信息\" class=\"headerlink\" title=\"保留原函数的帮助信息\"></a>保留原函数的帮助信息</h4><p>经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span><br><span class=\"line\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那么此时查看help(foo)，我们得到的输出结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function foo <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">foo(*args, **kwargs)</span><br><span class=\"line\">    Return the sum of x <span class=\"keyword\">and</span> y</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是<code>foo(x, y)</code>。</p>\n</blockquote>\n<h4 id=\"用户校验\"><a href=\"#用户校验\" class=\"headerlink\" title=\"用户校验\"></a>用户校验</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">User</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, username, email)</span>:</span></span><br><span class=\"line\">        self.username = username</span><br><span class=\"line\">        self.email = email</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnonymousUser</span><span class=\"params\">(User)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.username = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.email = <span class=\"keyword\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__nonzero__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">require_user</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(func)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(user, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> user <span class=\"keyword\">and</span> isinstance(user, User):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> func(user, *args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@require_user</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(user)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> user.username <span class=\"keyword\">and</span> user.email:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> user.username + <span class=\"string\">','</span> + user.email</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'None'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    user = User(<span class=\"string\">'Tom'</span>,<span class=\"string\">'tom.smith@tom.com'</span>)</span><br><span class=\"line\">    a_user = AnonymousUser()</span><br><span class=\"line\">    foo(user)</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Tom,tom.smith@tom.com</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">39</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">25</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">ValueError: A valid user <span class=\"keyword\">is</span> required to run this.</span><br></pre></td></tr></table></figure>\n<p>我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了<strong>nonzero</strong>方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了<strong>nonzero</strong>返回False，所以这里就没有办法通过if检查，从而rasie了异常。</p>\n<h4 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h4><p>除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span><br><span class=\"line\">    to JSON, and return the JSON string.</span><br><span class=\"line\">    \"\"\"</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            result = decorated(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">            result = &#123;</span><br><span class=\"line\">                <span class=\"string\">'status'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> JSONOutputError(<span class=\"string\">'This function is erratic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">other_error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'The grass is always greener..'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># print do_nothing()</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> error()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"error\"</span>, <span class=\"string\">\"message\"</span>: <span class=\"string\">\"This function is erratic\"</span>&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"打印日志\"><a href=\"#打印日志\" class=\"headerlink\" title=\"打印日志\"></a>打印日志</h4><p>最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> logging</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\">logging.basicConfig(evel=logging.DEBUG)</span><br><span class=\"line\">LOG = logging.getLogger(__name__)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">logged</span><span class=\"params\">(method)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(method)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        start = time.time()</span><br><span class=\"line\">        return_value = method(*args, **kwargs)</span><br><span class=\"line\">        end = time.time()</span><br><span class=\"line\">        delta = end - start</span><br><span class=\"line\">        LOG.warn(<span class=\"string\">'Called method %s at %.02f; execution time %.02f '</span></span><br><span class=\"line\">                 <span class=\"string\">'seconds; result %r.'</span> %</span><br><span class=\"line\">                 (method.__name__, start, delta, return_value))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@logged</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sleep_and_return</span><span class=\"params\">(return_value)</span>:</span></span><br><span class=\"line\">    time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> sleep_and_return(<span class=\"number\">27</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">WARNING:__main__:Called method sleep_and_return at <span class=\"number\">1505889774.61</span>; execution time <span class=\"number\">2.00</span> seconds; result <span class=\"number\">27.</span></span><br><span class=\"line\"><span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h2><p>本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。</p>\n<p>目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。</p>\n","excerpt":"<h2 id=\"认识装饰器\"><a href=\"#认识装饰器\" class=\"headerlink\" title=\"认识装饰器\"></a>认识装饰器</h2><p>装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数","more":"（或称为callable，比如一个对象具有<strong>call</strong>方法），并且对被装饰的函数做些处理。举个例子：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nDecorated by decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    add = decorated_by(add)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。</p>\n<h2 id=\"装饰器应用的顺序\"><a href=\"#装饰器应用的顺序\" class=\"headerlink\" title=\"装饰器应用的顺序\"></a>装饰器应用的顺序</h2><p>当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：<br>我们有另外的一个函数叫做also_decorated_by，也是在func.<strong>doc</strong>后面添加一段话，然后对add函数应用该装饰器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">also_decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nAlso decorated by also_decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@also_decorated_by</span></span><br><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br></pre></td></tr></table></figure></p>\n<p>按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br><span class=\"line\">Also decorated by also_decorated_by.</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"装饰器的应用场景\"><a href=\"#装饰器的应用场景\" class=\"headerlink\" title=\"装饰器的应用场景\"></a>装饰器的应用场景</h2><p>标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。<br>常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。</p>\n<h2 id=\"为什么要使用装饰器\"><a href=\"#为什么要使用装饰器\" class=\"headerlink\" title=\"为什么要使用装饰器\"></a>为什么要使用装饰器</h2><p> 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。<br>在Python应用程序和模块中编写装饰器有几个非常好的用例——</p>\n<ul>\n<li>附加功能 - 在被装饰的方法前后执行额外的附加功能</li>\n<li>数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints</li>\n<li>功能注册</li>\n</ul>\n<h2 id=\"动手写几个装饰器\"><a href=\"#动手写几个装饰器\" class=\"headerlink\" title=\"动手写几个装饰器\"></a>动手写几个装饰器</h2><p>纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。</p>\n<h3 id=\"功能注册\"><a href=\"#功能注册\" class=\"headerlink\" title=\"功能注册\"></a>功能注册</h3><p>先上代码打个样：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Registry</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self._functions = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, decorated)</span>:</span></span><br><span class=\"line\">        self._functions.append(decorated)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_all</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        return_values = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> func <span class=\"keyword\">in</span> self._functions:</span><br><span class=\"line\">            return_values.append(func(*args, **kwargs))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_values</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">a = Registry()</span><br><span class=\"line\">b = Registry()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x=<span class=\"number\">3</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bar</span><span class=\"params\">(x=<span class=\"number\">5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">baz</span><span class=\"params\">(x=<span class=\"number\">7</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">a_r = a.run_all() \t<span class=\"comment\"># [3, 7]</span></span><br><span class=\"line\">b_r = b.run_all() \t<span class=\"comment\"># [5, 7]</span></span><br><span class=\"line\">a_r = a.run_all(x=<span class=\"number\">4</span>) \t<span class=\"comment\"># [4, 4]</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"运行时封装代码（wrap-code）\"><a href=\"#运行时封装代码（wrap-code）\" class=\"headerlink\" title=\"运行时封装代码（wrap code）\"></a>运行时封装代码（wrap code）</h3><p>上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：</p>\n<h4 id=\"类型检查\"><a href=\"#类型检查\" class=\"headerlink\" title=\"类型检查\"></a>类型检查</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span><br><span class=\"line\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> list(args) + kwarg_values:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(arg, int):</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> TypeError(<span class=\"string\">'%s only accepts integers as arguments.'</span> %</span><br><span class=\"line\">                                decorated.__name__)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated(*args, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@requires_int</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" Return the sum of x and y\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x+y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">17</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">7</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    decorated.__name__)</span><br><span class=\"line\">TypeError: foo only accepts integers <span class=\"keyword\">as</span> arguments.</span><br></pre></td></tr></table></figure>\n<p>上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。</p>\n<p>如果此时我们执行help(foo)会发现，得到的结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function inner <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">inner(*args, **kwargs)</span><br><span class=\"line\">    Get any values that may have been sent <span class=\"keyword\">as</span> keyword arguments.</span><br></pre></td></tr></table></figure></p>\n<p>很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(<em>args, *</em>kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。</p>\n<h4 id=\"保留原函数的帮助信息\"><a href=\"#保留原函数的帮助信息\" class=\"headerlink\" title=\"保留原函数的帮助信息\"></a>保留原函数的帮助信息</h4><p>经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span><br><span class=\"line\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那么此时查看help(foo)，我们得到的输出结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function foo <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">foo(*args, **kwargs)</span><br><span class=\"line\">    Return the sum of x <span class=\"keyword\">and</span> y</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是<code>foo(x, y)</code>。</p>\n</blockquote>\n<h4 id=\"用户校验\"><a href=\"#用户校验\" class=\"headerlink\" title=\"用户校验\"></a>用户校验</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">User</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, username, email)</span>:</span></span><br><span class=\"line\">        self.username = username</span><br><span class=\"line\">        self.email = email</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnonymousUser</span><span class=\"params\">(User)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.username = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.email = <span class=\"keyword\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__nonzero__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">require_user</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(func)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(user, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> user <span class=\"keyword\">and</span> isinstance(user, User):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> func(user, *args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@require_user</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(user)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> user.username <span class=\"keyword\">and</span> user.email:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> user.username + <span class=\"string\">','</span> + user.email</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'None'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    user = User(<span class=\"string\">'Tom'</span>,<span class=\"string\">'tom.smith@tom.com'</span>)</span><br><span class=\"line\">    a_user = AnonymousUser()</span><br><span class=\"line\">    foo(user)</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Tom,tom.smith@tom.com</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">39</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">25</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">ValueError: A valid user <span class=\"keyword\">is</span> required to run this.</span><br></pre></td></tr></table></figure>\n<p>我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了<strong>nonzero</strong>方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了<strong>nonzero</strong>返回False，所以这里就没有办法通过if检查，从而rasie了异常。</p>\n<h4 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h4><p>除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span><br><span class=\"line\">    to JSON, and return the JSON string.</span><br><span class=\"line\">    \"\"\"</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            result = decorated(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">            result = &#123;</span><br><span class=\"line\">                <span class=\"string\">'status'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> JSONOutputError(<span class=\"string\">'This function is erratic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">other_error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'The grass is always greener..'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># print do_nothing()</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> error()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"error\"</span>, <span class=\"string\">\"message\"</span>: <span class=\"string\">\"This function is erratic\"</span>&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"打印日志\"><a href=\"#打印日志\" class=\"headerlink\" title=\"打印日志\"></a>打印日志</h4><p>最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> logging</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\">logging.basicConfig(evel=logging.DEBUG)</span><br><span class=\"line\">LOG = logging.getLogger(__name__)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">logged</span><span class=\"params\">(method)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(method)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        start = time.time()</span><br><span class=\"line\">        return_value = method(*args, **kwargs)</span><br><span class=\"line\">        end = time.time()</span><br><span class=\"line\">        delta = end - start</span><br><span class=\"line\">        LOG.warn(<span class=\"string\">'Called method %s at %.02f; execution time %.02f '</span></span><br><span class=\"line\">                 <span class=\"string\">'seconds; result %r.'</span> %</span><br><span class=\"line\">                 (method.__name__, start, delta, return_value))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@logged</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sleep_and_return</span><span class=\"params\">(return_value)</span>:</span></span><br><span class=\"line\">    time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> sleep_and_return(<span class=\"number\">27</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">WARNING:__main__:Called method sleep_and_return at <span class=\"number\">1505889774.61</span>; execution time <span class=\"number\">2.00</span> seconds; result <span class=\"number\">27.</span></span><br><span class=\"line\"><span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h2><p>本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。</p>\n<p>目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。</p>"},{"title":"Got signal:6 (Aborted) 引起的MongoDB崩溃分析解决","date":"2017-06-23T01:51:41.000Z","_content":"## 一、背景\n\n近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——\n<!--more-->\n发现，在日志中，有如下的一段backtrace：\n```\n2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).\n\n 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad\n----- BEGIN BACKTRACE -----\n{\"backtrace\":[{\"b\":\"400000\",\"o\":\"B5E669\"},{\"b\":\"400000\",\"o\":\"B5DCE2\"},{\"b\":\"400000\",\"o\":\"B5E096\"},{\"b\":\"3221000000\",\"o\":\"32660\"},{\"b\":\"3221000000\",\"o\":\"325E5\"},{\"b\":\"3221000000\",\"o\":\"33DC5\"},{\"b\":\"400000\",\"o\":\"9A0C59\"},{\"b\":\"400000\",\"o\":\"4DD622\"},{\"b\":\"400000\",\"o\":\"4DE181\"},{\"b\":\"400000\",\"o\":\"4B31D7\"},{\"b\":\"400000\",\"o\":\"4D1A17\"},{\"b\":\"400000\",\"o\":\"4D34D6\"},{\"b\":\"400000\",\"o\":\"5BDC64\"},{\"b\":\"400000\",\"o\":\"5BEBED\"},{\"b\":\"400000\",\"o\":\"5BF8FB\"},{\"b\":\"400000\",\"o\":\"79340A\"},{\"b\":\"400000\",\"o\":\"6A3480\"},{\"b\":\"400000\",\"o\":\"3E99FD\"},{\"b\":\"400000\",\"o\":\"B1BADB\"},{\"b\":\"3221400000\",\"o\":\"7AA1\"},{\"b\":\"3221000000\",\"o\":\"E8AAD\"}],\"processInfo\":{ \"mongodbVersion\" : \"3.0.6\", \"gitVersion\" : \"1ef45a23a4c5e3480ac919b28afcba3c615488f2\", \"uname\" : { \"sysname\" : \"Linux\", \"release\" : \"2.6.32-642.6.2.el6.x86_64\", \"version\" : \"#1 SMP Wed Oct 26 06:52:09 UTC 2016\", \"machine\" : \"x86_64\" }, \"somap\" : [ { \"elfType\" : 2, \"b\" : \"400000\" }, { \"b\" : \"7FFC4BCCC000\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libpthread.so.0\", \"elfType\" : 3 }, { \"path\" : \"/lib64/librt.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libdl.so.2\", \"elfType\" : 3 }, { \"path\" : \"/usr/lib64/libstdc++.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libm.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libgcc_s.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libc.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/ld-linux-x86-64.so.2\", \"elfType\" : 3 } ] }}\n mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]\n mongod(+0xB5DCE2) [0xf5dce2]\n mongod(+0xB5E096) [0xf5e096]\n libc.so.6(+0x32660) [0x3221032660]\n libc.so.6(gsignal+0x35) [0x32210325e5]\n libc.so.6(abort+0x175) [0x3221033dc5]\n mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]\n mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]\n mongod(+0x4D1A17) [0x8d1a17]\n mongod(+0x4D34D6) [0x8d34d6]\n mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]\n mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]\n mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]\n mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]\n mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]\n mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]\n mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]\n libpthread.so.0(+0x7AA1) [0x3221407aa1]\n libc.so.6(clone+0x6D) [0x32210e8aad]\n-----  END BACKTRACE  -----\n\n```\n\n除了`Got signal: 6 (Aborted)`还有点意义，下面的这些trace，完全不知所云。\n\n## 二、查询分析\n\n找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，[>>传送门](https://jira.mongodb.org/browse/SERVER-28001)，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的`ulimit`中的配置，并给出了配置的文档说明，[>>>传送门](https://docs.mongodb.com/manual/reference/ulimit/)，下面简单的总结一下——\n\n大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即`ulimit`，用于避免单用户使用过多的系统资源，当然，有些时候`ulimit`的一些默认值相对较低，所以会影响一些正常的MongoDB操作。\n\n简单的看一下如何设置资源限制——我们可以使用`ulimit`命令来检查目前的配置，例如：\n```\n[root@mongodb-master ~]# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 63706\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 10240\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 63706\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n在使用`ulimit`修改具体某个配置项的值时，例如修改open file时，语法为`ulimit -n <value>`。修改时还要注意，有`hard`和`soft`两个选项：\n\n|选项|含义|例子|\n|:---|:---|:---|\n|-H|设置硬资源限制，一旦设置不能增加|ulimit -Hs 64，限制硬资源，线程栈大小为64K|\n|-S|设置软资源限制，设置后可以增加，但是不能超过硬资源设置|ulimit -Sn 32，限制软资源，32个文件描述符|\n\nMongoDB官方手册中给出的`mongod`和`mongos`的设置推荐值为：\n* -f (file size): unlimited\n* -t (cpu time): unlimited\n* -v (virtual memory): unlimited \n* -n (open files): 64000\n* -m (memory size): unlimited \n* -u (processes/threads): 64000\n\n所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读[手册](https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits)获得帮助。\n\n>注：修改后需要对应重启`mongod`服务。\n\n## 三、延伸\n\nulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看`ulimit -a`会发现open file的值看起来像“恢复原状”（revert）一样。\n\n那么问题来了，刚才我们的设置是否生效还如何检查呢？\n首先，我们要知道修改后重启的`mongod`服务的PID，然后使用命令：`cat /proc/<PID>/limits`来查看当前进程的`ulimit`配置：\n```\n[root@mongodb-master ~]# ps -ef | grep mongo\nroot      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf\nroot     29337 28455  0 15:17 pts/0    00:00:00 grep mongo\n\n[root@mongodb-master ~]# cat /proc/4802/limits\nLimit                     Soft Limit           Hard Limit           Units     \nMax cpu time              unlimited            unlimited            seconds   \nMax file size             unlimited            unlimited            bytes     \nMax data size             unlimited            unlimited            bytes     \nMax stack size            10485760             unlimited            bytes     \nMax core file size        0                    unlimited            bytes     \nMax resident set          unlimited            unlimited            bytes     \nMax processes             63706                63706                processes \nMax open files            64000                64000                files     \nMax locked memory         65536                65536                bytes     \nMax address space         unlimited            unlimited            bytes     \nMax file locks            unlimited            unlimited            locks     \nMax pending signals       63706                63706                signals   \nMax msgqueue size         819200               819200               bytes     \nMax nice priority         0                    0                    \nMax realtime priority     0                    0                    \nMax realtime timeout      unlimited            unlimited            us        \n\n```\n可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。\n\n那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的`/etc/security/limits.conf`配置文件，格式如下：\n```\n<domain>      <type>  <item>         <value>\n```\n其中，`<domain>`表示用户或者组的名字，还可以使用`*`作为通配符，不过**通配符对`root`用户可是不生效的**，切记。\n\n不过我尝试各种软硬修改配置文件后，并没有发现`ulimit -a`有丝毫的变化，真的是扎铁了，老心，也许因为我用的是`root`用户？欢迎邮件交流：[zh.f@outlook.com](mailto:zh.f@outlook.com)\n\n## 四、参考\n\n[[1].Mongodb Crashed with the Got signal: 6 (Aborted)](https://jira.mongodb.org/browse/SERVER-28001)\n[[2].Unix ulimit Settings](https://docs.mongodb.com/manual/reference/ulimit/)\n[[3].How do I change the number of open files limit in Linux?](https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)\n[[4].Linux ulimit命令](http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html)\n[[5].ulimit -n not changing - values limits.conf has no effect](https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect)\n\n\n\n","source":"_posts/mongodb-crashed-with-the-Got-signal-6-Aborted.md","raw":"---\ntitle: Got signal:6 (Aborted) 引起的MongoDB崩溃分析解决\ndate: 2017-06-23 09:51:41\ntags: [MongoDB]\n---\n## 一、背景\n\n近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——\n<!--more-->\n发现，在日志中，有如下的一段backtrace：\n```\n2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).\n\n 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad\n----- BEGIN BACKTRACE -----\n{\"backtrace\":[{\"b\":\"400000\",\"o\":\"B5E669\"},{\"b\":\"400000\",\"o\":\"B5DCE2\"},{\"b\":\"400000\",\"o\":\"B5E096\"},{\"b\":\"3221000000\",\"o\":\"32660\"},{\"b\":\"3221000000\",\"o\":\"325E5\"},{\"b\":\"3221000000\",\"o\":\"33DC5\"},{\"b\":\"400000\",\"o\":\"9A0C59\"},{\"b\":\"400000\",\"o\":\"4DD622\"},{\"b\":\"400000\",\"o\":\"4DE181\"},{\"b\":\"400000\",\"o\":\"4B31D7\"},{\"b\":\"400000\",\"o\":\"4D1A17\"},{\"b\":\"400000\",\"o\":\"4D34D6\"},{\"b\":\"400000\",\"o\":\"5BDC64\"},{\"b\":\"400000\",\"o\":\"5BEBED\"},{\"b\":\"400000\",\"o\":\"5BF8FB\"},{\"b\":\"400000\",\"o\":\"79340A\"},{\"b\":\"400000\",\"o\":\"6A3480\"},{\"b\":\"400000\",\"o\":\"3E99FD\"},{\"b\":\"400000\",\"o\":\"B1BADB\"},{\"b\":\"3221400000\",\"o\":\"7AA1\"},{\"b\":\"3221000000\",\"o\":\"E8AAD\"}],\"processInfo\":{ \"mongodbVersion\" : \"3.0.6\", \"gitVersion\" : \"1ef45a23a4c5e3480ac919b28afcba3c615488f2\", \"uname\" : { \"sysname\" : \"Linux\", \"release\" : \"2.6.32-642.6.2.el6.x86_64\", \"version\" : \"#1 SMP Wed Oct 26 06:52:09 UTC 2016\", \"machine\" : \"x86_64\" }, \"somap\" : [ { \"elfType\" : 2, \"b\" : \"400000\" }, { \"b\" : \"7FFC4BCCC000\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libpthread.so.0\", \"elfType\" : 3 }, { \"path\" : \"/lib64/librt.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libdl.so.2\", \"elfType\" : 3 }, { \"path\" : \"/usr/lib64/libstdc++.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libm.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libgcc_s.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libc.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/ld-linux-x86-64.so.2\", \"elfType\" : 3 } ] }}\n mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]\n mongod(+0xB5DCE2) [0xf5dce2]\n mongod(+0xB5E096) [0xf5e096]\n libc.so.6(+0x32660) [0x3221032660]\n libc.so.6(gsignal+0x35) [0x32210325e5]\n libc.so.6(abort+0x175) [0x3221033dc5]\n mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]\n mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]\n mongod(+0x4D1A17) [0x8d1a17]\n mongod(+0x4D34D6) [0x8d34d6]\n mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]\n mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]\n mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]\n mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]\n mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]\n mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]\n mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]\n libpthread.so.0(+0x7AA1) [0x3221407aa1]\n libc.so.6(clone+0x6D) [0x32210e8aad]\n-----  END BACKTRACE  -----\n\n```\n\n除了`Got signal: 6 (Aborted)`还有点意义，下面的这些trace，完全不知所云。\n\n## 二、查询分析\n\n找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，[>>传送门](https://jira.mongodb.org/browse/SERVER-28001)，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的`ulimit`中的配置，并给出了配置的文档说明，[>>>传送门](https://docs.mongodb.com/manual/reference/ulimit/)，下面简单的总结一下——\n\n大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即`ulimit`，用于避免单用户使用过多的系统资源，当然，有些时候`ulimit`的一些默认值相对较低，所以会影响一些正常的MongoDB操作。\n\n简单的看一下如何设置资源限制——我们可以使用`ulimit`命令来检查目前的配置，例如：\n```\n[root@mongodb-master ~]# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 63706\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 10240\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 63706\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n在使用`ulimit`修改具体某个配置项的值时，例如修改open file时，语法为`ulimit -n <value>`。修改时还要注意，有`hard`和`soft`两个选项：\n\n|选项|含义|例子|\n|:---|:---|:---|\n|-H|设置硬资源限制，一旦设置不能增加|ulimit -Hs 64，限制硬资源，线程栈大小为64K|\n|-S|设置软资源限制，设置后可以增加，但是不能超过硬资源设置|ulimit -Sn 32，限制软资源，32个文件描述符|\n\nMongoDB官方手册中给出的`mongod`和`mongos`的设置推荐值为：\n* -f (file size): unlimited\n* -t (cpu time): unlimited\n* -v (virtual memory): unlimited \n* -n (open files): 64000\n* -m (memory size): unlimited \n* -u (processes/threads): 64000\n\n所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读[手册](https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits)获得帮助。\n\n>注：修改后需要对应重启`mongod`服务。\n\n## 三、延伸\n\nulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看`ulimit -a`会发现open file的值看起来像“恢复原状”（revert）一样。\n\n那么问题来了，刚才我们的设置是否生效还如何检查呢？\n首先，我们要知道修改后重启的`mongod`服务的PID，然后使用命令：`cat /proc/<PID>/limits`来查看当前进程的`ulimit`配置：\n```\n[root@mongodb-master ~]# ps -ef | grep mongo\nroot      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf\nroot     29337 28455  0 15:17 pts/0    00:00:00 grep mongo\n\n[root@mongodb-master ~]# cat /proc/4802/limits\nLimit                     Soft Limit           Hard Limit           Units     \nMax cpu time              unlimited            unlimited            seconds   \nMax file size             unlimited            unlimited            bytes     \nMax data size             unlimited            unlimited            bytes     \nMax stack size            10485760             unlimited            bytes     \nMax core file size        0                    unlimited            bytes     \nMax resident set          unlimited            unlimited            bytes     \nMax processes             63706                63706                processes \nMax open files            64000                64000                files     \nMax locked memory         65536                65536                bytes     \nMax address space         unlimited            unlimited            bytes     \nMax file locks            unlimited            unlimited            locks     \nMax pending signals       63706                63706                signals   \nMax msgqueue size         819200               819200               bytes     \nMax nice priority         0                    0                    \nMax realtime priority     0                    0                    \nMax realtime timeout      unlimited            unlimited            us        \n\n```\n可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。\n\n那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的`/etc/security/limits.conf`配置文件，格式如下：\n```\n<domain>      <type>  <item>         <value>\n```\n其中，`<domain>`表示用户或者组的名字，还可以使用`*`作为通配符，不过**通配符对`root`用户可是不生效的**，切记。\n\n不过我尝试各种软硬修改配置文件后，并没有发现`ulimit -a`有丝毫的变化，真的是扎铁了，老心，也许因为我用的是`root`用户？欢迎邮件交流：[zh.f@outlook.com](mailto:zh.f@outlook.com)\n\n## 四、参考\n\n[[1].Mongodb Crashed with the Got signal: 6 (Aborted)](https://jira.mongodb.org/browse/SERVER-28001)\n[[2].Unix ulimit Settings](https://docs.mongodb.com/manual/reference/ulimit/)\n[[3].How do I change the number of open files limit in Linux?](https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)\n[[4].Linux ulimit命令](http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html)\n[[5].ulimit -n not changing - values limits.conf has no effect](https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect)\n\n\n\n","slug":"mongodb-crashed-with-the-Got-signal-6-Aborted","published":1,"updated":"2017-06-30T08:39:21.427Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67h000dnshla7uy65p2","content":"<h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——<br><a id=\"more\"></a><br>发现，在日志中，有如下的一段backtrace：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).</span><br><span class=\"line\"></span><br><span class=\"line\"> 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad</span><br><span class=\"line\">----- BEGIN BACKTRACE -----</span><br><span class=\"line\">&#123;&quot;backtrace&quot;:[&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E669&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5DCE2&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E096&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;32660&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;325E5&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;33DC5&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;9A0C59&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DD622&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DE181&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4B31D7&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D1A17&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D34D6&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BDC64&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BEBED&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BF8FB&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;79340A&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;6A3480&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;3E99FD&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B1BADB&quot;&#125;,&#123;&quot;b&quot;:&quot;3221400000&quot;,&quot;o&quot;:&quot;7AA1&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;E8AAD&quot;&#125;],&quot;processInfo&quot;:&#123; &quot;mongodbVersion&quot; : &quot;3.0.6&quot;, &quot;gitVersion&quot; : &quot;1ef45a23a4c5e3480ac919b28afcba3c615488f2&quot;, &quot;uname&quot; : &#123; &quot;sysname&quot; : &quot;Linux&quot;, &quot;release&quot; : &quot;2.6.32-642.6.2.el6.x86_64&quot;, &quot;version&quot; : &quot;#1 SMP Wed Oct 26 06:52:09 UTC 2016&quot;, &quot;machine&quot; : &quot;x86_64&quot; &#125;, &quot;somap&quot; : [ &#123; &quot;elfType&quot; : 2, &quot;b&quot; : &quot;400000&quot; &#125;, &#123; &quot;b&quot; : &quot;7FFC4BCCC000&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libpthread.so.0&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/librt.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libdl.so.2&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/usr/lib64/libstdc++.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libm.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libgcc_s.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libc.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/ld-linux-x86-64.so.2&quot;, &quot;elfType&quot; : 3 &#125; ] &#125;&#125;</span><br><span class=\"line\"> mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]</span><br><span class=\"line\"> mongod(+0xB5DCE2) [0xf5dce2]</span><br><span class=\"line\"> mongod(+0xB5E096) [0xf5e096]</span><br><span class=\"line\"> libc.so.6(+0x32660) [0x3221032660]</span><br><span class=\"line\"> libc.so.6(gsignal+0x35) [0x32210325e5]</span><br><span class=\"line\"> libc.so.6(abort+0x175) [0x3221033dc5]</span><br><span class=\"line\"> mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]</span><br><span class=\"line\"> mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]</span><br><span class=\"line\"> mongod(+0x4D1A17) [0x8d1a17]</span><br><span class=\"line\"> mongod(+0x4D34D6) [0x8d34d6]</span><br><span class=\"line\"> mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]</span><br><span class=\"line\"> mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]</span><br><span class=\"line\"> mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]</span><br><span class=\"line\"> mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]</span><br><span class=\"line\"> mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]</span><br><span class=\"line\"> mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]</span><br><span class=\"line\"> mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]</span><br><span class=\"line\"> libpthread.so.0(+0x7AA1) [0x3221407aa1]</span><br><span class=\"line\"> libc.so.6(clone+0x6D) [0x32210e8aad]</span><br><span class=\"line\">-----  END BACKTRACE  -----</span><br></pre></td></tr></table></figure></p>\n<p>除了<code>Got signal: 6 (Aborted)</code>还有点意义，下面的这些trace，完全不知所云。</p>\n<h2 id=\"二、查询分析\"><a href=\"#二、查询分析\" class=\"headerlink\" title=\"二、查询分析\"></a>二、查询分析</h2><p>找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，<a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"external\">&gt;&gt;传送门</a>，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的<code>ulimit</code>中的配置，并给出了配置的文档说明，<a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"external\">&gt;&gt;&gt;传送门</a>，下面简单的总结一下——</p>\n<p>大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即<code>ulimit</code>，用于避免单用户使用过多的系统资源，当然，有些时候<code>ulimit</code>的一些默认值相对较低，所以会影响一些正常的MongoDB操作。</p>\n<p>简单的看一下如何设置资源限制——我们可以使用<code>ulimit</code>命令来检查目前的配置，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ulimit -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 63706</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64</span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited</span><br><span class=\"line\">open files                      (-n) 1024</span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 10240</span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 63706</span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure></p>\n<p>在使用<code>ulimit</code>修改具体某个配置项的值时，例如修改open file时，语法为<code>ulimit -n &lt;value&gt;</code>。修改时还要注意，有<code>hard</code>和<code>soft</code>两个选项：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-H</td>\n<td style=\"text-align:left\">设置硬资源限制，一旦设置不能增加</td>\n<td style=\"text-align:left\">ulimit -Hs 64，限制硬资源，线程栈大小为64K</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-S</td>\n<td style=\"text-align:left\">设置软资源限制，设置后可以增加，但是不能超过硬资源设置</td>\n<td style=\"text-align:left\">ulimit -Sn 32，限制软资源，32个文件描述符</td>\n</tr>\n</tbody>\n</table>\n<p>MongoDB官方手册中给出的<code>mongod</code>和<code>mongos</code>的设置推荐值为：</p>\n<ul>\n<li>-f (file size): unlimited</li>\n<li>-t (cpu time): unlimited</li>\n<li>-v (virtual memory): unlimited </li>\n<li>-n (open files): 64000</li>\n<li>-m (memory size): unlimited </li>\n<li>-u (processes/threads): 64000</li>\n</ul>\n<p>所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读<a href=\"https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits\" target=\"_blank\" rel=\"external\">手册</a>获得帮助。</p>\n<blockquote>\n<p>注：修改后需要对应重启<code>mongod</code>服务。</p>\n</blockquote>\n<h2 id=\"三、延伸\"><a href=\"#三、延伸\" class=\"headerlink\" title=\"三、延伸\"></a>三、延伸</h2><p>ulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看<code>ulimit -a</code>会发现open file的值看起来像“恢复原状”（revert）一样。</p>\n<p>那么问题来了，刚才我们的设置是否生效还如何检查呢？<br>首先，我们要知道修改后重启的<code>mongod</code>服务的PID，然后使用命令：<code>cat /proc/&lt;PID&gt;/limits</code>来查看当前进程的<code>ulimit</code>配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ps -ef | grep mongo</span><br><span class=\"line\">root      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf</span><br><span class=\"line\">root     29337 28455  0 15:17 pts/0    00:00:00 grep mongo</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mongodb-master ~]# cat /proc/4802/limits</span><br><span class=\"line\">Limit                     Soft Limit           Hard Limit           Units     </span><br><span class=\"line\">Max cpu time              unlimited            unlimited            seconds   </span><br><span class=\"line\">Max file size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max data size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max stack size            10485760             unlimited            bytes     </span><br><span class=\"line\">Max core file size        0                    unlimited            bytes     </span><br><span class=\"line\">Max resident set          unlimited            unlimited            bytes     </span><br><span class=\"line\">Max processes             63706                63706                processes </span><br><span class=\"line\">Max open files            64000                64000                files     </span><br><span class=\"line\">Max locked memory         65536                65536                bytes     </span><br><span class=\"line\">Max address space         unlimited            unlimited            bytes     </span><br><span class=\"line\">Max file locks            unlimited            unlimited            locks     </span><br><span class=\"line\">Max pending signals       63706                63706                signals   </span><br><span class=\"line\">Max msgqueue size         819200               819200               bytes     </span><br><span class=\"line\">Max nice priority         0                    0                    </span><br><span class=\"line\">Max realtime priority     0                    0                    </span><br><span class=\"line\">Max realtime timeout      unlimited            unlimited            us</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。</p>\n<p>那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的<code>/etc/security/limits.conf</code>配置文件，格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其中，<code>&lt;domain&gt;</code>表示用户或者组的名字，还可以使用<code>*</code>作为通配符，不过<strong>通配符对<code>root</code>用户可是不生效的</strong>，切记。</p>\n<p>不过我尝试各种软硬修改配置文件后，并没有发现<code>ulimit -a</code>有丝毫的变化，真的是扎铁了，老心，也许因为我用的是<code>root</code>用户？欢迎邮件交流：<a href=\"mailto:zh.f@outlook.com\" target=\"_blank\" rel=\"external\">zh.f@outlook.com</a></p>\n<h2 id=\"四、参考\"><a href=\"#四、参考\" class=\"headerlink\" title=\"四、参考\"></a>四、参考</h2><p><a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"external\">[1].Mongodb Crashed with the Got signal: 6 (Aborted)</a><br><a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"external\">[2].Unix ulimit Settings</a><br><a href=\"https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux\" target=\"_blank\" rel=\"external\">[3].How do I change the number of open files limit in Linux?</a><br><a href=\"http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html\" target=\"_blank\" rel=\"external\">[4].Linux ulimit命令</a><br><a href=\"https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect\" target=\"_blank\" rel=\"external\">[5].ulimit -n not changing - values limits.conf has no effect</a></p>\n","excerpt":"<h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——<br>","more":"<br>发现，在日志中，有如下的一段backtrace：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).</span><br><span class=\"line\"></span><br><span class=\"line\"> 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad</span><br><span class=\"line\">----- BEGIN BACKTRACE -----</span><br><span class=\"line\">&#123;&quot;backtrace&quot;:[&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E669&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5DCE2&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E096&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;32660&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;325E5&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;33DC5&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;9A0C59&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DD622&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DE181&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4B31D7&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D1A17&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D34D6&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BDC64&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BEBED&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BF8FB&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;79340A&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;6A3480&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;3E99FD&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B1BADB&quot;&#125;,&#123;&quot;b&quot;:&quot;3221400000&quot;,&quot;o&quot;:&quot;7AA1&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;E8AAD&quot;&#125;],&quot;processInfo&quot;:&#123; &quot;mongodbVersion&quot; : &quot;3.0.6&quot;, &quot;gitVersion&quot; : &quot;1ef45a23a4c5e3480ac919b28afcba3c615488f2&quot;, &quot;uname&quot; : &#123; &quot;sysname&quot; : &quot;Linux&quot;, &quot;release&quot; : &quot;2.6.32-642.6.2.el6.x86_64&quot;, &quot;version&quot; : &quot;#1 SMP Wed Oct 26 06:52:09 UTC 2016&quot;, &quot;machine&quot; : &quot;x86_64&quot; &#125;, &quot;somap&quot; : [ &#123; &quot;elfType&quot; : 2, &quot;b&quot; : &quot;400000&quot; &#125;, &#123; &quot;b&quot; : &quot;7FFC4BCCC000&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libpthread.so.0&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/librt.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libdl.so.2&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/usr/lib64/libstdc++.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libm.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libgcc_s.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libc.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/ld-linux-x86-64.so.2&quot;, &quot;elfType&quot; : 3 &#125; ] &#125;&#125;</span><br><span class=\"line\"> mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]</span><br><span class=\"line\"> mongod(+0xB5DCE2) [0xf5dce2]</span><br><span class=\"line\"> mongod(+0xB5E096) [0xf5e096]</span><br><span class=\"line\"> libc.so.6(+0x32660) [0x3221032660]</span><br><span class=\"line\"> libc.so.6(gsignal+0x35) [0x32210325e5]</span><br><span class=\"line\"> libc.so.6(abort+0x175) [0x3221033dc5]</span><br><span class=\"line\"> mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]</span><br><span class=\"line\"> mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]</span><br><span class=\"line\"> mongod(+0x4D1A17) [0x8d1a17]</span><br><span class=\"line\"> mongod(+0x4D34D6) [0x8d34d6]</span><br><span class=\"line\"> mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]</span><br><span class=\"line\"> mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]</span><br><span class=\"line\"> mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]</span><br><span class=\"line\"> mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]</span><br><span class=\"line\"> mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]</span><br><span class=\"line\"> mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]</span><br><span class=\"line\"> mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]</span><br><span class=\"line\"> libpthread.so.0(+0x7AA1) [0x3221407aa1]</span><br><span class=\"line\"> libc.so.6(clone+0x6D) [0x32210e8aad]</span><br><span class=\"line\">-----  END BACKTRACE  -----</span><br></pre></td></tr></table></figure></p>\n<p>除了<code>Got signal: 6 (Aborted)</code>还有点意义，下面的这些trace，完全不知所云。</p>\n<h2 id=\"二、查询分析\"><a href=\"#二、查询分析\" class=\"headerlink\" title=\"二、查询分析\"></a>二、查询分析</h2><p>找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，<a href=\"https://jira.mongodb.org/browse/SERVER-28001\">&gt;&gt;传送门</a>，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的<code>ulimit</code>中的配置，并给出了配置的文档说明，<a href=\"https://docs.mongodb.com/manual/reference/ulimit/\">&gt;&gt;&gt;传送门</a>，下面简单的总结一下——</p>\n<p>大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即<code>ulimit</code>，用于避免单用户使用过多的系统资源，当然，有些时候<code>ulimit</code>的一些默认值相对较低，所以会影响一些正常的MongoDB操作。</p>\n<p>简单的看一下如何设置资源限制——我们可以使用<code>ulimit</code>命令来检查目前的配置，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ulimit -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 63706</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64</span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited</span><br><span class=\"line\">open files                      (-n) 1024</span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 10240</span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 63706</span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure></p>\n<p>在使用<code>ulimit</code>修改具体某个配置项的值时，例如修改open file时，语法为<code>ulimit -n &lt;value&gt;</code>。修改时还要注意，有<code>hard</code>和<code>soft</code>两个选项：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-H</td>\n<td style=\"text-align:left\">设置硬资源限制，一旦设置不能增加</td>\n<td style=\"text-align:left\">ulimit -Hs 64，限制硬资源，线程栈大小为64K</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-S</td>\n<td style=\"text-align:left\">设置软资源限制，设置后可以增加，但是不能超过硬资源设置</td>\n<td style=\"text-align:left\">ulimit -Sn 32，限制软资源，32个文件描述符</td>\n</tr>\n</tbody>\n</table>\n<p>MongoDB官方手册中给出的<code>mongod</code>和<code>mongos</code>的设置推荐值为：</p>\n<ul>\n<li>-f (file size): unlimited</li>\n<li>-t (cpu time): unlimited</li>\n<li>-v (virtual memory): unlimited </li>\n<li>-n (open files): 64000</li>\n<li>-m (memory size): unlimited </li>\n<li>-u (processes/threads): 64000</li>\n</ul>\n<p>所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读<a href=\"https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits\">手册</a>获得帮助。</p>\n<blockquote>\n<p>注：修改后需要对应重启<code>mongod</code>服务。</p>\n</blockquote>\n<h2 id=\"三、延伸\"><a href=\"#三、延伸\" class=\"headerlink\" title=\"三、延伸\"></a>三、延伸</h2><p>ulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看<code>ulimit -a</code>会发现open file的值看起来像“恢复原状”（revert）一样。</p>\n<p>那么问题来了，刚才我们的设置是否生效还如何检查呢？<br>首先，我们要知道修改后重启的<code>mongod</code>服务的PID，然后使用命令：<code>cat /proc/&lt;PID&gt;/limits</code>来查看当前进程的<code>ulimit</code>配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ps -ef | grep mongo</span><br><span class=\"line\">root      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf</span><br><span class=\"line\">root     29337 28455  0 15:17 pts/0    00:00:00 grep mongo</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mongodb-master ~]# cat /proc/4802/limits</span><br><span class=\"line\">Limit                     Soft Limit           Hard Limit           Units     </span><br><span class=\"line\">Max cpu time              unlimited            unlimited            seconds   </span><br><span class=\"line\">Max file size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max data size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max stack size            10485760             unlimited            bytes     </span><br><span class=\"line\">Max core file size        0                    unlimited            bytes     </span><br><span class=\"line\">Max resident set          unlimited            unlimited            bytes     </span><br><span class=\"line\">Max processes             63706                63706                processes </span><br><span class=\"line\">Max open files            64000                64000                files     </span><br><span class=\"line\">Max locked memory         65536                65536                bytes     </span><br><span class=\"line\">Max address space         unlimited            unlimited            bytes     </span><br><span class=\"line\">Max file locks            unlimited            unlimited            locks     </span><br><span class=\"line\">Max pending signals       63706                63706                signals   </span><br><span class=\"line\">Max msgqueue size         819200               819200               bytes     </span><br><span class=\"line\">Max nice priority         0                    0                    </span><br><span class=\"line\">Max realtime priority     0                    0                    </span><br><span class=\"line\">Max realtime timeout      unlimited            unlimited            us</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。</p>\n<p>那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的<code>/etc/security/limits.conf</code>配置文件，格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其中，<code>&lt;domain&gt;</code>表示用户或者组的名字，还可以使用<code>*</code>作为通配符，不过<strong>通配符对<code>root</code>用户可是不生效的</strong>，切记。</p>\n<p>不过我尝试各种软硬修改配置文件后，并没有发现<code>ulimit -a</code>有丝毫的变化，真的是扎铁了，老心，也许因为我用的是<code>root</code>用户？欢迎邮件交流：<a href=\"mailto:zh.f@outlook.com\">zh.f@outlook.com</a></p>\n<h2 id=\"四、参考\"><a href=\"#四、参考\" class=\"headerlink\" title=\"四、参考\"></a>四、参考</h2><p><a href=\"https://jira.mongodb.org/browse/SERVER-28001\">[1].Mongodb Crashed with the Got signal: 6 (Aborted)</a><br><a href=\"https://docs.mongodb.com/manual/reference/ulimit/\">[2].Unix ulimit Settings</a><br><a href=\"https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux\">[3].How do I change the number of open files limit in Linux?</a><br><a href=\"http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html\">[4].Linux ulimit命令</a><br><a href=\"https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect\">[5].ulimit -n not changing - values limits.conf has no effect</a></p>"},{"title":"由一次服务连接MongoDB超时引发的思考","date":"2017-06-28T09:12:28.000Z","_content":"\n## 起因\n\n今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：\n<!-- more -->\n```\nCaused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed\n\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 63 common frames omitted\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]\n\t... 72 common frames omitted\n.....\n.....\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n{serverSelectors=[ReadPreferenceServerSelector{readPreference=primary}, LatencyMinimizingServerSelector{acceptableLatencyDifference=15 ms}]}. \nClient view of cluster state is {type=ReplicaSet, servers=[{address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected}, \n{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}, \n{address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected}]\n\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 49 common frames omitted\n```\n可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：\n```\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n...Client view of cluster state is...{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}...]\n```\n\n## 分析\n\n首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。\n\n这里需要将connectTimeout适当调整即可。\n\n## 探究\n\n在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的`connection timeout`和`socket timeout`两个参数。\n\n### Connection timeout\n\n这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会`hang`住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。\n\n这个参数的默认值，在Java的dirver中，`com.mongodb.MongoClientOptions.Builder#connectTimeout`的默认值是`1000*10`ms，即10s。\n\n那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。\n\n### Socket timeout\n\n这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。\n\n如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。\n\n在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，`com.mongodb.MongoClientOptions.Builder#socketTimeout`值是`0`,用于表示不限制。\n\n## 参考\n\n[[1].Do you want a timeout?](https://blog.mlab.com/2013/10/do-you-want-a-timeout/)\n[[2].mongodb connection timed out error](https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error)\n[[3].Class MongoClientOptions](https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html)\n\n\n","source":"_posts/mongodb-connecttimeout-and-sockettimeout.md","raw":"---\ntitle: 由一次服务连接MongoDB超时引发的思考\ndate: 2017-06-28 17:12:28\ntags: [MongoDB]\n---\n\n## 起因\n\n今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：\n<!-- more -->\n```\nCaused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed\n\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 63 common frames omitted\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]\n\t... 72 common frames omitted\n.....\n.....\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n{serverSelectors=[ReadPreferenceServerSelector{readPreference=primary}, LatencyMinimizingServerSelector{acceptableLatencyDifference=15 ms}]}. \nClient view of cluster state is {type=ReplicaSet, servers=[{address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected}, \n{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}, \n{address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected}]\n\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 49 common frames omitted\n```\n可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：\n```\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n...Client view of cluster state is...{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}...]\n```\n\n## 分析\n\n首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。\n\n这里需要将connectTimeout适当调整即可。\n\n## 探究\n\n在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的`connection timeout`和`socket timeout`两个参数。\n\n### Connection timeout\n\n这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会`hang`住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。\n\n这个参数的默认值，在Java的dirver中，`com.mongodb.MongoClientOptions.Builder#connectTimeout`的默认值是`1000*10`ms，即10s。\n\n那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。\n\n### Socket timeout\n\n这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。\n\n如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。\n\n在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，`com.mongodb.MongoClientOptions.Builder#socketTimeout`值是`0`,用于表示不限制。\n\n## 参考\n\n[[1].Do you want a timeout?](https://blog.mlab.com/2013/10/do-you-want-a-timeout/)\n[[2].mongodb connection timed out error](https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error)\n[[3].Class MongoClientOptions](https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html)\n\n\n","slug":"mongodb-connecttimeout-and-sockettimeout","published":1,"updated":"2017-06-30T08:39:21.426Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67i000enshlndqa7k4u","content":"<h2 id=\"起因\"><a href=\"#起因\" class=\"headerlink\" title=\"起因\"></a>起因</h2><p>今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：<br><a id=\"more\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed</span><br><span class=\"line\">\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 63 common frames omitted</span><br><span class=\"line\">Caused by: java.net.SocketException: Connection reset</span><br><span class=\"line\">\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]</span><br><span class=\"line\">\t... 72 common frames omitted</span><br><span class=\"line\">.....</span><br><span class=\"line\">.....</span><br><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">&#123;serverSelectors=[ReadPreferenceServerSelector&#123;readPreference=primary&#125;, LatencyMinimizingServerSelector&#123;acceptableLatencyDifference=15 ms&#125;]&#125;. </span><br><span class=\"line\">Client view of cluster state is &#123;type=ReplicaSet, servers=[&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected&#125;]</span><br><span class=\"line\">\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 49 common frames omitted</span><br></pre></td></tr></table></figure></p>\n<p>可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">...Client view of cluster state is...&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;...]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。</p>\n<p>这里需要将connectTimeout适当调整即可。</p>\n<h2 id=\"探究\"><a href=\"#探究\" class=\"headerlink\" title=\"探究\"></a>探究</h2><p>在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的<code>connection timeout</code>和<code>socket timeout</code>两个参数。</p>\n<h3 id=\"Connection-timeout\"><a href=\"#Connection-timeout\" class=\"headerlink\" title=\"Connection timeout\"></a>Connection timeout</h3><p>这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会<code>hang</code>住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。</p>\n<p>这个参数的默认值，在Java的dirver中，<code>com.mongodb.MongoClientOptions.Builder#connectTimeout</code>的默认值是<code>1000*10</code>ms，即10s。</p>\n<p>那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。</p>\n<h3 id=\"Socket-timeout\"><a href=\"#Socket-timeout\" class=\"headerlink\" title=\"Socket timeout\"></a>Socket timeout</h3><p>这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。</p>\n<p>如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。</p>\n<p>在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，<code>com.mongodb.MongoClientOptions.Builder#socketTimeout</code>值是<code>0</code>,用于表示不限制。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://blog.mlab.com/2013/10/do-you-want-a-timeout/\" target=\"_blank\" rel=\"external\">[1].Do you want a timeout?</a><br><a href=\"https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error\" target=\"_blank\" rel=\"external\">[2].mongodb connection timed out error</a><br><a href=\"https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html\" target=\"_blank\" rel=\"external\">[3].Class MongoClientOptions</a></p>\n","excerpt":"<h2 id=\"起因\"><a href=\"#起因\" class=\"headerlink\" title=\"起因\"></a>起因</h2><p>今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：<br>","more":"<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed</span><br><span class=\"line\">\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 63 common frames omitted</span><br><span class=\"line\">Caused by: java.net.SocketException: Connection reset</span><br><span class=\"line\">\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]</span><br><span class=\"line\">\t... 72 common frames omitted</span><br><span class=\"line\">.....</span><br><span class=\"line\">.....</span><br><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">&#123;serverSelectors=[ReadPreferenceServerSelector&#123;readPreference=primary&#125;, LatencyMinimizingServerSelector&#123;acceptableLatencyDifference=15 ms&#125;]&#125;. </span><br><span class=\"line\">Client view of cluster state is &#123;type=ReplicaSet, servers=[&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected&#125;]</span><br><span class=\"line\">\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 49 common frames omitted</span><br></pre></td></tr></table></figure></p>\n<p>可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">...Client view of cluster state is...&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;...]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。</p>\n<p>这里需要将connectTimeout适当调整即可。</p>\n<h2 id=\"探究\"><a href=\"#探究\" class=\"headerlink\" title=\"探究\"></a>探究</h2><p>在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的<code>connection timeout</code>和<code>socket timeout</code>两个参数。</p>\n<h3 id=\"Connection-timeout\"><a href=\"#Connection-timeout\" class=\"headerlink\" title=\"Connection timeout\"></a>Connection timeout</h3><p>这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会<code>hang</code>住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。</p>\n<p>这个参数的默认值，在Java的dirver中，<code>com.mongodb.MongoClientOptions.Builder#connectTimeout</code>的默认值是<code>1000*10</code>ms，即10s。</p>\n<p>那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。</p>\n<h3 id=\"Socket-timeout\"><a href=\"#Socket-timeout\" class=\"headerlink\" title=\"Socket timeout\"></a>Socket timeout</h3><p>这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。</p>\n<p>如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。</p>\n<p>在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，<code>com.mongodb.MongoClientOptions.Builder#socketTimeout</code>值是<code>0</code>,用于表示不限制。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://blog.mlab.com/2013/10/do-you-want-a-timeout/\">[1].Do you want a timeout?</a><br><a href=\"https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error\">[2].mongodb connection timed out error</a><br><a href=\"https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html\">[3].Class MongoClientOptions</a></p>"},{"title":"Python中的元组和Packing/Unpacking","date":"2017-03-30T03:02:31.000Z","_content":"\n## 什么是元组\n\n元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号`()`包起来，如：\n<!--more-->\n```python\n>>> x = ('a','b','c') #具有三个元素的元组\n>>> y = ('a',) #只有一个元素的元组，注意，必须有一个逗号来标识\n>>> z = () #空元组\n```\n元组的操作跟列表非常类似，如`+`，`*`，切片等，在元组中同样适用：\n```python\n>>> a = (1,2,3)\n>>> a[:2]\n(1, 2)\n>>> a * 1\n(1, 2, 3)\n>>> a + (4,5)\n(1, 2, 3, 4, 5)\n```\n\n## 元组的Packing/Unpacking\n\nPython中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：\n```python\n>>> (a,b,c,d) = (1,2,3,4)\n>>> a\n1\n>>> c\n3\n```\n上面的写法还可以简化为:\n```python\n>>> a,b,c,d = 1,2,3,4\n```\n这个用法还可以非常方便的完成交换两个变量的值：\n```python\n>>> var1, var2 = var2, var1\n```\n\n在Python3中，还提供了一个扩展的unpacking特性——使用`*`来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：\n```python\n>>> x = (1,2,3,4)\n>>> a, b, *c = x\n>>> a, b, c\n(1, 2, [3, 4])\n>>> a, *b, c = x\n>>> a, b, c\n(1, [2, 3], 4)\n>>> *a, b, c = x\n>>> a, b, c\n([1, 2], 3, 4)\n>>> a, b, c, d, *e = x\n>>> a, b, c, d, e\n(1, 2, 3, 4, [])\n```\n被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。\n\n## Python中的Packing/Unpacking应用\n\nPython中，我们可以使用`*`（对元组来说）和`**`（对字典来说）的Packing和Unpacking函数的参数。\n\n### * for tuples\n从下面这个例子说起，我们有一个函数`fun()`接收四个函数，并打印出来：\n```python\ndef fun(a, b, c, d):\n    print(a, b, c, d)\n```\n\n假设我们有一个list：\n```\n>>> my_list = [1, 2, 3, 4]\n```\n调用函数`fun()`：\n```python\n>>> my_list = [1,2,3,4]\n>>> fun(my_list)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: fun() missing 3 required positional arguments: 'b', 'c', and 'd'\n>>> \n```\n会得到报错信息，函数认为我们的`my_list`是单独的一个参数，而函数还需要额外的三个参数。\n\n这时候，我们可以使用`*`来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：\n```python\n>>> fun(*my_list)\n1 2 3 4\n```\n这里还有另一个例子，使用内置的`range()`函数，来演示解包列表的操作：\n>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值\n\n```python\n>>> list(range(3,7))\n[3, 4, 5, 6]\n>>> args = [3,7]\n>>> list(range(args))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'list' object cannot be interpreted as an integer\n>>> list(range(*args))\n[3, 4, 5, 6]\n```\n当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。\n\n我们有函数`iSum()`来做求和操作\n```python\ndef iSum(*args):\n    sum=0\n    print(args) #把args打印出来，看是否被打包为一个元组\n    for i in range(0, len(args)):\n        sum = sum + args[i]\n    return sum\n\n```\n测试时，传参个数不等，得到的输出如下：\n```python\n>>> print(iSum(1,2,3,4,5))\n(1, 2, 3, 4, 5)\n15\n>>> print(iSum(10,20,30))\n(10, 20, 30)\n60\n```\n\n可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。\n\n如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。\n我们有函数`func1()`用于打印入参，`func2()`用户修改入参的值：\n```python\n>>> def func1(a,b,c):\n...     print(a,b,c)\n... \n>>> def func2(*args):\n...     args = list(args)\n...     args[0] = 'elbarco.cn'\n...     args[1] = 'awesome'\n...     func1(*args)\n...\n```\n调用`func2()`，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：\n```python\n>>> func2('Hello','nice','visitors')\nelbarco.cn awesome visitors\n```\n### ** for dictionaries\n\n对于字典（Dictionary），Packing/Unpacking操作使用`**`。\n\n还是使用上面的`func1()`，如果要打印字典的值，则需要使用`**`来解包：\n```\n>>> dict = {'a':1,'b':3,'c':5}\n>>> func1(**dict)\n1 3 5\n```\n\n下面来一个打包的例子：\n```\n>>> def func3(**elbarco):\n...     print(type(elbarco))\n...     for key in elbarco:\n...         print(\"%s = %s\" % (key, elbarco[key]))\n... \n```\n传几个参数，用`func3()`将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：\n```python\n>>> func3(name='elbarco', location='Beijing', language='Java/Python')\n<class 'dict'>\nname = elbarco\nlocation = Beijing\nlanguage = Java/Python\n```\n\n以上。\n\n## 参考\n\n1.[The Quick Python Book 2nd Edition.Chaptor 5.7.3]()\n2.[Packing and Unpacking Arguments in Python](http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/)\n3.[Packing and Unpacking Arguments in Python](https://hangar.runway7.net/python/packing-unpacking-arguments)\n4.[Python’s range() Function Explained](http://pythoncentral.io/pythons-range-function-explained/)\n","source":"_posts/packing-and-unpacking-tuples.md","raw":"---\ntitle: Python中的元组和Packing/Unpacking\ndate: 2017-03-30 11:02:31\ntags: [Python, Tuple]\n---\n\n## 什么是元组\n\n元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号`()`包起来，如：\n<!--more-->\n```python\n>>> x = ('a','b','c') #具有三个元素的元组\n>>> y = ('a',) #只有一个元素的元组，注意，必须有一个逗号来标识\n>>> z = () #空元组\n```\n元组的操作跟列表非常类似，如`+`，`*`，切片等，在元组中同样适用：\n```python\n>>> a = (1,2,3)\n>>> a[:2]\n(1, 2)\n>>> a * 1\n(1, 2, 3)\n>>> a + (4,5)\n(1, 2, 3, 4, 5)\n```\n\n## 元组的Packing/Unpacking\n\nPython中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：\n```python\n>>> (a,b,c,d) = (1,2,3,4)\n>>> a\n1\n>>> c\n3\n```\n上面的写法还可以简化为:\n```python\n>>> a,b,c,d = 1,2,3,4\n```\n这个用法还可以非常方便的完成交换两个变量的值：\n```python\n>>> var1, var2 = var2, var1\n```\n\n在Python3中，还提供了一个扩展的unpacking特性——使用`*`来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：\n```python\n>>> x = (1,2,3,4)\n>>> a, b, *c = x\n>>> a, b, c\n(1, 2, [3, 4])\n>>> a, *b, c = x\n>>> a, b, c\n(1, [2, 3], 4)\n>>> *a, b, c = x\n>>> a, b, c\n([1, 2], 3, 4)\n>>> a, b, c, d, *e = x\n>>> a, b, c, d, e\n(1, 2, 3, 4, [])\n```\n被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。\n\n## Python中的Packing/Unpacking应用\n\nPython中，我们可以使用`*`（对元组来说）和`**`（对字典来说）的Packing和Unpacking函数的参数。\n\n### * for tuples\n从下面这个例子说起，我们有一个函数`fun()`接收四个函数，并打印出来：\n```python\ndef fun(a, b, c, d):\n    print(a, b, c, d)\n```\n\n假设我们有一个list：\n```\n>>> my_list = [1, 2, 3, 4]\n```\n调用函数`fun()`：\n```python\n>>> my_list = [1,2,3,4]\n>>> fun(my_list)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: fun() missing 3 required positional arguments: 'b', 'c', and 'd'\n>>> \n```\n会得到报错信息，函数认为我们的`my_list`是单独的一个参数，而函数还需要额外的三个参数。\n\n这时候，我们可以使用`*`来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：\n```python\n>>> fun(*my_list)\n1 2 3 4\n```\n这里还有另一个例子，使用内置的`range()`函数，来演示解包列表的操作：\n>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值\n\n```python\n>>> list(range(3,7))\n[3, 4, 5, 6]\n>>> args = [3,7]\n>>> list(range(args))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'list' object cannot be interpreted as an integer\n>>> list(range(*args))\n[3, 4, 5, 6]\n```\n当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。\n\n我们有函数`iSum()`来做求和操作\n```python\ndef iSum(*args):\n    sum=0\n    print(args) #把args打印出来，看是否被打包为一个元组\n    for i in range(0, len(args)):\n        sum = sum + args[i]\n    return sum\n\n```\n测试时，传参个数不等，得到的输出如下：\n```python\n>>> print(iSum(1,2,3,4,5))\n(1, 2, 3, 4, 5)\n15\n>>> print(iSum(10,20,30))\n(10, 20, 30)\n60\n```\n\n可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。\n\n如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。\n我们有函数`func1()`用于打印入参，`func2()`用户修改入参的值：\n```python\n>>> def func1(a,b,c):\n...     print(a,b,c)\n... \n>>> def func2(*args):\n...     args = list(args)\n...     args[0] = 'elbarco.cn'\n...     args[1] = 'awesome'\n...     func1(*args)\n...\n```\n调用`func2()`，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：\n```python\n>>> func2('Hello','nice','visitors')\nelbarco.cn awesome visitors\n```\n### ** for dictionaries\n\n对于字典（Dictionary），Packing/Unpacking操作使用`**`。\n\n还是使用上面的`func1()`，如果要打印字典的值，则需要使用`**`来解包：\n```\n>>> dict = {'a':1,'b':3,'c':5}\n>>> func1(**dict)\n1 3 5\n```\n\n下面来一个打包的例子：\n```\n>>> def func3(**elbarco):\n...     print(type(elbarco))\n...     for key in elbarco:\n...         print(\"%s = %s\" % (key, elbarco[key]))\n... \n```\n传几个参数，用`func3()`将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：\n```python\n>>> func3(name='elbarco', location='Beijing', language='Java/Python')\n<class 'dict'>\nname = elbarco\nlocation = Beijing\nlanguage = Java/Python\n```\n\n以上。\n\n## 参考\n\n1.[The Quick Python Book 2nd Edition.Chaptor 5.7.3]()\n2.[Packing and Unpacking Arguments in Python](http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/)\n3.[Packing and Unpacking Arguments in Python](https://hangar.runway7.net/python/packing-unpacking-arguments)\n4.[Python’s range() Function Explained](http://pythoncentral.io/pythons-range-function-explained/)\n","slug":"packing-and-unpacking-tuples","published":1,"updated":"2017-06-30T08:39:21.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67j000hnshltjmp70i4","content":"<h2 id=\"什么是元组\"><a href=\"#什么是元组\" class=\"headerlink\" title=\"什么是元组\"></a>什么是元组</h2><p>元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号<code>()</code>包起来，如：<br><a id=\"more\"></a><br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>) <span class=\"comment\">#具有三个元素的元组</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = (<span class=\"string\">'a'</span>,) <span class=\"comment\">#只有一个元素的元组，注意，必须有一个逗号来标识</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = () <span class=\"comment\">#空元组</span></span><br></pre></td></tr></table></figure></p>\n<p>元组的操作跟列表非常类似，如<code>+</code>，<code>*</code>，切片等，在元组中同样适用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a[:<span class=\"number\">2</span>]</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a * <span class=\"number\">1</span></span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a + (<span class=\"number\">4</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"元组的Packing-Unpacking\"><a href=\"#元组的Packing-Unpacking\" class=\"headerlink\" title=\"元组的Packing/Unpacking\"></a>元组的Packing/Unpacking</h2><p>Python中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>(a,b,c,d) = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>c</span><br><span class=\"line\"><span class=\"number\">3</span></span><br></pre></td></tr></table></figure></p>\n<p>上面的写法还可以简化为:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a,b,c,d = <span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这个用法还可以非常方便的完成交换两个变量的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>var1, var2 = var2, var1</span><br></pre></td></tr></table></figure></p>\n<p>在Python3中，还提供了一个扩展的unpacking特性——使用<code>*</code>来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, *c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, [<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, *b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, [<span class=\"number\">2</span>, <span class=\"number\">3</span>], <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>*a, b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">([<span class=\"number\">1</span>, <span class=\"number\">2</span>], <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, *e = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, e</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, [])</span><br></pre></td></tr></table></figure></p>\n<p>被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。</p>\n<h2 id=\"Python中的Packing-Unpacking应用\"><a href=\"#Python中的Packing-Unpacking应用\" class=\"headerlink\" title=\"Python中的Packing/Unpacking应用\"></a>Python中的Packing/Unpacking应用</h2><p>Python中，我们可以使用<code>*</code>（对元组来说）和<code>**</code>（对字典来说）的Packing和Unpacking函数的参数。</p>\n<h3 id=\"for-tuples\"><a href=\"#for-tuples\" class=\"headerlink\" title=\"* for tuples\"></a>* for tuples</h3><p>从下面这个例子说起，我们有一个函数<code>fun()</code>接收四个函数，并打印出来：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(a, b, c, d)</span>:</span></span><br><span class=\"line\">    print(a, b, c, d)</span><br></pre></td></tr></table></figure></p>\n<p>假设我们有一个list：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; my_list = [1, 2, 3, 4]</span><br></pre></td></tr></table></figure></p>\n<p>调用函数<code>fun()</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_list = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(my_list)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: fun() missing <span class=\"number\">3</span> required positional arguments: <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"keyword\">and</span> <span class=\"string\">'d'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>会得到报错信息，函数认为我们的<code>my_list</code>是单独的一个参数，而函数还需要额外的三个参数。</p>\n<p>这时候，我们可以使用<code>*</code>来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(*my_list)</span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这里还有另一个例子，使用内置的<code>range()</code>函数，来演示解包列表的操作：</p>\n<blockquote>\n<p>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(<span class=\"number\">3</span>,<span class=\"number\">7</span>))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>args = [<span class=\"number\">3</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(args))</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: <span class=\"string\">'list'</span> object cannot be interpreted <span class=\"keyword\">as</span> an integer</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(*args))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br></pre></td></tr></table></figure>\n<p>当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。</p>\n<p>我们有函数<code>iSum()</code>来做求和操作<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iSum</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\">    sum=<span class=\"number\">0</span></span><br><span class=\"line\">    print(args) <span class=\"comment\">#把args打印出来，看是否被打包为一个元组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(args)):</span><br><span class=\"line\">        sum = sum + args[i]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sum</span><br></pre></td></tr></table></figure></p>\n<p>测试时，传参个数不等，得到的输出如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>))</span><br><span class=\"line\">(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"number\">60</span></span><br></pre></td></tr></table></figure></p>\n<p>可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。</p>\n<p>如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。<br>我们有函数<code>func1()</code>用于打印入参，<code>func2()</code>用户修改入参的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func1</span><span class=\"params\">(a,b,c)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    print(a,b,c)</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func2</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args = list(args)</span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">0</span>] = <span class=\"string\">'elbarco.cn'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">1</span>] = <span class=\"string\">'awesome'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    func1(*args)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>调用<code>func2()</code>，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func2(<span class=\"string\">'Hello'</span>,<span class=\"string\">'nice'</span>,<span class=\"string\">'visitors'</span>)</span><br><span class=\"line\">elbarco.cn awesome visitors</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"for-dictionaries\"><a href=\"#for-dictionaries\" class=\"headerlink\" title=\"** for dictionaries\"></a>** for dictionaries</h3><p>对于字典（Dictionary），Packing/Unpacking操作使用<code>**</code>。</p>\n<p>还是使用上面的<code>func1()</code>，如果要打印字典的值，则需要使用<code>**</code>来解包：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; dict = &#123;&apos;a&apos;:1,&apos;b&apos;:3,&apos;c&apos;:5&#125;</span><br><span class=\"line\">&gt;&gt;&gt; func1(**dict)</span><br><span class=\"line\">1 3 5</span><br></pre></td></tr></table></figure></p>\n<p>下面来一个打包的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; def func3(**elbarco):</span><br><span class=\"line\">...     print(type(elbarco))</span><br><span class=\"line\">...     for key in elbarco:</span><br><span class=\"line\">...         print(&quot;%s = %s&quot; % (key, elbarco[key]))</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>传几个参数，用<code>func3()</code>将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：<br><figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; func3(name='elbarco', location='Beijing', language='Java/Python')</span><br><span class=\"line\">&lt;class 'dict'&gt;</span><br><span class=\"line\">name = elbarco</span><br><span class=\"line\">location = Beijing</span><br><span class=\"line\">language = Java/Python</span><br></pre></td></tr></table></figure></p>\n<p>以上。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"\">The Quick Python Book 2nd Edition.Chaptor 5.7.3</a><br>2.<a href=\"http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/\" target=\"_blank\" rel=\"external\">Packing and Unpacking Arguments in Python</a><br>3.<a href=\"https://hangar.runway7.net/python/packing-unpacking-arguments\" target=\"_blank\" rel=\"external\">Packing and Unpacking Arguments in Python</a><br>4.<a href=\"http://pythoncentral.io/pythons-range-function-explained/\" target=\"_blank\" rel=\"external\">Python’s range() Function Explained</a></p>\n","excerpt":"<h2 id=\"什么是元组\"><a href=\"#什么是元组\" class=\"headerlink\" title=\"什么是元组\"></a>什么是元组</h2><p>元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号<code>()</code>包起来，如：<br>","more":"<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>) <span class=\"comment\">#具有三个元素的元组</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = (<span class=\"string\">'a'</span>,) <span class=\"comment\">#只有一个元素的元组，注意，必须有一个逗号来标识</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = () <span class=\"comment\">#空元组</span></span><br></pre></td></tr></table></figure></p>\n<p>元组的操作跟列表非常类似，如<code>+</code>，<code>*</code>，切片等，在元组中同样适用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a[:<span class=\"number\">2</span>]</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a * <span class=\"number\">1</span></span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a + (<span class=\"number\">4</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"元组的Packing-Unpacking\"><a href=\"#元组的Packing-Unpacking\" class=\"headerlink\" title=\"元组的Packing/Unpacking\"></a>元组的Packing/Unpacking</h2><p>Python中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>(a,b,c,d) = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>c</span><br><span class=\"line\"><span class=\"number\">3</span></span><br></pre></td></tr></table></figure></p>\n<p>上面的写法还可以简化为:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a,b,c,d = <span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这个用法还可以非常方便的完成交换两个变量的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>var1, var2 = var2, var1</span><br></pre></td></tr></table></figure></p>\n<p>在Python3中，还提供了一个扩展的unpacking特性——使用<code>*</code>来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, *c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, [<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, *b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, [<span class=\"number\">2</span>, <span class=\"number\">3</span>], <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>*a, b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">([<span class=\"number\">1</span>, <span class=\"number\">2</span>], <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, *e = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, e</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, [])</span><br></pre></td></tr></table></figure></p>\n<p>被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。</p>\n<h2 id=\"Python中的Packing-Unpacking应用\"><a href=\"#Python中的Packing-Unpacking应用\" class=\"headerlink\" title=\"Python中的Packing/Unpacking应用\"></a>Python中的Packing/Unpacking应用</h2><p>Python中，我们可以使用<code>*</code>（对元组来说）和<code>**</code>（对字典来说）的Packing和Unpacking函数的参数。</p>\n<h3 id=\"for-tuples\"><a href=\"#for-tuples\" class=\"headerlink\" title=\"* for tuples\"></a>* for tuples</h3><p>从下面这个例子说起，我们有一个函数<code>fun()</code>接收四个函数，并打印出来：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(a, b, c, d)</span>:</span></span><br><span class=\"line\">    print(a, b, c, d)</span><br></pre></td></tr></table></figure></p>\n<p>假设我们有一个list：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; my_list = [1, 2, 3, 4]</span><br></pre></td></tr></table></figure></p>\n<p>调用函数<code>fun()</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_list = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(my_list)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: fun() missing <span class=\"number\">3</span> required positional arguments: <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"keyword\">and</span> <span class=\"string\">'d'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>会得到报错信息，函数认为我们的<code>my_list</code>是单独的一个参数，而函数还需要额外的三个参数。</p>\n<p>这时候，我们可以使用<code>*</code>来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(*my_list)</span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这里还有另一个例子，使用内置的<code>range()</code>函数，来演示解包列表的操作：</p>\n<blockquote>\n<p>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(<span class=\"number\">3</span>,<span class=\"number\">7</span>))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>args = [<span class=\"number\">3</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(args))</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: <span class=\"string\">'list'</span> object cannot be interpreted <span class=\"keyword\">as</span> an integer</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(*args))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br></pre></td></tr></table></figure>\n<p>当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。</p>\n<p>我们有函数<code>iSum()</code>来做求和操作<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iSum</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\">    sum=<span class=\"number\">0</span></span><br><span class=\"line\">    print(args) <span class=\"comment\">#把args打印出来，看是否被打包为一个元组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(args)):</span><br><span class=\"line\">        sum = sum + args[i]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sum</span><br></pre></td></tr></table></figure></p>\n<p>测试时，传参个数不等，得到的输出如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>))</span><br><span class=\"line\">(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"number\">60</span></span><br></pre></td></tr></table></figure></p>\n<p>可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。</p>\n<p>如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。<br>我们有函数<code>func1()</code>用于打印入参，<code>func2()</code>用户修改入参的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func1</span><span class=\"params\">(a,b,c)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    print(a,b,c)</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func2</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args = list(args)</span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">0</span>] = <span class=\"string\">'elbarco.cn'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">1</span>] = <span class=\"string\">'awesome'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    func1(*args)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>调用<code>func2()</code>，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func2(<span class=\"string\">'Hello'</span>,<span class=\"string\">'nice'</span>,<span class=\"string\">'visitors'</span>)</span><br><span class=\"line\">elbarco.cn awesome visitors</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"for-dictionaries\"><a href=\"#for-dictionaries\" class=\"headerlink\" title=\"** for dictionaries\"></a>** for dictionaries</h3><p>对于字典（Dictionary），Packing/Unpacking操作使用<code>**</code>。</p>\n<p>还是使用上面的<code>func1()</code>，如果要打印字典的值，则需要使用<code>**</code>来解包：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; dict = &#123;&apos;a&apos;:1,&apos;b&apos;:3,&apos;c&apos;:5&#125;</span><br><span class=\"line\">&gt;&gt;&gt; func1(**dict)</span><br><span class=\"line\">1 3 5</span><br></pre></td></tr></table></figure></p>\n<p>下面来一个打包的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; def func3(**elbarco):</span><br><span class=\"line\">...     print(type(elbarco))</span><br><span class=\"line\">...     for key in elbarco:</span><br><span class=\"line\">...         print(&quot;%s = %s&quot; % (key, elbarco[key]))</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>传几个参数，用<code>func3()</code>将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：<br><figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; func3(name='elbarco', location='Beijing', language='Java/Python')</span><br><span class=\"line\">&lt;class 'dict'&gt;</span><br><span class=\"line\">name = elbarco</span><br><span class=\"line\">location = Beijing</span><br><span class=\"line\">language = Java/Python</span><br></pre></td></tr></table></figure></p>\n<p>以上。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"\">The Quick Python Book 2nd Edition.Chaptor 5.7.3</a><br>2.<a href=\"http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/\">Packing and Unpacking Arguments in Python</a><br>3.<a href=\"https://hangar.runway7.net/python/packing-unpacking-arguments\">Packing and Unpacking Arguments in Python</a><br>4.<a href=\"http://pythoncentral.io/pythons-range-function-explained/\">Python’s range() Function Explained</a></p>"},{"title":"一个成功的Git分支模型","date":"2016-03-08T02:29:22.000Z","_content":"\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/一个成功的Git分支模型.md","raw":"---\ntitle: 一个成功的Git分支模型\ndate: 2016-03-08 10:29:22\ntags: Git\n---\n\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"一个成功的Git分支模型","published":1,"updated":"2017-06-30T08:39:21.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67l000jnshloiw3vq49","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\" target=\"_blank\" rel=\"external\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\" target=\"_blank\" rel=\"external\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>\n<a id=\"more\"></a>\n<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch <span class=\"_\">-d</span> myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\" target=\"_blank\" rel=\"external\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\" target=\"_blank\" rel=\"external\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\" target=\"_blank\" rel=\"external\">@nvie</a> </p>\n</blockquote>\n","excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>","more":"<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch <span class=\"_\">-d</span> myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\">@nvie</a> </p>\n</blockquote>"},{"title":"为CentOS6.5安装Kernel3.10","date":"2016-03-12T01:08:34.000Z","_content":"\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","source":"_posts/为CentOS6-5安装Kernel3-10.md","raw":"---\ntitle: 为CentOS6.5安装Kernel3.10\ndate: 2016-03-12 09:08:34\ntags: [Linux, CentOS6.5]\n---\n\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","slug":"为CentOS6-5安装Kernel3-10","published":1,"updated":"2017-06-30T08:39:21.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67n000lnshl7segvmkw","content":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br><a id=\"more\"></a></p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\" target=\"_blank\" rel=\"external\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>\n","excerpt":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br>","more":"</p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>"},{"title":"使用Logrotate管理MongoDB日志-后记","date":"2016-07-01T07:23:11.000Z","_content":"\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/使用Logrotate管理MongoDB日志-后记.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志-后记\ndate: 2016-07-01 15:23:11\ntags: [Logrotate, MongoDB]\n---\n\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","slug":"使用Logrotate管理MongoDB日志-后记","published":1,"updated":"2017-06-30T08:39:21.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd67o000nnshl8dhkk3f9","content":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<a id=\"more\"></a></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job &apos;cron.daily&apos; in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job &apos;cron.daily&apos; started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job &apos;cron.daily&apos; terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"external\">参考文章</a></p>\n","excerpt":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！","more":"</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job &apos;cron.daily&apos; in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job &apos;cron.daily&apos; started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job &apos;cron.daily&apos; terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\">参考文章</a></p>"},{"title":"OpenStack DBaaS组件Trove简介","date":"2017-07-25T08:02:28.000Z","_content":"## Trove架构\nTrove包含下面几个主要组件：<!--more-->\n* API Server\n* Message Bus\n* Task Manager\n* Guest Agent\n* Conductor\n\n### API Server\nAPI endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。\n\nAPI Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。\n\n* 一个RESTful风格的组件\n* 入口 - `Trove/bin/trove-api`\n* 使用WSGI launcher，由`Trove/etc/trove/api-paste.ini`配置\n\t* 定义了过滤器管道、令牌认证、速率限制等\n\t* 定义了app_factory为`trove.common.api:app_factory`提供给trove应用\n* API 类（WSGI Router）将REST路径连接到相应的Controller上\n\t* Controller的实现在相关的模块下（如versions/instance/flavor/limits）的`service.py`中\n* Controller通常将实现重定向到`models.py`中的一个类\n* 另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求\n\n### Message Bus\n\n这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。\n\n一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。\n\n### Task Manager\n\nTask Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。\n\n任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）\n\n* 这是一个监听RabbitMQ topic的服务\n* 入口 - `Trove/bin/trove-taskmanager`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-taskmanager.conf.sample`配置文件进行配置，定义了`trove.taskmanager.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用TaskManager的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将该处理重定向到`models.py`模块中的一个对象，它使用context和instance_id从相关类加载一个对象\n* 实际的处理一般在`models.py`中完成\n\n### Guest Agent\n\n客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。\n\n每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。\n\n* 与Task Manager类似，服务运行起来监听RabbitMQ topic\n* Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）\n* 入口 - `Trove/bin/trove-guestagent`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-guestagent.conf.sample`配置文件进行配置，定义了`trove.guestagent.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用Guest Agent的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将对对象的处理重定向到`dbaas.py`中\n* 实际处理一般在`dbaas.py`中完成\n \n### Conductor\n\n指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为`trove-conductor`——来与指挥器进行信息交互。\n\n* 入口 - `Trove/bin/trove-conductor`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-conductor.conf.sample`配置文件进行配置，定义了`trove.conductor.manager.Manager`作为Manager\n* 如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为`{\"method\": \"<method_name>\", \"args\": {<arguments>}}`\n* 实际的数据库更新操作由`trove/conductor/manager.py`完成\n* \"heartbeat\"操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等\n* \"update_backup\"方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）\n\n## 代码仓库\n\n* Trove Server (https://github.com/openstack/trove)\n* Trove Integration (https://github.com/openstack/trove-integration)\n* Trove Client (https://github.com/openstack/python-troveclient)\n\n## 安装部署\n\n* How to install trove as part of devstack: [trove/installation](https://wiki.openstack.org/wiki/Trove/installation)\n* How to use trove-integration: [trove/trove-integration](https://wiki.openstack.org/wiki/Trove/trove-integration)\n* How to set up unit tests to run with tox: [trove/unit-testing](https://wiki.openstack.org/wiki/Trove/unit-testing)\n* How to set up a testing environment and run redstack tests after installation: [trove/integration-testing](https://wiki.openstack.org/wiki/Trove/integration-testing)\n* How to set up your Mac dev environment to debug: [trove/dev-env](https://wiki.openstack.org/wiki/Trove/dev-env)\n* Releasing python-troveclient [trove/release-python-troveclient](https://wiki.openstack.org/wiki/Trove/release-python-troveclient)\n* Creating release notes with Reno [trove/create-release-notes-with-reno](https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno)\n\n## 说明\n\n翻译自[Trove wiki](https://wiki.openstack.org/wiki/Trove)","source":"_posts/introduction-to-trove.md","raw":"---\ntitle: OpenStack DBaaS组件Trove简介\ndate: 2017-07-25 16:02:28\ntags: [OpenStack, Trove, Translation]\n---\n## Trove架构\nTrove包含下面几个主要组件：<!--more-->\n* API Server\n* Message Bus\n* Task Manager\n* Guest Agent\n* Conductor\n\n### API Server\nAPI endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。\n\nAPI Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。\n\n* 一个RESTful风格的组件\n* 入口 - `Trove/bin/trove-api`\n* 使用WSGI launcher，由`Trove/etc/trove/api-paste.ini`配置\n\t* 定义了过滤器管道、令牌认证、速率限制等\n\t* 定义了app_factory为`trove.common.api:app_factory`提供给trove应用\n* API 类（WSGI Router）将REST路径连接到相应的Controller上\n\t* Controller的实现在相关的模块下（如versions/instance/flavor/limits）的`service.py`中\n* Controller通常将实现重定向到`models.py`中的一个类\n* 另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求\n\n### Message Bus\n\n这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。\n\n一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。\n\n### Task Manager\n\nTask Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。\n\n任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）\n\n* 这是一个监听RabbitMQ topic的服务\n* 入口 - `Trove/bin/trove-taskmanager`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-taskmanager.conf.sample`配置文件进行配置，定义了`trove.taskmanager.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用TaskManager的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将该处理重定向到`models.py`模块中的一个对象，它使用context和instance_id从相关类加载一个对象\n* 实际的处理一般在`models.py`中完成\n\n### Guest Agent\n\n客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。\n\n每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。\n\n* 与Task Manager类似，服务运行起来监听RabbitMQ topic\n* Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）\n* 入口 - `Trove/bin/trove-guestagent`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-guestagent.conf.sample`配置文件进行配置，定义了`trove.guestagent.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用Guest Agent的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将对对象的处理重定向到`dbaas.py`中\n* 实际处理一般在`dbaas.py`中完成\n \n### Conductor\n\n指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为`trove-conductor`——来与指挥器进行信息交互。\n\n* 入口 - `Trove/bin/trove-conductor`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-conductor.conf.sample`配置文件进行配置，定义了`trove.conductor.manager.Manager`作为Manager\n* 如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为`{\"method\": \"<method_name>\", \"args\": {<arguments>}}`\n* 实际的数据库更新操作由`trove/conductor/manager.py`完成\n* \"heartbeat\"操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等\n* \"update_backup\"方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）\n\n## 代码仓库\n\n* Trove Server (https://github.com/openstack/trove)\n* Trove Integration (https://github.com/openstack/trove-integration)\n* Trove Client (https://github.com/openstack/python-troveclient)\n\n## 安装部署\n\n* How to install trove as part of devstack: [trove/installation](https://wiki.openstack.org/wiki/Trove/installation)\n* How to use trove-integration: [trove/trove-integration](https://wiki.openstack.org/wiki/Trove/trove-integration)\n* How to set up unit tests to run with tox: [trove/unit-testing](https://wiki.openstack.org/wiki/Trove/unit-testing)\n* How to set up a testing environment and run redstack tests after installation: [trove/integration-testing](https://wiki.openstack.org/wiki/Trove/integration-testing)\n* How to set up your Mac dev environment to debug: [trove/dev-env](https://wiki.openstack.org/wiki/Trove/dev-env)\n* Releasing python-troveclient [trove/release-python-troveclient](https://wiki.openstack.org/wiki/Trove/release-python-troveclient)\n* Creating release notes with Reno [trove/create-release-notes-with-reno](https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno)\n\n## 说明\n\n翻译自[Trove wiki](https://wiki.openstack.org/wiki/Trove)","slug":"introduction-to-trove","published":1,"updated":"2017-07-25T08:14:44.040Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68k001nnshl2a48yksp","content":"<h2 id=\"Trove架构\"><a href=\"#Trove架构\" class=\"headerlink\" title=\"Trove架构\"></a>Trove架构</h2><p>Trove包含下面几个主要组件：<a id=\"more\"></a></p>\n<ul>\n<li>API Server</li>\n<li>Message Bus</li>\n<li>Task Manager</li>\n<li>Guest Agent</li>\n<li>Conductor</li>\n</ul>\n<h3 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h3><p>API endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。</p>\n<p>API Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。</p>\n<ul>\n<li>一个RESTful风格的组件</li>\n<li>入口 - <code>Trove/bin/trove-api</code></li>\n<li>使用WSGI launcher，由<code>Trove/etc/trove/api-paste.ini</code>配置<ul>\n<li>定义了过滤器管道、令牌认证、速率限制等</li>\n<li>定义了app_factory为<code>trove.common.api:app_factory</code>提供给trove应用</li>\n</ul>\n</li>\n<li>API 类（WSGI Router）将REST路径连接到相应的Controller上<ul>\n<li>Controller的实现在相关的模块下（如versions/instance/flavor/limits）的<code>service.py</code>中</li>\n</ul>\n</li>\n<li>Controller通常将实现重定向到<code>models.py</code>中的一个类</li>\n<li>另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求</li>\n</ul>\n<h3 id=\"Message-Bus\"><a href=\"#Message-Bus\" class=\"headerlink\" title=\"Message Bus\"></a>Message Bus</h3><p>这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。</p>\n<p>一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。</p>\n<h3 id=\"Task-Manager\"><a href=\"#Task-Manager\" class=\"headerlink\" title=\"Task Manager\"></a>Task Manager</h3><p>Task Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。</p>\n<p>任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）</p>\n<ul>\n<li>这是一个监听RabbitMQ topic的服务</li>\n<li>入口 - <code>Trove/bin/trove-taskmanager</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-taskmanager.conf.sample</code>配置文件进行配置，定义了<code>trove.taskmanager.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用TaskManager的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将该处理重定向到<code>models.py</code>模块中的一个对象，它使用context和instance_id从相关类加载一个对象</li>\n<li>实际的处理一般在<code>models.py</code>中完成</li>\n</ul>\n<h3 id=\"Guest-Agent\"><a href=\"#Guest-Agent\" class=\"headerlink\" title=\"Guest Agent\"></a>Guest Agent</h3><p>客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。</p>\n<p>每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。</p>\n<ul>\n<li>与Task Manager类似，服务运行起来监听RabbitMQ topic</li>\n<li>Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）</li>\n<li>入口 - <code>Trove/bin/trove-guestagent</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-guestagent.conf.sample</code>配置文件进行配置，定义了<code>trove.guestagent.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用Guest Agent的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将对对象的处理重定向到<code>dbaas.py</code>中</li>\n<li>实际处理一般在<code>dbaas.py</code>中完成</li>\n</ul>\n<h3 id=\"Conductor\"><a href=\"#Conductor\" class=\"headerlink\" title=\"Conductor\"></a>Conductor</h3><p>指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为<code>trove-conductor</code>——来与指挥器进行信息交互。</p>\n<ul>\n<li>入口 - <code>Trove/bin/trove-conductor</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-conductor.conf.sample</code>配置文件进行配置，定义了<code>trove.conductor.manager.Manager</code>作为Manager</li>\n<li>如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为<code>{&quot;method&quot;: &quot;&lt;method_name&gt;&quot;, &quot;args&quot;: {&lt;arguments&gt;}}</code></li>\n<li>实际的数据库更新操作由<code>trove/conductor/manager.py</code>完成</li>\n<li>“heartbeat”操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等</li>\n<li>“update_backup”方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）</li>\n</ul>\n<h2 id=\"代码仓库\"><a href=\"#代码仓库\" class=\"headerlink\" title=\"代码仓库\"></a>代码仓库</h2><ul>\n<li>Trove Server (<a href=\"https://github.com/openstack/trove\" target=\"_blank\" rel=\"external\">https://github.com/openstack/trove</a>)</li>\n<li>Trove Integration (<a href=\"https://github.com/openstack/trove-integration\" target=\"_blank\" rel=\"external\">https://github.com/openstack/trove-integration</a>)</li>\n<li>Trove Client (<a href=\"https://github.com/openstack/python-troveclient\" target=\"_blank\" rel=\"external\">https://github.com/openstack/python-troveclient</a>)</li>\n</ul>\n<h2 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h2><ul>\n<li>How to install trove as part of devstack: <a href=\"https://wiki.openstack.org/wiki/Trove/installation\" target=\"_blank\" rel=\"external\">trove/installation</a></li>\n<li>How to use trove-integration: <a href=\"https://wiki.openstack.org/wiki/Trove/trove-integration\" target=\"_blank\" rel=\"external\">trove/trove-integration</a></li>\n<li>How to set up unit tests to run with tox: <a href=\"https://wiki.openstack.org/wiki/Trove/unit-testing\" target=\"_blank\" rel=\"external\">trove/unit-testing</a></li>\n<li>How to set up a testing environment and run redstack tests after installation: <a href=\"https://wiki.openstack.org/wiki/Trove/integration-testing\" target=\"_blank\" rel=\"external\">trove/integration-testing</a></li>\n<li>How to set up your Mac dev environment to debug: <a href=\"https://wiki.openstack.org/wiki/Trove/dev-env\" target=\"_blank\" rel=\"external\">trove/dev-env</a></li>\n<li>Releasing python-troveclient <a href=\"https://wiki.openstack.org/wiki/Trove/release-python-troveclient\" target=\"_blank\" rel=\"external\">trove/release-python-troveclient</a></li>\n<li>Creating release notes with Reno <a href=\"https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno\" target=\"_blank\" rel=\"external\">trove/create-release-notes-with-reno</a></li>\n</ul>\n<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><p>翻译自<a href=\"https://wiki.openstack.org/wiki/Trove\" target=\"_blank\" rel=\"external\">Trove wiki</a></p>\n","excerpt":"<h2 id=\"Trove架构\"><a href=\"#Trove架构\" class=\"headerlink\" title=\"Trove架构\"></a>Trove架构</h2><p>Trove包含下面几个主要组件：","more":"</p>\n<ul>\n<li>API Server</li>\n<li>Message Bus</li>\n<li>Task Manager</li>\n<li>Guest Agent</li>\n<li>Conductor</li>\n</ul>\n<h3 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h3><p>API endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。</p>\n<p>API Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。</p>\n<ul>\n<li>一个RESTful风格的组件</li>\n<li>入口 - <code>Trove/bin/trove-api</code></li>\n<li>使用WSGI launcher，由<code>Trove/etc/trove/api-paste.ini</code>配置<ul>\n<li>定义了过滤器管道、令牌认证、速率限制等</li>\n<li>定义了app_factory为<code>trove.common.api:app_factory</code>提供给trove应用</li>\n</ul>\n</li>\n<li>API 类（WSGI Router）将REST路径连接到相应的Controller上<ul>\n<li>Controller的实现在相关的模块下（如versions/instance/flavor/limits）的<code>service.py</code>中</li>\n</ul>\n</li>\n<li>Controller通常将实现重定向到<code>models.py</code>中的一个类</li>\n<li>另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求</li>\n</ul>\n<h3 id=\"Message-Bus\"><a href=\"#Message-Bus\" class=\"headerlink\" title=\"Message Bus\"></a>Message Bus</h3><p>这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。</p>\n<p>一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。</p>\n<h3 id=\"Task-Manager\"><a href=\"#Task-Manager\" class=\"headerlink\" title=\"Task Manager\"></a>Task Manager</h3><p>Task Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。</p>\n<p>任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）</p>\n<ul>\n<li>这是一个监听RabbitMQ topic的服务</li>\n<li>入口 - <code>Trove/bin/trove-taskmanager</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-taskmanager.conf.sample</code>配置文件进行配置，定义了<code>trove.taskmanager.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用TaskManager的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将该处理重定向到<code>models.py</code>模块中的一个对象，它使用context和instance_id从相关类加载一个对象</li>\n<li>实际的处理一般在<code>models.py</code>中完成</li>\n</ul>\n<h3 id=\"Guest-Agent\"><a href=\"#Guest-Agent\" class=\"headerlink\" title=\"Guest Agent\"></a>Guest Agent</h3><p>客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。</p>\n<p>每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。</p>\n<ul>\n<li>与Task Manager类似，服务运行起来监听RabbitMQ topic</li>\n<li>Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）</li>\n<li>入口 - <code>Trove/bin/trove-guestagent</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-guestagent.conf.sample</code>配置文件进行配置，定义了<code>trove.guestagent.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用Guest Agent的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将对对象的处理重定向到<code>dbaas.py</code>中</li>\n<li>实际处理一般在<code>dbaas.py</code>中完成</li>\n</ul>\n<h3 id=\"Conductor\"><a href=\"#Conductor\" class=\"headerlink\" title=\"Conductor\"></a>Conductor</h3><p>指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为<code>trove-conductor</code>——来与指挥器进行信息交互。</p>\n<ul>\n<li>入口 - <code>Trove/bin/trove-conductor</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-conductor.conf.sample</code>配置文件进行配置，定义了<code>trove.conductor.manager.Manager</code>作为Manager</li>\n<li>如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为<code>{&quot;method&quot;: &quot;&lt;method_name&gt;&quot;, &quot;args&quot;: {&lt;arguments&gt;}}</code></li>\n<li>实际的数据库更新操作由<code>trove/conductor/manager.py</code>完成</li>\n<li>“heartbeat”操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等</li>\n<li>“update_backup”方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）</li>\n</ul>\n<h2 id=\"代码仓库\"><a href=\"#代码仓库\" class=\"headerlink\" title=\"代码仓库\"></a>代码仓库</h2><ul>\n<li>Trove Server (<a href=\"https://github.com/openstack/trove\">https://github.com/openstack/trove</a>)</li>\n<li>Trove Integration (<a href=\"https://github.com/openstack/trove-integration\">https://github.com/openstack/trove-integration</a>)</li>\n<li>Trove Client (<a href=\"https://github.com/openstack/python-troveclient\">https://github.com/openstack/python-troveclient</a>)</li>\n</ul>\n<h2 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h2><ul>\n<li>How to install trove as part of devstack: <a href=\"https://wiki.openstack.org/wiki/Trove/installation\">trove/installation</a></li>\n<li>How to use trove-integration: <a href=\"https://wiki.openstack.org/wiki/Trove/trove-integration\">trove/trove-integration</a></li>\n<li>How to set up unit tests to run with tox: <a href=\"https://wiki.openstack.org/wiki/Trove/unit-testing\">trove/unit-testing</a></li>\n<li>How to set up a testing environment and run redstack tests after installation: <a href=\"https://wiki.openstack.org/wiki/Trove/integration-testing\">trove/integration-testing</a></li>\n<li>How to set up your Mac dev environment to debug: <a href=\"https://wiki.openstack.org/wiki/Trove/dev-env\">trove/dev-env</a></li>\n<li>Releasing python-troveclient <a href=\"https://wiki.openstack.org/wiki/Trove/release-python-troveclient\">trove/release-python-troveclient</a></li>\n<li>Creating release notes with Reno <a href=\"https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno\">trove/create-release-notes-with-reno</a></li>\n</ul>\n<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><p>翻译自<a href=\"https://wiki.openstack.org/wiki/Trove\">Trove wiki</a></p>"},{"title":"使用Logrotate管理MongoDB日志","date":"2016-06-30T07:26:03.000Z","_content":"\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","source":"_posts/使用Logrotate管理MongoDB日志.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志\ndate: 2016-06-30 15:26:03\ntags: [Logrotate, MongoDB]\n---\n\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","slug":"使用Logrotate管理MongoDB日志","published":1,"updated":"2017-06-30T08:39:21.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68m001pnshlre4x7t12","content":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<a id=\"more\"></a></p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\" target=\"_blank\" rel=\"external\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\" target=\"_blank\" rel=\"external\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"external\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix &apos;-20160630&apos;</span><br><span class=\"line\">glob pattern &apos;-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]&apos;</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"external\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>\n","excerpt":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。","more":"</p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix &apos;-20160630&apos;</span><br><span class=\"line\">glob pattern &apos;-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]&apos;</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>"},{"title":"基于Redis的Tomcat集群Session共享","date":"2016-03-10T08:18:06.000Z","_content":"\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","source":"_posts/基于Redis的Tomcat集群Session共享.md","raw":"---\ntitle: 基于Redis的Tomcat集群Session共享\ndate: 2016-03-10 16:18:06\ntags: [Reids, Tomcat]\n---\n\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","slug":"基于Redis的Tomcat集群Session共享","published":1,"updated":"2017-06-30T08:39:21.430Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68p001rnshle7f88qkt","content":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<a id=\"more\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\" target=\"_blank\" rel=\"external\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\" target=\"_blank\" rel=\"external\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\" target=\"_blank\" rel=\"external\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\" target=\"_blank\" rel=\"external\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</context></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span><br><span class=\"line\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span><br><span class=\"line\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span><br><span class=\"line\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span><br><span class=\"line\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span><br><span class=\"line\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span><br><span class=\"line\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p></p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p><p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\" target=\"_blank\" rel=\"external\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\" target=\"_blank\" rel=\"external\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\" target=\"_blank\" rel=\"external\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>\n","excerpt":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。","more":"</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span><br><span class=\"line\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span><br><span class=\"line\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span><br><span class=\"line\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span><br><span class=\"line\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span><br><span class=\"line\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span><br><span class=\"line\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>"},{"title":"如何在CentOS7上安装和配置VNCServer","date":"2016-03-09T09:22:56.000Z","_content":"\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","source":"_posts/如何在CentOS7上安装和配置VNCServer.md","raw":"---\ntitle: 如何在CentOS7上安装和配置VNCServer\ndate: 2016-03-09 17:22:56\ntags: [Linux, CentOS7]\n---\n\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","slug":"如何在CentOS7上安装和配置VNCServer","published":1,"updated":"2017-06-30T08:39:21.430Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68r001tnshludsvw65k","content":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\" target=\"_blank\" rel=\"external\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\" target=\"_blank\" rel=\"external\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"external\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"external\">VNC 服务器</a>。</p>\n<a id=\"more\"></a>\n<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\" target=\"_blank\" rel=\"external\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum check-update</span><br><span class=\"line\"># yum groupinstall &quot;X Window System&quot;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">### 设置默认启动图形界面</span><br><span class=\"line\"># unlink /etc/systemd/system/default.target</span><br><span class=\"line\"># ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># reboot</span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install tigervnc-server -y</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl daemon-reload</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"># su linoxide</span><br><span class=\"line\">$ sudo vncpasswd</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl enable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl start vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo firewall-cmd --permanent --add-service vnc-server</span><br><span class=\"line\">$ sudo systemctl restart firewalld.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\" target=\"_blank\" rel=\"external\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\" target=\"_blank\" rel=\"external\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># curl -s checkip.dyndns.org|sed -e &apos;s/.*Current IP Address: //&apos; -e &apos;s/&lt;.*$//&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl disable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>\n","excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\">VNC 服务器</a>。</p>","more":"<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum check-update</span><br><span class=\"line\"># yum groupinstall &quot;X Window System&quot;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">### 设置默认启动图形界面</span><br><span class=\"line\"># unlink /etc/systemd/system/default.target</span><br><span class=\"line\"># ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># reboot</span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install tigervnc-server -y</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl daemon-reload</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"># su linoxide</span><br><span class=\"line\">$ sudo vncpasswd</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl enable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl start vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo firewall-cmd --permanent --add-service vnc-server</span><br><span class=\"line\">$ sudo systemctl restart firewalld.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># curl -s checkip.dyndns.org|sed -e &apos;s/.*Current IP Address: //&apos; -e &apos;s/&lt;.*$//&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl disable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>"},{"title":"开山第一篇","date":"2016-03-03T01:30:24.000Z","_content":"\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","source":"_posts/开山第一篇.md","raw":"---\ntitle: 开山第一篇\ndate: 2016-03-03 09:30:24\ntags: 杂\n---\n\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","slug":"开山第一篇","published":1,"updated":"2017-06-30T08:39:21.437Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68u001wnshltkhkh53o","content":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\" target=\"_blank\" rel=\"external\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\" target=\"_blank\" rel=\"external\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\" target=\"_blank\" rel=\"external\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br><a id=\"more\"></a></p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"external\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\" target=\"_blank\" rel=\"external\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\" target=\"_blank\" rel=\"external\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>\n","excerpt":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br>","more":"</p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>"},{"title":"英雄联盟中的随机行为优化","date":"2016-03-07T05:48:24.000Z","_content":"> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","source":"_posts/英雄联盟中的随机行为优化.md","raw":"---\ntitle: 英雄联盟中的随机行为优化\ndate: 2016-03-07 13:48:24\ntags: 翻译\n---\n> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","slug":"英雄联盟中的随机行为优化","published":1,"updated":"2017-06-30T08:39:21.438Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd68v001xnshll1nx3tg1","content":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\" target=\"_blank\" rel=\"external\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br><a id=\"more\"></a><br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\" target=\"_blank\" rel=\"external\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\" target=\"_blank\" rel=\"external\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\" target=\"_blank\" rel=\"external\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\" target=\"_blank\" rel=\"external\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\" target=\"_blank\" rel=\"external\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariablePrecomputed</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">struct</span> Key</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>\n","excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br>","more":"<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariablePrecomputed</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">struct</span> Key</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>"},{"title":"Python中的生成器和yield关键字","date":"2017-09-18T08:49:46.000Z","_content":"## 前言\n\n我们都知道`yield`语句用于定义生成器，替代函数的`return`语句来向其调用者提供结果，并且不破坏局部变量。<!--more-->与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。\n\n## 关于Python生成器\n\nPython中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：\n```python\n>>> # 定义列表\n>>> the_list = [2**i for i in range(5)]\n>>> # 类型检查，确实是一个列表\n>>> type(the_list)\n<type 'list'>\n>>> for j in the_list:\n...     print j\n... \n1\n2\n4\n8\n16\n>>> # 列表长度为5\n>>> len(the_list)\n5\n>>> # 定义一个生成器，注意是'()'而不是'[]'\n>>> the_gen = (x+x for x in range(5))\n>>> # 类型检查，确实是一个生成器\n>>> type(the_gen)\n<type 'generator'>\n>>> # 遍历生成器中的元素，并打印\n>>> for j in the_gen:\n...     print j\n... \n0\n2\n4\n6\n8\n>>> # 看起来好像跟列表似的，那如果我们来检查一下长度……\n>>> len(the_gen)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: object of type 'generator' has no len()\n>>> \n\n```\n从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。\n\n正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。\n\n## 使用Python的`yield`关键字\n\n这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？\n\n这里我们就可以使用`yield`关键字/语句来定义一个生成器。`yield`指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：\n```python\ndef search(keyword, filename):\n    print 'Generator started'\n    f = open(filename,'r')\n    for line in f:\n        if keyword in line:\n            yield line\n    f.close()\n\n# 在data.txt中搜索yield关键字\nthe_gen = search('yield', 'data.txt')\n# 检查the_gen的类型\nprint type(the_gen)\n# 也可以用the_gen.next()或next(the_gen)遍历\nfor i in the_gen:\n    print i\n\n```\n最终，我们得到的the_gen的类型是`<type 'generator'>`，遍历the_gen得到`data.txt`中包含`yield`关键字的每一行，输出结果为：\n```\n<type 'generator'>\nGenerator started\nUsing the Python \"yield\" keyword\n\nThe yield instruction should be put into a place... \n\nSince the yield keyword is only used with generators...\n```\n## 更多的例子\n\n生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：\n```python\ndef buffered_read():\n    while True:\n        buffer = fetch_big_chunk()\n        for small_chunk in buffer:\n            yield small_chunk\n```\n\n最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：\n```python\ndef fibonacci(n):\n    curr = 1\n    prev = 0\n    counter = 0\n    while counter < n:\n        yield curr\n        prev, curr = curr, prev + curr\n        counter += 1\n\nf = fibonacci(6)\n    for i in f:\n        print i\n1\n1\n2\n3\n5\n8\n```\n直到`counter = n`，停止while循环。\n\n## 参考\n\n[1].[Python generators and the yield keyword](http://pythoncentral.io/python-generators-and-yield-keyword/)\n[2].[What does the “yield” keyword do?](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do)\n","source":"_posts/python-generators-and-yield-keyword.md","raw":"---\ntitle: Python中的生成器和yield关键字\ndate: 2017-09-18 16:49:46\ntags: [Python, yield]\n---\n## 前言\n\n我们都知道`yield`语句用于定义生成器，替代函数的`return`语句来向其调用者提供结果，并且不破坏局部变量。<!--more-->与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。\n\n## 关于Python生成器\n\nPython中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：\n```python\n>>> # 定义列表\n>>> the_list = [2**i for i in range(5)]\n>>> # 类型检查，确实是一个列表\n>>> type(the_list)\n<type 'list'>\n>>> for j in the_list:\n...     print j\n... \n1\n2\n4\n8\n16\n>>> # 列表长度为5\n>>> len(the_list)\n5\n>>> # 定义一个生成器，注意是'()'而不是'[]'\n>>> the_gen = (x+x for x in range(5))\n>>> # 类型检查，确实是一个生成器\n>>> type(the_gen)\n<type 'generator'>\n>>> # 遍历生成器中的元素，并打印\n>>> for j in the_gen:\n...     print j\n... \n0\n2\n4\n6\n8\n>>> # 看起来好像跟列表似的，那如果我们来检查一下长度……\n>>> len(the_gen)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: object of type 'generator' has no len()\n>>> \n\n```\n从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。\n\n正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。\n\n## 使用Python的`yield`关键字\n\n这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？\n\n这里我们就可以使用`yield`关键字/语句来定义一个生成器。`yield`指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：\n```python\ndef search(keyword, filename):\n    print 'Generator started'\n    f = open(filename,'r')\n    for line in f:\n        if keyword in line:\n            yield line\n    f.close()\n\n# 在data.txt中搜索yield关键字\nthe_gen = search('yield', 'data.txt')\n# 检查the_gen的类型\nprint type(the_gen)\n# 也可以用the_gen.next()或next(the_gen)遍历\nfor i in the_gen:\n    print i\n\n```\n最终，我们得到的the_gen的类型是`<type 'generator'>`，遍历the_gen得到`data.txt`中包含`yield`关键字的每一行，输出结果为：\n```\n<type 'generator'>\nGenerator started\nUsing the Python \"yield\" keyword\n\nThe yield instruction should be put into a place... \n\nSince the yield keyword is only used with generators...\n```\n## 更多的例子\n\n生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：\n```python\ndef buffered_read():\n    while True:\n        buffer = fetch_big_chunk()\n        for small_chunk in buffer:\n            yield small_chunk\n```\n\n最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：\n```python\ndef fibonacci(n):\n    curr = 1\n    prev = 0\n    counter = 0\n    while counter < n:\n        yield curr\n        prev, curr = curr, prev + curr\n        counter += 1\n\nf = fibonacci(6)\n    for i in f:\n        print i\n1\n1\n2\n3\n5\n8\n```\n直到`counter = n`，停止while循环。\n\n## 参考\n\n[1].[Python generators and the yield keyword](http://pythoncentral.io/python-generators-and-yield-keyword/)\n[2].[What does the “yield” keyword do?](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do)\n","slug":"python-generators-and-yield-keyword","published":1,"updated":"2017-09-18T10:05:26.680Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj7spd698002dnshlf2ddlbyp","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>我们都知道<code>yield</code>语句用于定义生成器，替代函数的<code>return</code>语句来向其调用者提供结果，并且不破坏局部变量。<a id=\"more\"></a>与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。</p>\n<h2 id=\"关于Python生成器\"><a href=\"#关于Python生成器\" class=\"headerlink\" title=\"关于Python生成器\"></a>关于Python生成器</h2><p>Python中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_list = [<span class=\"number\">2</span>**i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_list)</span><br><span class=\"line\">&lt;type <span class=\"string\">'list'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_list:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"number\">16</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 列表长度为5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_list)</span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义一个生成器，注意是'()'而不是'[]'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_gen = (x+x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个生成器</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_gen)</span><br><span class=\"line\">&lt;type <span class=\"string\">'generator'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 遍历生成器中的元素，并打印</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">6</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 看起来好像跟列表似的，那如果我们来检查一下长度……</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_gen)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: object of type <span class=\"string\">'generator'</span> has no len()</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。</p>\n<p>正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。</p>\n<h2 id=\"使用Python的yield关键字\"><a href=\"#使用Python的yield关键字\" class=\"headerlink\" title=\"使用Python的yield关键字\"></a>使用Python的<code>yield</code>关键字</h2><p>这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？</p>\n<p>这里我们就可以使用<code>yield</code>关键字/语句来定义一个生成器。<code>yield</code>指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">search</span><span class=\"params\">(keyword, filename)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Generator started'</span></span><br><span class=\"line\">    f = open(filename,<span class=\"string\">'r'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> keyword <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> line</span><br><span class=\"line\">    f.close()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在data.txt中搜索yield关键字</span></span><br><span class=\"line\">the_gen = search(<span class=\"string\">'yield'</span>, <span class=\"string\">'data.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 检查the_gen的类型</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> type(the_gen)</span><br><span class=\"line\"><span class=\"comment\"># 也可以用the_gen.next()或next(the_gen)遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> i</span><br></pre></td></tr></table></figure></p>\n<p>最终，我们得到的the_gen的类型是<code>&lt;type &#39;generator&#39;&gt;</code>，遍历the_gen得到<code>data.txt</code>中包含<code>yield</code>关键字的每一行，输出结果为：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;type &apos;generator&apos;&gt;</span><br><span class=\"line\">Generator started</span><br><span class=\"line\">Using the Python &quot;yield&quot; keyword</span><br><span class=\"line\"></span><br><span class=\"line\">The yield instruction should be put into a place... </span><br><span class=\"line\"></span><br><span class=\"line\">Since the yield keyword is only used with generators...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更多的例子\"><a href=\"#更多的例子\" class=\"headerlink\" title=\"更多的例子\"></a>更多的例子</h2><p>生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buffered_read</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        buffer = fetch_big_chunk()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_chunk <span class=\"keyword\">in</span> buffer:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> small_chunk</span><br></pre></td></tr></table></figure></p>\n<p>最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fibonacci</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    curr = <span class=\"number\">1</span></span><br><span class=\"line\">    prev = <span class=\"number\">0</span></span><br><span class=\"line\">    counter = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> counter &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> curr</span><br><span class=\"line\">        prev, curr = curr, prev + curr</span><br><span class=\"line\">        counter += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = fibonacci(<span class=\"number\">6</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> i</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br></pre></td></tr></table></figure></p>\n<p>直到<code>counter = n</code>，停止while循环。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://pythoncentral.io/python-generators-and-yield-keyword/\" target=\"_blank\" rel=\"external\">Python generators and the yield keyword</a><br>[2].<a href=\"https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\" target=\"_blank\" rel=\"external\">What does the “yield” keyword do?</a></p>\n","excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>我们都知道<code>yield</code>语句用于定义生成器，替代函数的<code>return</code>语句来向其调用者提供结果，并且不破坏局部变量。","more":"与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。</p>\n<h2 id=\"关于Python生成器\"><a href=\"#关于Python生成器\" class=\"headerlink\" title=\"关于Python生成器\"></a>关于Python生成器</h2><p>Python中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_list = [<span class=\"number\">2</span>**i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_list)</span><br><span class=\"line\">&lt;type <span class=\"string\">'list'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_list:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"number\">16</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 列表长度为5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_list)</span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义一个生成器，注意是'()'而不是'[]'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_gen = (x+x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个生成器</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_gen)</span><br><span class=\"line\">&lt;type <span class=\"string\">'generator'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 遍历生成器中的元素，并打印</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">6</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 看起来好像跟列表似的，那如果我们来检查一下长度……</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_gen)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: object of type <span class=\"string\">'generator'</span> has no len()</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。</p>\n<p>正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。</p>\n<h2 id=\"使用Python的yield关键字\"><a href=\"#使用Python的yield关键字\" class=\"headerlink\" title=\"使用Python的yield关键字\"></a>使用Python的<code>yield</code>关键字</h2><p>这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？</p>\n<p>这里我们就可以使用<code>yield</code>关键字/语句来定义一个生成器。<code>yield</code>指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">search</span><span class=\"params\">(keyword, filename)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Generator started'</span></span><br><span class=\"line\">    f = open(filename,<span class=\"string\">'r'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> keyword <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> line</span><br><span class=\"line\">    f.close()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在data.txt中搜索yield关键字</span></span><br><span class=\"line\">the_gen = search(<span class=\"string\">'yield'</span>, <span class=\"string\">'data.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 检查the_gen的类型</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> type(the_gen)</span><br><span class=\"line\"><span class=\"comment\"># 也可以用the_gen.next()或next(the_gen)遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> i</span><br></pre></td></tr></table></figure></p>\n<p>最终，我们得到的the_gen的类型是<code>&lt;type &#39;generator&#39;&gt;</code>，遍历the_gen得到<code>data.txt</code>中包含<code>yield</code>关键字的每一行，输出结果为：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;type &apos;generator&apos;&gt;</span><br><span class=\"line\">Generator started</span><br><span class=\"line\">Using the Python &quot;yield&quot; keyword</span><br><span class=\"line\"></span><br><span class=\"line\">The yield instruction should be put into a place... </span><br><span class=\"line\"></span><br><span class=\"line\">Since the yield keyword is only used with generators...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更多的例子\"><a href=\"#更多的例子\" class=\"headerlink\" title=\"更多的例子\"></a>更多的例子</h2><p>生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buffered_read</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        buffer = fetch_big_chunk()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_chunk <span class=\"keyword\">in</span> buffer:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> small_chunk</span><br></pre></td></tr></table></figure></p>\n<p>最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fibonacci</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    curr = <span class=\"number\">1</span></span><br><span class=\"line\">    prev = <span class=\"number\">0</span></span><br><span class=\"line\">    counter = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> counter &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> curr</span><br><span class=\"line\">        prev, curr = curr, prev + curr</span><br><span class=\"line\">        counter += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = fibonacci(<span class=\"number\">6</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> i</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br></pre></td></tr></table></figure></p>\n<p>直到<code>counter = n</code>，停止while循环。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://pythoncentral.io/python-generators-and-yield-keyword/\">Python generators and the yield keyword</a><br>[2].<a href=\"https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\">What does the “yield” keyword do?</a></p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cj7spd66u0000nshlz16g0w33","tag_id":"cj7spd6750003nshl9260annb","_id":"cj7spd67c0008nshlx9zobaat"},{"post_id":"cj7spd6710002nshl4wi8ch0f","tag_id":"cj7spd67a0006nshlec9ca114","_id":"cj7spd67h000cnshlr2arzyoc"},{"post_id":"cj7spd67h000dnshla7uy65p2","tag_id":"cj7spd67a0006nshlec9ca114","_id":"cj7spd67j000gnshlagu441t0"},{"post_id":"cj7spd67i000enshlndqa7k4u","tag_id":"cj7spd67a0006nshlec9ca114","_id":"cj7spd67l000inshl2vifi8ns"},{"post_id":"cj7spd6770004nshl5sibmcyn","tag_id":"cj7spd67h000bnshlho5c0q0z","_id":"cj7spd67n000mnshlsg9piwxo"},{"post_id":"cj7spd6770004nshl5sibmcyn","tag_id":"cj7spd67j000fnshl2s7a4dhv","_id":"cj7spd67p000onshlirgspb4m"},{"post_id":"cj7spd6780005nshlwcdcsl2u","tag_id":"cj7spd67m000knshlubcjdssu","_id":"cj7spd67v000snshl6f3g1wo4"},{"post_id":"cj7spd6780005nshlwcdcsl2u","tag_id":"cj7spd67q000pnshluxxmkeuh","_id":"cj7spd67v000tnshloj1b06bi"},{"post_id":"cj7spd6780005nshlwcdcsl2u","tag_id":"cj7spd67s000qnshlx9ttk60k","_id":"cj7spd67w000vnshl5ks0os47"},{"post_id":"cj7spd67a0007nshlmrwhiin9","tag_id":"cj7spd67h000bnshlho5c0q0z","_id":"cj7spd67x000ynshl7hlzj574"},{"post_id":"cj7spd67a0007nshlmrwhiin9","tag_id":"cj7spd67v000unshl90thuy5t","_id":"cj7spd67x000znshlmwr0apo3"},{"post_id":"cj7spd67a0007nshlmrwhiin9","tag_id":"cj7spd67w000wnshluv6vs4bp","_id":"cj7spd67x0011nshl7jykuvqb"},{"post_id":"cj7spd67c0009nshlqo7bst5q","tag_id":"cj7spd67w000xnshl042q4gw0","_id":"cj7spd67y0014nshlbpif8ba6"},{"post_id":"cj7spd67c0009nshlqo7bst5q","tag_id":"cj7spd67x0010nshlhxl9oqig","_id":"cj7spd67z0015nshlyom24ytk"},{"post_id":"cj7spd67c0009nshlqo7bst5q","tag_id":"cj7spd67y0012nshlpzw2f6s0","_id":"cj7spd67z0017nshlgv3vfkvs"},{"post_id":"cj7spd67f000anshlysxng9r0","tag_id":"cj7spd67w000xnshl042q4gw0","_id":"cj7spd67z0019nshlhvwp1l2e"},{"post_id":"cj7spd67f000anshlysxng9r0","tag_id":"cj7spd67z0016nshll1ck8wjd","_id":"cj7spd680001anshlo44bykja"},{"post_id":"cj7spd67j000hnshltjmp70i4","tag_id":"cj7spd67w000xnshl042q4gw0","_id":"cj7spd681001dnshl4an28mwm"},{"post_id":"cj7spd67j000hnshltjmp70i4","tag_id":"cj7spd680001bnshl6hqy9cdm","_id":"cj7spd681001enshlfi7bpvww"},{"post_id":"cj7spd67l000jnshloiw3vq49","tag_id":"cj7spd680001cnshl0mbvumv9","_id":"cj7spd681001gnshld391ouc5"},{"post_id":"cj7spd67n000lnshl7segvmkw","tag_id":"cj7spd681001fnshln7stqygp","_id":"cj7spd682001jnshlq29hcqgw"},{"post_id":"cj7spd67n000lnshl7segvmkw","tag_id":"cj7spd682001hnshlgcbymb5n","_id":"cj7spd682001knshln50w5lij"},{"post_id":"cj7spd67o000nnshl8dhkk3f9","tag_id":"cj7spd682001inshl8rjrej6k","_id":"cj7spd682001lnshlgsd3cs7u"},{"post_id":"cj7spd67o000nnshl8dhkk3f9","tag_id":"cj7spd67a0006nshlec9ca114","_id":"cj7spd683001mnshls3cqp2p4"},{"post_id":"cj7spd68m001pnshlre4x7t12","tag_id":"cj7spd682001inshl8rjrej6k","_id":"cj7spd68r001snshlamh34b61"},{"post_id":"cj7spd68m001pnshlre4x7t12","tag_id":"cj7spd67a0006nshlec9ca114","_id":"cj7spd68u001unshl7xx7boo7"},{"post_id":"cj7spd68k001nnshl2a48yksp","tag_id":"cj7spd68n001qnshlrsc98ys7","_id":"cj7spd68y0020nshlf3ug1syt"},{"post_id":"cj7spd68k001nnshl2a48yksp","tag_id":"cj7spd68u001vnshlt27wz0l9","_id":"cj7spd68z0021nshlc8qqsro6"},{"post_id":"cj7spd68k001nnshl2a48yksp","tag_id":"cj7spd68w001ynshls2k9mn98","_id":"cj7spd68z0023nshl1y0fwubs"},{"post_id":"cj7spd68p001rnshle7f88qkt","tag_id":"cj7spd68x001znshlop4n3lc6","_id":"cj7spd6910025nshlzo8q4ml4"},{"post_id":"cj7spd68p001rnshle7f88qkt","tag_id":"cj7spd68z0022nshl1vhbxdxe","_id":"cj7spd6930026nshlh5nh7pxq"},{"post_id":"cj7spd68r001tnshludsvw65k","tag_id":"cj7spd681001fnshln7stqygp","_id":"cj7spd6930028nshlmt66i97i"},{"post_id":"cj7spd68r001tnshludsvw65k","tag_id":"cj7spd6900024nshl0o74zg88","_id":"cj7spd6930029nshl7z1fu1mq"},{"post_id":"cj7spd68u001wnshltkhkh53o","tag_id":"cj7spd6930027nshl1oobh5oa","_id":"cj7spd694002bnshlmyrd4ebi"},{"post_id":"cj7spd68v001xnshll1nx3tg1","tag_id":"cj7spd693002anshl8ox62ly5","_id":"cj7spd694002cnshl4netgadh"},{"post_id":"cj7spd698002dnshlf2ddlbyp","tag_id":"cj7spd67w000xnshl042q4gw0","_id":"cj7spd69c002fnshlaaocejay"},{"post_id":"cj7spd698002dnshlf2ddlbyp","tag_id":"cj7spd69a002enshlai4gt97l","_id":"cj7spd69d002gnshlb7yd43ji"}],"Tag":[{"name":"Java","_id":"cj7spd6750003nshl9260annb"},{"name":"MongoDB","_id":"cj7spd67a0006nshlec9ca114"},{"name":"Concurrency","_id":"cj7spd67h000bnshlho5c0q0z"},{"name":"Actor Model","_id":"cj7spd67j000fnshl2s7a4dhv"},{"name":"MySQL","_id":"cj7spd67m000knshlubcjdssu"},{"name":"Galera Cluster","_id":"cj7spd67q000pnshluxxmkeuh"},{"name":"DB","_id":"cj7spd67s000qnshlx9ttk60k"},{"name":"Parallelism","_id":"cj7spd67v000unshl90thuy5t"},{"name":"Coroutine","_id":"cj7spd67w000wnshluv6vs4bp"},{"name":"Python","_id":"cj7spd67w000xnshl042q4gw0"},{"name":"Deep Copy","_id":"cj7spd67x0010nshlhxl9oqig"},{"name":"Shallow Copy","_id":"cj7spd67y0012nshlpzw2f6s0"},{"name":"decorator","_id":"cj7spd67z0016nshll1ck8wjd"},{"name":"Tuple","_id":"cj7spd680001bnshl6hqy9cdm"},{"name":"Git","_id":"cj7spd680001cnshl0mbvumv9"},{"name":"Linux","_id":"cj7spd681001fnshln7stqygp"},{"name":"CentOS6.5","_id":"cj7spd682001hnshlgcbymb5n"},{"name":"Logrotate","_id":"cj7spd682001inshl8rjrej6k"},{"name":"OpenStack","_id":"cj7spd68n001qnshlrsc98ys7"},{"name":"Trove","_id":"cj7spd68u001vnshlt27wz0l9"},{"name":"Translation","_id":"cj7spd68w001ynshls2k9mn98"},{"name":"Reids","_id":"cj7spd68x001znshlop4n3lc6"},{"name":"Tomcat","_id":"cj7spd68z0022nshl1vhbxdxe"},{"name":"CentOS7","_id":"cj7spd6900024nshl0o74zg88"},{"name":"杂","_id":"cj7spd6930027nshl1oobh5oa"},{"name":"翻译","_id":"cj7spd693002anshl8ox62ly5"},{"name":"yield","_id":"cj7spd69a002enshlai4gt97l"}]}}