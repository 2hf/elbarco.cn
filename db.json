{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/indigo/source/css/style.less","path":"css/style.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.min.js","path":"js/main.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.min.js","path":"js/search.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/cc.png","path":"img/cc.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/brand.jpg","path":"img/brand.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/cloudTie/mobile.less","path":"css/cloudTie/mobile.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/cloudTie/pc.less","path":"css/cloudTie/pc.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/loader.js","path":"js/cloudTie/loader.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/loader.min.js","path":"js/cloudTie/loader.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/mobile.min.js","path":"js/cloudTie/mobile.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/wechat.jpg","path":"img/wechat.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/mobile.js","path":"js/cloudTie/mobile.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/pc.min.js","path":"js/cloudTie/pc.min.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/cloudTie/pc.js","path":"js/cloudTie/pc.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"1a89366c93973bea7d7b92488e4a2113b7c3dee1","modified":1519804978767},{"_id":"themes/indigo/.DS_Store","hash":"08641f8b02141765c9aebf8e698bb0bd6fa80292","modified":1498911889000},{"_id":"themes/indigo/.gitignore","hash":"01ded238bb1d5a6738431f2c7c0409deb5423fa1","modified":1498913461000},{"_id":"themes/indigo/_config.yml","hash":"539fd2211e9f62edbac13a9cb0c53e67b6e06cd2","modified":1525317737895},{"_id":"themes/indigo/README.md","hash":"b188fb95a9c16eb188eeffa6caa0895a14676338","modified":1498878295000},{"_id":"themes/indigo/.editorconfig","hash":"9b0445427777519defe360ea38c61729d847b3d3","modified":1498878295000},{"_id":"themes/indigo/LICENSE","hash":"24944bf7920108f5a4790e6071c32e9102760c37","modified":1498878295000},{"_id":"themes/indigo/package.json","hash":"ea0031d1a0ea5369e9c2a45fba920041c720c3b1","modified":1498878295000},{"_id":"source/_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","hash":"cf9561b8c073b37987bf2b9a2daf735953a4822b","modified":1467293510000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1516849055722},{"_id":"source/_posts/difference-between-stringbuilder-and-stringbuffer.md","hash":"1c4816d973434e6afb53f29540f3a458e7b5948c","modified":1498878295000},{"_id":"source/_posts/general-concepts-concurrency-parallelism-process-thread-coroutine.md","hash":"51518b3f88b8d97761365855c9fed8962941222b","modified":1498878295000},{"_id":"source/_posts/introduction-to-actor-model.md","hash":"456ef454b40eb984790122f0818b35c38a1b0466","modified":1498878295000},{"_id":"source/_posts/git-rebase-local-branch-with-upstream-branch.md","hash":"6974744d3d597149cc672ace9c86b999a3260256","modified":1508801517000},{"_id":"source/_posts/introduction-to-trove-strategies.md","hash":"01c0258b51cdd05cfe4b1fb16479719195ce38f1","modified":1508801517000},{"_id":"source/_posts/introduction-to-galera-cluster-for-mysql.md","hash":"325ef1a7664459b8ca2bfabc12cfff7ca986deb2","modified":1498878295000},{"_id":"source/_posts/introduction-to-trove.md","hash":"eb50d66732a5b73f2a594654a1e8a2413c606cf1","modified":1508801517000},{"_id":"source/_posts/learning-nova-architecture-overview.md","hash":"5980e7519d01d771005c7c6ce5eb5134f662c2d9","modified":1516260785496},{"_id":"source/_posts/mongodb-connecttimeout-and-sockettimeout.md","hash":"9fdda071e6f47f0f5e412bc9b0a6f716e0bad052","modified":1498878295000},{"_id":"source/_posts/mongodb-crashed-with-the-Got-signal-6-Aborted.md","hash":"eda6a1ea2952e43c8bd24f387ad9cead0bc9b3cd","modified":1498878295000},{"_id":"source/_posts/nested-lists-and-deep-copies.md","hash":"36cc0e544fa5513323eaaf525a567e414616065f","modified":1498878295000},{"_id":"source/_posts/packing-and-unpacking-tuples.md","hash":"39d480ce1e82cb21651bfbaebf8945d22a61c7e8","modified":1498878295000},{"_id":"source/_posts/python-coroutines.md","hash":"3dc41cdd1109e3bc6f1988ba352e7a9c14eda702","modified":1508801517000},{"_id":"source/_posts/python-introduction-to-decorator-arguments.md","hash":"2430c921f6ac29fd9f1155edb627e3826038e8c0","modified":1508801517000},{"_id":"source/_posts/python-generators-and-yield-keyword.md","hash":"0beb6c9595a270e3b7d0fa6e4a4e11f7d5df9ba5","modified":1508801517000},{"_id":"source/_posts/nova-placement-api.md","hash":"7ad6255f8d8ad0af7f7e1235ed91f6ba9c807cc3","modified":1519701464796},{"_id":"source/_posts/python-introduction-to-decorators-with-examples.md","hash":"87cb168ff3f7808ba409a8b6b69fe7c6b4c9e614","modified":1508801517000},{"_id":"source/_posts/virtio-balloon.md","hash":"55d2c841f82030ef4edf335a85565e76b64e2766","modified":1531819089756},{"_id":"source/_posts/understanding-message-with-rabbitmq.md","hash":"6d7e95812fde1e07551f28e5f7ea811497b99152","modified":1516005543691},{"_id":"source/_posts/一个成功的Git分支模型.md","hash":"d9f1363791cf26c5f09aa4fbead91a77ce231026","modified":1467293510000},{"_id":"source/_posts/使用Logrotate管理MongoDB日志-后记.md","hash":"b918217e5f81f53a28f61394358563e3e885158b","modified":1498878295000},{"_id":"source/_posts/使用Logrotate管理MongoDB日志.md","hash":"9a145f1c3af5669dbc6edd151e3afb0108b66300","modified":1498878295000},{"_id":"source/_posts/基于Redis的Tomcat集群Session共享.md","hash":"f68ecab1180cca1bde75cc5ccadeba981d45e091","modified":1467293510000},{"_id":"source/_posts/为CentOS6-5安装Kernel3-10.md","hash":"b267423cd44948ce381c6de7eeb131e2fc2aa663","modified":1467293510000},{"_id":"source/_posts/如何在CentOS7上安装和配置VNCServer.md","hash":"7e9ed8b71146e195d9510740768f7c3c8bfd80c9","modified":1467293510000},{"_id":"source/_posts/开山第一篇.md","hash":"1d6832fbca7f2b18281bc330ef278589cf47f1f0","modified":1467293510000},{"_id":"source/_posts/英雄联盟中的随机行为优化.md","hash":"8089ece87fb797abbe536fc1e2a15f1ead021acc","modified":1498878295000},{"_id":"source/links/index.md","hash":"313c6a21749737e4939ea6dd55db5582d590bca5","modified":1519464327587},{"_id":"source/tags/index.md","hash":"8cd4bb27b82c3174f45565ea5b8a17cab3c370b5","modified":1498913033000},{"_id":"themes/indigo/languages/en.yml","hash":"1957d2bfc3a4cef299f4f169b431e9b1128ba162","modified":1498878295000},{"_id":"themes/indigo/languages/zh-CN.yml","hash":"7dc6ae434dde390b6768d244132e23cc78c33817","modified":1498878295000},{"_id":"themes/indigo/languages/zh-TW.yml","hash":"6a9e820be66eb12ae746f2527e0dc1adf927c685","modified":1498878295000},{"_id":"themes/indigo/layout/.DS_Store","hash":"f7c693faa6786696e8cd305b732743f1a1a08ff7","modified":1467293936000},{"_id":"themes/indigo/layout/archive.ejs","hash":"d039719e21f6a6fa2925b00aaa623a180a78c818","modified":1498878295000},{"_id":"themes/indigo/layout/categories.ejs","hash":"41783d2069d5080566a99e6312aa2113105f8b41","modified":1498878295000},{"_id":"themes/indigo/layout/category.ejs","hash":"7ea26a8a935886963eda82f41c7bd5270cf780d9","modified":1498878295000},{"_id":"themes/indigo/layout/index.ejs","hash":"39477807b98b2d2df78f3b82498a11e90be8222c","modified":1498878295000},{"_id":"themes/indigo/layout/layout.ejs","hash":"d52f43fa9572d70cae834e4887c8897b43744805","modified":1498878295000},{"_id":"themes/indigo/layout/post.ejs","hash":"afbf8532dc8d148ca4dff2ca127a3382907cf2f5","modified":1498878295000},{"_id":"themes/indigo/layout/page.ejs","hash":"afb98face24d39a21ebbbde6592a9afc98572aa4","modified":1498878295000},{"_id":"themes/indigo/layout/tag.ejs","hash":"36786a3de7f6cad58209603f7d84ba23addea174","modified":1498878295000},{"_id":"themes/indigo/scripts/plugins.js","hash":"e439d717513616bedeed37ba9b05117470809b21","modified":1498878295000},{"_id":"themes/indigo/layout/tags.ejs","hash":"20466446c41409d14a3d42ccaec24a65a045efef","modified":1498878295000},{"_id":"themes/indigo/source/.DS_Store","hash":"843aca88890b95fd45ae5154d8abc669793d049b","modified":1498911895000},{"_id":"themes/indigo/layout/_partial/.DS_Store","hash":"46bf374f3c92ba4efc15bdf6d509c82e7c583c94","modified":1467293670000},{"_id":"themes/indigo/layout/_partial/after-footer.ejs","hash":"9ac30b9439fab69973cf4722dbf2945a18fd3804","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/archive.ejs","hash":"55cd81ef9183426d6d99fd91550fce0a9cc92aa0","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/footer.ejs","hash":"9585a9c031cdbe7500fa11124814a63b143ca7b7","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/header.ejs","hash":"6156bf20791e46fc1c5872113276c1c1f5c13773","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/head.ejs","hash":"e01d1987f1016c521a19355d38d35dc78d20f3da","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/index-item.ejs","hash":"01bfe2ab45af7f93036a2bb1cdfbc092958b657b","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/loading.ejs","hash":"bc4cb19b20de55a0332647f4dca9684184383685","modified":1467293510000},{"_id":"themes/indigo/layout/_partial/paginator.ejs","hash":"24984bc96a9106ca0af722436822c3418e615d20","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/menu.ejs","hash":"d39afaad6b0dd2a3ae27e6db3e9a6cd6014622fa","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/script.ejs","hash":"439d6315a1b16e32b77a68c3f0cb2961d581086a","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post.ejs","hash":"a87d9b0485b3bf4cdfdad890e5974c43dbaa8240","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/search.ejs","hash":"c2091c621b5480ef1e69d72027028cec8e929892","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/tags-bar.ejs","hash":"19eff4876d31080a427644f7a43fe172d0c008c6","modified":1498878295000},{"_id":"themes/indigo/source/css/.DS_Store","hash":"85c939744975f275cee96dbf4294fa85370221b6","modified":1498911895000},{"_id":"themes/indigo/source/css/style.less","hash":"27dc4b93b93e92824d748f66b85de343b6a68f71","modified":1498878295000},{"_id":"themes/indigo/source/js/.DS_Store","hash":"a738736da19d836dc1aa9a6969358acb31104877","modified":1467293659000},{"_id":"themes/indigo/source/js/main.js","hash":"26688338ac55bed772e630099d2ce1ed69ef1431","modified":1498878295000},{"_id":"themes/indigo/source/js/search.js","hash":"c3f80dee3bab6bd4895b55b849085c8af7d1e647","modified":1498878295000},{"_id":"themes/indigo/source/js/main.min.js","hash":"dcec14830cf056fbbab82313ecd5886a03cdf580","modified":1498878295000},{"_id":"themes/indigo/source/js/search.min.js","hash":"c0c3d048af0d6b840f6f1dfda08911c7bfdb5dc1","modified":1498878295000},{"_id":"themes/indigo/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1467293510000},{"_id":"themes/indigo/source/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1467293510000},{"_id":"themes/indigo/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1467293510000},{"_id":"themes/indigo/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1467293510000},{"_id":"themes/indigo/source/img/alipay.jpg","hash":"815d6b304af810accce4bf2cbbe05a00758d71e9","modified":1498878295000},{"_id":"themes/indigo/source/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1467293510000},{"_id":"themes/indigo/layout/_partial/plugins/dynamic-title.ejs","hash":"23c101d45911eb0846533aaa2d409c43aa5e899a","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/disqus.ejs","hash":"4a0c01e4195f685f9825fcd016d01249dbdd52ca","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/baidu.ejs","hash":"e44d526029f122e9c2c74f3a647c35002c818cbe","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/mathjax.ejs","hash":"ea603a057196de53bd6afab1fddb93d11f27eb81","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/google-analytics.ejs","hash":"a947f4076b54b48d4df5baf2d5b3c39b632c7576","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/gitment.ejs","hash":"5723d507eca4390e8e5d18c0770e7953b8c22f5a","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/page-visit.ejs","hash":"2decb77bf3c1a064ea6ce1d4e78892c434d9c884","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/site-visit.ejs","hash":"8fbd0910828f1ab6eba728bdecc9811d623baae2","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/tajs.ejs","hash":"97b48fe10be1c71d4ff25ccec3bd92d97466c9c5","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/uyan.ejs","hash":"e370bd04ea5cf1c83e0c20516aff7ba3ca8b2d0b","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/comment.ejs","hash":"298e3ad59b358620b49dc933d39e5f26388d43be","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/plugins/wangyi-ygt.ejs","hash":"0540808912afbbd8dddbdd15b8d1b54426d8b221","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/category.ejs","hash":"c7476165721a3a5e34d00d8c5c07e1e5474cd800","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/copyright.ejs","hash":"968b27ca952d01b066cfe49fb670faf177d6b67e","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/date.ejs","hash":"ea85b46e12d3b9c3612eef7aa76289a663fbc096","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/head-meta.ejs","hash":"b0c680ce5b8aaf461a6731b1ff1287bd140c168a","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/nav.ejs","hash":"b3363972ef0499ec03f44af4b48ddb75cca7ca4b","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/reward-btn.ejs","hash":"0201008665c958747c3eda4b5ec00016e45dabc3","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/reward.ejs","hash":"eb1c5cda5f9a5106f9d395650f2629b9eb483a59","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/share-fab.ejs","hash":"93482ad7d1e01b966f5ee1c5d12b88564e02b349","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/share.ejs","hash":"8df0d7bf6f8e106cdbdac2dd10a97367aa0695f8","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/tag.ejs","hash":"b3dc38652c4a018a37418136478dcd522fc49f79","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/title.ejs","hash":"062d56cb88ae2be3a6616b911d4ebeffcbfe3cff","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/toc.ejs","hash":"b6123e895c16ace651f1832281ff655776d4068c","modified":1498878295000},{"_id":"themes/indigo/layout/_partial/post/updated.ejs","hash":"5caa71745aa340ce57938a930f3b898ee7518d74","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/archives.less","hash":"382fc22cd5cc073e881768a65600d97eba9f1d21","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/header.less","hash":"880b4a28e97d556ed15b07642d25115f9b6ba4f6","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/gotop.less","hash":"bad63006b3bd4849bf53ad38482af0d9971061d3","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/article.less","hash":"6944b67d793b3e1a645e9d61de766f74b38eb600","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/highlight.less","hash":"99e48793dc0b4ffb66ecaf2d1315145872f9bb98","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/loading.less","hash":"85157ddf3877b5c58e8f1d737dda3dfb1bfd540b","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/lightbox.less","hash":"38419aaf3c1832e84ade331f051f110fdc8b960f","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/layout.less","hash":"b0695de88dc4f1053dfd977dfc24805886a2b1d5","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/page.less","hash":"d411248ac382d20cf5d851463795bd3b28510694","modified":1498911903000},{"_id":"themes/indigo/source/css/_partial/postlist.less","hash":"df2f01c2514e060f2a6f3aca819bdf1e94ea8a4c","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/reward.less","hash":"e690327ce648f8b7920c82f28df2e6333b8d6462","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/roboto.less","hash":"3e457942995da8840e7662fa6cb551a7e12ea294","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/search.less","hash":"dbc23e77e586ee682a21475f5eb568628ea6720f","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/share.less","hash":"a683c96a59470efd35722b763c55149a46e35156","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/tags.less","hash":"01eb7f84193180928a6ed4796ee8802f6c1628e7","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/variable.less","hash":"89124f48aed2a61a4c8ab1f207f1d4c6df129abd","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/waves.less","hash":"a02eaa601887f947257f6016679b62dc96a61c0c","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/_reset.less","hash":"2e8ff3e47dadac5259f5ac7218e31edc88df8aff","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/_inputBox.less","hash":"c7d7c8eaf26fbc878b0170b64318c8e04066b26a","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/_share.less","hash":"adc02184e9a9dabc72beeebc9ce8f9b3c7ee826e","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/_joinCount.less","hash":"e251746eb432d5597a2883fe01dd2307ef1a231f","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/mobile.less","hash":"8a00d06f62b937a2c7c38249f877f709dc1ae27b","modified":1498878295000},{"_id":"themes/indigo/source/css/cloudTie/pc.less","hash":"fcb5bb53f9211ac845d8e52b985099bf2a7f4a85","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/.DS_Store","hash":"94730e1d89c9c0b990a536ca842e1301843eb613","modified":1467293653000},{"_id":"themes/indigo/source/js/cloudTie/loader.js","hash":"299d58e74946a2aeb8db74d3e4b6b5adfe694e15","modified":1498878295000},{"_id":"themes/indigo/source/js/cloudTie/loader.min.js","hash":"e73fcd885be2c4585f154861c9969e3c955d03e3","modified":1498878295000},{"_id":"themes/indigo/source/js/cloudTie/mobile.min.js","hash":"859e3efb15db88cedfd18f8523ecfd21f3a22324","modified":1498878295000},{"_id":"themes/indigo/source/img/wechat.jpg","hash":"b77bf94cae10f3e15c927a1871003c567c3d6fcc","modified":1498878295000},{"_id":"themes/indigo/source/css/_partial/fontawesome.less","hash":"907c10fa4388b7ae7e141b026fb98cc9f758d785","modified":1498878295000},{"_id":"themes/indigo/source/js/cloudTie/mobile.js","hash":"67a0a31ee1e491635369b0401d629e97fccd4d94","modified":1498878295000},{"_id":"themes/indigo/source/js/cloudTie/pc.min.js","hash":"aea28510192fb36a36bf174716a39afd1ca20240","modified":1498878295000},{"_id":"themes/indigo/source/img/avatar.jpg","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1467293510000},{"_id":"themes/indigo/source/js/cloudTie/pc.js","hash":"25d4ae345f8122f8c7e8e48959d37523dd1e4abb","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1467293510000},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1498878295000},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1498878295000},{"_id":"public/content.json","hash":"f2109c2a56b92fb6f4c27e820a269439bb2074a9","modified":1531819100149},{"_id":"public/links/index.html","hash":"1460ffd6f0cac5f0a6f027825c3b74491fb68ff8","modified":1531818655241},{"_id":"public/archives/page/3/index.html","hash":"51cb64edb3310ea1ea764b37cd26d8e424eed496","modified":1531818655275},{"_id":"public/archives/2016/page/2/index.html","hash":"8165b3dfff22ab4e2ebc0afc1ddc2807ab002068","modified":1531818655276},{"_id":"public/archives/2016/03/index.html","hash":"a1f9877f3129e4d41623e0f2c49eec2cde2c0dc0","modified":1531818655276},{"_id":"public/archives/2016/04/index.html","hash":"59abe152e289dd60fc741d8378d693dbee34237d","modified":1531818655276},{"_id":"public/archives/2016/06/index.html","hash":"a1ba95c5a2cc2c6ef823d0da2a7ec8f3a2f07601","modified":1531818655276},{"_id":"public/archives/2016/07/index.html","hash":"4799a55dc2e1e1c47422ec5fd09736dd29a6053e","modified":1531818655276},{"_id":"public/archives/2016/09/index.html","hash":"2a30a9a94dc4f57804dc23a18de0ac81913abe59","modified":1531818655276},{"_id":"public/archives/2016/12/index.html","hash":"0ae48b0314f2a26bbc6081afc238b791370b7638","modified":1531818655276},{"_id":"public/archives/2017/page/2/index.html","hash":"f654895f8d4bc171445e56fc4260053092a0d89e","modified":1531818655276},{"_id":"public/archives/2017/01/index.html","hash":"98b9895d01deb18689413e9df0676a4ec009ecb9","modified":1531818655276},{"_id":"public/archives/2017/03/index.html","hash":"5906e715c420f33be414749f6af68f41f688f306","modified":1531818655276},{"_id":"public/archives/2017/06/index.html","hash":"19645c7d986f69ca935799c86fdfcd89a902c7de","modified":1531818655276},{"_id":"public/archives/2017/07/index.html","hash":"a4a0296682902f1db21b4247a0e753480ed23908","modified":1531818655276},{"_id":"public/archives/2017/09/index.html","hash":"667f8c02ae007e3a8a1f10aff6e7a9d62cd06df9","modified":1531818655276},{"_id":"public/archives/2017/10/index.html","hash":"24f14cfaf6f5a41a964bfd61e2c27f5402504160","modified":1531818655277},{"_id":"public/archives/2017/12/index.html","hash":"ca0e8e2f13908b968f083aed12f1b21772b4a38a","modified":1531818655277},{"_id":"public/archives/2018/index.html","hash":"11c167bba30a5dc4110e1b82202a1985a9c28370","modified":1531818655277},{"_id":"public/archives/2018/01/index.html","hash":"c7d11796340ac868de3320e35442a22ce8a3aecd","modified":1531818655277},{"_id":"public/archives/2018/02/index.html","hash":"8622f7fe3ae9fcd1aa841429d94b5e42dfdb7340","modified":1531818655277},{"_id":"public/tags/Java/index.html","hash":"b91c06095400db8037dceafd07393f415e033758","modified":1531818655277},{"_id":"public/tags/Parallelism/index.html","hash":"9fbf0491100232da6f37ee13f06f2666ab47b6cf","modified":1531818655277},{"_id":"public/tags/Coroutine/index.html","hash":"936487775e21722275133bf631cf325c1ef75eca","modified":1531818655277},{"_id":"public/tags/Actor-Model/index.html","hash":"32f58b4995a926bc8f73f7129539ad111ec8bc78","modified":1531818655277},{"_id":"public/tags/Git/index.html","hash":"62ad8c0a38acbc0e2fcf3d52a115661be3d96fcb","modified":1531818655277},{"_id":"public/tags/rebase/index.html","hash":"c41bf1292cb4c71e2e6d2e22d960e76a2f070c31","modified":1531818655277},{"_id":"public/tags/MySQL/index.html","hash":"343b22a7a2e2d82c2a015433cd0ada232fccb86f","modified":1531818655277},{"_id":"public/tags/Galera-Cluster/index.html","hash":"ba33728a6d7e24fca6986ce8d934eb437e4d18a4","modified":1531818655277},{"_id":"public/tags/DB/index.html","hash":"a1832d8a61c807c66aa4d79b67433d53ed479e54","modified":1531818655277},{"_id":"public/tags/Translation/index.html","hash":"2d473fc5cd9c14045bb0f6f2a9586850225829fd","modified":1531818655277},{"_id":"public/tags/Nova/index.html","hash":"3238b06e86f4770178b274b3fec43abe643f51a5","modified":1531818655277},{"_id":"public/tags/Deep-Copy/index.html","hash":"e4e98f880e98375b4ffd8a9b3e6b96f395a533a5","modified":1531818655277},{"_id":"public/tags/Shallow-Copy/index.html","hash":"bc1f007551bc670acd2ffa7d08542370734b097d","modified":1531818655277},{"_id":"public/tags/Tuple/index.html","hash":"61426271f363790fea22fc3ccca4cf5892231447","modified":1531818655277},{"_id":"public/tags/Coroutines/index.html","hash":"28405f04c01dd3746881f7d6d799f9de04961293","modified":1531818655277},{"_id":"public/tags/yield/index.html","hash":"faaf5e2982fe9da8a000da7eadbe2f23f7d41103","modified":1531818655277},{"_id":"public/tags/AMQP/index.html","hash":"b987d94525a8a52c8b01a4f5b17708b176cce5a9","modified":1531818655277},{"_id":"public/tags/RabbitMQ/index.html","hash":"f481e39fca2a7914f597d13f3550549692429463","modified":1531818655278},{"_id":"public/tags/Reids/index.html","hash":"04f2c743e14614335e362fd337b1974fbb4fa82a","modified":1531818655278},{"_id":"public/tags/Tomcat/index.html","hash":"83191981b857c5fe9e3e60e5006923d59d918141","modified":1531818655278},{"_id":"public/tags/CentOS6-5/index.html","hash":"d9f8c9e120fb22bfa3fab457595b1f2df013e9c9","modified":1531818655278},{"_id":"public/tags/CentOS7/index.html","hash":"7cbc54ec22d79feaedf733b7790846abed102f16","modified":1531818655278},{"_id":"public/tags/杂/index.html","hash":"286f7e85c74779baee2cf68eb6cd1934ab6d6e8a","modified":1531818655278},{"_id":"public/tags/翻译/index.html","hash":"cbd791a30c1e099823d0cf480487a631b3da747b","modified":1531818655278},{"_id":"public/tags/index.html","hash":"ba350c3f60047e2f6e9ec2a915437205643a1aca","modified":1531818655278},{"_id":"public/2018/02/23/nova-placement-api/index.html","hash":"6fa8dc051af916f073d1f7b191c18403f90b95ad","modified":1531818655278},{"_id":"public/2018/01/16/learning-nova-architecture-overview/index.html","hash":"92fcdd854668d04eee7efe9d586a45ce87187e3c","modified":1531818655278},{"_id":"public/2017/12/01/understanding-message-with-rabbitmq/index.html","hash":"3e4c30a44a7807057219c8a39f74d6d12ab8cc57","modified":1531818655279},{"_id":"public/2017/10/18/python-coroutines/index.html","hash":"f92e776fa3c8543764e1dc6e495746081a2a10d7","modified":1531818655279},{"_id":"public/2017/10/17/introduction-to-trove-strategies/index.html","hash":"306ed7191718d22625812ea1afbfb4078af391b1","modified":1531818655279},{"_id":"public/2017/09/28/git-rebase-local-branch-with-upstream-branch/index.html","hash":"dd9e348b375d39ea84144416be5bba634aa69dfc","modified":1531818655279},{"_id":"public/2017/09/20/python-introduction-to-decorator-arguments/index.html","hash":"8facd1781355a40db700f28af564cd4d4681512d","modified":1531818655279},{"_id":"public/2017/09/20/python-introduction-to-decorators-with-examples/index.html","hash":"14015b62c9aee58d91a0b8899a973670a8b80908","modified":1531818655279},{"_id":"public/2017/09/18/python-generators-and-yield-keyword/index.html","hash":"71612438b0659f296d765e7747161c5967d6f76a","modified":1531818655280},{"_id":"public/2017/07/25/introduction-to-trove/index.html","hash":"71ff3203ce93f23ccade39a213c9cc740d97ca56","modified":1531818655280},{"_id":"public/2017/06/28/mongodb-connecttimeout-and-sockettimeout/index.html","hash":"608e8497fed2808831b84e2931c60d8fef403eee","modified":1531818655280},{"_id":"public/2017/06/23/mongodb-crashed-with-the-Got-signal-6-Aborted/index.html","hash":"9940584fd659ae3f9d7b5e59b8837e64a7feb16c","modified":1531818655280},{"_id":"public/2017/03/30/packing-and-unpacking-tuples/index.html","hash":"ad5391bd4cd35f37ddafb5c6a413071104096dda","modified":1531818655280},{"_id":"public/2017/03/29/nested-lists-and-deep-copies/index.html","hash":"a69b5e32ac9f3de0ce83507b3b6e4be87bcb204a","modified":1531818655280},{"_id":"public/2017/01/21/introduction-to-actor-model/index.html","hash":"c5130ae3ad4c2aa1b132f1c05eff1f5f8e2f74c4","modified":1531818655280},{"_id":"public/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/index.html","hash":"5674aa5e110823ed29a5f68d3475988163c7b394","modified":1531818655280},{"_id":"public/2016/12/28/introduction-to-galera-cluster-for-mysql/index.html","hash":"f9326525dff15ffd4c0c93cbba589f7b735c76d5","modified":1531818655280},{"_id":"public/2016/09/05/difference-between-stringbuilder-and-stringbuffer/index.html","hash":"b7b8ca1890774a82bca214b1e3eeb146693d2853","modified":1531818655281},{"_id":"public/2016/07/01/使用Logrotate管理MongoDB日志-后记/index.html","hash":"09d7e216517e0c5a34a74a41f7f97de73160d12d","modified":1531818655281},{"_id":"public/2016/06/30/使用Logrotate管理MongoDB日志/index.html","hash":"06e757d332c68607e842a204addf92e6acba7bdd","modified":1531818655281},{"_id":"public/2016/04/27/MongoDB复制集Secondary节点持续Recovering状态解决办法/index.html","hash":"3c0f3adaaa7138146fd432710812114a1694fa50","modified":1531818655281},{"_id":"public/2016/03/12/为CentOS6-5安装Kernel3-10/index.html","hash":"5fffeccf1e5ce3182ddbf169e2ec64fc7b9ad11c","modified":1531818655281},{"_id":"public/2016/03/10/基于Redis的Tomcat集群Session共享/index.html","hash":"49fa6e2d7be3c07a9571450f763da5c09b41b5d7","modified":1531818655281},{"_id":"public/2016/03/09/如何在CentOS7上安装和配置VNCServer/index.html","hash":"19af2c177fd4a5cd9b9642d2a41a32181eac86f0","modified":1531818655281},{"_id":"public/2016/03/08/一个成功的Git分支模型/index.html","hash":"3ba84789ff49efa9c64886724ff820b26aebb97e","modified":1531818655281},{"_id":"public/2016/03/07/英雄联盟中的随机行为优化/index.html","hash":"03387f82792e7d44b6b34798dbc1937ced530288","modified":1531818655281},{"_id":"public/2016/03/03/开山第一篇/index.html","hash":"bbe36237c7a3a4653d0ef117c140c426168a0a73","modified":1531818655281},{"_id":"public/archives/index.html","hash":"1e28cc45b82bbe6f69ab610f3e91035a57a54c97","modified":1531818655281},{"_id":"public/archives/page/2/index.html","hash":"776f3055eb798125c131b9002b8f3ec601a51ce6","modified":1531818655281},{"_id":"public/archives/2016/index.html","hash":"2e227a7a57eb2e9d8e2ac4fd8266ccbc1cb574e4","modified":1531818655281},{"_id":"public/archives/2017/index.html","hash":"a3ac3cb3c2789218b9a15cbbc8c842386306f6ac","modified":1531818655282},{"_id":"public/index.html","hash":"6bb6e805c60770dd7691651c7fa65b8430d0aecc","modified":1531818655282},{"_id":"public/page/2/index.html","hash":"a6bf37a016d1a79d57b010447819c1750dc593fd","modified":1531818655282},{"_id":"public/page/3/index.html","hash":"d3710e0edef64db0bfdbf09b5d721fa6047a756e","modified":1531818655282},{"_id":"public/tags/MongoDB/index.html","hash":"2edbcf16eeadf7c19cafc877fee53a40753afd82","modified":1531818655282},{"_id":"public/tags/Concurrency/index.html","hash":"aba1a2784f0bdda8b5201d7e260cd53c787b3a8d","modified":1531818655282},{"_id":"public/tags/OpenStack/index.html","hash":"c8484b6cbd521626f00eee44bb7b433105a9a6cd","modified":1531818655282},{"_id":"public/tags/Trove/index.html","hash":"5aa58ec5b02004a3494912854dede7612512d519","modified":1531818655282},{"_id":"public/tags/Python/index.html","hash":"78f9561ac1872534774609fefff68ef55694afba","modified":1531818655282},{"_id":"public/tags/decorator/index.html","hash":"7ee1990d5fadad241022261951fd0fabf2a7b27c","modified":1531818655282},{"_id":"public/tags/Logrotate/index.html","hash":"641c371ed153104e382ccecd5849f579b53a1507","modified":1531818655282},{"_id":"public/tags/Linux/index.html","hash":"e1ea0b789ccd52b3d6dd1529601226bcad18aed1","modified":1531818655282},{"_id":"public/archives/2018/07/index.html","hash":"fecd7a7c9e20e8fa7bf3e94ed80e0bfe8c8dc971","modified":1531818655306},{"_id":"public/tags/Virtio/index.html","hash":"63c63df83ee16865d406cc9e7624437b05e04dc1","modified":1531818655306},{"_id":"public/tags/KVM/index.html","hash":"530fdf46e7b86eabee69cdb039ca0eebabf79c19","modified":1531818655307},{"_id":"public/tags/Virtualization/index.html","hash":"7640aecbc0a00812397cf58068a99b1d76283e99","modified":1531818655307},{"_id":"public/2018/07/16/virtio-balloon/index.html","hash":"e1e087ce23c5c6c4e43c8f297e809531e58eda2b","modified":1531819100823},{"_id":"public/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1531818655318},{"_id":"public/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1531818655319},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1531818655319},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1531818655319},{"_id":"public/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1531818655321},{"_id":"public/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1531818655322},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1531818655322},{"_id":"public/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1531818655322},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1531818655323},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1531818655323},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1531818655324},{"_id":"public/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1531818655324},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1531818655325},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1531818655325},{"_id":"public/img/alipay.jpg","hash":"815d6b304af810accce4bf2cbbe05a00758d71e9","modified":1531818655617},{"_id":"public/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1531818655619},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1531818655623},{"_id":"public/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1531818655623},{"_id":"public/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1531818655623},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1531818655623},{"_id":"public/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1531818655623},{"_id":"public/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1531818655623},{"_id":"public/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1531818655623},{"_id":"public/js/search.js","hash":"c3f80dee3bab6bd4895b55b849085c8af7d1e647","modified":1531818655632},{"_id":"public/js/main.min.js","hash":"dcec14830cf056fbbab82313ecd5886a03cdf580","modified":1531818655633},{"_id":"public/js/search.min.js","hash":"c0c3d048af0d6b840f6f1dfda08911c7bfdb5dc1","modified":1531818655633},{"_id":"public/js/cloudTie/loader.js","hash":"299d58e74946a2aeb8db74d3e4b6b5adfe694e15","modified":1531818655633},{"_id":"public/js/cloudTie/loader.min.js","hash":"e73fcd885be2c4585f154861c9969e3c955d03e3","modified":1531818655633},{"_id":"public/js/main.js","hash":"26688338ac55bed772e630099d2ce1ed69ef1431","modified":1531818655633},{"_id":"public/js/cloudTie/mobile.min.js","hash":"859e3efb15db88cedfd18f8523ecfd21f3a22324","modified":1531818655633},{"_id":"public/js/cloudTie/pc.min.js","hash":"aea28510192fb36a36bf174716a39afd1ca20240","modified":1531818655633},{"_id":"public/js/cloudTie/mobile.js","hash":"67a0a31ee1e491635369b0401d629e97fccd4d94","modified":1531818655633},{"_id":"public/js/cloudTie/pc.js","hash":"25d4ae345f8122f8c7e8e48959d37523dd1e4abb","modified":1531818655633},{"_id":"public/img/wechat.jpg","hash":"b77bf94cae10f3e15c927a1871003c567c3d6fcc","modified":1531818655633},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1531818655635},{"_id":"public/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1531818655635},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1531818655636},{"_id":"public/css/cloudTie/mobile.css","hash":"1b3dd9263c84bdc017669bbbb128574265bb8143","modified":1531818655656},{"_id":"public/img/avatar.jpg","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1531818655656},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1531818655724},{"_id":"public/css/style.css","hash":"acc289383207a1fd2534c7d426be55ecaee39e50","modified":1531818656415},{"_id":"public/css/cloudTie/pc.css","hash":"609fa486186db92f853ec13cec2d55a26266419e","modified":1531818656415}],"Category":[],"Data":[],"Page":[{"noDate":true,"comments":1,"reward":false,"title":"Links","_content":"\n>排名不分先后 :)\n\n| DA LAO | Names | Links |\n|:-------|:------|:------|\n|刘世民|世民谈云计算|[http://www.cnblogs.com/sammyliu/](hhttp://www.cnblogs.com/sammyliu/)|\n|孔令贤|技术改变世界|[https://lingxiankong.github.io/](https://lingxiankong.github.io/)|\n|付广平|int32bit|[http://int32bit.me/](http://int32bit.me/)|\n|姜逸坤|Yikun|[http://yikun.github.io/](http://yikun.github.io/)|\n|陈沙克|陈沙克日志|[http://www.chenshake.com/](http://www.chenshake.com/)|\n|陈皓|CoolShell|[http://coolshell.cn/](http://coolshell.cn/)|\n|阮一峰|阮一峰的个人网站|[http://www.ruanyifeng.com/home.html](http://www.ruanyifeng.com/home.html)|\n|廖雪峰|廖雪峰的官方网站|[https://www.liaoxuefeng.com/](https://www.liaoxuefeng.com/)|\n|..|..|[..](..)|\n\n\n| Friends | Links |\n|:--------|:------|\n|郭建祥|[guojianxiang.com](http://guojianxiang.com/)|\n|浩哥|[iyeele.com](http://www.iyeele.com/)|\n|高文|[wencst.com](http://www.wencst.com/)|\n|壮壮|[l-zz.cn](http://l-zz.cn)|\n|dwon|[bt91.net](http://www.bt91.net/)|\n|董桐|[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)|\n|LYang|[ly798.github.io/](http://ly798.github.io/)|\n|王昱森|[imys.net](http://imys.net)|\n|blkart|[blog.blkart.org](http://blog.blkart.org/)|\n\n\n>排名真的不分先后 :)\n\n","source":"links/index.md","raw":"---\nnoDate: true\ncomments: true\nreward: false\ntitle: Links\n---\n\n>排名不分先后 :)\n\n| DA LAO | Names | Links |\n|:-------|:------|:------|\n|刘世民|世民谈云计算|[http://www.cnblogs.com/sammyliu/](hhttp://www.cnblogs.com/sammyliu/)|\n|孔令贤|技术改变世界|[https://lingxiankong.github.io/](https://lingxiankong.github.io/)|\n|付广平|int32bit|[http://int32bit.me/](http://int32bit.me/)|\n|姜逸坤|Yikun|[http://yikun.github.io/](http://yikun.github.io/)|\n|陈沙克|陈沙克日志|[http://www.chenshake.com/](http://www.chenshake.com/)|\n|陈皓|CoolShell|[http://coolshell.cn/](http://coolshell.cn/)|\n|阮一峰|阮一峰的个人网站|[http://www.ruanyifeng.com/home.html](http://www.ruanyifeng.com/home.html)|\n|廖雪峰|廖雪峰的官方网站|[https://www.liaoxuefeng.com/](https://www.liaoxuefeng.com/)|\n|..|..|[..](..)|\n\n\n| Friends | Links |\n|:--------|:------|\n|郭建祥|[guojianxiang.com](http://guojianxiang.com/)|\n|浩哥|[iyeele.com](http://www.iyeele.com/)|\n|高文|[wencst.com](http://www.wencst.com/)|\n|壮壮|[l-zz.cn](http://l-zz.cn)|\n|dwon|[bt91.net](http://www.bt91.net/)|\n|董桐|[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)|\n|LYang|[ly798.github.io/](http://ly798.github.io/)|\n|王昱森|[imys.net](http://imys.net)|\n|blkart|[blog.blkart.org](http://blog.blkart.org/)|\n\n\n>排名真的不分先后 :)\n\n","date":"2018-02-24T09:25:27.600Z","updated":"2018-02-24T09:25:27.587Z","path":"links/index.html","layout":"page","_id":"cjjph9wwg0001xu2zb5ozab6l","content":"<blockquote>\n<p>排名不分先后 :)</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">DA LAO</th>\n<th style=\"text-align:left\">Names</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">刘世民</td>\n<td style=\"text-align:left\">世民谈云计算</td>\n<td style=\"text-align:left\"><a href=\"hhttp://www.cnblogs.com/sammyliu/\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/sammyliu/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">孔令贤</td>\n<td style=\"text-align:left\">技术改变世界</td>\n<td style=\"text-align:left\"><a href=\"https://lingxiankong.github.io/\" target=\"_blank\" rel=\"noopener\">https://lingxiankong.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">付广平</td>\n<td style=\"text-align:left\">int32bit</td>\n<td style=\"text-align:left\"><a href=\"http://int32bit.me/\" target=\"_blank\" rel=\"noopener\">http://int32bit.me/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">姜逸坤</td>\n<td style=\"text-align:left\">Yikun</td>\n<td style=\"text-align:left\"><a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">http://yikun.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">陈沙克</td>\n<td style=\"text-align:left\">陈沙克日志</td>\n<td style=\"text-align:left\"><a href=\"http://www.chenshake.com/\" target=\"_blank\" rel=\"noopener\">http://www.chenshake.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">陈皓</td>\n<td style=\"text-align:left\">CoolShell</td>\n<td style=\"text-align:left\"><a href=\"http://coolshell.cn/\" target=\"_blank\" rel=\"noopener\">http://coolshell.cn/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">阮一峰</td>\n<td style=\"text-align:left\">阮一峰的个人网站</td>\n<td style=\"text-align:left\"><a href=\"http://www.ruanyifeng.com/home.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/home.html</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">廖雪峰</td>\n<td style=\"text-align:left\">廖雪峰的官方网站</td>\n<td style=\"text-align:left\"><a href=\"https://www.liaoxuefeng.com/\" target=\"_blank\" rel=\"noopener\">https://www.liaoxuefeng.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">..</td>\n<td style=\"text-align:left\">..</td>\n<td style=\"text-align:left\"><a href=\"..\">..</a></td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Friends</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">郭建祥</td>\n<td style=\"text-align:left\"><a href=\"http://guojianxiang.com/\" target=\"_blank\" rel=\"noopener\">guojianxiang.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">浩哥</td>\n<td style=\"text-align:left\"><a href=\"http://www.iyeele.com/\" target=\"_blank\" rel=\"noopener\">iyeele.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">高文</td>\n<td style=\"text-align:left\"><a href=\"http://www.wencst.com/\" target=\"_blank\" rel=\"noopener\">wencst.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">壮壮</td>\n<td style=\"text-align:left\"><a href=\"http://l-zz.cn\" target=\"_blank\" rel=\"noopener\">l-zz.cn</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dwon</td>\n<td style=\"text-align:left\"><a href=\"http://www.bt91.net/\" target=\"_blank\" rel=\"noopener\">bt91.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">董桐</td>\n<td style=\"text-align:left\"><a href=\"http://www.cnblogs.com/ytu2010dt/\" target=\"_blank\" rel=\"noopener\">www.cnblogs.com/ytu2010dt</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">LYang</td>\n<td style=\"text-align:left\"><a href=\"http://ly798.github.io/\" target=\"_blank\" rel=\"noopener\">ly798.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">王昱森</td>\n<td style=\"text-align:left\"><a href=\"http://imys.net\" target=\"_blank\" rel=\"noopener\">imys.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">blkart</td>\n<td style=\"text-align:left\"><a href=\"http://blog.blkart.org/\" target=\"_blank\" rel=\"noopener\">blog.blkart.org</a></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>排名真的不分先后 :)</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>排名不分先后 :)</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">DA LAO</th>\n<th style=\"text-align:left\">Names</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">刘世民</td>\n<td style=\"text-align:left\">世民谈云计算</td>\n<td style=\"text-align:left\"><a href=\"hhttp://www.cnblogs.com/sammyliu/\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/sammyliu/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">孔令贤</td>\n<td style=\"text-align:left\">技术改变世界</td>\n<td style=\"text-align:left\"><a href=\"https://lingxiankong.github.io/\" target=\"_blank\" rel=\"noopener\">https://lingxiankong.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">付广平</td>\n<td style=\"text-align:left\">int32bit</td>\n<td style=\"text-align:left\"><a href=\"http://int32bit.me/\" target=\"_blank\" rel=\"noopener\">http://int32bit.me/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">姜逸坤</td>\n<td style=\"text-align:left\">Yikun</td>\n<td style=\"text-align:left\"><a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">http://yikun.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">陈沙克</td>\n<td style=\"text-align:left\">陈沙克日志</td>\n<td style=\"text-align:left\"><a href=\"http://www.chenshake.com/\" target=\"_blank\" rel=\"noopener\">http://www.chenshake.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">陈皓</td>\n<td style=\"text-align:left\">CoolShell</td>\n<td style=\"text-align:left\"><a href=\"http://coolshell.cn/\" target=\"_blank\" rel=\"noopener\">http://coolshell.cn/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">阮一峰</td>\n<td style=\"text-align:left\">阮一峰的个人网站</td>\n<td style=\"text-align:left\"><a href=\"http://www.ruanyifeng.com/home.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/home.html</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">廖雪峰</td>\n<td style=\"text-align:left\">廖雪峰的官方网站</td>\n<td style=\"text-align:left\"><a href=\"https://www.liaoxuefeng.com/\" target=\"_blank\" rel=\"noopener\">https://www.liaoxuefeng.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">..</td>\n<td style=\"text-align:left\">..</td>\n<td style=\"text-align:left\"><a href=\"..\">..</a></td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Friends</th>\n<th style=\"text-align:left\">Links</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">郭建祥</td>\n<td style=\"text-align:left\"><a href=\"http://guojianxiang.com/\" target=\"_blank\" rel=\"noopener\">guojianxiang.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">浩哥</td>\n<td style=\"text-align:left\"><a href=\"http://www.iyeele.com/\" target=\"_blank\" rel=\"noopener\">iyeele.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">高文</td>\n<td style=\"text-align:left\"><a href=\"http://www.wencst.com/\" target=\"_blank\" rel=\"noopener\">wencst.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">壮壮</td>\n<td style=\"text-align:left\"><a href=\"http://l-zz.cn\" target=\"_blank\" rel=\"noopener\">l-zz.cn</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dwon</td>\n<td style=\"text-align:left\"><a href=\"http://www.bt91.net/\" target=\"_blank\" rel=\"noopener\">bt91.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">董桐</td>\n<td style=\"text-align:left\"><a href=\"http://www.cnblogs.com/ytu2010dt/\" target=\"_blank\" rel=\"noopener\">www.cnblogs.com/ytu2010dt</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">LYang</td>\n<td style=\"text-align:left\"><a href=\"http://ly798.github.io/\" target=\"_blank\" rel=\"noopener\">ly798.github.io/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">王昱森</td>\n<td style=\"text-align:left\"><a href=\"http://imys.net\" target=\"_blank\" rel=\"noopener\">imys.net</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">blkart</td>\n<td style=\"text-align:left\"><a href=\"http://blog.blkart.org/\" target=\"_blank\" rel=\"noopener\">blog.blkart.org</a></td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>排名真的不分先后 :)</p>\n</blockquote>\n"},{"noDate":true,"comments":0,"reward":false,"layout":"tags","_content":"","source":"tags/index.md","raw":"noDate: true\ncomments: false\nreward: false\nlayout: tags\n---","date":"2017-07-01T12:43:53.000Z","updated":"2017-07-01T12:43:53.000Z","path":"tags/index.html","title":"","_id":"cjjph9wwm0003xu2zwkaxway6","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"MongoDB复制集Secondary节点持续Recovering状态解决办法","date":"2016-04-26T21:51:27.000Z","_content":"\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","source":"_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","raw":"---\ntitle: MongoDB复制集Secondary节点持续Recovering状态解决办法\ndate: 2016-04-27 05:51:27\ntags: [MongoDB]\n---\n\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","slug":"MongoDB复制集Secondary节点持续Recovering状态解决办法","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wwa0000xu2zpw3kb75z","content":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\" target=\"_blank\" rel=\"noopener\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<a id=\"more\"></a>当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\" target=\"_blank\" rel=\"noopener\">官方文档</a>，这里就不赘述了。</p>\n","site":{"data":{}},"excerpt":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\" target=\"_blank\" rel=\"noopener\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……","more":"当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\" target=\"_blank\" rel=\"noopener\">官方文档</a>，这里就不赘述了。</p>"},{"title":"简述StringBuilder和StringBuffer的区别","date":"2016-09-05T06:36:37.000Z","_content":"\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/difference-between-stringbuilder-and-stringbuffer.md","raw":"---\ntitle: 简述StringBuilder和StringBuffer的区别\ndate: 2016-09-05 14:36:37\ntags: [Java]\n---\n\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","slug":"difference-between-stringbuilder-and-stringbuffer","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wwj0002xu2z82622otr","content":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\" target=\"_blank\" rel=\"noopener\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛<a id=\"more\"></a>，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\" target=\"_blank\" rel=\"noopener\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\" target=\"_blank\" rel=\"noopener\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\" target=\"_blank\" rel=\"noopener\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\" target=\"_blank\" rel=\"noopener\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\" target=\"_blank\" rel=\"noopener\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\" target=\"_blank\" rel=\"noopener\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛","more":"，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\" target=\"_blank\" rel=\"noopener\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\" target=\"_blank\" rel=\"noopener\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\" target=\"_blank\" rel=\"noopener\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\" target=\"_blank\" rel=\"noopener\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\" target=\"_blank\" rel=\"noopener\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>"},{"title":"几个概念：并发、并行、进程、线程和协程","date":"2017-01-20T02:11:19.000Z","_content":"\n“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书[《不一样的技术创新》](https://102.alibaba.com/newsInfo.htm?newsId=28&channel=127)中看到这样一句话。<!-- more -->看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如[Akka](http://akka.io/)起一个头。\n\n## 并发和并行\n\n在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。\n\n### 并发（Concurrency）\n\n并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png)\n\n比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。\n\n### 并行（Parallelism）\n\n并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png)\n\n比如吃饭的同时，我还能打电话，这就是并行。\n\n### 对比\n\n由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。\n\n另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。\n\n并发与顺序相对，而并行是并发的子集。\n\n这里还有一个更形象的例子：\n![](http://elbarco.eos.eayun.com/imgs/con_and_par.jpg)\n\n\n## 进程、线程和协程\n\n### 进程（Process）\n\n是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。\n\n### 线程（Thread）\n\n线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。\n\n### 协程（Coroutine, Fiber）\n\n协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考[廖雪峰的文章](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000)，举个例子：\n如果有两个子程序A和B：\n```python\ndef A():\n    print '1'\n    print '2'\n    print '3'\n\ndef B():\n    print 'x'\n    print 'y'\n    print 'z'\n```\n\n对于这两个子程序，一次调用，一次返回，返回结果很有可能是：\n```\n1\n2\n3\nx\ny\nz\n```\n而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：\n```\n1\n2\nx\ny\n3\nz\n```\n有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。\n\n### Java与协程\n\nJava语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。\n\n\n\n\n\n","source":"_posts/general-concepts-concurrency-parallelism-process-thread-coroutine.md","raw":"---\ntitle: 几个概念：并发、并行、进程、线程和协程\ndate: 2017-01-20 10:11:19\ntags: [Concurrency, Parallelism, Coroutine]\n---\n\n“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书[《不一样的技术创新》](https://102.alibaba.com/newsInfo.htm?newsId=28&channel=127)中看到这样一句话。<!-- more -->看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如[Akka](http://akka.io/)起一个头。\n\n## 并发和并行\n\n在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。\n\n### 并发（Concurrency）\n\n并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png)\n\n比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。\n\n### 并行（Parallelism）\n\n并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。\n![](http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png)\n\n比如吃饭的同时，我还能打电话，这就是并行。\n\n### 对比\n\n由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。\n\n另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。\n\n并发与顺序相对，而并行是并发的子集。\n\n这里还有一个更形象的例子：\n![](http://elbarco.eos.eayun.com/imgs/con_and_par.jpg)\n\n\n## 进程、线程和协程\n\n### 进程（Process）\n\n是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。\n\n### 线程（Thread）\n\n线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。\n\n### 协程（Coroutine, Fiber）\n\n协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考[廖雪峰的文章](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000)，举个例子：\n如果有两个子程序A和B：\n```python\ndef A():\n    print '1'\n    print '2'\n    print '3'\n\ndef B():\n    print 'x'\n    print 'y'\n    print 'z'\n```\n\n对于这两个子程序，一次调用，一次返回，返回结果很有可能是：\n```\n1\n2\n3\nx\ny\nz\n```\n而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：\n```\n1\n2\nx\ny\n3\nz\n```\n有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。\n\n### Java与协程\n\nJava语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。\n\n\n\n\n\n","slug":"general-concepts-concurrency-parallelism-process-thread-coroutine","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wwr0005xu2z4eaq4tla","content":"<p>“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书<a href=\"https://102.alibaba.com/newsInfo.htm?newsId=28&amp;channel=127\" target=\"_blank\" rel=\"noopener\">《不一样的技术创新》</a>中看到这样一句话。<a id=\"more\"></a>看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如<a href=\"http://akka.io/\" target=\"_blank\" rel=\"noopener\">Akka</a>起一个头。</p>\n<h2 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h2><p>在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。</p>\n<h3 id=\"并发（Concurrency）\"><a href=\"#并发（Concurrency）\" class=\"headerlink\" title=\"并发（Concurrency）\"></a>并发（Concurrency）</h3><p>并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png\" alt=\"\"></p>\n<p>比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。</p>\n<h3 id=\"并行（Parallelism）\"><a href=\"#并行（Parallelism）\" class=\"headerlink\" title=\"并行（Parallelism）\"></a>并行（Parallelism）</h3><p>并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png\" alt=\"\"></p>\n<p>比如吃饭的同时，我还能打电话，这就是并行。</p>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h3><p>由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。</p>\n<p>另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。</p>\n<p>并发与顺序相对，而并行是并发的子集。</p>\n<p>这里还有一个更形象的例子：<br><img src=\"http://elbarco.eos.eayun.com/imgs/con_and_par.jpg\" alt=\"\"></p>\n<h2 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h2><h3 id=\"进程（Process）\"><a href=\"#进程（Process）\" class=\"headerlink\" title=\"进程（Process）\"></a>进程（Process）</h3><p>是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。</p>\n<h3 id=\"线程（Thread）\"><a href=\"#线程（Thread）\" class=\"headerlink\" title=\"线程（Thread）\"></a>线程（Thread）</h3><p>线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。</p>\n<h3 id=\"协程（Coroutine-Fiber）\"><a href=\"#协程（Coroutine-Fiber）\" class=\"headerlink\" title=\"协程（Coroutine, Fiber）\"></a>协程（Coroutine, Fiber）</h3><p>协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考<a href=\"http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000\" target=\"_blank\" rel=\"noopener\">廖雪峰的文章</a>，举个例子：<br>如果有两个子程序A和B：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">A</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'1'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'2'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'3'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">B</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'x'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'y'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'z'</span></span><br></pre></td></tr></table></figure></p>\n<p>对于这两个子程序，一次调用，一次返回，返回结果很有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">3</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。</p>\n<h3 id=\"Java与协程\"><a href=\"#Java与协程\" class=\"headerlink\" title=\"Java与协程\"></a>Java与协程</h3><p>Java语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。</p>\n","site":{"data":{}},"excerpt":"<p>“有了协程框架再也不用关注线程池调度问题”，在阿里双十一电子书<a href=\"https://102.alibaba.com/newsInfo.htm?newsId=28&amp;channel=127\" target=\"_blank\" rel=\"noopener\">《不一样的技术创新》</a>中看到这样一句话。","more":"看到这句话的时候，内心活动是这样的——当我们还在玩线程池的时候，阿里的爸爸们已经在研究调度问题并有解决方案了。所以保持对这句话的质疑和思考，有了今天的整理和学习，为进一步学习协程框架，如<a href=\"http://akka.io/\" target=\"_blank\" rel=\"noopener\">Akka</a>起一个头。</p>\n<h2 id=\"并发和并行\"><a href=\"#并发和并行\" class=\"headerlink\" title=\"并发和并行\"></a>并发和并行</h2><p>在多线程编程中，并发（Concurrency）和并行（Parallelism）这两个概念时常会被提到，但是这两个概念却不是一个意思。</p>\n<h3 id=\"并发（Concurrency）\"><a href=\"#并发（Concurrency）\" class=\"headerlink\" title=\"并发（Concurrency）\"></a>并发（Concurrency）</h3><p>并发指的是应用程序同时处理多个任务，多个任务都能同时取得进展。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-1.png\" alt=\"\"></p>\n<p>比如吃饭的时候，电话来了，停下手和嘴去接电话，打完电话继续吃饭，这叫并发。</p>\n<h3 id=\"并行（Parallelism）\"><a href=\"#并行（Parallelism）\" class=\"headerlink\" title=\"并行（Parallelism）\"></a>并行（Parallelism）</h3><p>并行指的是应用可以将任务拆成更小的子任务，而这些子任务可以同时平行着被处理。<br><img src=\"http://elbarco.eos.eayun.com/imgs/concurrency-vs-parallelism-2.png\" alt=\"\"></p>\n<p>比如吃饭的同时，我还能打电话，这就是并行。</p>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h3><p>由上面可以看出，并发依赖于应用如何处理多任务。应用同时只能处理一个任务，处理完在进行下一个任务，这叫顺序地（Sequentially）执行；如果应用同时能处理多个任务，这就叫并发地。</p>\n<p>另一方面，并行，则依赖于应用如何处理每个独立的任务。应用可以顺序的将任务从头至尾的执行完，也可以将任务分解成子任务，而子任务可以平行执行。</p>\n<p>并发与顺序相对，而并行是并发的子集。</p>\n<p>这里还有一个更形象的例子：<br><img src=\"http://elbarco.eos.eayun.com/imgs/con_and_par.jpg\" alt=\"\"></p>\n<h2 id=\"进程、线程和协程\"><a href=\"#进程、线程和协程\" class=\"headerlink\" title=\"进程、线程和协程\"></a>进程、线程和协程</h2><h3 id=\"进程（Process）\"><a href=\"#进程（Process）\" class=\"headerlink\" title=\"进程（Process）\"></a>进程（Process）</h3><p>是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。</p>\n<h3 id=\"线程（Thread）\"><a href=\"#线程（Thread）\" class=\"headerlink\" title=\"线程（Thread）\"></a>线程（Thread）</h3><p>线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。</p>\n<h3 id=\"协程（Coroutine-Fiber）\"><a href=\"#协程（Coroutine-Fiber）\" class=\"headerlink\" title=\"协程（Coroutine, Fiber）\"></a>协程（Coroutine, Fiber）</h3><p>协程，又称为微线程，在Lua、Python、Go中有所体现。这里参考<a href=\"http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000\" target=\"_blank\" rel=\"noopener\">廖雪峰的文章</a>，举个例子：<br>如果有两个子程序A和B：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">A</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'1'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'2'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'3'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">B</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'x'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'y'</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'z'</span></span><br></pre></td></tr></table></figure></p>\n<p>对于这两个子程序，一次调用，一次返回，返回结果很有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>而协程看上去虽然也是子程序，但是在执行过程中，在子程序内部可以中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。比如上面的两个子程序假设由协程执行，那么再执行A的过程中，可以随时终端，去执行B，B也有可能在执行过程中中断再去执行A，结果有可能是：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">x</span><br><span class=\"line\">y</span><br><span class=\"line\">3</span><br><span class=\"line\">z</span><br></pre></td></tr></table></figure></p>\n<p>有些类似多线程，但是协程的特点实在一个线程中执行。其优势就是具有极高的执行效率，因为执行过程中不需要县城切换，减少了CPU切换线程的开销。另一方面，避免了多线程的锁机制，不会存在同时的写冲突。</p>\n<h3 id=\"Java与协程\"><a href=\"#Java与协程\" class=\"headerlink\" title=\"Java与协程\"></a>Java与协程</h3><p>Java语言本身不支持协程，通过第三方的库、协程框架可以实现，如注明的akka，kilim等。</p>"},{"title":"并发编程模型之Actor模型","date":"2017-01-21T09:30:30.000Z","_content":"\n\n上一篇文章[《几个概念：并发、并行、进程、线程和协程》](https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/)中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。\n\n<!--more-->\n\n## 两种并发编程模型\n\n并发编程中有两类常见的模型：共享内存和消息传递。\n\n### 共享内存模型\n\n![](http://elbarco.eos.eayun.com/imgs/shared-memory.png)\n\n在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。\n\n共享内存模型的其他示例：\n* A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存\n* A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写\n* A、B是同一Java程序中的两个线程，共享相同的Java对象。\n\n### 消息传递模型\n\n![](http://elbarco.eos.eayun.com/imgs/message-passing.png)\n\n在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。\n\n消息传递模型的示例还有：\n* A和B是通网络中的两台计算机，通过网络通讯\n* A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A\n\n## Actor模型\n\n### 认识Actor模型\n\n上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：\n* 将有限数量的消息传递给其他的actor\n* 产生有限数量的新的actor\n* 当下一个传入的消息被处理时，改变自己的内部行为\n\nactor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，\n\nactor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。\n\n支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。\n\n## 写在后面\n\n本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。\n\n\n## 参考资料\n\n[1].MIT.6.005.[Reading 17:Concurrency](http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/)\n[2].Wikipedia.[Actor Model](https://en.wikipedia.org/wiki/Actor_model)\n[3].Ruben Vermeersch.[Concurrency in Erlang and Scala](https://rocketeer.be/articles/concurrency-in-erlang-scala/)\n[4].Marko Dvečko.[Introduction to Concurrent Programming](https://www.toptal.com/software/introduction-to-concurrent-programming)\n","source":"_posts/introduction-to-actor-model.md","raw":"---\ntitle: 并发编程模型之Actor模型\ndate: 2017-01-21 17:30:30\ntags: [Concurrency, Actor Model]\n---\n\n\n上一篇文章[《几个概念：并发、并行、进程、线程和协程》](https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/)中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。\n\n<!--more-->\n\n## 两种并发编程模型\n\n并发编程中有两类常见的模型：共享内存和消息传递。\n\n### 共享内存模型\n\n![](http://elbarco.eos.eayun.com/imgs/shared-memory.png)\n\n在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。\n\n共享内存模型的其他示例：\n* A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存\n* A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写\n* A、B是同一Java程序中的两个线程，共享相同的Java对象。\n\n### 消息传递模型\n\n![](http://elbarco.eos.eayun.com/imgs/message-passing.png)\n\n在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。\n\n消息传递模型的示例还有：\n* A和B是通网络中的两台计算机，通过网络通讯\n* A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A\n\n## Actor模型\n\n### 认识Actor模型\n\n上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：\n* 将有限数量的消息传递给其他的actor\n* 产生有限数量的新的actor\n* 当下一个传入的消息被处理时，改变自己的内部行为\n\nactor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，\n\nactor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。\n\n支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。\n\n## 写在后面\n\n本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。\n\n\n## 参考资料\n\n[1].MIT.6.005.[Reading 17:Concurrency](http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/)\n[2].Wikipedia.[Actor Model](https://en.wikipedia.org/wiki/Actor_model)\n[3].Ruben Vermeersch.[Concurrency in Erlang and Scala](https://rocketeer.be/articles/concurrency-in-erlang-scala/)\n[4].Marko Dvečko.[Introduction to Concurrent Programming](https://www.toptal.com/software/introduction-to-concurrent-programming)\n","slug":"introduction-to-actor-model","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wwu0006xu2z177bw7i1","content":"<p>上一篇文章<a href=\"https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/\">《几个概念：并发、并行、进程、线程和协程》</a>中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。</p>\n<a id=\"more\"></a>\n<h2 id=\"两种并发编程模型\"><a href=\"#两种并发编程模型\" class=\"headerlink\" title=\"两种并发编程模型\"></a>两种并发编程模型</h2><p>并发编程中有两类常见的模型：共享内存和消息传递。</p>\n<h3 id=\"共享内存模型\"><a href=\"#共享内存模型\" class=\"headerlink\" title=\"共享内存模型\"></a>共享内存模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/shared-memory.png\" alt=\"\"></p>\n<p>在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。</p>\n<p>共享内存模型的其他示例：</p>\n<ul>\n<li>A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存</li>\n<li>A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写</li>\n<li>A、B是同一Java程序中的两个线程，共享相同的Java对象。</li>\n</ul>\n<h3 id=\"消息传递模型\"><a href=\"#消息传递模型\" class=\"headerlink\" title=\"消息传递模型\"></a>消息传递模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/message-passing.png\" alt=\"\"></p>\n<p>在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。</p>\n<p>消息传递模型的示例还有：</p>\n<ul>\n<li>A和B是通网络中的两台计算机，通过网络通讯</li>\n<li>A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A</li>\n</ul>\n<h2 id=\"Actor模型\"><a href=\"#Actor模型\" class=\"headerlink\" title=\"Actor模型\"></a>Actor模型</h2><h3 id=\"认识Actor模型\"><a href=\"#认识Actor模型\" class=\"headerlink\" title=\"认识Actor模型\"></a>认识Actor模型</h3><p>上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：</p>\n<ul>\n<li>将有限数量的消息传递给其他的actor</li>\n<li>产生有限数量的新的actor</li>\n<li>当下一个传入的消息被处理时，改变自己的内部行为</li>\n</ul>\n<p>actor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，</p>\n<p>actor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。</p>\n<p>支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。</p>\n<h2 id=\"写在后面\"><a href=\"#写在后面\" class=\"headerlink\" title=\"写在后面\"></a>写在后面</h2><p>本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1].MIT.6.005.<a href=\"http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/\" target=\"_blank\" rel=\"noopener\">Reading 17:Concurrency</a><br>[2].Wikipedia.<a href=\"https://en.wikipedia.org/wiki/Actor_model\" target=\"_blank\" rel=\"noopener\">Actor Model</a><br>[3].Ruben Vermeersch.<a href=\"https://rocketeer.be/articles/concurrency-in-erlang-scala/\" target=\"_blank\" rel=\"noopener\">Concurrency in Erlang and Scala</a><br>[4].Marko Dvečko.<a href=\"https://www.toptal.com/software/introduction-to-concurrent-programming\" target=\"_blank\" rel=\"noopener\">Introduction to Concurrent Programming</a></p>\n","site":{"data":{}},"excerpt":"<p>上一篇文章<a href=\"https://elbarco.cn/2017/01/20/general-concepts-concurrency-parallelism-process-thread-coroutine/\">《几个概念：并发、并行、进程、线程和协程》</a>中，对并发和并行的概念做了一个简单的解释，而本文中则从两种并发编程模型讲起，简单的介绍一下Actor模型。</p>","more":"<h2 id=\"两种并发编程模型\"><a href=\"#两种并发编程模型\" class=\"headerlink\" title=\"两种并发编程模型\"></a>两种并发编程模型</h2><p>并发编程中有两类常见的模型：共享内存和消息传递。</p>\n<h3 id=\"共享内存模型\"><a href=\"#共享内存模型\" class=\"headerlink\" title=\"共享内存模型\"></a>共享内存模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/shared-memory.png\" alt=\"\"></p>\n<p>在并发编程的共享内存模型中，各组件通过读写内存中的共享对象进行交互。</p>\n<p>共享内存模型的其他示例：</p>\n<ul>\n<li>A、B两个在同一个电脑中的处理器（或者同一个处理器的两个核）共享同一物理内存</li>\n<li>A、B两个运行在同一电脑上的程序，共享同一文件系统，其中文件可以读写</li>\n<li>A、B是同一Java程序中的两个线程，共享相同的Java对象。</li>\n</ul>\n<h3 id=\"消息传递模型\"><a href=\"#消息传递模型\" class=\"headerlink\" title=\"消息传递模型\"></a>消息传递模型</h3><p><img src=\"http://elbarco.eos.eayun.com/imgs/message-passing.png\" alt=\"\"></p>\n<p>在消息传递模型中，并发模块通过通信信道将消息发送到彼此进行交互。发出的消息会在队列中等待处理。</p>\n<p>消息传递模型的示例还有：</p>\n<ul>\n<li>A和B是通网络中的两台计算机，通过网络通讯</li>\n<li>A是一个浏览器，B是一个web服务器，A打开连接请求网页，B发送页面数据给A</li>\n</ul>\n<h2 id=\"Actor模型\"><a href=\"#Actor模型\" class=\"headerlink\" title=\"Actor模型\"></a>Actor模型</h2><h3 id=\"认识Actor模型\"><a href=\"#认识Actor模型\" class=\"headerlink\" title=\"认识Actor模型\"></a>认识Actor模型</h3><p>上面我们认识了两种并发模型，actor模型就属于消息传递模型。actor模型的基本思想是使用actor作为并发基元，可以根据接收的消息做出不同的响应（或动作、行为）：</p>\n<ul>\n<li>将有限数量的消息传递给其他的actor</li>\n<li>产生有限数量的新的actor</li>\n<li>当下一个传入的消息被处理时，改变自己的内部行为</li>\n</ul>\n<p>actor模型使用异步消息传递进行通信。特别要指出，actor之间不适用任何中间实体，比如通道，相反的，每个actor拥有可以被寻址的信箱。不要把地址和身份信息弄混淆，每个actor可以有零个、一个或多个地址。当一个actor发送信息时，它必须知道接收方的地址。此外，actor可以给自己发信息，这样他们就可以自己接受信息并且稍后进行处理。注意，这里提到的邮箱并不是概念的一部分，而是一个特性的实现，</p>\n<p>actor模型可以用于并发系统的建模，正是因为每个actor与其他actor完全独立，没有共享状态，则就没有了竞争状态（race condition），actor之间的通讯和交互完全通过异步消息。</p>\n<p>支持actor模型的编程语言有Elixir、Erlang、Scala等，Java语言层面并不支持，但是可以引入Akka，一个用Scala编写的库，用于简化编写容错的、高可伸缩性的Java和Scala的actor模型应用。</p>\n<h2 id=\"写在后面\"><a href=\"#写在后面\" class=\"headerlink\" title=\"写在后面\"></a>写在后面</h2><p>本文重点关注并发编程的两种模型及对Actor模型做一个简单的介绍，Akka的学习会放到后面，由于对Scala不了解，网上看到的例子没有办法贴到这里与大家一起分析。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1].MIT.6.005.<a href=\"http://web.mit.edu/6.005/www/fa14/classes/17-concurrency/\" target=\"_blank\" rel=\"noopener\">Reading 17:Concurrency</a><br>[2].Wikipedia.<a href=\"https://en.wikipedia.org/wiki/Actor_model\" target=\"_blank\" rel=\"noopener\">Actor Model</a><br>[3].Ruben Vermeersch.<a href=\"https://rocketeer.be/articles/concurrency-in-erlang-scala/\" target=\"_blank\" rel=\"noopener\">Concurrency in Erlang and Scala</a><br>[4].Marko Dvečko.<a href=\"https://www.toptal.com/software/introduction-to-concurrent-programming\" target=\"_blank\" rel=\"noopener\">Introduction to Concurrent Programming</a></p>"},{"title":"Git中使用rebase命令更新本地分支","date":"2017-09-28T06:34:49.000Z","_content":"\n最近在开发`trove`中，因为误提交，本地项目的`devel`分支已经与上游的的`devel`分支不一致了<!--more-->。为了更好的创建分支，或者后面进行`cherry-pick`准备打包，都需要将本地的分支与上游的分支做一下rebase。\n\n> 注：上游指的是[`eayunstack/trove`](https://github.com/eayunstack/trove)，本地指的是[`2hf/trove`](https://github.com/2hf/trove)\n\n首先，我们要添加`upstream`远程仓库：\n```\n$ git remote\norigin\n$ git remote add upstream git@github.com:eayunstack/trove.git\n$ git remote -v\norigin  git@github.com:2hf/trove.git (fetch)\norigin  git@github.com:2hf/trove.git (push)\nupstream        git@github.com:eayunstack/trove.git (fetch)\nupstream        git@github.com:eayunstack/trove.git (push)\n\n```\n\n然后更新`upstream`：\n```\n$ git fetch upstream\n```\n\n此时远程仓库已经准备就绪了，这时候我们就可以rebase本地的分支了。两种做法：\n```\n# option one\n$ git checkout devel\n$ git rebase -i upstream/devel\n\n# option two\n$ git checkout devel\n$ git reset --hard upstream/devel\n```\n\n> 注：如果之前`2hf/devel`分支已经做过push了，为了保持与上游一致，需要`git push -f`。\n\n\n","source":"_posts/git-rebase-local-branch-with-upstream-branch.md","raw":"---\ntitle: Git中使用rebase命令更新本地分支\ndate: 2017-09-28 14:34:49\ntags: [Git, rebase]\n---\n\n最近在开发`trove`中，因为误提交，本地项目的`devel`分支已经与上游的的`devel`分支不一致了<!--more-->。为了更好的创建分支，或者后面进行`cherry-pick`准备打包，都需要将本地的分支与上游的分支做一下rebase。\n\n> 注：上游指的是[`eayunstack/trove`](https://github.com/eayunstack/trove)，本地指的是[`2hf/trove`](https://github.com/2hf/trove)\n\n首先，我们要添加`upstream`远程仓库：\n```\n$ git remote\norigin\n$ git remote add upstream git@github.com:eayunstack/trove.git\n$ git remote -v\norigin  git@github.com:2hf/trove.git (fetch)\norigin  git@github.com:2hf/trove.git (push)\nupstream        git@github.com:eayunstack/trove.git (fetch)\nupstream        git@github.com:eayunstack/trove.git (push)\n\n```\n\n然后更新`upstream`：\n```\n$ git fetch upstream\n```\n\n此时远程仓库已经准备就绪了，这时候我们就可以rebase本地的分支了。两种做法：\n```\n# option one\n$ git checkout devel\n$ git rebase -i upstream/devel\n\n# option two\n$ git checkout devel\n$ git reset --hard upstream/devel\n```\n\n> 注：如果之前`2hf/devel`分支已经做过push了，为了保持与上游一致，需要`git push -f`。\n\n\n","slug":"git-rebase-local-branch-with-upstream-branch","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wwx0007xu2z74cm8dxi","content":"<p>最近在开发<code>trove</code>中，因为误提交，本地项目的<code>devel</code>分支已经与上游的的<code>devel</code>分支不一致了<a id=\"more\"></a>。为了更好的创建分支，或者后面进行<code>cherry-pick</code>准备打包，都需要将本地的分支与上游的分支做一下rebase。</p>\n<blockquote>\n<p>注：上游指的是<a href=\"https://github.com/eayunstack/trove\" target=\"_blank\" rel=\"noopener\"><code>eayunstack/trove</code></a>，本地指的是<a href=\"https://github.com/2hf/trove\" target=\"_blank\" rel=\"noopener\"><code>2hf/trove</code></a></p>\n</blockquote>\n<p>首先，我们要添加<code>upstream</code>远程仓库：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git remote</span><br><span class=\"line\">origin</span><br><span class=\"line\">$ git remote add upstream git@github.com:eayunstack/trove.git</span><br><span class=\"line\">$ git remote -v</span><br><span class=\"line\">origin  git@github.com:2hf/trove.git (fetch)</span><br><span class=\"line\">origin  git@github.com:2hf/trove.git (push)</span><br><span class=\"line\">upstream        git@github.com:eayunstack/trove.git (fetch)</span><br><span class=\"line\">upstream        git@github.com:eayunstack/trove.git (push)</span><br></pre></td></tr></table></figure></p>\n<p>然后更新<code>upstream</code>：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git fetch upstream</span><br></pre></td></tr></table></figure></p>\n<p>此时远程仓库已经准备就绪了，这时候我们就可以rebase本地的分支了。两种做法：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># option one</span><br><span class=\"line\">$ git checkout devel</span><br><span class=\"line\">$ git rebase -i upstream/devel</span><br><span class=\"line\"></span><br><span class=\"line\"># option two</span><br><span class=\"line\">$ git checkout devel</span><br><span class=\"line\">$ git reset --hard upstream/devel</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：如果之前<code>2hf/devel</code>分支已经做过push了，为了保持与上游一致，需要<code>git push -f</code>。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>最近在开发<code>trove</code>中，因为误提交，本地项目的<code>devel</code>分支已经与上游的的<code>devel</code>分支不一致了","more":"。为了更好的创建分支，或者后面进行<code>cherry-pick</code>准备打包，都需要将本地的分支与上游的分支做一下rebase。</p>\n<blockquote>\n<p>注：上游指的是<a href=\"https://github.com/eayunstack/trove\" target=\"_blank\" rel=\"noopener\"><code>eayunstack/trove</code></a>，本地指的是<a href=\"https://github.com/2hf/trove\" target=\"_blank\" rel=\"noopener\"><code>2hf/trove</code></a></p>\n</blockquote>\n<p>首先，我们要添加<code>upstream</code>远程仓库：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git remote</span><br><span class=\"line\">origin</span><br><span class=\"line\">$ git remote add upstream git@github.com:eayunstack/trove.git</span><br><span class=\"line\">$ git remote -v</span><br><span class=\"line\">origin  git@github.com:2hf/trove.git (fetch)</span><br><span class=\"line\">origin  git@github.com:2hf/trove.git (push)</span><br><span class=\"line\">upstream        git@github.com:eayunstack/trove.git (fetch)</span><br><span class=\"line\">upstream        git@github.com:eayunstack/trove.git (push)</span><br></pre></td></tr></table></figure></p>\n<p>然后更新<code>upstream</code>：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git fetch upstream</span><br></pre></td></tr></table></figure></p>\n<p>此时远程仓库已经准备就绪了，这时候我们就可以rebase本地的分支了。两种做法：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># option one</span><br><span class=\"line\">$ git checkout devel</span><br><span class=\"line\">$ git rebase -i upstream/devel</span><br><span class=\"line\"></span><br><span class=\"line\"># option two</span><br><span class=\"line\">$ git checkout devel</span><br><span class=\"line\">$ git reset --hard upstream/devel</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：如果之前<code>2hf/devel</code>分支已经做过push了，为了保持与上游一致，需要<code>git push -f</code>。</p>\n</blockquote>"},{"title":"学习和认识Trove Strategies","date":"2017-10-17T07:28:57.000Z","_content":"\n在Trove的[上篇文章](https://elbarco.cn/2017/07/25/introduction-to-trove/)中，我们简单的介绍了一下Trove的架构和各个组件，最近看到一张图，感觉非常清晰，列到这里：\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/openstack-dbaas-trove.png)\n\n看图，可以简单回顾一下，Trove这个基于OpenStack中的计算、存储、网络、镜像等之上的一个DBaaS项目，图中可以看到它的几个组件，以及它跟其他OpenStack组件的交互。\n\n## Trove strategies\n\n对于Trove来讲，其目标就是提供一个数据库无关的功能集，并且可以在框架内实现扩展，这里我们就引入了Trove的Strategies，即策略。 策略是Trove中的一个设计结构，允许开发人员在Trove作为整体框架的前提下，建立指定抽象的新的实现来扩展Trove，举个🌰来说明——\n\n我们知道，无论是MySQL、PostgreSQL等关系型数据库，还是其他的非关系型数据库比如MongoDB、Redis，均提供备份的功能。然而不同数据库的备份功能又有所差别，甚至同一个数据库具有不同的集中方式来产生一个备份。下面结合MySQL备份的消息流转图来说明：\n\n\n### MySQL备份功能中的策略\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/mysql-backup-flow.png)\n\n客户端通过Trove API发起备份的请求，通过阅读代码我们知道调用的API的方法是`trove.backup.service.BackupController#create`，API通过消息队列发起对Task Manager中`create_backup`的异步调用（见`trove.taskmanager.api.API#create_backup`）:\n```python\n    def create_backup(self, backup_info, instance_id):\n        LOG.debug(\"Making async call to create a backup for instance: %s\" %\n                  instance_id)\n\n        self._cast(\"create_backup\", self.version_cap,\n                   backup_info=backup_info,\n                   instance_id=instance_id)\n```\n\n然后Task Manager中（见`trove.taskmanager.manager.Manager#create_backup`）:\n```python\n    def create_backup(self, context, backup_info, instance_id):\n        with EndNotification(context, backup_id=backup_info['id']):\n            instance_tasks = models.BuiltInstanceTasks.load(context,\n                                                            instance_id)\n            instance_tasks.create_backup(backup_info)\n```\n\n其中又调用了BuildInstanceTasks中的`create_backup`方法，这里实际发起了对Guest Agent中备份创建的调用：\n```python\n    def create_backup(self, backup_info):\n        LOG.info(_(\"Initiating backup for instance %s.\") % self.id)\n        self.guest.create_backup(backup_info)\n```\n\n对于MySQL来讲，Guest Agent中我们肯定要去找`trove.guestagent.datastore.mysql_common.manager.MySqlManager`，那么对应的方法就是：\n```python\n    def create_backup(self, context, backup_info):\n        \"\"\"\n        Entry point for initiating a backup for this guest agents db instance.\n        The call currently blocks until the backup is complete or errors. If\n        device_path is specified, it will be mounted based to a point specified\n        in configuration.\n\n        :param backup_info: a dictionary containing the db instance id of the\n                            backup task, location, type, and other data.\n        \"\"\"\n        with EndNotification(context):\n            backup.backup(context, backup_info)\n```\n\n我们在去看看`backup.backup(context, backup_info)`（见`trove.guestagent.backup.backup`）：\n```python\nfrom trove.guestagent.backup.backupagent import BackupAgent\n\nAGENT = BackupAgent()\n\ndef backup(context, backup_info):\n    \"\"\"\n    Main entry point for starting a backup based on the given backup id.  This\n    will create a backup for this DB instance and will then store the backup\n    in a configured repository (e.g. Swift)\n\n    :param context:     the context token which contains the users details\n    :param backup_id:   the id of the persisted backup object\n    \"\"\"\n    return AGENT.execute_backup(context, backup_info)\n```\n\n其中，对实际执行备份，使用的是`trove.guestagent.backup.backupagent.BackupAgent`中的`execute_backup`：\n```python\nCONFIG_MANAGER = CONF.get('mysql'\n                          if not CONF.datastore_manager\n                          else CONF.datastore_manager)\n\nSTRATEGY = CONFIG_MANAGER.backup_strategy\nBACKUP_NAMESPACE = CONFIG_MANAGER.backup_namespace\nRESTORE_NAMESPACE = CONFIG_MANAGER.restore_namespace\nRUNNER = get_backup_strategy(STRATEGY, BACKUP_NAMESPACE)\n\nclass BackupAgent(object):\n    ...\n    def execute_backup(self, context, backup_info,\n                       runner=RUNNER, extra_opts=EXTRA_OPTS,\n                       incremental_runner=INCREMENTAL_RUNNER):\n\n        LOG.debug(\"Running backup %(id)s.\", backup_info)\n        ...\n\n        self.stream_backup_to_storage(context, backup_info, runner, storage,\n                                      parent_metadata, extra_opts)\n```\n\n注意`BACKUP_NAMESPACE`指明了策略的命名空间，这里的`RUNNER`，才是实际加载备份策略的地方，当然，要根据`/trove/common/cfg.py`中的配置：\n```python\n    cfg.StrOpt('backup_namespace',\n               default='trove.guestagent.strategies.backup.mysql_impl',\n               help='Namespace to load backup strategies from.',\n               deprecated_name='backup_namespace',\n               deprecated_group='DEFAULT'),\n    cfg.StrOpt('backup_strategy', default='InnoBackupEx',\n               help='Default strategy to perform backups.',\n               deprecated_name='backup_strategy',\n               deprecated_group='DEFAULT'),\n```\n\n当然，这部分配置我们是可以在`trove-guestagent.conf`中配置的：\n```ini\n# ========== Datastore Specific Configuration Options ==========\n...\n[mysql]\n# For mysql, the following are the defaults for backup, and restore:\nbackup_strategy = InnoBackupEx\nbackup_namespace = trove.guestagent.strategies.backup.mysql_impl\n...\n```\n\n那我们就知道，其实MySQL的备份使用的是`trove.guestagent.strategies.backup.mysql_impl.InnoBackupEx`：\n```python\nclass InnoBackupEx(base.BackupRunner):\n    \"\"\"Implementation of Backup Strategy for InnoBackupEx.\"\"\"\n    __strategy_name__ = 'innobackupex'\n\n    ...\n    @property\n    def cmd(self):\n        cmd = ('sudo innobackupex'\n               ' --stream=xbstream'\n               ' %(extra_opts)s ' +\n               self.user_and_pass +\n               MySqlApp.get_data_dir() +\n               ' 2>/tmp/innobackupex.log'\n               )\n        return cmd + self.zip_cmd + self.encrypt_cmd\n\n    ...\n```\n\n这里额外说一下，究竟是在哪里触发执行的备份呢？\n\n在前面`self.stream_backup_to_storage(context, backup_info, runner, storage,                                    parent_metadata, extra_opts)`中，使用了`with`来执行`runner`：\n```python\n    def stream_backup_to_storage(self, context, backup_info, runner, storage,\n                                 parent_metadata={}, extra_opts=EXTRA_OPTS):\n        ...\n        try:\n            with runner(filename=backup_id, extra_opts=extra_opts,\n                        **parent_metadata) as bkup:\n                LOG.debug(\"Starting backup %s.\", backup_id)\n                ...\n```\n\n即这里，调用了`InnoBackupEx`的构造方法，而`InnoBackupEx`是继承自`BackupRunner`，则：\n```python\nclass BackupRunner(Strategy):\n    \"\"\"Base class for Backup Strategy implementations.\"\"\"\n    __strategy_type__ = 'backup_runner'\n    __strategy_ns__ = 'trove.guestagent.strategies.backup'\n\n    # The actual system call to run the backup\n    cmd = None\n    is_zipped = CONF.backup_use_gzip_compression\n    is_encrypted = CONF.backup_use_openssl_encryption\n    encrypt_key = CONF.backup_aes_cbc_key\n\n    def __init__(self, filename, **kwargs):\n        self.base_filename = filename\n        self.process = None\n        self.pid = None\n        kwargs.update({'filename': filename})\n        self.command = self.cmd % kwargs\n        super(BackupRunner, self).__init__()\n    ...\n    def _run(self):\n        LOG.debug(\"BackupRunner running cmd: %s\", self.command)\n        self.process = subprocess.Popen(self.command, shell=True,\n                                        stdout=subprocess.PIPE,\n                                        stderr=subprocess.PIPE,\n                                        preexec_fn=os.setsid)\n        self.pid = self.process.pid\n\n\n    def __enter__(self):\n        \"\"\"Start up the process.\"\"\"\n        self._run_pre_backup()\n        self._run()\n        return self\n    ...\n```\n\n看到这里，我们就知道备份执行是在哪里触发的了——首先，在构造方法中，通过`self.command = self.cmd % kwargs`获取了`InnoBackupEx`中的`cmd`，然后因为我们使用`with`来调用，则会调用`__enter__(self)`方法，其中的`_run(self)`中使用`Popen`协程来真正的执行。后面补充一篇对`eventlent`和`Popen`的学习心得。\n\n### 其他策略应用场景\n\n除了上面例子中的MySQL备份功能，Trove的Strategies还可以通过扩展Guest Agent、API和Task Manager等来实现集群的功能，比如下面列举了MongoDB中的扩展：\n```python\n    cfg.StrOpt('api_strategy',\n               default='trove.common.strategies.cluster.experimental.'\n               'mongodb.api.MongoDbAPIStrategy',\n               help='Class that implements datastore-specific API logic.'),\n    cfg.StrOpt('taskmanager_strategy',\n               default='trove.common.strategies.cluster.experimental.mongodb.'\n               'taskmanager.MongoDbTaskManagerStrategy',\n               help='Class that implements datastore-specific task manager '\n                    'logic.'),\n    cfg.StrOpt('guestagent_strategy',\n               default='trove.common.strategies.cluster.experimental.'\n               'mongodb.guestagent.MongoDbGuestAgentStrategy',\n               help='Class that implements datastore-specific Guest Agent API '\n                    'logic.'),\n```\n\n当用户请求API`trove.cluster.service.ClusterController#create`，对MongoDB创建集群时，经过各种调用，会去执行`trove.common.strategies.cluster.experimental.mongodb.api.MongoDbCluster#create`来创建MongoDB的Cluster。后面的具体流程我们这里就在赘述了，感兴趣的童鞋可以去阅读一下代码。不过目前在MongoDB集群功能中，还没有区分Replica set和Shard，需要紧跟上游或者自己实现（有位同事最近在做这项功能，还是很有希望提交上游的……这就跑题了😂）\n\n## 结语\n\n本文主要以MySQL备份的代码过程为例，讲解了Trove中的Strategies的应用，了解其基本原理和几个使用场景，同时在看代码的过程中，遇到的新的知识点`eventlet`和`eventlet.green.subprocess.Popen`，值得我们去学习和研究一番。\n\n## 参考\n\n[1].[OpenStack Trove by Amrith Kumar](http://www.apress.com/us/book/9781484212226)\n[2].[OpenStack Architecture](https://www.tesora.com/openstack-trove-architecture/)\n[3].[openstack/trove](https://github.com/openstack/trove)\n\n\n\n\n","source":"_posts/introduction-to-trove-strategies.md","raw":"---\ntitle: 学习和认识Trove Strategies\ndate: 2017-10-17 15:28:57\ntags: [OpenStack, Trove]\n---\n\n在Trove的[上篇文章](https://elbarco.cn/2017/07/25/introduction-to-trove/)中，我们简单的介绍了一下Trove的架构和各个组件，最近看到一张图，感觉非常清晰，列到这里：\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/openstack-dbaas-trove.png)\n\n看图，可以简单回顾一下，Trove这个基于OpenStack中的计算、存储、网络、镜像等之上的一个DBaaS项目，图中可以看到它的几个组件，以及它跟其他OpenStack组件的交互。\n\n## Trove strategies\n\n对于Trove来讲，其目标就是提供一个数据库无关的功能集，并且可以在框架内实现扩展，这里我们就引入了Trove的Strategies，即策略。 策略是Trove中的一个设计结构，允许开发人员在Trove作为整体框架的前提下，建立指定抽象的新的实现来扩展Trove，举个🌰来说明——\n\n我们知道，无论是MySQL、PostgreSQL等关系型数据库，还是其他的非关系型数据库比如MongoDB、Redis，均提供备份的功能。然而不同数据库的备份功能又有所差别，甚至同一个数据库具有不同的集中方式来产生一个备份。下面结合MySQL备份的消息流转图来说明：\n\n\n### MySQL备份功能中的策略\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/mysql-backup-flow.png)\n\n客户端通过Trove API发起备份的请求，通过阅读代码我们知道调用的API的方法是`trove.backup.service.BackupController#create`，API通过消息队列发起对Task Manager中`create_backup`的异步调用（见`trove.taskmanager.api.API#create_backup`）:\n```python\n    def create_backup(self, backup_info, instance_id):\n        LOG.debug(\"Making async call to create a backup for instance: %s\" %\n                  instance_id)\n\n        self._cast(\"create_backup\", self.version_cap,\n                   backup_info=backup_info,\n                   instance_id=instance_id)\n```\n\n然后Task Manager中（见`trove.taskmanager.manager.Manager#create_backup`）:\n```python\n    def create_backup(self, context, backup_info, instance_id):\n        with EndNotification(context, backup_id=backup_info['id']):\n            instance_tasks = models.BuiltInstanceTasks.load(context,\n                                                            instance_id)\n            instance_tasks.create_backup(backup_info)\n```\n\n其中又调用了BuildInstanceTasks中的`create_backup`方法，这里实际发起了对Guest Agent中备份创建的调用：\n```python\n    def create_backup(self, backup_info):\n        LOG.info(_(\"Initiating backup for instance %s.\") % self.id)\n        self.guest.create_backup(backup_info)\n```\n\n对于MySQL来讲，Guest Agent中我们肯定要去找`trove.guestagent.datastore.mysql_common.manager.MySqlManager`，那么对应的方法就是：\n```python\n    def create_backup(self, context, backup_info):\n        \"\"\"\n        Entry point for initiating a backup for this guest agents db instance.\n        The call currently blocks until the backup is complete or errors. If\n        device_path is specified, it will be mounted based to a point specified\n        in configuration.\n\n        :param backup_info: a dictionary containing the db instance id of the\n                            backup task, location, type, and other data.\n        \"\"\"\n        with EndNotification(context):\n            backup.backup(context, backup_info)\n```\n\n我们在去看看`backup.backup(context, backup_info)`（见`trove.guestagent.backup.backup`）：\n```python\nfrom trove.guestagent.backup.backupagent import BackupAgent\n\nAGENT = BackupAgent()\n\ndef backup(context, backup_info):\n    \"\"\"\n    Main entry point for starting a backup based on the given backup id.  This\n    will create a backup for this DB instance and will then store the backup\n    in a configured repository (e.g. Swift)\n\n    :param context:     the context token which contains the users details\n    :param backup_id:   the id of the persisted backup object\n    \"\"\"\n    return AGENT.execute_backup(context, backup_info)\n```\n\n其中，对实际执行备份，使用的是`trove.guestagent.backup.backupagent.BackupAgent`中的`execute_backup`：\n```python\nCONFIG_MANAGER = CONF.get('mysql'\n                          if not CONF.datastore_manager\n                          else CONF.datastore_manager)\n\nSTRATEGY = CONFIG_MANAGER.backup_strategy\nBACKUP_NAMESPACE = CONFIG_MANAGER.backup_namespace\nRESTORE_NAMESPACE = CONFIG_MANAGER.restore_namespace\nRUNNER = get_backup_strategy(STRATEGY, BACKUP_NAMESPACE)\n\nclass BackupAgent(object):\n    ...\n    def execute_backup(self, context, backup_info,\n                       runner=RUNNER, extra_opts=EXTRA_OPTS,\n                       incremental_runner=INCREMENTAL_RUNNER):\n\n        LOG.debug(\"Running backup %(id)s.\", backup_info)\n        ...\n\n        self.stream_backup_to_storage(context, backup_info, runner, storage,\n                                      parent_metadata, extra_opts)\n```\n\n注意`BACKUP_NAMESPACE`指明了策略的命名空间，这里的`RUNNER`，才是实际加载备份策略的地方，当然，要根据`/trove/common/cfg.py`中的配置：\n```python\n    cfg.StrOpt('backup_namespace',\n               default='trove.guestagent.strategies.backup.mysql_impl',\n               help='Namespace to load backup strategies from.',\n               deprecated_name='backup_namespace',\n               deprecated_group='DEFAULT'),\n    cfg.StrOpt('backup_strategy', default='InnoBackupEx',\n               help='Default strategy to perform backups.',\n               deprecated_name='backup_strategy',\n               deprecated_group='DEFAULT'),\n```\n\n当然，这部分配置我们是可以在`trove-guestagent.conf`中配置的：\n```ini\n# ========== Datastore Specific Configuration Options ==========\n...\n[mysql]\n# For mysql, the following are the defaults for backup, and restore:\nbackup_strategy = InnoBackupEx\nbackup_namespace = trove.guestagent.strategies.backup.mysql_impl\n...\n```\n\n那我们就知道，其实MySQL的备份使用的是`trove.guestagent.strategies.backup.mysql_impl.InnoBackupEx`：\n```python\nclass InnoBackupEx(base.BackupRunner):\n    \"\"\"Implementation of Backup Strategy for InnoBackupEx.\"\"\"\n    __strategy_name__ = 'innobackupex'\n\n    ...\n    @property\n    def cmd(self):\n        cmd = ('sudo innobackupex'\n               ' --stream=xbstream'\n               ' %(extra_opts)s ' +\n               self.user_and_pass +\n               MySqlApp.get_data_dir() +\n               ' 2>/tmp/innobackupex.log'\n               )\n        return cmd + self.zip_cmd + self.encrypt_cmd\n\n    ...\n```\n\n这里额外说一下，究竟是在哪里触发执行的备份呢？\n\n在前面`self.stream_backup_to_storage(context, backup_info, runner, storage,                                    parent_metadata, extra_opts)`中，使用了`with`来执行`runner`：\n```python\n    def stream_backup_to_storage(self, context, backup_info, runner, storage,\n                                 parent_metadata={}, extra_opts=EXTRA_OPTS):\n        ...\n        try:\n            with runner(filename=backup_id, extra_opts=extra_opts,\n                        **parent_metadata) as bkup:\n                LOG.debug(\"Starting backup %s.\", backup_id)\n                ...\n```\n\n即这里，调用了`InnoBackupEx`的构造方法，而`InnoBackupEx`是继承自`BackupRunner`，则：\n```python\nclass BackupRunner(Strategy):\n    \"\"\"Base class for Backup Strategy implementations.\"\"\"\n    __strategy_type__ = 'backup_runner'\n    __strategy_ns__ = 'trove.guestagent.strategies.backup'\n\n    # The actual system call to run the backup\n    cmd = None\n    is_zipped = CONF.backup_use_gzip_compression\n    is_encrypted = CONF.backup_use_openssl_encryption\n    encrypt_key = CONF.backup_aes_cbc_key\n\n    def __init__(self, filename, **kwargs):\n        self.base_filename = filename\n        self.process = None\n        self.pid = None\n        kwargs.update({'filename': filename})\n        self.command = self.cmd % kwargs\n        super(BackupRunner, self).__init__()\n    ...\n    def _run(self):\n        LOG.debug(\"BackupRunner running cmd: %s\", self.command)\n        self.process = subprocess.Popen(self.command, shell=True,\n                                        stdout=subprocess.PIPE,\n                                        stderr=subprocess.PIPE,\n                                        preexec_fn=os.setsid)\n        self.pid = self.process.pid\n\n\n    def __enter__(self):\n        \"\"\"Start up the process.\"\"\"\n        self._run_pre_backup()\n        self._run()\n        return self\n    ...\n```\n\n看到这里，我们就知道备份执行是在哪里触发的了——首先，在构造方法中，通过`self.command = self.cmd % kwargs`获取了`InnoBackupEx`中的`cmd`，然后因为我们使用`with`来调用，则会调用`__enter__(self)`方法，其中的`_run(self)`中使用`Popen`协程来真正的执行。后面补充一篇对`eventlent`和`Popen`的学习心得。\n\n### 其他策略应用场景\n\n除了上面例子中的MySQL备份功能，Trove的Strategies还可以通过扩展Guest Agent、API和Task Manager等来实现集群的功能，比如下面列举了MongoDB中的扩展：\n```python\n    cfg.StrOpt('api_strategy',\n               default='trove.common.strategies.cluster.experimental.'\n               'mongodb.api.MongoDbAPIStrategy',\n               help='Class that implements datastore-specific API logic.'),\n    cfg.StrOpt('taskmanager_strategy',\n               default='trove.common.strategies.cluster.experimental.mongodb.'\n               'taskmanager.MongoDbTaskManagerStrategy',\n               help='Class that implements datastore-specific task manager '\n                    'logic.'),\n    cfg.StrOpt('guestagent_strategy',\n               default='trove.common.strategies.cluster.experimental.'\n               'mongodb.guestagent.MongoDbGuestAgentStrategy',\n               help='Class that implements datastore-specific Guest Agent API '\n                    'logic.'),\n```\n\n当用户请求API`trove.cluster.service.ClusterController#create`，对MongoDB创建集群时，经过各种调用，会去执行`trove.common.strategies.cluster.experimental.mongodb.api.MongoDbCluster#create`来创建MongoDB的Cluster。后面的具体流程我们这里就在赘述了，感兴趣的童鞋可以去阅读一下代码。不过目前在MongoDB集群功能中，还没有区分Replica set和Shard，需要紧跟上游或者自己实现（有位同事最近在做这项功能，还是很有希望提交上游的……这就跑题了😂）\n\n## 结语\n\n本文主要以MySQL备份的代码过程为例，讲解了Trove中的Strategies的应用，了解其基本原理和几个使用场景，同时在看代码的过程中，遇到的新的知识点`eventlet`和`eventlet.green.subprocess.Popen`，值得我们去学习和研究一番。\n\n## 参考\n\n[1].[OpenStack Trove by Amrith Kumar](http://www.apress.com/us/book/9781484212226)\n[2].[OpenStack Architecture](https://www.tesora.com/openstack-trove-architecture/)\n[3].[openstack/trove](https://github.com/openstack/trove)\n\n\n\n\n","slug":"introduction-to-trove-strategies","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wx0000axu2z0qmpr84v","content":"<p>在Trove的<a href=\"https://elbarco.cn/2017/07/25/introduction-to-trove/\">上篇文章</a>中，我们简单的介绍了一下Trove的架构和各个组件，最近看到一张图，感觉非常清晰，列到这里：<br><a id=\"more\"></a><br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/openstack-dbaas-trove.png\" alt=\"\"></p>\n<p>看图，可以简单回顾一下，Trove这个基于OpenStack中的计算、存储、网络、镜像等之上的一个DBaaS项目，图中可以看到它的几个组件，以及它跟其他OpenStack组件的交互。</p>\n<h2 id=\"Trove-strategies\"><a href=\"#Trove-strategies\" class=\"headerlink\" title=\"Trove strategies\"></a>Trove strategies</h2><p>对于Trove来讲，其目标就是提供一个数据库无关的功能集，并且可以在框架内实现扩展，这里我们就引入了Trove的Strategies，即策略。 策略是Trove中的一个设计结构，允许开发人员在Trove作为整体框架的前提下，建立指定抽象的新的实现来扩展Trove，举个🌰来说明——</p>\n<p>我们知道，无论是MySQL、PostgreSQL等关系型数据库，还是其他的非关系型数据库比如MongoDB、Redis，均提供备份的功能。然而不同数据库的备份功能又有所差别，甚至同一个数据库具有不同的集中方式来产生一个备份。下面结合MySQL备份的消息流转图来说明：</p>\n<h3 id=\"MySQL备份功能中的策略\"><a href=\"#MySQL备份功能中的策略\" class=\"headerlink\" title=\"MySQL备份功能中的策略\"></a>MySQL备份功能中的策略</h3><p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/mysql-backup-flow.png\" alt=\"\"></p>\n<p>客户端通过Trove API发起备份的请求，通过阅读代码我们知道调用的API的方法是<code>trove.backup.service.BackupController#create</code>，API通过消息队列发起对Task Manager中<code>create_backup</code>的异步调用（见<code>trove.taskmanager.api.API#create_backup</code>）:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, backup_info, instance_id)</span>:</span></span><br><span class=\"line\">    LOG.debug(<span class=\"string\">\"Making async call to create a backup for instance: %s\"</span> %</span><br><span class=\"line\">              instance_id)</span><br><span class=\"line\"></span><br><span class=\"line\">    self._cast(<span class=\"string\">\"create_backup\"</span>, self.version_cap,</span><br><span class=\"line\">               backup_info=backup_info,</span><br><span class=\"line\">               instance_id=instance_id)</span><br></pre></td></tr></table></figure></p>\n<p>然后Task Manager中（见<code>trove.taskmanager.manager.Manager#create_backup</code>）:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, context, backup_info, instance_id)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> EndNotification(context, backup_id=backup_info[<span class=\"string\">'id'</span>]):</span><br><span class=\"line\">        instance_tasks = models.BuiltInstanceTasks.load(context,</span><br><span class=\"line\">                                                        instance_id)</span><br><span class=\"line\">        instance_tasks.create_backup(backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>其中又调用了BuildInstanceTasks中的<code>create_backup</code>方法，这里实际发起了对Guest Agent中备份创建的调用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, backup_info)</span>:</span></span><br><span class=\"line\">    LOG.info(_(<span class=\"string\">\"Initiating backup for instance %s.\"</span>) % self.id)</span><br><span class=\"line\">    self.guest.create_backup(backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>对于MySQL来讲，Guest Agent中我们肯定要去找<code>trove.guestagent.datastore.mysql_common.manager.MySqlManager</code>，那么对应的方法就是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, context, backup_info)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Entry point for initiating a backup for this guest agents db instance.</span></span><br><span class=\"line\"><span class=\"string\">    The call currently blocks until the backup is complete or errors. If</span></span><br><span class=\"line\"><span class=\"string\">    device_path is specified, it will be mounted based to a point specified</span></span><br><span class=\"line\"><span class=\"string\">    in configuration.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param backup_info: a dictionary containing the db instance id of the</span></span><br><span class=\"line\"><span class=\"string\">                        backup task, location, type, and other data.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> EndNotification(context):</span><br><span class=\"line\">        backup.backup(context, backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>我们在去看看<code>backup.backup(context, backup_info)</code>（见<code>trove.guestagent.backup.backup</code>）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> trove.guestagent.backup.backupagent <span class=\"keyword\">import</span> BackupAgent</span><br><span class=\"line\"></span><br><span class=\"line\">AGENT = BackupAgent()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backup</span><span class=\"params\">(context, backup_info)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Main entry point for starting a backup based on the given backup id.  This</span></span><br><span class=\"line\"><span class=\"string\">    will create a backup for this DB instance and will then store the backup</span></span><br><span class=\"line\"><span class=\"string\">    in a configured repository (e.g. Swift)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param context:     the context token which contains the users details</span></span><br><span class=\"line\"><span class=\"string\">    :param backup_id:   the id of the persisted backup object</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> AGENT.execute_backup(context, backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>其中，对实际执行备份，使用的是<code>trove.guestagent.backup.backupagent.BackupAgent</code>中的<code>execute_backup</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">CONFIG_MANAGER = CONF.get(<span class=\"string\">'mysql'</span></span><br><span class=\"line\">                          <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> CONF.datastore_manager</span><br><span class=\"line\">                          <span class=\"keyword\">else</span> CONF.datastore_manager)</span><br><span class=\"line\"></span><br><span class=\"line\">STRATEGY = CONFIG_MANAGER.backup_strategy</span><br><span class=\"line\">BACKUP_NAMESPACE = CONFIG_MANAGER.backup_namespace</span><br><span class=\"line\">RESTORE_NAMESPACE = CONFIG_MANAGER.restore_namespace</span><br><span class=\"line\">RUNNER = get_backup_strategy(STRATEGY, BACKUP_NAMESPACE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BackupAgent</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">execute_backup</span><span class=\"params\">(self, context, backup_info,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                       runner=RUNNER, extra_opts=EXTRA_OPTS,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                       incremental_runner=INCREMENTAL_RUNNER)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">        LOG.debug(<span class=\"string\">\"Running backup %(id)s.\"</span>, backup_info)</span><br><span class=\"line\">        ...</span><br><span class=\"line\"></span><br><span class=\"line\">        self.stream_backup_to_storage(context, backup_info, runner, storage,</span><br><span class=\"line\">                                      parent_metadata, extra_opts)</span><br></pre></td></tr></table></figure></p>\n<p>注意<code>BACKUP_NAMESPACE</code>指明了策略的命名空间，这里的<code>RUNNER</code>，才是实际加载备份策略的地方，当然，要根据<code>/trove/common/cfg.py</code>中的配置：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">cfg.StrOpt(<span class=\"string\">'backup_namespace'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.guestagent.strategies.backup.mysql_impl'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Namespace to load backup strategies from.'</span>,</span><br><span class=\"line\">           deprecated_name=<span class=\"string\">'backup_namespace'</span>,</span><br><span class=\"line\">           deprecated_group=<span class=\"string\">'DEFAULT'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'backup_strategy'</span>, default=<span class=\"string\">'InnoBackupEx'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Default strategy to perform backups.'</span>,</span><br><span class=\"line\">           deprecated_name=<span class=\"string\">'backup_strategy'</span>,</span><br><span class=\"line\">           deprecated_group=<span class=\"string\">'DEFAULT'</span>),</span><br></pre></td></tr></table></figure></p>\n<p>当然，这部分配置我们是可以在<code>trove-guestagent.conf</code>中配置的：<br><figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ========== Datastore Specific Configuration Options ==========</span></span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"section\">[mysql]</span></span><br><span class=\"line\"><span class=\"comment\"># For mysql, the following are the defaults for backup, and restore:</span></span><br><span class=\"line\"><span class=\"attr\">backup_strategy</span> = InnoBackupEx</span><br><span class=\"line\"><span class=\"attr\">backup_namespace</span> = trove.guestagent.strategies.backup.mysql_impl</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那我们就知道，其实MySQL的备份使用的是<code>trove.guestagent.strategies.backup.mysql_impl.InnoBackupEx</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">InnoBackupEx</span><span class=\"params\">(base.BackupRunner)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Implementation of Backup Strategy for InnoBackupEx.\"\"\"</span></span><br><span class=\"line\">    __strategy_name__ = <span class=\"string\">'innobackupex'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cmd</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        cmd = (<span class=\"string\">'sudo innobackupex'</span></span><br><span class=\"line\">               <span class=\"string\">' --stream=xbstream'</span></span><br><span class=\"line\">               <span class=\"string\">' %(extra_opts)s '</span> +</span><br><span class=\"line\">               self.user_and_pass +</span><br><span class=\"line\">               MySqlApp.get_data_dir() +</span><br><span class=\"line\">               <span class=\"string\">' 2&gt;/tmp/innobackupex.log'</span></span><br><span class=\"line\">               )</span><br><span class=\"line\">        <span class=\"keyword\">return</span> cmd + self.zip_cmd + self.encrypt_cmd</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<p>这里额外说一下，究竟是在哪里触发执行的备份呢？</p>\n<p>在前面<code>self.stream_backup_to_storage(context, backup_info, runner, storage,                                    parent_metadata, extra_opts)</code>中，使用了<code>with</code>来执行<code>runner</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">stream_backup_to_storage</span><span class=\"params\">(self, context, backup_info, runner, storage,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                             parent_metadata=&#123;&#125;, extra_opts=EXTRA_OPTS)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">with</span> runner(filename=backup_id, extra_opts=extra_opts,</span><br><span class=\"line\">                    **parent_metadata) <span class=\"keyword\">as</span> bkup:</span><br><span class=\"line\">            LOG.debug(<span class=\"string\">\"Starting backup %s.\"</span>, backup_id)</span><br><span class=\"line\">            ...</span><br></pre></td></tr></table></figure></p>\n<p>即这里，调用了<code>InnoBackupEx</code>的构造方法，而<code>InnoBackupEx</code>是继承自<code>BackupRunner</code>，则：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BackupRunner</span><span class=\"params\">(Strategy)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Base class for Backup Strategy implementations.\"\"\"</span></span><br><span class=\"line\">    __strategy_type__ = <span class=\"string\">'backup_runner'</span></span><br><span class=\"line\">    __strategy_ns__ = <span class=\"string\">'trove.guestagent.strategies.backup'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># The actual system call to run the backup</span></span><br><span class=\"line\">    cmd = <span class=\"keyword\">None</span></span><br><span class=\"line\">    is_zipped = CONF.backup_use_gzip_compression</span><br><span class=\"line\">    is_encrypted = CONF.backup_use_openssl_encryption</span><br><span class=\"line\">    encrypt_key = CONF.backup_aes_cbc_key</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, filename, **kwargs)</span>:</span></span><br><span class=\"line\">        self.base_filename = filename</span><br><span class=\"line\">        self.process = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.pid = <span class=\"keyword\">None</span></span><br><span class=\"line\">        kwargs.update(&#123;<span class=\"string\">'filename'</span>: filename&#125;)</span><br><span class=\"line\">        self.command = self.cmd % kwargs</span><br><span class=\"line\">        super(BackupRunner, self).__init__()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        LOG.debug(<span class=\"string\">\"BackupRunner running cmd: %s\"</span>, self.command)</span><br><span class=\"line\">        self.process = subprocess.Popen(self.command, shell=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">                                        stdout=subprocess.PIPE,</span><br><span class=\"line\">                                        stderr=subprocess.PIPE,</span><br><span class=\"line\">                                        preexec_fn=os.setsid)</span><br><span class=\"line\">        self.pid = self.process.pid</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__enter__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"Start up the process.\"\"\"</span></span><br><span class=\"line\">        self._run_pre_backup()</span><br><span class=\"line\">        self._run()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<p>看到这里，我们就知道备份执行是在哪里触发的了——首先，在构造方法中，通过<code>self.command = self.cmd % kwargs</code>获取了<code>InnoBackupEx</code>中的<code>cmd</code>，然后因为我们使用<code>with</code>来调用，则会调用<code>__enter__(self)</code>方法，其中的<code>_run(self)</code>中使用<code>Popen</code>协程来真正的执行。后面补充一篇对<code>eventlent</code>和<code>Popen</code>的学习心得。</p>\n<h3 id=\"其他策略应用场景\"><a href=\"#其他策略应用场景\" class=\"headerlink\" title=\"其他策略应用场景\"></a>其他策略应用场景</h3><p>除了上面例子中的MySQL备份功能，Trove的Strategies还可以通过扩展Guest Agent、API和Task Manager等来实现集群的功能，比如下面列举了MongoDB中的扩展：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">cfg.StrOpt(<span class=\"string\">'api_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.'</span></span><br><span class=\"line\">           <span class=\"string\">'mongodb.api.MongoDbAPIStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific API logic.'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'taskmanager_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.mongodb.'</span></span><br><span class=\"line\">           <span class=\"string\">'taskmanager.MongoDbTaskManagerStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific task manager '</span></span><br><span class=\"line\">                <span class=\"string\">'logic.'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'guestagent_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.'</span></span><br><span class=\"line\">           <span class=\"string\">'mongodb.guestagent.MongoDbGuestAgentStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific Guest Agent API '</span></span><br><span class=\"line\">                <span class=\"string\">'logic.'</span>),</span><br></pre></td></tr></table></figure></p>\n<p>当用户请求API<code>trove.cluster.service.ClusterController#create</code>，对MongoDB创建集群时，经过各种调用，会去执行<code>trove.common.strategies.cluster.experimental.mongodb.api.MongoDbCluster#create</code>来创建MongoDB的Cluster。后面的具体流程我们这里就在赘述了，感兴趣的童鞋可以去阅读一下代码。不过目前在MongoDB集群功能中，还没有区分Replica set和Shard，需要紧跟上游或者自己实现（有位同事最近在做这项功能，还是很有希望提交上游的……这就跑题了😂）</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>本文主要以MySQL备份的代码过程为例，讲解了Trove中的Strategies的应用，了解其基本原理和几个使用场景，同时在看代码的过程中，遇到的新的知识点<code>eventlet</code>和<code>eventlet.green.subprocess.Popen</code>，值得我们去学习和研究一番。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://www.apress.com/us/book/9781484212226\" target=\"_blank\" rel=\"noopener\">OpenStack Trove by Amrith Kumar</a><br>[2].<a href=\"https://www.tesora.com/openstack-trove-architecture/\" target=\"_blank\" rel=\"noopener\">OpenStack Architecture</a><br>[3].<a href=\"https://github.com/openstack/trove\" target=\"_blank\" rel=\"noopener\">openstack/trove</a></p>\n","site":{"data":{}},"excerpt":"<p>在Trove的<a href=\"https://elbarco.cn/2017/07/25/introduction-to-trove/\">上篇文章</a>中，我们简单的介绍了一下Trove的架构和各个组件，最近看到一张图，感觉非常清晰，列到这里：<br>","more":"<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/openstack-dbaas-trove.png\" alt=\"\"></p>\n<p>看图，可以简单回顾一下，Trove这个基于OpenStack中的计算、存储、网络、镜像等之上的一个DBaaS项目，图中可以看到它的几个组件，以及它跟其他OpenStack组件的交互。</p>\n<h2 id=\"Trove-strategies\"><a href=\"#Trove-strategies\" class=\"headerlink\" title=\"Trove strategies\"></a>Trove strategies</h2><p>对于Trove来讲，其目标就是提供一个数据库无关的功能集，并且可以在框架内实现扩展，这里我们就引入了Trove的Strategies，即策略。 策略是Trove中的一个设计结构，允许开发人员在Trove作为整体框架的前提下，建立指定抽象的新的实现来扩展Trove，举个🌰来说明——</p>\n<p>我们知道，无论是MySQL、PostgreSQL等关系型数据库，还是其他的非关系型数据库比如MongoDB、Redis，均提供备份的功能。然而不同数据库的备份功能又有所差别，甚至同一个数据库具有不同的集中方式来产生一个备份。下面结合MySQL备份的消息流转图来说明：</p>\n<h3 id=\"MySQL备份功能中的策略\"><a href=\"#MySQL备份功能中的策略\" class=\"headerlink\" title=\"MySQL备份功能中的策略\"></a>MySQL备份功能中的策略</h3><p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/mysql-backup-flow.png\" alt=\"\"></p>\n<p>客户端通过Trove API发起备份的请求，通过阅读代码我们知道调用的API的方法是<code>trove.backup.service.BackupController#create</code>，API通过消息队列发起对Task Manager中<code>create_backup</code>的异步调用（见<code>trove.taskmanager.api.API#create_backup</code>）:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, backup_info, instance_id)</span>:</span></span><br><span class=\"line\">    LOG.debug(<span class=\"string\">\"Making async call to create a backup for instance: %s\"</span> %</span><br><span class=\"line\">              instance_id)</span><br><span class=\"line\"></span><br><span class=\"line\">    self._cast(<span class=\"string\">\"create_backup\"</span>, self.version_cap,</span><br><span class=\"line\">               backup_info=backup_info,</span><br><span class=\"line\">               instance_id=instance_id)</span><br></pre></td></tr></table></figure></p>\n<p>然后Task Manager中（见<code>trove.taskmanager.manager.Manager#create_backup</code>）:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, context, backup_info, instance_id)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> EndNotification(context, backup_id=backup_info[<span class=\"string\">'id'</span>]):</span><br><span class=\"line\">        instance_tasks = models.BuiltInstanceTasks.load(context,</span><br><span class=\"line\">                                                        instance_id)</span><br><span class=\"line\">        instance_tasks.create_backup(backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>其中又调用了BuildInstanceTasks中的<code>create_backup</code>方法，这里实际发起了对Guest Agent中备份创建的调用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, backup_info)</span>:</span></span><br><span class=\"line\">    LOG.info(_(<span class=\"string\">\"Initiating backup for instance %s.\"</span>) % self.id)</span><br><span class=\"line\">    self.guest.create_backup(backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>对于MySQL来讲，Guest Agent中我们肯定要去找<code>trove.guestagent.datastore.mysql_common.manager.MySqlManager</code>，那么对应的方法就是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_backup</span><span class=\"params\">(self, context, backup_info)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Entry point for initiating a backup for this guest agents db instance.</span></span><br><span class=\"line\"><span class=\"string\">    The call currently blocks until the backup is complete or errors. If</span></span><br><span class=\"line\"><span class=\"string\">    device_path is specified, it will be mounted based to a point specified</span></span><br><span class=\"line\"><span class=\"string\">    in configuration.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param backup_info: a dictionary containing the db instance id of the</span></span><br><span class=\"line\"><span class=\"string\">                        backup task, location, type, and other data.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> EndNotification(context):</span><br><span class=\"line\">        backup.backup(context, backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>我们在去看看<code>backup.backup(context, backup_info)</code>（见<code>trove.guestagent.backup.backup</code>）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> trove.guestagent.backup.backupagent <span class=\"keyword\">import</span> BackupAgent</span><br><span class=\"line\"></span><br><span class=\"line\">AGENT = BackupAgent()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backup</span><span class=\"params\">(context, backup_info)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Main entry point for starting a backup based on the given backup id.  This</span></span><br><span class=\"line\"><span class=\"string\">    will create a backup for this DB instance and will then store the backup</span></span><br><span class=\"line\"><span class=\"string\">    in a configured repository (e.g. Swift)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    :param context:     the context token which contains the users details</span></span><br><span class=\"line\"><span class=\"string\">    :param backup_id:   the id of the persisted backup object</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> AGENT.execute_backup(context, backup_info)</span><br></pre></td></tr></table></figure></p>\n<p>其中，对实际执行备份，使用的是<code>trove.guestagent.backup.backupagent.BackupAgent</code>中的<code>execute_backup</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">CONFIG_MANAGER = CONF.get(<span class=\"string\">'mysql'</span></span><br><span class=\"line\">                          <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> CONF.datastore_manager</span><br><span class=\"line\">                          <span class=\"keyword\">else</span> CONF.datastore_manager)</span><br><span class=\"line\"></span><br><span class=\"line\">STRATEGY = CONFIG_MANAGER.backup_strategy</span><br><span class=\"line\">BACKUP_NAMESPACE = CONFIG_MANAGER.backup_namespace</span><br><span class=\"line\">RESTORE_NAMESPACE = CONFIG_MANAGER.restore_namespace</span><br><span class=\"line\">RUNNER = get_backup_strategy(STRATEGY, BACKUP_NAMESPACE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BackupAgent</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">execute_backup</span><span class=\"params\">(self, context, backup_info,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                       runner=RUNNER, extra_opts=EXTRA_OPTS,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                       incremental_runner=INCREMENTAL_RUNNER)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">        LOG.debug(<span class=\"string\">\"Running backup %(id)s.\"</span>, backup_info)</span><br><span class=\"line\">        ...</span><br><span class=\"line\"></span><br><span class=\"line\">        self.stream_backup_to_storage(context, backup_info, runner, storage,</span><br><span class=\"line\">                                      parent_metadata, extra_opts)</span><br></pre></td></tr></table></figure></p>\n<p>注意<code>BACKUP_NAMESPACE</code>指明了策略的命名空间，这里的<code>RUNNER</code>，才是实际加载备份策略的地方，当然，要根据<code>/trove/common/cfg.py</code>中的配置：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">cfg.StrOpt(<span class=\"string\">'backup_namespace'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.guestagent.strategies.backup.mysql_impl'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Namespace to load backup strategies from.'</span>,</span><br><span class=\"line\">           deprecated_name=<span class=\"string\">'backup_namespace'</span>,</span><br><span class=\"line\">           deprecated_group=<span class=\"string\">'DEFAULT'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'backup_strategy'</span>, default=<span class=\"string\">'InnoBackupEx'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Default strategy to perform backups.'</span>,</span><br><span class=\"line\">           deprecated_name=<span class=\"string\">'backup_strategy'</span>,</span><br><span class=\"line\">           deprecated_group=<span class=\"string\">'DEFAULT'</span>),</span><br></pre></td></tr></table></figure></p>\n<p>当然，这部分配置我们是可以在<code>trove-guestagent.conf</code>中配置的：<br><figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ========== Datastore Specific Configuration Options ==========</span></span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"section\">[mysql]</span></span><br><span class=\"line\"><span class=\"comment\"># For mysql, the following are the defaults for backup, and restore:</span></span><br><span class=\"line\"><span class=\"attr\">backup_strategy</span> = InnoBackupEx</span><br><span class=\"line\"><span class=\"attr\">backup_namespace</span> = trove.guestagent.strategies.backup.mysql_impl</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那我们就知道，其实MySQL的备份使用的是<code>trove.guestagent.strategies.backup.mysql_impl.InnoBackupEx</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">InnoBackupEx</span><span class=\"params\">(base.BackupRunner)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Implementation of Backup Strategy for InnoBackupEx.\"\"\"</span></span><br><span class=\"line\">    __strategy_name__ = <span class=\"string\">'innobackupex'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cmd</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        cmd = (<span class=\"string\">'sudo innobackupex'</span></span><br><span class=\"line\">               <span class=\"string\">' --stream=xbstream'</span></span><br><span class=\"line\">               <span class=\"string\">' %(extra_opts)s '</span> +</span><br><span class=\"line\">               self.user_and_pass +</span><br><span class=\"line\">               MySqlApp.get_data_dir() +</span><br><span class=\"line\">               <span class=\"string\">' 2&gt;/tmp/innobackupex.log'</span></span><br><span class=\"line\">               )</span><br><span class=\"line\">        <span class=\"keyword\">return</span> cmd + self.zip_cmd + self.encrypt_cmd</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<p>这里额外说一下，究竟是在哪里触发执行的备份呢？</p>\n<p>在前面<code>self.stream_backup_to_storage(context, backup_info, runner, storage,                                    parent_metadata, extra_opts)</code>中，使用了<code>with</code>来执行<code>runner</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">stream_backup_to_storage</span><span class=\"params\">(self, context, backup_info, runner, storage,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                             parent_metadata=&#123;&#125;, extra_opts=EXTRA_OPTS)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">with</span> runner(filename=backup_id, extra_opts=extra_opts,</span><br><span class=\"line\">                    **parent_metadata) <span class=\"keyword\">as</span> bkup:</span><br><span class=\"line\">            LOG.debug(<span class=\"string\">\"Starting backup %s.\"</span>, backup_id)</span><br><span class=\"line\">            ...</span><br></pre></td></tr></table></figure></p>\n<p>即这里，调用了<code>InnoBackupEx</code>的构造方法，而<code>InnoBackupEx</code>是继承自<code>BackupRunner</code>，则：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BackupRunner</span><span class=\"params\">(Strategy)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Base class for Backup Strategy implementations.\"\"\"</span></span><br><span class=\"line\">    __strategy_type__ = <span class=\"string\">'backup_runner'</span></span><br><span class=\"line\">    __strategy_ns__ = <span class=\"string\">'trove.guestagent.strategies.backup'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># The actual system call to run the backup</span></span><br><span class=\"line\">    cmd = <span class=\"keyword\">None</span></span><br><span class=\"line\">    is_zipped = CONF.backup_use_gzip_compression</span><br><span class=\"line\">    is_encrypted = CONF.backup_use_openssl_encryption</span><br><span class=\"line\">    encrypt_key = CONF.backup_aes_cbc_key</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, filename, **kwargs)</span>:</span></span><br><span class=\"line\">        self.base_filename = filename</span><br><span class=\"line\">        self.process = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.pid = <span class=\"keyword\">None</span></span><br><span class=\"line\">        kwargs.update(&#123;<span class=\"string\">'filename'</span>: filename&#125;)</span><br><span class=\"line\">        self.command = self.cmd % kwargs</span><br><span class=\"line\">        super(BackupRunner, self).__init__()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        LOG.debug(<span class=\"string\">\"BackupRunner running cmd: %s\"</span>, self.command)</span><br><span class=\"line\">        self.process = subprocess.Popen(self.command, shell=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">                                        stdout=subprocess.PIPE,</span><br><span class=\"line\">                                        stderr=subprocess.PIPE,</span><br><span class=\"line\">                                        preexec_fn=os.setsid)</span><br><span class=\"line\">        self.pid = self.process.pid</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__enter__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"Start up the process.\"\"\"</span></span><br><span class=\"line\">        self._run_pre_backup()</span><br><span class=\"line\">        self._run()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<p>看到这里，我们就知道备份执行是在哪里触发的了——首先，在构造方法中，通过<code>self.command = self.cmd % kwargs</code>获取了<code>InnoBackupEx</code>中的<code>cmd</code>，然后因为我们使用<code>with</code>来调用，则会调用<code>__enter__(self)</code>方法，其中的<code>_run(self)</code>中使用<code>Popen</code>协程来真正的执行。后面补充一篇对<code>eventlent</code>和<code>Popen</code>的学习心得。</p>\n<h3 id=\"其他策略应用场景\"><a href=\"#其他策略应用场景\" class=\"headerlink\" title=\"其他策略应用场景\"></a>其他策略应用场景</h3><p>除了上面例子中的MySQL备份功能，Trove的Strategies还可以通过扩展Guest Agent、API和Task Manager等来实现集群的功能，比如下面列举了MongoDB中的扩展：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">cfg.StrOpt(<span class=\"string\">'api_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.'</span></span><br><span class=\"line\">           <span class=\"string\">'mongodb.api.MongoDbAPIStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific API logic.'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'taskmanager_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.mongodb.'</span></span><br><span class=\"line\">           <span class=\"string\">'taskmanager.MongoDbTaskManagerStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific task manager '</span></span><br><span class=\"line\">                <span class=\"string\">'logic.'</span>),</span><br><span class=\"line\">cfg.StrOpt(<span class=\"string\">'guestagent_strategy'</span>,</span><br><span class=\"line\">           default=<span class=\"string\">'trove.common.strategies.cluster.experimental.'</span></span><br><span class=\"line\">           <span class=\"string\">'mongodb.guestagent.MongoDbGuestAgentStrategy'</span>,</span><br><span class=\"line\">           help=<span class=\"string\">'Class that implements datastore-specific Guest Agent API '</span></span><br><span class=\"line\">                <span class=\"string\">'logic.'</span>),</span><br></pre></td></tr></table></figure></p>\n<p>当用户请求API<code>trove.cluster.service.ClusterController#create</code>，对MongoDB创建集群时，经过各种调用，会去执行<code>trove.common.strategies.cluster.experimental.mongodb.api.MongoDbCluster#create</code>来创建MongoDB的Cluster。后面的具体流程我们这里就在赘述了，感兴趣的童鞋可以去阅读一下代码。不过目前在MongoDB集群功能中，还没有区分Replica set和Shard，需要紧跟上游或者自己实现（有位同事最近在做这项功能，还是很有希望提交上游的……这就跑题了😂）</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>本文主要以MySQL备份的代码过程为例，讲解了Trove中的Strategies的应用，了解其基本原理和几个使用场景，同时在看代码的过程中，遇到的新的知识点<code>eventlet</code>和<code>eventlet.green.subprocess.Popen</code>，值得我们去学习和研究一番。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://www.apress.com/us/book/9781484212226\" target=\"_blank\" rel=\"noopener\">OpenStack Trove by Amrith Kumar</a><br>[2].<a href=\"https://www.tesora.com/openstack-trove-architecture/\" target=\"_blank\" rel=\"noopener\">OpenStack Architecture</a><br>[3].<a href=\"https://github.com/openstack/trove\" target=\"_blank\" rel=\"noopener\">openstack/trove</a></p>"},{"title":"Galera Cluster for MySQL介绍","date":"2016-12-28T06:27:53.000Z","_content":"## 关于数据库复制\n\n数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——\n<!--more-->\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png)\n* Master/Slave Replication\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png)\n* Multi-master Replication\n\n对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。\n而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。\n\n无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——\n* Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。\n* Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。\n\n目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。\n\n为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：\n1. 同步复制，主备无延迟\n2. 支持多主同时读写，保证数据一致性\n3. 集群中各个节点保存全量数据\n4. 节点添加或删除，集群具备自动监测和配置\n5. 行级锁并行复制\n6. 不需要写binlog\n\n## Galera Cluster for MySQL架构\n\n使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png)\n\n当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个`write-set`中，紧接着，数据库节点就会将`write-set`发送到所有的其他节点。\n\n之后，`write-set`会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用`write-set`。如果验证未通过，则节点丢掉`write-set`并且集群回滚；如果验证通过，则事务提交，并且`write-set`会被应用到集群的其他节点。\n\n上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。\n\n那么Galera Cluster内部又是如何工作的呢？\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png)\n\n如上图所示，Galera Cluster有四个组件组成：\n* DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB\n* wsrep API  \n* Galera Replication Plugin\n* Group Communication plugins\n\n这里就不一一展开具体解释了，详细的可以参见[Replication API](http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api)\n\n\n## 部分关键字解释\n\n### Primary Componet\n\n除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。\n\nPrimary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png)\n\n如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。\n\n所以为了能够实现自动故障转移，需要至少三个节点——\n* 单交换器的集群应该至少具备3个节点\n* 跨交换机的集群应该至少具备3个交换机\n* 跨网络的集群应该至少具备3个网络\n* 跨数据中心的集群应该至少具备3个数据中心\n\n\n### Replication Configuration\n\n* wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。\n* wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。\n* wsrep_node_name - 节点名称。\n* wsrep_node_address - 每个节点自己的IP地址。\n* wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过`find / -name libgalera_smm.so` 来查找。\n* wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：`gcache.size`，表示节点缓存`write-sets`集合的磁盘空间，默认值是128M；`gcache.page_size`表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。\n* wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有`mysqldump`和`rsync`两种，在大数据集的场景中，后者比前者更快。\n\n上面是我们`/etc/my.cnf.d/wsrep.cnf`文件中几个配置项的解释，更多的详细内容，请参见[http://galeracluster.com/documentation-webpages/reference.html](http://galeracluster.com/documentation-webpages/reference.html)。\n","source":"_posts/introduction-to-galera-cluster-for-mysql.md","raw":"---\ntitle: Galera Cluster for MySQL介绍\ndate: 2016-12-28 14:27:53\ntags: [MySQL, Galera Cluster, DB]\n---\n## 关于数据库复制\n\n数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——\n<!--more-->\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png)\n* Master/Slave Replication\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png)\n* Multi-master Replication\n\n对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。\n而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。\n\n无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——\n* Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。\n* Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。\n\n目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。\n\n为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：\n1. 同步复制，主备无延迟\n2. 支持多主同时读写，保证数据一致性\n3. 集群中各个节点保存全量数据\n4. 节点添加或删除，集群具备自动监测和配置\n5. 行级锁并行复制\n6. 不需要写binlog\n\n## Galera Cluster for MySQL架构\n\n使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png)\n\n当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个`write-set`中，紧接着，数据库节点就会将`write-set`发送到所有的其他节点。\n\n之后，`write-set`会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用`write-set`。如果验证未通过，则节点丢掉`write-set`并且集群回滚；如果验证通过，则事务提交，并且`write-set`会被应用到集群的其他节点。\n\n上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。\n\n那么Galera Cluster内部又是如何工作的呢？\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png)\n\n如上图所示，Galera Cluster有四个组件组成：\n* DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB\n* wsrep API  \n* Galera Replication Plugin\n* Group Communication plugins\n\n这里就不一一展开具体解释了，详细的可以参见[Replication API](http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api)\n\n\n## 部分关键字解释\n\n### Primary Componet\n\n除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。\n\nPrimary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png)\n\n如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。\n\n所以为了能够实现自动故障转移，需要至少三个节点——\n* 单交换器的集群应该至少具备3个节点\n* 跨交换机的集群应该至少具备3个交换机\n* 跨网络的集群应该至少具备3个网络\n* 跨数据中心的集群应该至少具备3个数据中心\n\n\n### Replication Configuration\n\n* wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。\n* wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。\n* wsrep_node_name - 节点名称。\n* wsrep_node_address - 每个节点自己的IP地址。\n* wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过`find / -name libgalera_smm.so` 来查找。\n* wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：`gcache.size`，表示节点缓存`write-sets`集合的磁盘空间，默认值是128M；`gcache.page_size`表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。\n* wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有`mysqldump`和`rsync`两种，在大数据集的场景中，后者比前者更快。\n\n上面是我们`/etc/my.cnf.d/wsrep.cnf`文件中几个配置项的解释，更多的详细内容，请参见[http://galeracluster.com/documentation-webpages/reference.html](http://galeracluster.com/documentation-webpages/reference.html)。\n","slug":"introduction-to-galera-cluster-for-mysql","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wx2000bxu2zwvmueij1","content":"<h2 id=\"关于数据库复制\"><a href=\"#关于数据库复制\" class=\"headerlink\" title=\"关于数据库复制\"></a>关于数据库复制</h2><p>数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——<br><a id=\"more\"></a></p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png\" alt=\"\"></p>\n<ul>\n<li>Master/Slave Replication</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png\" alt=\"\"></p>\n<ul>\n<li>Multi-master Replication</li>\n</ul>\n<p>对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。<br>而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。</p>\n<p>无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——</p>\n<ul>\n<li>Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。</li>\n<li>Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。</li>\n</ul>\n<p>目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。</p>\n<p>为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：</p>\n<ol>\n<li>同步复制，主备无延迟</li>\n<li>支持多主同时读写，保证数据一致性</li>\n<li>集群中各个节点保存全量数据</li>\n<li>节点添加或删除，集群具备自动监测和配置</li>\n<li>行级锁并行复制</li>\n<li>不需要写binlog</li>\n</ol>\n<h2 id=\"Galera-Cluster-for-MySQL架构\"><a href=\"#Galera-Cluster-for-MySQL架构\" class=\"headerlink\" title=\"Galera Cluster for MySQL架构\"></a>Galera Cluster for MySQL架构</h2><p>使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png\" alt=\"\"></p>\n<p>当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个<code>write-set</code>中，紧接着，数据库节点就会将<code>write-set</code>发送到所有的其他节点。</p>\n<p>之后，<code>write-set</code>会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用<code>write-set</code>。如果验证未通过，则节点丢掉<code>write-set</code>并且集群回滚；如果验证通过，则事务提交，并且<code>write-set</code>会被应用到集群的其他节点。</p>\n<p>上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。</p>\n<p>那么Galera Cluster内部又是如何工作的呢？</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png\" alt=\"\"></p>\n<p>如上图所示，Galera Cluster有四个组件组成：</p>\n<ul>\n<li>DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB</li>\n<li>wsrep API  </li>\n<li>Galera Replication Plugin</li>\n<li>Group Communication plugins</li>\n</ul>\n<p>这里就不一一展开具体解释了，详细的可以参见<a href=\"http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api\" target=\"_blank\" rel=\"noopener\">Replication API</a></p>\n<h2 id=\"部分关键字解释\"><a href=\"#部分关键字解释\" class=\"headerlink\" title=\"部分关键字解释\"></a>部分关键字解释</h2><h3 id=\"Primary-Componet\"><a href=\"#Primary-Componet\" class=\"headerlink\" title=\"Primary Componet\"></a>Primary Componet</h3><p>除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。</p>\n<p>Primary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png\" alt=\"\"></p>\n<p>如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。</p>\n<p>所以为了能够实现自动故障转移，需要至少三个节点——</p>\n<ul>\n<li>单交换器的集群应该至少具备3个节点</li>\n<li>跨交换机的集群应该至少具备3个交换机</li>\n<li>跨网络的集群应该至少具备3个网络</li>\n<li>跨数据中心的集群应该至少具备3个数据中心</li>\n</ul>\n<h3 id=\"Replication-Configuration\"><a href=\"#Replication-Configuration\" class=\"headerlink\" title=\"Replication Configuration\"></a>Replication Configuration</h3><ul>\n<li>wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。</li>\n<li>wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。</li>\n<li>wsrep_node_name - 节点名称。</li>\n<li>wsrep_node_address - 每个节点自己的IP地址。</li>\n<li>wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过<code>find / -name libgalera_smm.so</code> 来查找。</li>\n<li>wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：<code>gcache.size</code>，表示节点缓存<code>write-sets</code>集合的磁盘空间，默认值是128M；<code>gcache.page_size</code>表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。</li>\n<li>wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有<code>mysqldump</code>和<code>rsync</code>两种，在大数据集的场景中，后者比前者更快。</li>\n</ul>\n<p>上面是我们<code>/etc/my.cnf.d/wsrep.cnf</code>文件中几个配置项的解释，更多的详细内容，请参见<a href=\"http://galeracluster.com/documentation-webpages/reference.html\" target=\"_blank\" rel=\"noopener\">http://galeracluster.com/documentation-webpages/reference.html</a>。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"关于数据库复制\"><a href=\"#关于数据库复制\" class=\"headerlink\" title=\"关于数据库复制\"></a>关于数据库复制</h2><p>数据库的复制，一般指的是在数据库集群中，数据在一个数据库服务节点拷贝到另一个数据库节点。常见的RDBMS的复制方式有两种——<br>","more":"</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/master-slave-repl.png\" alt=\"\"></p>\n<ul>\n<li>Master/Slave Replication</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/multi-master-repl.png\" alt=\"\"></p>\n<ul>\n<li>Multi-master Replication</li>\n</ul>\n<p>对于主从方式的复制方式，master节点上的写操作会通过数据库日志（如MySQ了的binary log）记录，并通过网络传递给slave节点，然后由slave节点根据master节点传递的日志执行这些变更。<br>而对于多主的复制方式，每个节点都可执行写操作，然后将写操作同步到其他节点。</p>\n<p>无论是哪种方式，根据事务在集群中传递的方式，我们又将复制分为两类——</p>\n<ul>\n<li>Synchronous Replication - 同步复制，所有的节点在一个单一事务中完成同步，即，在一个事务提交时，所有节点有相同的值。</li>\n<li>Asynchronous Replication - 异步复制，主节点的写操作，异步的更新到其他节点中，即，当主节点事务提交时，在很短的时间内，有些节点的值与直接点不一致。</li>\n</ul>\n<p>目前，我们的MySQL集群部署方式是双主，但是同一时刻所有的读写压力只在启动一台上，并没有真正意义上实现资源的合理利用，即，仅保证了高可用，但是没有保证负载均衡。</p>\n<p>为了实现真正的数据库集群的负载均衡及高可用，我们找到了一个不错的MySQL集群的解决方案，即Galera Cluster for MySQL。它将多个数据库节点组织成一个cluster，并提供以下特性：</p>\n<ol>\n<li>同步复制，主备无延迟</li>\n<li>支持多主同时读写，保证数据一致性</li>\n<li>集群中各个节点保存全量数据</li>\n<li>节点添加或删除，集群具备自动监测和配置</li>\n<li>行级锁并行复制</li>\n<li>不需要写binlog</li>\n</ol>\n<h2 id=\"Galera-Cluster-for-MySQL架构\"><a href=\"#Galera-Cluster-for-MySQL架构\" class=\"headerlink\" title=\"Galera Cluster for MySQL架构\"></a>Galera Cluster for MySQL架构</h2><p>使用了Galera之后，客户端和Galera节点之间交互的时序图如下所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/certification-based-replication.png\" alt=\"\"></p>\n<p>当客户端执行COMMIT命令，但实际提交未发生前，所有的数据库同一事务中的变更和变更行的主键会被收集到一个<code>write-set</code>中，紧接着，数据库节点就会将<code>write-set</code>发送到所有的其他节点。</p>\n<p>之后，<code>write-set</code>会使用主键执行一次验证，这个操作在集群的每个节点上都会进行，验证操作决定了是否可以应用<code>write-set</code>。如果验证未通过，则节点丢掉<code>write-set</code>并且集群回滚；如果验证通过，则事务提交，并且<code>write-set</code>会被应用到集群的其他节点。</p>\n<p>上面这中复制方式又称为“基于认证的复制”（Certification Based Replication）。</p>\n<p>那么Galera Cluster内部又是如何工作的呢？</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/repl-api.png\" alt=\"\"></p>\n<p>如上图所示，Galera Cluster有四个组件组成：</p>\n<ul>\n<li>DBMS - Galera Cluster支持MySQL、MariaDB和Percona XtraDB</li>\n<li>wsrep API  </li>\n<li>Galera Replication Plugin</li>\n<li>Group Communication plugins</li>\n</ul>\n<p>这里就不一一展开具体解释了，详细的可以参见<a href=\"http://galeracluster.com/documentation-webpages/architecture.html#wsrep-api\" target=\"_blank\" rel=\"noopener\">Replication API</a></p>\n<h2 id=\"部分关键字解释\"><a href=\"#部分关键字解释\" class=\"headerlink\" title=\"部分关键字解释\"></a>部分关键字解释</h2><h3 id=\"Primary-Componet\"><a href=\"#Primary-Componet\" class=\"headerlink\" title=\"Primary Componet\"></a>Primary Componet</h3><p>除了单一节点故障之外，集群可能会由于网络原因分裂成几个组件，在这种情况下，为了避免冲突，只有一个组件可以继续修改数据库状态，而这个组件，就称为Primary Component。</p>\n<p>Primary Component其实是一个集群，当发生集群分裂的时候，Galera Cluster会执行一个特殊的权重算法，来选举一个组件作为Primary Component，如下图所示：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/primary-componet.png\" alt=\"\"></p>\n<p>如果集群具有偶数个节点，则会存在脑裂的风险。如果由于网络导致集群被分裂成恰好数量相等的两个cluster，则每个cluster都有可能保持自己的权重，并且两个都会变成non-primary状态。</p>\n<p>所以为了能够实现自动故障转移，需要至少三个节点——</p>\n<ul>\n<li>单交换器的集群应该至少具备3个节点</li>\n<li>跨交换机的集群应该至少具备3个交换机</li>\n<li>跨网络的集群应该至少具备3个网络</li>\n<li>跨数据中心的集群应该至少具备3个数据中心</li>\n</ul>\n<h3 id=\"Replication-Configuration\"><a href=\"#Replication-Configuration\" class=\"headerlink\" title=\"Replication Configuration\"></a>Replication Configuration</h3><ul>\n<li>wsrep_cluster_name - 集群名称，所有集群中的节点，名称必须一致。</li>\n<li>wsrep_cluster_address - 定义集群中的节点IP地址，多个地址使用逗号分割。</li>\n<li>wsrep_node_name - 节点名称。</li>\n<li>wsrep_node_address - 每个节点自己的IP地址。</li>\n<li>wsrep_provider - 定义Galera Replication Plugin的路径，安装之后不确定在哪里的情况下，可以通过<code>find / -name libgalera_smm.so</code> 来查找。</li>\n<li>wsrep_provider_options - 定义节点传递给wsrep provider的一些可选配置，如：<code>gcache.size</code>，表示节点缓存<code>write-sets</code>集合的磁盘空间，默认值是128M；<code>gcache.page_size</code>表示页存储中单页大小，整体页面存储的上限是磁盘的大小，默认值是128M。</li>\n<li>wsrep_method - 定义了节点在单个状态快照传输（State Snapshot Transfer，指完整的数据从一个集群节点——又称为donor——拷贝到一个新加入的节点——又称为joiner——的过程）中使用的方法或者脚本，支持的方法有<code>mysqldump</code>和<code>rsync</code>两种，在大数据集的场景中，后者比前者更快。</li>\n</ul>\n<p>上面是我们<code>/etc/my.cnf.d/wsrep.cnf</code>文件中几个配置项的解释，更多的详细内容，请参见<a href=\"http://galeracluster.com/documentation-webpages/reference.html\" target=\"_blank\" rel=\"noopener\">http://galeracluster.com/documentation-webpages/reference.html</a>。</p>"},{"title":"OpenStack DBaaS组件Trove简介","date":"2017-07-25T08:02:28.000Z","_content":"## Trove架构\nTrove包含下面几个主要组件：<!--more-->\n* API Server\n* Message Bus\n* Task Manager\n* Guest Agent\n* Conductor\n\n### API Server\nAPI endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。\n\nAPI Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。\n\n* 一个RESTful风格的组件\n* 入口 - `Trove/bin/trove-api`\n* 使用WSGI launcher，由`Trove/etc/trove/api-paste.ini`配置\n\t* 定义了过滤器管道、令牌认证、速率限制等\n\t* 定义了app_factory为`trove.common.api:app_factory`提供给trove应用\n* API 类（WSGI Router）将REST路径连接到相应的Controller上\n\t* Controller的实现在相关的模块下（如versions/instance/flavor/limits）的`service.py`中\n* Controller通常将实现重定向到`models.py`中的一个类\n* 另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求\n\n### Message Bus\n\n这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。\n\n一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。\n\n### Task Manager\n\nTask Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。\n\n任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）\n\n* 这是一个监听RabbitMQ topic的服务\n* 入口 - `Trove/bin/trove-taskmanager`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-taskmanager.conf.sample`配置文件进行配置，定义了`trove.taskmanager.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用TaskManager的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将该处理重定向到`models.py`模块中的一个对象，它使用context和instance_id从相关类加载一个对象\n* 实际的处理一般在`models.py`中完成\n\n### Guest Agent\n\n客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。\n\n每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。\n\n* 与Task Manager类似，服务运行起来监听RabbitMQ topic\n* Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）\n* 入口 - `Trove/bin/trove-guestagent`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-guestagent.conf.sample`配置文件进行配置，定义了`trove.guestagent.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用Guest Agent的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将对对象的处理重定向到`dbaas.py`中\n* 实际处理一般在`dbaas.py`中完成\n \n### Conductor\n\n指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为`trove-conductor`——来与指挥器进行信息交互。\n\n* 入口 - `Trove/bin/trove-conductor`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-conductor.conf.sample`配置文件进行配置，定义了`trove.conductor.manager.Manager`作为Manager\n* 如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为`{\"method\": \"<method_name>\", \"args\": {<arguments>}}`\n* 实际的数据库更新操作由`trove/conductor/manager.py`完成\n* \"heartbeat\"操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等\n* \"update_backup\"方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）\n\n## 代码仓库\n\n* Trove Server (https://github.com/openstack/trove)\n* Trove Integration (https://github.com/openstack/trove-integration)\n* Trove Client (https://github.com/openstack/python-troveclient)\n\n## 安装部署\n\n* How to install trove as part of devstack: [trove/installation](https://wiki.openstack.org/wiki/Trove/installation)\n* How to use trove-integration: [trove/trove-integration](https://wiki.openstack.org/wiki/Trove/trove-integration)\n* How to set up unit tests to run with tox: [trove/unit-testing](https://wiki.openstack.org/wiki/Trove/unit-testing)\n* How to set up a testing environment and run redstack tests after installation: [trove/integration-testing](https://wiki.openstack.org/wiki/Trove/integration-testing)\n* How to set up your Mac dev environment to debug: [trove/dev-env](https://wiki.openstack.org/wiki/Trove/dev-env)\n* Releasing python-troveclient [trove/release-python-troveclient](https://wiki.openstack.org/wiki/Trove/release-python-troveclient)\n* Creating release notes with Reno [trove/create-release-notes-with-reno](https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno)\n\n## 说明\n\n翻译自[Trove wiki](https://wiki.openstack.org/wiki/Trove)","source":"_posts/introduction-to-trove.md","raw":"---\ntitle: OpenStack DBaaS组件Trove简介\ndate: 2017-07-25 16:02:28\ntags: [OpenStack, Trove, Translation]\n---\n## Trove架构\nTrove包含下面几个主要组件：<!--more-->\n* API Server\n* Message Bus\n* Task Manager\n* Guest Agent\n* Conductor\n\n### API Server\nAPI endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。\n\nAPI Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。\n\n* 一个RESTful风格的组件\n* 入口 - `Trove/bin/trove-api`\n* 使用WSGI launcher，由`Trove/etc/trove/api-paste.ini`配置\n\t* 定义了过滤器管道、令牌认证、速率限制等\n\t* 定义了app_factory为`trove.common.api:app_factory`提供给trove应用\n* API 类（WSGI Router）将REST路径连接到相应的Controller上\n\t* Controller的实现在相关的模块下（如versions/instance/flavor/limits）的`service.py`中\n* Controller通常将实现重定向到`models.py`中的一个类\n* 另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求\n\n### Message Bus\n\n这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。\n\n一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。\n\n### Task Manager\n\nTask Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。\n\n任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）\n\n* 这是一个监听RabbitMQ topic的服务\n* 入口 - `Trove/bin/trove-taskmanager`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-taskmanager.conf.sample`配置文件进行配置，定义了`trove.taskmanager.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用TaskManager的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将该处理重定向到`models.py`模块中的一个对象，它使用context和instance_id从相关类加载一个对象\n* 实际的处理一般在`models.py`中完成\n\n### Guest Agent\n\n客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。\n\n每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。\n\n* 与Task Manager类似，服务运行起来监听RabbitMQ topic\n* Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）\n* 入口 - `Trove/bin/trove-guestagent`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-guestagent.conf.sample`配置文件进行配置，定义了`trove.guestagent.manager.Manager`作为manager，基本上这是通过队列到达的请求的入口点\n* 如上所述，使用Guest Agent的api模块，使用`_cast()`或者`_call()`（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数\n* `Trove/openstack/common/rpc/dispatcher.py` 中的`RpcDispatcher.dispatch()`通过反射的方式调用Manager中合适的方法\n* 然后，Manager将对对象的处理重定向到`dbaas.py`中\n* 实际处理一般在`dbaas.py`中完成\n \n### Conductor\n\n指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为`trove-conductor`——来与指挥器进行信息交互。\n\n* 入口 - `Trove/bin/trove-conductor`\n* 作为一个RpcService运行，通过`Trove/etc/trove/trove-conductor.conf.sample`配置文件进行配置，定义了`trove.conductor.manager.Manager`作为Manager\n* 如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为`{\"method\": \"<method_name>\", \"args\": {<arguments>}}`\n* 实际的数据库更新操作由`trove/conductor/manager.py`完成\n* \"heartbeat\"操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等\n* \"update_backup\"方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）\n\n## 代码仓库\n\n* Trove Server (https://github.com/openstack/trove)\n* Trove Integration (https://github.com/openstack/trove-integration)\n* Trove Client (https://github.com/openstack/python-troveclient)\n\n## 安装部署\n\n* How to install trove as part of devstack: [trove/installation](https://wiki.openstack.org/wiki/Trove/installation)\n* How to use trove-integration: [trove/trove-integration](https://wiki.openstack.org/wiki/Trove/trove-integration)\n* How to set up unit tests to run with tox: [trove/unit-testing](https://wiki.openstack.org/wiki/Trove/unit-testing)\n* How to set up a testing environment and run redstack tests after installation: [trove/integration-testing](https://wiki.openstack.org/wiki/Trove/integration-testing)\n* How to set up your Mac dev environment to debug: [trove/dev-env](https://wiki.openstack.org/wiki/Trove/dev-env)\n* Releasing python-troveclient [trove/release-python-troveclient](https://wiki.openstack.org/wiki/Trove/release-python-troveclient)\n* Creating release notes with Reno [trove/create-release-notes-with-reno](https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno)\n\n## 说明\n\n翻译自[Trove wiki](https://wiki.openstack.org/wiki/Trove)","slug":"introduction-to-trove","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wx4000dxu2ztq7tmf8m","content":"<h2 id=\"Trove架构\"><a href=\"#Trove架构\" class=\"headerlink\" title=\"Trove架构\"></a>Trove架构</h2><p>Trove包含下面几个主要组件：<a id=\"more\"></a></p>\n<ul>\n<li>API Server</li>\n<li>Message Bus</li>\n<li>Task Manager</li>\n<li>Guest Agent</li>\n<li>Conductor</li>\n</ul>\n<h3 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h3><p>API endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。</p>\n<p>API Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。</p>\n<ul>\n<li>一个RESTful风格的组件</li>\n<li>入口 - <code>Trove/bin/trove-api</code></li>\n<li>使用WSGI launcher，由<code>Trove/etc/trove/api-paste.ini</code>配置<ul>\n<li>定义了过滤器管道、令牌认证、速率限制等</li>\n<li>定义了app_factory为<code>trove.common.api:app_factory</code>提供给trove应用</li>\n</ul>\n</li>\n<li>API 类（WSGI Router）将REST路径连接到相应的Controller上<ul>\n<li>Controller的实现在相关的模块下（如versions/instance/flavor/limits）的<code>service.py</code>中</li>\n</ul>\n</li>\n<li>Controller通常将实现重定向到<code>models.py</code>中的一个类</li>\n<li>另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求</li>\n</ul>\n<h3 id=\"Message-Bus\"><a href=\"#Message-Bus\" class=\"headerlink\" title=\"Message Bus\"></a>Message Bus</h3><p>这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。</p>\n<p>一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。</p>\n<h3 id=\"Task-Manager\"><a href=\"#Task-Manager\" class=\"headerlink\" title=\"Task Manager\"></a>Task Manager</h3><p>Task Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。</p>\n<p>任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）</p>\n<ul>\n<li>这是一个监听RabbitMQ topic的服务</li>\n<li>入口 - <code>Trove/bin/trove-taskmanager</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-taskmanager.conf.sample</code>配置文件进行配置，定义了<code>trove.taskmanager.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用TaskManager的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将该处理重定向到<code>models.py</code>模块中的一个对象，它使用context和instance_id从相关类加载一个对象</li>\n<li>实际的处理一般在<code>models.py</code>中完成</li>\n</ul>\n<h3 id=\"Guest-Agent\"><a href=\"#Guest-Agent\" class=\"headerlink\" title=\"Guest Agent\"></a>Guest Agent</h3><p>客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。</p>\n<p>每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。</p>\n<ul>\n<li>与Task Manager类似，服务运行起来监听RabbitMQ topic</li>\n<li>Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）</li>\n<li>入口 - <code>Trove/bin/trove-guestagent</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-guestagent.conf.sample</code>配置文件进行配置，定义了<code>trove.guestagent.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用Guest Agent的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将对对象的处理重定向到<code>dbaas.py</code>中</li>\n<li>实际处理一般在<code>dbaas.py</code>中完成</li>\n</ul>\n<h3 id=\"Conductor\"><a href=\"#Conductor\" class=\"headerlink\" title=\"Conductor\"></a>Conductor</h3><p>指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为<code>trove-conductor</code>——来与指挥器进行信息交互。</p>\n<ul>\n<li>入口 - <code>Trove/bin/trove-conductor</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-conductor.conf.sample</code>配置文件进行配置，定义了<code>trove.conductor.manager.Manager</code>作为Manager</li>\n<li>如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为<code>{&quot;method&quot;: &quot;&lt;method_name&gt;&quot;, &quot;args&quot;: {&lt;arguments&gt;}}</code></li>\n<li>实际的数据库更新操作由<code>trove/conductor/manager.py</code>完成</li>\n<li>“heartbeat”操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等</li>\n<li>“update_backup”方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）</li>\n</ul>\n<h2 id=\"代码仓库\"><a href=\"#代码仓库\" class=\"headerlink\" title=\"代码仓库\"></a>代码仓库</h2><ul>\n<li>Trove Server (<a href=\"https://github.com/openstack/trove\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/trove</a>)</li>\n<li>Trove Integration (<a href=\"https://github.com/openstack/trove-integration\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/trove-integration</a>)</li>\n<li>Trove Client (<a href=\"https://github.com/openstack/python-troveclient\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/python-troveclient</a>)</li>\n</ul>\n<h2 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h2><ul>\n<li>How to install trove as part of devstack: <a href=\"https://wiki.openstack.org/wiki/Trove/installation\" target=\"_blank\" rel=\"noopener\">trove/installation</a></li>\n<li>How to use trove-integration: <a href=\"https://wiki.openstack.org/wiki/Trove/trove-integration\" target=\"_blank\" rel=\"noopener\">trove/trove-integration</a></li>\n<li>How to set up unit tests to run with tox: <a href=\"https://wiki.openstack.org/wiki/Trove/unit-testing\" target=\"_blank\" rel=\"noopener\">trove/unit-testing</a></li>\n<li>How to set up a testing environment and run redstack tests after installation: <a href=\"https://wiki.openstack.org/wiki/Trove/integration-testing\" target=\"_blank\" rel=\"noopener\">trove/integration-testing</a></li>\n<li>How to set up your Mac dev environment to debug: <a href=\"https://wiki.openstack.org/wiki/Trove/dev-env\" target=\"_blank\" rel=\"noopener\">trove/dev-env</a></li>\n<li>Releasing python-troveclient <a href=\"https://wiki.openstack.org/wiki/Trove/release-python-troveclient\" target=\"_blank\" rel=\"noopener\">trove/release-python-troveclient</a></li>\n<li>Creating release notes with Reno <a href=\"https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno\" target=\"_blank\" rel=\"noopener\">trove/create-release-notes-with-reno</a></li>\n</ul>\n<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><p>翻译自<a href=\"https://wiki.openstack.org/wiki/Trove\" target=\"_blank\" rel=\"noopener\">Trove wiki</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"Trove架构\"><a href=\"#Trove架构\" class=\"headerlink\" title=\"Trove架构\"></a>Trove架构</h2><p>Trove包含下面几个主要组件：","more":"</p>\n<ul>\n<li>API Server</li>\n<li>Message Bus</li>\n<li>Task Manager</li>\n<li>Guest Agent</li>\n<li>Conductor</li>\n</ul>\n<h3 id=\"API-Server\"><a href=\"#API-Server\" class=\"headerlink\" title=\"API Server\"></a>API Server</h3><p>API endpoint（trove-api）本质上是一个HTTP的Web服务，具备处理鉴权、授权、与数据存储相关的基本命令和控制功能。根据数据库不同，API还有一些不同的扩展。</p>\n<p>API Server与两个系统沟通——与Task Manager沟通，来处理复杂的异步任务；直接与Guest Agent沟通来处理简单的任务比如获取MySQL用户列表等，这部分操作均是同步的。API Server不做任何重大/复杂的事情，它的任务就是接收请求，将其转化为消息，校验它们，并将这些消息转发到任务管理器（Task Manager）和访客代理（Guest Agent）。</p>\n<ul>\n<li>一个RESTful风格的组件</li>\n<li>入口 - <code>Trove/bin/trove-api</code></li>\n<li>使用WSGI launcher，由<code>Trove/etc/trove/api-paste.ini</code>配置<ul>\n<li>定义了过滤器管道、令牌认证、速率限制等</li>\n<li>定义了app_factory为<code>trove.common.api:app_factory</code>提供给trove应用</li>\n</ul>\n</li>\n<li>API 类（WSGI Router）将REST路径连接到相应的Controller上<ul>\n<li>Controller的实现在相关的模块下（如versions/instance/flavor/limits）的<code>service.py</code>中</li>\n</ul>\n</li>\n<li>Controller通常将实现重定向到<code>models.py</code>中的一个类</li>\n<li>另一些组件（Task Manager，Guest Agent）的api模块通过RabbitMQ发送请求</li>\n</ul>\n<h3 id=\"Message-Bus\"><a href=\"#Message-Bus\" class=\"headerlink\" title=\"Message Bus\"></a>Message Bus</h3><p>这部分组件仿照了Nova架构。Message Bus其实就是一个消息队列。</p>\n<p>一个典型的消息传递事件从API服务器接收到用户的请求开始。API服务器认证用户确保用户具备执行响应命令的权限。对请求中涉及到的对象的可用性进行评估，如果可用，将请求路由到相关Worker的排队引擎。Workers不断根据自己的角色监听消息队列，当这种监听产生一个工作请求时，Worker将对该任务进行任务分配并开始执行。完成任务后，Worker将响应发送到消息队列，由API服务器接受并中继到始发用户的队列。在整个过程中，数据库记录根据需要会被查询、添加或者删除。</p>\n<h3 id=\"Task-Manager\"><a href=\"#Task-Manager\" class=\"headerlink\" title=\"Task Manager\"></a>Task Manager</h3><p>Task Manager（trove-taskmanager）就是干粗活累活的家伙，比如配置一台实例，管理实例生命周期和在实例上进行操作。任务管理器接收来自API Server的消息，通过同意消息进行响应，并开始执行任务。有几个复杂的任务，比如重新分配数据库规格和创建实例等，他们均需要通过HTTP请求调用OpenStack的服务，同时也需要轮询服务，知道实例变为活动状态，并且还向客户代理发送消息。任务管理器处理在多个分布式系统中发生的进程流。</p>\n<p>任务管理器是有状态的，它在其系统内部运行复杂的流程。如果在状态处理期间任务管理器节点脱机，则操作将失败。任务流系统将最终实现为长时间运行运行的任务。（The Task Flow system will be eventually implemented for long running tasks.）</p>\n<ul>\n<li>这是一个监听RabbitMQ topic的服务</li>\n<li>入口 - <code>Trove/bin/trove-taskmanager</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-taskmanager.conf.sample</code>配置文件进行配置，定义了<code>trove.taskmanager.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用TaskManager的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将该处理重定向到<code>models.py</code>模块中的一个对象，它使用context和instance_id从相关类加载一个对象</li>\n<li>实际的处理一般在<code>models.py</code>中完成</li>\n</ul>\n<h3 id=\"Guest-Agent\"><a href=\"#Guest-Agent\" class=\"headerlink\" title=\"Guest Agent\"></a>Guest Agent</h3><p>客户代理（Guest Agent，trove-guestagent）运行在客户实例内部，负责管理和执行数据存储本身的操作。它负责使数据存储在线，这可能是一个复杂的任务。热支持（Heat support）将来将成为Trove的默认配置和仪器引擎，从而减少了将数据存储库联机的任务。Guest Agent还通过Conductor（指挥器）向API Server发送心跳信息。</p>\n<p>每个数据存储器都实现有一个客户端代理，负责为该数据存储器执行特定人物。比如Redis的客户代理行为与MySQL的客户代理行为就会不同。不过他们必须履行诸如创建和调整规格的基础操作。</p>\n<ul>\n<li>与Task Manager类似，服务运行起来监听RabbitMQ topic</li>\n<li>Guest Agent在每个数据库实例中运行，所以使用专有的RabbitMQ topic（通过实例ID来标识）</li>\n<li>入口 - <code>Trove/bin/trove-guestagent</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-guestagent.conf.sample</code>配置文件进行配置，定义了<code>trove.guestagent.manager.Manager</code>作为manager，基本上这是通过队列到达的请求的入口点</li>\n<li>如上所述，使用Guest Agent的api模块，使用<code>_cast()</code>或者<code>_call()</code>（同步/异步）将对该组件的请求从另一个组件推送到MQ中，并放置方法命作为一个参数</li>\n<li><code>Trove/openstack/common/rpc/dispatcher.py</code> 中的<code>RpcDispatcher.dispatch()</code>通过反射的方式调用Manager中合适的方法</li>\n<li>然后，Manager将对对象的处理重定向到<code>dbaas.py</code>中</li>\n<li>实际处理一般在<code>dbaas.py</code>中完成</li>\n</ul>\n<h3 id=\"Conductor\"><a href=\"#Conductor\" class=\"headerlink\" title=\"Conductor\"></a>Conductor</h3><p>指挥器（Conductor）是运行在宿主机上的饿一个服务，负责接收客户实例中的消息，并在宿主机上更新信息，比如，实例的状态和当前备份的状态。有了指挥器，用户的实例不需要直接连接到宿主机的数据库。指挥器通过Message Bus监听RPC消息，并执行相关的操作。指挥器与客户代理有些类似，因为它是一个监听RabbitMQ主题的服务，不同的是Conductor运行在宿主机上，而非客户实例内部。客户代理通过将消息放入配置的消息队列——conductor_queue，默认为<code>trove-conductor</code>——来与指挥器进行信息交互。</p>\n<ul>\n<li>入口 - <code>Trove/bin/trove-conductor</code></li>\n<li>作为一个RpcService运行，通过<code>Trove/etc/trove/trove-conductor.conf.sample</code>配置文件进行配置，定义了<code>trove.conductor.manager.Manager</code>作为Manager</li>\n<li>如上面的客户代理类似，请求通过其他组件使用_cast()（异步的）推送到消息队列。一般来讲，消息格式为<code>{&quot;method&quot;: &quot;&lt;method_name&gt;&quot;, &quot;args&quot;: {&lt;arguments&gt;}}</code></li>\n<li>实际的数据库更新操作由<code>trove/conductor/manager.py</code>完成</li>\n<li>“heartbeat”操作更新实例的状态，通常由Guest Agent来报告实例状态，如从NEW到BUILDING到ACTIVE等等</li>\n<li>“update_backup”方法修改备份的详情，包括它的当前状态、备份大小、类型和校验码（checksum）</li>\n</ul>\n<h2 id=\"代码仓库\"><a href=\"#代码仓库\" class=\"headerlink\" title=\"代码仓库\"></a>代码仓库</h2><ul>\n<li>Trove Server (<a href=\"https://github.com/openstack/trove\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/trove</a>)</li>\n<li>Trove Integration (<a href=\"https://github.com/openstack/trove-integration\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/trove-integration</a>)</li>\n<li>Trove Client (<a href=\"https://github.com/openstack/python-troveclient\" target=\"_blank\" rel=\"noopener\">https://github.com/openstack/python-troveclient</a>)</li>\n</ul>\n<h2 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h2><ul>\n<li>How to install trove as part of devstack: <a href=\"https://wiki.openstack.org/wiki/Trove/installation\" target=\"_blank\" rel=\"noopener\">trove/installation</a></li>\n<li>How to use trove-integration: <a href=\"https://wiki.openstack.org/wiki/Trove/trove-integration\" target=\"_blank\" rel=\"noopener\">trove/trove-integration</a></li>\n<li>How to set up unit tests to run with tox: <a href=\"https://wiki.openstack.org/wiki/Trove/unit-testing\" target=\"_blank\" rel=\"noopener\">trove/unit-testing</a></li>\n<li>How to set up a testing environment and run redstack tests after installation: <a href=\"https://wiki.openstack.org/wiki/Trove/integration-testing\" target=\"_blank\" rel=\"noopener\">trove/integration-testing</a></li>\n<li>How to set up your Mac dev environment to debug: <a href=\"https://wiki.openstack.org/wiki/Trove/dev-env\" target=\"_blank\" rel=\"noopener\">trove/dev-env</a></li>\n<li>Releasing python-troveclient <a href=\"https://wiki.openstack.org/wiki/Trove/release-python-troveclient\" target=\"_blank\" rel=\"noopener\">trove/release-python-troveclient</a></li>\n<li>Creating release notes with Reno <a href=\"https://wiki.openstack.org/wiki/Trove/create-release-notes-with-reno\" target=\"_blank\" rel=\"noopener\">trove/create-release-notes-with-reno</a></li>\n</ul>\n<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><p>翻译自<a href=\"https://wiki.openstack.org/wiki/Trove\" target=\"_blank\" rel=\"noopener\">Trove wiki</a></p>"},{"title":"Nova架构体系概览","date":"2018-01-16T03:11:07.000Z","_content":"\n## What's Nova\n\n我们首先来看一下OpenStack的逻辑架构图：<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/osog_0001.png)\n\n接触过云计算，接触过OpenStack的童鞋都会有所了解，IaaS中最重要的就是计算、存储和网络。Nova，作为OpenStack核心项目，承担起了提供计算资源的重任，即，为用户提供了计算实例，这些实例又称为虚拟机。从上面的逻辑架构图中也可以看到，有了虚拟机之后，才可以外接存储、网络，亦或是有类似Trove（OpenStack中Database-as-a-Service的项目，详见[>>>传送门](https://www.openstack.org/software/releases/ocata/components/trove)）这种在虚机中运行数据库服务的PaaS项目。当然，虚机也需要像认证服务（Keystone）、镜像（Glance）、网络（Neutron）、存储（Cinder、Swift）这些项目的支持，可谓是你中有我，我中有你。\n\n目前在OpenStack Nova项目的页面（详见[>>>传送门](https://www.openstack.org/software/releases/ocata/components/nova)）显示的生产环境的应用率高达95%，可以说是很“强势”。\n\n本文就作为Nova学习系列的开篇文章，先熟悉一下Nova架构体系及代码结构。\n\n## Components \n\nNova项目也是有好几个组件构成，组件的关系架构图如下所示，其中网络模块一个是Nova-networking，一个是Neutron，当然现在大部分使用的都是Neutron，所以我们只关注第二张图就OK了：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/architecture.svg)\n\n可以看到，在Nova中，有这么几个主要的服务：\n\n* DB：用于数据存储的基础设施数据库\n* API: 即nova-api服务，通过oslo.messaging队列或者HTTP，接收响应终端用户的计算服务API请求或者与其他组件进行通讯\n* Scheduler: 即nova-scheduler服务，用于调度每台实例具体落到哪个计算服务节点上\n* Compute: 即nova-compute服务，管理hypervisor与虚机的通讯，通过虚拟机管理程序API对虚拟机实例进行创建、终止等操作的一个工作守护进程\n* Conductor: 即nova-conductor服务，处理需要协同合作的请求，比如创建实例和调整实例等操作；同时还扮演了数据库代理的角色或者是处理对象转换\n\n在这个图中，值得注意的一点是Nova的几个主要服务组件之间，是通过oslo.messaging进行RPC调用，与外部服务之间通过HTTP的方式、RESTFul接口进行通讯和交互。\n\n在Compute中，有一个“Hypervisor”，这又是什么呢？\n\n我们讲，OpenStack其实是一个云管平台，即其本身不提供虚拟化功能，还是要依赖于操作系统底层的虚拟化技术，其中Hypervisor是虚拟化技术的核心。它是一种运行在物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）——\n>In computing, a hypervisor, also called virtual machine monitor (VMM), is a piece of software/hardware platform-virtualization software that allows multiple operating systems to run on a host computer concurrently.\n\n目前常见的Hypervisor有QEMU、KVM、XEN、VMware等，其中，KVM是集成到Linux内核的Hypervisor，是X86架构且硬件支持虚拟化技术（Intel VT或AMD-V）的Linux的全虚拟化解决方案。它是Linux的一个很小的模块，利用Linux做大量的事，如任务调度、内存管理与硬件设备交互等。最为热门，也最为常用。\n\n此外，需要提一下qemu-kvm——\n> QEMU将KVM整合进来，通过ioctl调用/dev/kvm接口，将有关CPU指令的部分交由内核模块来做。KVM负责CPU虚拟化+内存虚拟化，实现了CPU和内存的虚拟化，但KVM不能模拟其他设备。QEMU模拟IO设备（网卡，磁盘等），KVM加上QEMU之后就能实现真正意义上服务器虚拟化。因为用到了上面两个东西，所以称之为qemu-kvm，来张图：\n> ![](http://7xrgsx.com1.z0.glb.clouddn.com/kvm_archi_base_oh9pnk.png)\n\n在KVM这一层之上，是libvirt，它提供统一、稳定、开放源码的对各种虚拟机进行管理的工具（守护进程libvirtd、默认命令行管理工具virsh）和应用程序接口（API）。一些常用的虚拟机管理工具（如virsh、virt-install、virt-manager等）和云计算框架平台（如OpenStack等）都在底层使用libvirt的应用程序接口。\n\n在Nova的Compute服务中，通过不同的驱动来支持多种Hypervisor，与各种Hypervisor驱动的关系可以用下面的一张图来表示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/nova-compute-drivers.jpg)\n\n## Instance Life Cycle Management Process\n\n在实例的生命周期管理流程中，常见的一些操作如下：\n\n* 创建：nova boot\n\t* boot from image\n\t* boot from volume\n* 重启：nova reboot\n\t* 软重启，默认情况\n\t* 硬重启：nova reboot --hard，具体不同还需要用代码说话\n* 启动：nova start\n* 停止：nova stop\n* 挂起：nova suspend\n* 暂停：nova pause，pause与suspend的区别在于pause将instance的运行状态保存在计算节点的内存中，而suspend保存在磁盘上。pause的优点在于恢复的速度比suspend快，缺点是如果计算节点重启，内存数据丢失，则无法resume。suspend就不存在该问题\n* 恢复：nova resume\n* 调整实例：nova resize\n* 迁移实例：\n\t* nova live-migration\n\t* nova migrate，代码与nova resize相同，如果在resize时未提供flavor id，则仅migrate实例\n* 重建：nova rebuild\n* 快照：nova image-create，对运行的虚机创建一个快照镜像，直接上传到Glance中，可用于恢复主机或以此镜像为模板创建新的主机\n* 备份：nova backup，通过创建一个`backup`类型的快照来备份主机\n* 删除：nova delete，立即关闭主机并删除实例\n\n后续需要对上面这些主要流程进行梳理，包括上面描述的几个命令的不同或者相似之处，我们让代码来说话。\n\n## Reference\n\n[1]. [虚拟化类型](https://huangwei.me/wiki/tech_cloud_kvm_qemu_libvirt_openstack.html)\n[2]. [Under the Hood with Nova, Libvirt and KVM](https://www.openstack.org/assets/presentation-media/OSSummitAtlanta2014-NovaLibvirtKVM2.pdf)\n[3]. [OpenStack系列--Nova](https://zhangchenchen.github.io/2016/08/22/openstack-nova/)\n[4]. [OpenStack Compute(Nova)](https://docs.openstack.org/nova/latest/)\n\n\n\n\n","source":"_posts/learning-nova-architecture-overview.md","raw":"---\ntitle: Nova架构体系概览\ndate: 2018-01-16 11:11:07\ntags: [OpenStack, Nova]\n---\n\n## What's Nova\n\n我们首先来看一下OpenStack的逻辑架构图：<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/osog_0001.png)\n\n接触过云计算，接触过OpenStack的童鞋都会有所了解，IaaS中最重要的就是计算、存储和网络。Nova，作为OpenStack核心项目，承担起了提供计算资源的重任，即，为用户提供了计算实例，这些实例又称为虚拟机。从上面的逻辑架构图中也可以看到，有了虚拟机之后，才可以外接存储、网络，亦或是有类似Trove（OpenStack中Database-as-a-Service的项目，详见[>>>传送门](https://www.openstack.org/software/releases/ocata/components/trove)）这种在虚机中运行数据库服务的PaaS项目。当然，虚机也需要像认证服务（Keystone）、镜像（Glance）、网络（Neutron）、存储（Cinder、Swift）这些项目的支持，可谓是你中有我，我中有你。\n\n目前在OpenStack Nova项目的页面（详见[>>>传送门](https://www.openstack.org/software/releases/ocata/components/nova)）显示的生产环境的应用率高达95%，可以说是很“强势”。\n\n本文就作为Nova学习系列的开篇文章，先熟悉一下Nova架构体系及代码结构。\n\n## Components \n\nNova项目也是有好几个组件构成，组件的关系架构图如下所示，其中网络模块一个是Nova-networking，一个是Neutron，当然现在大部分使用的都是Neutron，所以我们只关注第二张图就OK了：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/architecture.svg)\n\n可以看到，在Nova中，有这么几个主要的服务：\n\n* DB：用于数据存储的基础设施数据库\n* API: 即nova-api服务，通过oslo.messaging队列或者HTTP，接收响应终端用户的计算服务API请求或者与其他组件进行通讯\n* Scheduler: 即nova-scheduler服务，用于调度每台实例具体落到哪个计算服务节点上\n* Compute: 即nova-compute服务，管理hypervisor与虚机的通讯，通过虚拟机管理程序API对虚拟机实例进行创建、终止等操作的一个工作守护进程\n* Conductor: 即nova-conductor服务，处理需要协同合作的请求，比如创建实例和调整实例等操作；同时还扮演了数据库代理的角色或者是处理对象转换\n\n在这个图中，值得注意的一点是Nova的几个主要服务组件之间，是通过oslo.messaging进行RPC调用，与外部服务之间通过HTTP的方式、RESTFul接口进行通讯和交互。\n\n在Compute中，有一个“Hypervisor”，这又是什么呢？\n\n我们讲，OpenStack其实是一个云管平台，即其本身不提供虚拟化功能，还是要依赖于操作系统底层的虚拟化技术，其中Hypervisor是虚拟化技术的核心。它是一种运行在物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）——\n>In computing, a hypervisor, also called virtual machine monitor (VMM), is a piece of software/hardware platform-virtualization software that allows multiple operating systems to run on a host computer concurrently.\n\n目前常见的Hypervisor有QEMU、KVM、XEN、VMware等，其中，KVM是集成到Linux内核的Hypervisor，是X86架构且硬件支持虚拟化技术（Intel VT或AMD-V）的Linux的全虚拟化解决方案。它是Linux的一个很小的模块，利用Linux做大量的事，如任务调度、内存管理与硬件设备交互等。最为热门，也最为常用。\n\n此外，需要提一下qemu-kvm——\n> QEMU将KVM整合进来，通过ioctl调用/dev/kvm接口，将有关CPU指令的部分交由内核模块来做。KVM负责CPU虚拟化+内存虚拟化，实现了CPU和内存的虚拟化，但KVM不能模拟其他设备。QEMU模拟IO设备（网卡，磁盘等），KVM加上QEMU之后就能实现真正意义上服务器虚拟化。因为用到了上面两个东西，所以称之为qemu-kvm，来张图：\n> ![](http://7xrgsx.com1.z0.glb.clouddn.com/kvm_archi_base_oh9pnk.png)\n\n在KVM这一层之上，是libvirt，它提供统一、稳定、开放源码的对各种虚拟机进行管理的工具（守护进程libvirtd、默认命令行管理工具virsh）和应用程序接口（API）。一些常用的虚拟机管理工具（如virsh、virt-install、virt-manager等）和云计算框架平台（如OpenStack等）都在底层使用libvirt的应用程序接口。\n\n在Nova的Compute服务中，通过不同的驱动来支持多种Hypervisor，与各种Hypervisor驱动的关系可以用下面的一张图来表示：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/nova-compute-drivers.jpg)\n\n## Instance Life Cycle Management Process\n\n在实例的生命周期管理流程中，常见的一些操作如下：\n\n* 创建：nova boot\n\t* boot from image\n\t* boot from volume\n* 重启：nova reboot\n\t* 软重启，默认情况\n\t* 硬重启：nova reboot --hard，具体不同还需要用代码说话\n* 启动：nova start\n* 停止：nova stop\n* 挂起：nova suspend\n* 暂停：nova pause，pause与suspend的区别在于pause将instance的运行状态保存在计算节点的内存中，而suspend保存在磁盘上。pause的优点在于恢复的速度比suspend快，缺点是如果计算节点重启，内存数据丢失，则无法resume。suspend就不存在该问题\n* 恢复：nova resume\n* 调整实例：nova resize\n* 迁移实例：\n\t* nova live-migration\n\t* nova migrate，代码与nova resize相同，如果在resize时未提供flavor id，则仅migrate实例\n* 重建：nova rebuild\n* 快照：nova image-create，对运行的虚机创建一个快照镜像，直接上传到Glance中，可用于恢复主机或以此镜像为模板创建新的主机\n* 备份：nova backup，通过创建一个`backup`类型的快照来备份主机\n* 删除：nova delete，立即关闭主机并删除实例\n\n后续需要对上面这些主要流程进行梳理，包括上面描述的几个命令的不同或者相似之处，我们让代码来说话。\n\n## Reference\n\n[1]. [虚拟化类型](https://huangwei.me/wiki/tech_cloud_kvm_qemu_libvirt_openstack.html)\n[2]. [Under the Hood with Nova, Libvirt and KVM](https://www.openstack.org/assets/presentation-media/OSSummitAtlanta2014-NovaLibvirtKVM2.pdf)\n[3]. [OpenStack系列--Nova](https://zhangchenchen.github.io/2016/08/22/openstack-nova/)\n[4]. [OpenStack Compute(Nova)](https://docs.openstack.org/nova/latest/)\n\n\n\n\n","slug":"learning-nova-architecture-overview","published":1,"updated":"2018-01-18T07:33:05.496Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wx6000fxu2zvpa4wure","content":"<h2 id=\"What’s-Nova\"><a href=\"#What’s-Nova\" class=\"headerlink\" title=\"What’s Nova\"></a>What’s Nova</h2><p>我们首先来看一下OpenStack的逻辑架构图：<a id=\"more\"></a><br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/osog_0001.png\" alt=\"\"></p>\n<p>接触过云计算，接触过OpenStack的童鞋都会有所了解，IaaS中最重要的就是计算、存储和网络。Nova，作为OpenStack核心项目，承担起了提供计算资源的重任，即，为用户提供了计算实例，这些实例又称为虚拟机。从上面的逻辑架构图中也可以看到，有了虚拟机之后，才可以外接存储、网络，亦或是有类似Trove（OpenStack中Database-as-a-Service的项目，详见<a href=\"https://www.openstack.org/software/releases/ocata/components/trove\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>）这种在虚机中运行数据库服务的PaaS项目。当然，虚机也需要像认证服务（Keystone）、镜像（Glance）、网络（Neutron）、存储（Cinder、Swift）这些项目的支持，可谓是你中有我，我中有你。</p>\n<p>目前在OpenStack Nova项目的页面（详见<a href=\"https://www.openstack.org/software/releases/ocata/components/nova\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>）显示的生产环境的应用率高达95%，可以说是很“强势”。</p>\n<p>本文就作为Nova学习系列的开篇文章，先熟悉一下Nova架构体系及代码结构。</p>\n<h2 id=\"Components\"><a href=\"#Components\" class=\"headerlink\" title=\"Components\"></a>Components</h2><p>Nova项目也是有好几个组件构成，组件的关系架构图如下所示，其中网络模块一个是Nova-networking，一个是Neutron，当然现在大部分使用的都是Neutron，所以我们只关注第二张图就OK了：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/architecture.svg\" alt=\"\"></p>\n<p>可以看到，在Nova中，有这么几个主要的服务：</p>\n<ul>\n<li>DB：用于数据存储的基础设施数据库</li>\n<li>API: 即nova-api服务，通过oslo.messaging队列或者HTTP，接收响应终端用户的计算服务API请求或者与其他组件进行通讯</li>\n<li>Scheduler: 即nova-scheduler服务，用于调度每台实例具体落到哪个计算服务节点上</li>\n<li>Compute: 即nova-compute服务，管理hypervisor与虚机的通讯，通过虚拟机管理程序API对虚拟机实例进行创建、终止等操作的一个工作守护进程</li>\n<li>Conductor: 即nova-conductor服务，处理需要协同合作的请求，比如创建实例和调整实例等操作；同时还扮演了数据库代理的角色或者是处理对象转换</li>\n</ul>\n<p>在这个图中，值得注意的一点是Nova的几个主要服务组件之间，是通过oslo.messaging进行RPC调用，与外部服务之间通过HTTP的方式、RESTFul接口进行通讯和交互。</p>\n<p>在Compute中，有一个“Hypervisor”，这又是什么呢？</p>\n<p>我们讲，OpenStack其实是一个云管平台，即其本身不提供虚拟化功能，还是要依赖于操作系统底层的虚拟化技术，其中Hypervisor是虚拟化技术的核心。它是一种运行在物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）——</p>\n<blockquote>\n<p>In computing, a hypervisor, also called virtual machine monitor (VMM), is a piece of software/hardware platform-virtualization software that allows multiple operating systems to run on a host computer concurrently.</p>\n</blockquote>\n<p>目前常见的Hypervisor有QEMU、KVM、XEN、VMware等，其中，KVM是集成到Linux内核的Hypervisor，是X86架构且硬件支持虚拟化技术（Intel VT或AMD-V）的Linux的全虚拟化解决方案。它是Linux的一个很小的模块，利用Linux做大量的事，如任务调度、内存管理与硬件设备交互等。最为热门，也最为常用。</p>\n<p>此外，需要提一下qemu-kvm——</p>\n<blockquote>\n<p>QEMU将KVM整合进来，通过ioctl调用/dev/kvm接口，将有关CPU指令的部分交由内核模块来做。KVM负责CPU虚拟化+内存虚拟化，实现了CPU和内存的虚拟化，但KVM不能模拟其他设备。QEMU模拟IO设备（网卡，磁盘等），KVM加上QEMU之后就能实现真正意义上服务器虚拟化。因为用到了上面两个东西，所以称之为qemu-kvm，来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/kvm_archi_base_oh9pnk.png\" alt=\"\"></p>\n</blockquote>\n<p>在KVM这一层之上，是libvirt，它提供统一、稳定、开放源码的对各种虚拟机进行管理的工具（守护进程libvirtd、默认命令行管理工具virsh）和应用程序接口（API）。一些常用的虚拟机管理工具（如virsh、virt-install、virt-manager等）和云计算框架平台（如OpenStack等）都在底层使用libvirt的应用程序接口。</p>\n<p>在Nova的Compute服务中，通过不同的驱动来支持多种Hypervisor，与各种Hypervisor驱动的关系可以用下面的一张图来表示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/nova-compute-drivers.jpg\" alt=\"\"></p>\n<h2 id=\"Instance-Life-Cycle-Management-Process\"><a href=\"#Instance-Life-Cycle-Management-Process\" class=\"headerlink\" title=\"Instance Life Cycle Management Process\"></a>Instance Life Cycle Management Process</h2><p>在实例的生命周期管理流程中，常见的一些操作如下：</p>\n<ul>\n<li>创建：nova boot<ul>\n<li>boot from image</li>\n<li>boot from volume</li>\n</ul>\n</li>\n<li>重启：nova reboot<ul>\n<li>软重启，默认情况</li>\n<li>硬重启：nova reboot –hard，具体不同还需要用代码说话</li>\n</ul>\n</li>\n<li>启动：nova start</li>\n<li>停止：nova stop</li>\n<li>挂起：nova suspend</li>\n<li>暂停：nova pause，pause与suspend的区别在于pause将instance的运行状态保存在计算节点的内存中，而suspend保存在磁盘上。pause的优点在于恢复的速度比suspend快，缺点是如果计算节点重启，内存数据丢失，则无法resume。suspend就不存在该问题</li>\n<li>恢复：nova resume</li>\n<li>调整实例：nova resize</li>\n<li>迁移实例：<ul>\n<li>nova live-migration</li>\n<li>nova migrate，代码与nova resize相同，如果在resize时未提供flavor id，则仅migrate实例</li>\n</ul>\n</li>\n<li>重建：nova rebuild</li>\n<li>快照：nova image-create，对运行的虚机创建一个快照镜像，直接上传到Glance中，可用于恢复主机或以此镜像为模板创建新的主机</li>\n<li>备份：nova backup，通过创建一个<code>backup</code>类型的快照来备份主机</li>\n<li>删除：nova delete，立即关闭主机并删除实例</li>\n</ul>\n<p>后续需要对上面这些主要流程进行梳理，包括上面描述的几个命令的不同或者相似之处，我们让代码来说话。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]. <a href=\"https://huangwei.me/wiki/tech_cloud_kvm_qemu_libvirt_openstack.html\" target=\"_blank\" rel=\"noopener\">虚拟化类型</a><br>[2]. <a href=\"https://www.openstack.org/assets/presentation-media/OSSummitAtlanta2014-NovaLibvirtKVM2.pdf\" target=\"_blank\" rel=\"noopener\">Under the Hood with Nova, Libvirt and KVM</a><br>[3]. <a href=\"https://zhangchenchen.github.io/2016/08/22/openstack-nova/\" target=\"_blank\" rel=\"noopener\">OpenStack系列–Nova</a><br>[4]. <a href=\"https://docs.openstack.org/nova/latest/\" target=\"_blank\" rel=\"noopener\">OpenStack Compute(Nova)</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"What’s-Nova\"><a href=\"#What’s-Nova\" class=\"headerlink\" title=\"What’s Nova\"></a>What’s Nova</h2><p>我们首先来看一下OpenStack的逻辑架构图：","more":"<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/osog_0001.png\" alt=\"\"></p>\n<p>接触过云计算，接触过OpenStack的童鞋都会有所了解，IaaS中最重要的就是计算、存储和网络。Nova，作为OpenStack核心项目，承担起了提供计算资源的重任，即，为用户提供了计算实例，这些实例又称为虚拟机。从上面的逻辑架构图中也可以看到，有了虚拟机之后，才可以外接存储、网络，亦或是有类似Trove（OpenStack中Database-as-a-Service的项目，详见<a href=\"https://www.openstack.org/software/releases/ocata/components/trove\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>）这种在虚机中运行数据库服务的PaaS项目。当然，虚机也需要像认证服务（Keystone）、镜像（Glance）、网络（Neutron）、存储（Cinder、Swift）这些项目的支持，可谓是你中有我，我中有你。</p>\n<p>目前在OpenStack Nova项目的页面（详见<a href=\"https://www.openstack.org/software/releases/ocata/components/nova\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>）显示的生产环境的应用率高达95%，可以说是很“强势”。</p>\n<p>本文就作为Nova学习系列的开篇文章，先熟悉一下Nova架构体系及代码结构。</p>\n<h2 id=\"Components\"><a href=\"#Components\" class=\"headerlink\" title=\"Components\"></a>Components</h2><p>Nova项目也是有好几个组件构成，组件的关系架构图如下所示，其中网络模块一个是Nova-networking，一个是Neutron，当然现在大部分使用的都是Neutron，所以我们只关注第二张图就OK了：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/architecture.svg\" alt=\"\"></p>\n<p>可以看到，在Nova中，有这么几个主要的服务：</p>\n<ul>\n<li>DB：用于数据存储的基础设施数据库</li>\n<li>API: 即nova-api服务，通过oslo.messaging队列或者HTTP，接收响应终端用户的计算服务API请求或者与其他组件进行通讯</li>\n<li>Scheduler: 即nova-scheduler服务，用于调度每台实例具体落到哪个计算服务节点上</li>\n<li>Compute: 即nova-compute服务，管理hypervisor与虚机的通讯，通过虚拟机管理程序API对虚拟机实例进行创建、终止等操作的一个工作守护进程</li>\n<li>Conductor: 即nova-conductor服务，处理需要协同合作的请求，比如创建实例和调整实例等操作；同时还扮演了数据库代理的角色或者是处理对象转换</li>\n</ul>\n<p>在这个图中，值得注意的一点是Nova的几个主要服务组件之间，是通过oslo.messaging进行RPC调用，与外部服务之间通过HTTP的方式、RESTFul接口进行通讯和交互。</p>\n<p>在Compute中，有一个“Hypervisor”，这又是什么呢？</p>\n<p>我们讲，OpenStack其实是一个云管平台，即其本身不提供虚拟化功能，还是要依赖于操作系统底层的虚拟化技术，其中Hypervisor是虚拟化技术的核心。它是一种运行在物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）——</p>\n<blockquote>\n<p>In computing, a hypervisor, also called virtual machine monitor (VMM), is a piece of software/hardware platform-virtualization software that allows multiple operating systems to run on a host computer concurrently.</p>\n</blockquote>\n<p>目前常见的Hypervisor有QEMU、KVM、XEN、VMware等，其中，KVM是集成到Linux内核的Hypervisor，是X86架构且硬件支持虚拟化技术（Intel VT或AMD-V）的Linux的全虚拟化解决方案。它是Linux的一个很小的模块，利用Linux做大量的事，如任务调度、内存管理与硬件设备交互等。最为热门，也最为常用。</p>\n<p>此外，需要提一下qemu-kvm——</p>\n<blockquote>\n<p>QEMU将KVM整合进来，通过ioctl调用/dev/kvm接口，将有关CPU指令的部分交由内核模块来做。KVM负责CPU虚拟化+内存虚拟化，实现了CPU和内存的虚拟化，但KVM不能模拟其他设备。QEMU模拟IO设备（网卡，磁盘等），KVM加上QEMU之后就能实现真正意义上服务器虚拟化。因为用到了上面两个东西，所以称之为qemu-kvm，来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/kvm_archi_base_oh9pnk.png\" alt=\"\"></p>\n</blockquote>\n<p>在KVM这一层之上，是libvirt，它提供统一、稳定、开放源码的对各种虚拟机进行管理的工具（守护进程libvirtd、默认命令行管理工具virsh）和应用程序接口（API）。一些常用的虚拟机管理工具（如virsh、virt-install、virt-manager等）和云计算框架平台（如OpenStack等）都在底层使用libvirt的应用程序接口。</p>\n<p>在Nova的Compute服务中，通过不同的驱动来支持多种Hypervisor，与各种Hypervisor驱动的关系可以用下面的一张图来表示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/nova-compute-drivers.jpg\" alt=\"\"></p>\n<h2 id=\"Instance-Life-Cycle-Management-Process\"><a href=\"#Instance-Life-Cycle-Management-Process\" class=\"headerlink\" title=\"Instance Life Cycle Management Process\"></a>Instance Life Cycle Management Process</h2><p>在实例的生命周期管理流程中，常见的一些操作如下：</p>\n<ul>\n<li>创建：nova boot<ul>\n<li>boot from image</li>\n<li>boot from volume</li>\n</ul>\n</li>\n<li>重启：nova reboot<ul>\n<li>软重启，默认情况</li>\n<li>硬重启：nova reboot –hard，具体不同还需要用代码说话</li>\n</ul>\n</li>\n<li>启动：nova start</li>\n<li>停止：nova stop</li>\n<li>挂起：nova suspend</li>\n<li>暂停：nova pause，pause与suspend的区别在于pause将instance的运行状态保存在计算节点的内存中，而suspend保存在磁盘上。pause的优点在于恢复的速度比suspend快，缺点是如果计算节点重启，内存数据丢失，则无法resume。suspend就不存在该问题</li>\n<li>恢复：nova resume</li>\n<li>调整实例：nova resize</li>\n<li>迁移实例：<ul>\n<li>nova live-migration</li>\n<li>nova migrate，代码与nova resize相同，如果在resize时未提供flavor id，则仅migrate实例</li>\n</ul>\n</li>\n<li>重建：nova rebuild</li>\n<li>快照：nova image-create，对运行的虚机创建一个快照镜像，直接上传到Glance中，可用于恢复主机或以此镜像为模板创建新的主机</li>\n<li>备份：nova backup，通过创建一个<code>backup</code>类型的快照来备份主机</li>\n<li>删除：nova delete，立即关闭主机并删除实例</li>\n</ul>\n<p>后续需要对上面这些主要流程进行梳理，包括上面描述的几个命令的不同或者相似之处，我们让代码来说话。</p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]. <a href=\"https://huangwei.me/wiki/tech_cloud_kvm_qemu_libvirt_openstack.html\" target=\"_blank\" rel=\"noopener\">虚拟化类型</a><br>[2]. <a href=\"https://www.openstack.org/assets/presentation-media/OSSummitAtlanta2014-NovaLibvirtKVM2.pdf\" target=\"_blank\" rel=\"noopener\">Under the Hood with Nova, Libvirt and KVM</a><br>[3]. <a href=\"https://zhangchenchen.github.io/2016/08/22/openstack-nova/\" target=\"_blank\" rel=\"noopener\">OpenStack系列–Nova</a><br>[4]. <a href=\"https://docs.openstack.org/nova/latest/\" target=\"_blank\" rel=\"noopener\">OpenStack Compute(Nova)</a></p>"},{"title":"由一次服务连接MongoDB超时引发的思考","date":"2017-06-28T09:12:28.000Z","_content":"\n## 起因\n\n今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：\n<!-- more -->\n```\nCaused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed\n\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 63 common frames omitted\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]\n\t... 72 common frames omitted\n.....\n.....\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n{serverSelectors=[ReadPreferenceServerSelector{readPreference=primary}, LatencyMinimizingServerSelector{acceptableLatencyDifference=15 ms}]}. \nClient view of cluster state is {type=ReplicaSet, servers=[{address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected}, \n{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}, \n{address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected}]\n\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 49 common frames omitted\n```\n可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：\n```\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n...Client view of cluster state is...{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}...]\n```\n\n## 分析\n\n首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。\n\n这里需要将connectTimeout适当调整即可。\n\n## 探究\n\n在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的`connection timeout`和`socket timeout`两个参数。\n\n### Connection timeout\n\n这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会`hang`住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。\n\n这个参数的默认值，在Java的dirver中，`com.mongodb.MongoClientOptions.Builder#connectTimeout`的默认值是`1000*10`ms，即10s。\n\n那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。\n\n### Socket timeout\n\n这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。\n\n如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。\n\n在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，`com.mongodb.MongoClientOptions.Builder#socketTimeout`值是`0`,用于表示不限制。\n\n## 参考\n\n[[1].Do you want a timeout?](https://blog.mlab.com/2013/10/do-you-want-a-timeout/)\n[[2].mongodb connection timed out error](https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error)\n[[3].Class MongoClientOptions](https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html)\n\n\n","source":"_posts/mongodb-connecttimeout-and-sockettimeout.md","raw":"---\ntitle: 由一次服务连接MongoDB超时引发的思考\ndate: 2017-06-28 17:12:28\ntags: [MongoDB]\n---\n\n## 起因\n\n今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：\n<!-- more -->\n```\nCaused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed\n\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 63 common frames omitted\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]\n\t... 72 common frames omitted\n.....\n.....\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n{serverSelectors=[ReadPreferenceServerSelector{readPreference=primary}, LatencyMinimizingServerSelector{acceptableLatencyDifference=15 ms}]}. \nClient view of cluster state is {type=ReplicaSet, servers=[{address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected}, \n{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}, \n{address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected}]\n\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]\n\t... 49 common frames omitted\n```\n可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：\n```\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches \n...Client view of cluster state is...{address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting}...]\n```\n\n## 分析\n\n首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。\n\n这里需要将connectTimeout适当调整即可。\n\n## 探究\n\n在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的`connection timeout`和`socket timeout`两个参数。\n\n### Connection timeout\n\n这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会`hang`住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。\n\n这个参数的默认值，在Java的dirver中，`com.mongodb.MongoClientOptions.Builder#connectTimeout`的默认值是`1000*10`ms，即10s。\n\n那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。\n\n### Socket timeout\n\n这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。\n\n如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。\n\n在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，`com.mongodb.MongoClientOptions.Builder#socketTimeout`值是`0`,用于表示不限制。\n\n## 参考\n\n[[1].Do you want a timeout?](https://blog.mlab.com/2013/10/do-you-want-a-timeout/)\n[[2].mongodb connection timed out error](https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error)\n[[3].Class MongoClientOptions](https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html)\n\n\n","slug":"mongodb-connecttimeout-and-sockettimeout","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wx8000hxu2zbjxt85qv","content":"<h2 id=\"起因\"><a href=\"#起因\" class=\"headerlink\" title=\"起因\"></a>起因</h2><p>今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：<br><a id=\"more\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed</span><br><span class=\"line\">\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 63 common frames omitted</span><br><span class=\"line\">Caused by: java.net.SocketException: Connection reset</span><br><span class=\"line\">\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]</span><br><span class=\"line\">\t... 72 common frames omitted</span><br><span class=\"line\">.....</span><br><span class=\"line\">.....</span><br><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">&#123;serverSelectors=[ReadPreferenceServerSelector&#123;readPreference=primary&#125;, LatencyMinimizingServerSelector&#123;acceptableLatencyDifference=15 ms&#125;]&#125;. </span><br><span class=\"line\">Client view of cluster state is &#123;type=ReplicaSet, servers=[&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected&#125;]</span><br><span class=\"line\">\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 49 common frames omitted</span><br></pre></td></tr></table></figure></p>\n<p>可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">...Client view of cluster state is...&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;...]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。</p>\n<p>这里需要将connectTimeout适当调整即可。</p>\n<h2 id=\"探究\"><a href=\"#探究\" class=\"headerlink\" title=\"探究\"></a>探究</h2><p>在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的<code>connection timeout</code>和<code>socket timeout</code>两个参数。</p>\n<h3 id=\"Connection-timeout\"><a href=\"#Connection-timeout\" class=\"headerlink\" title=\"Connection timeout\"></a>Connection timeout</h3><p>这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会<code>hang</code>住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。</p>\n<p>这个参数的默认值，在Java的dirver中，<code>com.mongodb.MongoClientOptions.Builder#connectTimeout</code>的默认值是<code>1000*10</code>ms，即10s。</p>\n<p>那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。</p>\n<h3 id=\"Socket-timeout\"><a href=\"#Socket-timeout\" class=\"headerlink\" title=\"Socket timeout\"></a>Socket timeout</h3><p>这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。</p>\n<p>如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。</p>\n<p>在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，<code>com.mongodb.MongoClientOptions.Builder#socketTimeout</code>值是<code>0</code>,用于表示不限制。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://blog.mlab.com/2013/10/do-you-want-a-timeout/\" target=\"_blank\" rel=\"noopener\">[1].Do you want a timeout?</a><br><a href=\"https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error\" target=\"_blank\" rel=\"noopener\">[2].mongodb connection timed out error</a><br><a href=\"https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html\" target=\"_blank\" rel=\"noopener\">[3].Class MongoClientOptions</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"起因\"><a href=\"#起因\" class=\"headerlink\" title=\"起因\"></a>起因</h2><p>今天某个业务操作突然执行失败，查询服务日志发现，服务在些写数据的时候，连接被重置，和MongoTimeoutException，截取部分日志如下：<br>","more":"<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoException$Network: Operation on server xx.xx.xx.xx:27017 failed</span><br><span class=\"line\">\tat com.mongodb.DBTCPConnector.doOperation(DBTCPConnector.java:215) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 63 common frames omitted</span><br><span class=\"line\">Caused by: java.net.SocketException: Connection reset</span><br><span class=\"line\">\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[na:1.7.0_80]</span><br><span class=\"line\">\t... 72 common frames omitted</span><br><span class=\"line\">.....</span><br><span class=\"line\">.....</span><br><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">&#123;serverSelectors=[ReadPreferenceServerSelector&#123;readPreference=primary&#125;, LatencyMinimizingServerSelector&#123;acceptableLatencyDifference=15 ms&#125;]&#125;. </span><br><span class=\"line\">Client view of cluster state is &#123;type=ReplicaSet, servers=[&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetArbiter, averageLatency=1.3 ms, state=Connected&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;, </span><br><span class=\"line\">&#123;address=xx.xx.xx.xx:27017, type=ReplicaSetSecondary, averageLatency=1.1 ms, state=Connected&#125;]</span><br><span class=\"line\">\tat com.mongodb.BaseCluster.getServer(BaseCluster.java:82) ~[mongo-java-driver-2.13.0.jar:na]</span><br><span class=\"line\">\t... 49 common frames omitted</span><br></pre></td></tr></table></figure></p>\n<p>可以看到我们的服务在连接MongoDB时超时——没找到primary节点，在0ms后Timeout，抛出异常，即下面这段异常才是暴露问题的地方：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Caused by: com.mongodb.MongoTimeoutException: Timed out after 0 ms while waiting for a server that matches </span><br><span class=\"line\">...Client view of cluster state is...&#123;address=xx.xx.xx.xx:27017, type=Unknown, state=Connecting&#125;...]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先，通过在日志中找到最关键的那一部分，分析得出当时业务异常的问题是业务server到MongoDB Master节点网络稍微有些抖动/延迟，而我们配置的connectTimeout=0ms，所以业务server没有取得replica set中的primary节点，不知道该如何写入数据，才会抛出这个异常。</p>\n<p>这里需要将connectTimeout适当调整即可。</p>\n<h2 id=\"探究\"><a href=\"#探究\" class=\"headerlink\" title=\"探究\"></a>探究</h2><p>在我们的上层，无论何时创建MongoClient，driver会建立和service的连接，应用建立连接的等待时长和客户端请求后等待服务器响应的时长，取决于我们的<code>connection timeout</code>和<code>socket timeout</code>两个参数。</p>\n<h3 id=\"Connection-timeout\"><a href=\"#Connection-timeout\" class=\"headerlink\" title=\"Connection timeout\"></a>Connection timeout</h3><p>这个参数决定了我们的客户端等待建立与服务器建立一个连接的最长时间。一方面，我们希望连接超时时间足够长，这样我们的应用即使在面对较大的服务器负载或者断断续续的网络延迟的情况下，也可以较为可靠的与服务器端建立起一个连接，但是，另一方面，我们又不希望这个值过大，否则应用会<code>hang</code>住，在服务器暂时不可访问的情况下，过度的浪费时间在等待服务器的连接上。 所以设置这个值的大小便是仁者见仁智者见智的事情了。</p>\n<p>这个参数的默认值，在Java的dirver中，<code>com.mongodb.MongoClientOptions.Builder#connectTimeout</code>的默认值是<code>1000*10</code>ms，即10s。</p>\n<p>那在上面我们的案例中，设置为0ms显然是不可理的，网络延迟是不可能不存在的。</p>\n<h3 id=\"Socket-timeout\"><a href=\"#Socket-timeout\" class=\"headerlink\" title=\"Socket timeout\"></a>Socket timeout</h3><p>这个参数决定了我们的客户端等待服务端响应的最长时间，这个timeout参数控制了所有类型的请求——query、write、commands、authentication等等。</p>\n<p>如果我们将数值设置为30s，则客户端不会等服务端响应超过30s钟。所以通常来讲，我们是不会限制这个时间的，这样可以使数据库的操作响应比较自由。</p>\n<p>在大多数的driver中，这个参数都是无限大（或者没有限制的）。这个参数在Java的driver中，<code>com.mongodb.MongoClientOptions.Builder#socketTimeout</code>值是<code>0</code>,用于表示不限制。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://blog.mlab.com/2013/10/do-you-want-a-timeout/\" target=\"_blank\" rel=\"noopener\">[1].Do you want a timeout?</a><br><a href=\"https://stackoverflow.com/questions/40216639/mongodb-connection-timed-out-error\" target=\"_blank\" rel=\"noopener\">[2].mongodb connection timed out error</a><br><a href=\"https://mongodb.github.io/mongo-java-driver/3.4/javadoc/com/mongodb/MongoClientOptions.html\" target=\"_blank\" rel=\"noopener\">[3].Class MongoClientOptions</a></p>"},{"title":"Got signal:6 (Aborted) 引起的MongoDB崩溃分析解决","date":"2017-06-23T01:51:41.000Z","_content":"## 一、背景\n\n近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——\n<!--more-->\n发现，在日志中，有如下的一段backtrace：\n```\n2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).\n\n 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad\n----- BEGIN BACKTRACE -----\n{\"backtrace\":[{\"b\":\"400000\",\"o\":\"B5E669\"},{\"b\":\"400000\",\"o\":\"B5DCE2\"},{\"b\":\"400000\",\"o\":\"B5E096\"},{\"b\":\"3221000000\",\"o\":\"32660\"},{\"b\":\"3221000000\",\"o\":\"325E5\"},{\"b\":\"3221000000\",\"o\":\"33DC5\"},{\"b\":\"400000\",\"o\":\"9A0C59\"},{\"b\":\"400000\",\"o\":\"4DD622\"},{\"b\":\"400000\",\"o\":\"4DE181\"},{\"b\":\"400000\",\"o\":\"4B31D7\"},{\"b\":\"400000\",\"o\":\"4D1A17\"},{\"b\":\"400000\",\"o\":\"4D34D6\"},{\"b\":\"400000\",\"o\":\"5BDC64\"},{\"b\":\"400000\",\"o\":\"5BEBED\"},{\"b\":\"400000\",\"o\":\"5BF8FB\"},{\"b\":\"400000\",\"o\":\"79340A\"},{\"b\":\"400000\",\"o\":\"6A3480\"},{\"b\":\"400000\",\"o\":\"3E99FD\"},{\"b\":\"400000\",\"o\":\"B1BADB\"},{\"b\":\"3221400000\",\"o\":\"7AA1\"},{\"b\":\"3221000000\",\"o\":\"E8AAD\"}],\"processInfo\":{ \"mongodbVersion\" : \"3.0.6\", \"gitVersion\" : \"1ef45a23a4c5e3480ac919b28afcba3c615488f2\", \"uname\" : { \"sysname\" : \"Linux\", \"release\" : \"2.6.32-642.6.2.el6.x86_64\", \"version\" : \"#1 SMP Wed Oct 26 06:52:09 UTC 2016\", \"machine\" : \"x86_64\" }, \"somap\" : [ { \"elfType\" : 2, \"b\" : \"400000\" }, { \"b\" : \"7FFC4BCCC000\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libpthread.so.0\", \"elfType\" : 3 }, { \"path\" : \"/lib64/librt.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libdl.so.2\", \"elfType\" : 3 }, { \"path\" : \"/usr/lib64/libstdc++.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libm.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libgcc_s.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libc.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/ld-linux-x86-64.so.2\", \"elfType\" : 3 } ] }}\n mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]\n mongod(+0xB5DCE2) [0xf5dce2]\n mongod(+0xB5E096) [0xf5e096]\n libc.so.6(+0x32660) [0x3221032660]\n libc.so.6(gsignal+0x35) [0x32210325e5]\n libc.so.6(abort+0x175) [0x3221033dc5]\n mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]\n mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]\n mongod(+0x4D1A17) [0x8d1a17]\n mongod(+0x4D34D6) [0x8d34d6]\n mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]\n mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]\n mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]\n mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]\n mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]\n mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]\n mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]\n libpthread.so.0(+0x7AA1) [0x3221407aa1]\n libc.so.6(clone+0x6D) [0x32210e8aad]\n-----  END BACKTRACE  -----\n\n```\n\n除了`Got signal: 6 (Aborted)`还有点意义，下面的这些trace，完全不知所云。\n\n## 二、查询分析\n\n找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，[>>传送门](https://jira.mongodb.org/browse/SERVER-28001)，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的`ulimit`中的配置，并给出了配置的文档说明，[>>>传送门](https://docs.mongodb.com/manual/reference/ulimit/)，下面简单的总结一下——\n\n大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即`ulimit`，用于避免单用户使用过多的系统资源，当然，有些时候`ulimit`的一些默认值相对较低，所以会影响一些正常的MongoDB操作。\n\n简单的看一下如何设置资源限制——我们可以使用`ulimit`命令来检查目前的配置，例如：\n```\n[root@mongodb-master ~]# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 63706\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 10240\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 63706\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n在使用`ulimit`修改具体某个配置项的值时，例如修改open file时，语法为`ulimit -n <value>`。修改时还要注意，有`hard`和`soft`两个选项：\n\n|选项|含义|例子|\n|:---|:---|:---|\n|-H|设置硬资源限制，一旦设置不能增加|ulimit -Hs 64，限制硬资源，线程栈大小为64K|\n|-S|设置软资源限制，设置后可以增加，但是不能超过硬资源设置|ulimit -Sn 32，限制软资源，32个文件描述符|\n\nMongoDB官方手册中给出的`mongod`和`mongos`的设置推荐值为：\n* -f (file size): unlimited\n* -t (cpu time): unlimited\n* -v (virtual memory): unlimited \n* -n (open files): 64000\n* -m (memory size): unlimited \n* -u (processes/threads): 64000\n\n所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读[手册](https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits)获得帮助。\n\n>注：修改后需要对应重启`mongod`服务。\n\n## 三、延伸\n\nulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看`ulimit -a`会发现open file的值看起来像“恢复原状”（revert）一样。\n\n那么问题来了，刚才我们的设置是否生效还如何检查呢？\n首先，我们要知道修改后重启的`mongod`服务的PID，然后使用命令：`cat /proc/<PID>/limits`来查看当前进程的`ulimit`配置：\n```\n[root@mongodb-master ~]# ps -ef | grep mongo\nroot      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf\nroot     29337 28455  0 15:17 pts/0    00:00:00 grep mongo\n\n[root@mongodb-master ~]# cat /proc/4802/limits\nLimit                     Soft Limit           Hard Limit           Units     \nMax cpu time              unlimited            unlimited            seconds   \nMax file size             unlimited            unlimited            bytes     \nMax data size             unlimited            unlimited            bytes     \nMax stack size            10485760             unlimited            bytes     \nMax core file size        0                    unlimited            bytes     \nMax resident set          unlimited            unlimited            bytes     \nMax processes             63706                63706                processes \nMax open files            64000                64000                files     \nMax locked memory         65536                65536                bytes     \nMax address space         unlimited            unlimited            bytes     \nMax file locks            unlimited            unlimited            locks     \nMax pending signals       63706                63706                signals   \nMax msgqueue size         819200               819200               bytes     \nMax nice priority         0                    0                    \nMax realtime priority     0                    0                    \nMax realtime timeout      unlimited            unlimited            us        \n\n```\n可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。\n\n那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的`/etc/security/limits.conf`配置文件，格式如下：\n```\n<domain>      <type>  <item>         <value>\n```\n其中，`<domain>`表示用户或者组的名字，还可以使用`*`作为通配符，不过**通配符对`root`用户可是不生效的**，切记。\n\n不过我尝试各种软硬修改配置文件后，并没有发现`ulimit -a`有丝毫的变化，真的是扎铁了，老心，也许因为我用的是`root`用户？欢迎邮件交流：[zh.f@outlook.com](mailto:zh.f@outlook.com)\n\n## 四、参考\n\n[[1].Mongodb Crashed with the Got signal: 6 (Aborted)](https://jira.mongodb.org/browse/SERVER-28001)\n[[2].Unix ulimit Settings](https://docs.mongodb.com/manual/reference/ulimit/)\n[[3].How do I change the number of open files limit in Linux?](https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)\n[[4].Linux ulimit命令](http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html)\n[[5].ulimit -n not changing - values limits.conf has no effect](https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect)\n\n\n\n","source":"_posts/mongodb-crashed-with-the-Got-signal-6-Aborted.md","raw":"---\ntitle: Got signal:6 (Aborted) 引起的MongoDB崩溃分析解决\ndate: 2017-06-23 09:51:41\ntags: [MongoDB]\n---\n## 一、背景\n\n近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——\n<!--more-->\n发现，在日志中，有如下的一段backtrace：\n```\n2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).\n\n 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad\n----- BEGIN BACKTRACE -----\n{\"backtrace\":[{\"b\":\"400000\",\"o\":\"B5E669\"},{\"b\":\"400000\",\"o\":\"B5DCE2\"},{\"b\":\"400000\",\"o\":\"B5E096\"},{\"b\":\"3221000000\",\"o\":\"32660\"},{\"b\":\"3221000000\",\"o\":\"325E5\"},{\"b\":\"3221000000\",\"o\":\"33DC5\"},{\"b\":\"400000\",\"o\":\"9A0C59\"},{\"b\":\"400000\",\"o\":\"4DD622\"},{\"b\":\"400000\",\"o\":\"4DE181\"},{\"b\":\"400000\",\"o\":\"4B31D7\"},{\"b\":\"400000\",\"o\":\"4D1A17\"},{\"b\":\"400000\",\"o\":\"4D34D6\"},{\"b\":\"400000\",\"o\":\"5BDC64\"},{\"b\":\"400000\",\"o\":\"5BEBED\"},{\"b\":\"400000\",\"o\":\"5BF8FB\"},{\"b\":\"400000\",\"o\":\"79340A\"},{\"b\":\"400000\",\"o\":\"6A3480\"},{\"b\":\"400000\",\"o\":\"3E99FD\"},{\"b\":\"400000\",\"o\":\"B1BADB\"},{\"b\":\"3221400000\",\"o\":\"7AA1\"},{\"b\":\"3221000000\",\"o\":\"E8AAD\"}],\"processInfo\":{ \"mongodbVersion\" : \"3.0.6\", \"gitVersion\" : \"1ef45a23a4c5e3480ac919b28afcba3c615488f2\", \"uname\" : { \"sysname\" : \"Linux\", \"release\" : \"2.6.32-642.6.2.el6.x86_64\", \"version\" : \"#1 SMP Wed Oct 26 06:52:09 UTC 2016\", \"machine\" : \"x86_64\" }, \"somap\" : [ { \"elfType\" : 2, \"b\" : \"400000\" }, { \"b\" : \"7FFC4BCCC000\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libpthread.so.0\", \"elfType\" : 3 }, { \"path\" : \"/lib64/librt.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libdl.so.2\", \"elfType\" : 3 }, { \"path\" : \"/usr/lib64/libstdc++.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libm.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libgcc_s.so.1\", \"elfType\" : 3 }, { \"path\" : \"/lib64/libc.so.6\", \"elfType\" : 3 }, { \"path\" : \"/lib64/ld-linux-x86-64.so.2\", \"elfType\" : 3 } ] }}\n mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]\n mongod(+0xB5DCE2) [0xf5dce2]\n mongod(+0xB5E096) [0xf5e096]\n libc.so.6(+0x32660) [0x3221032660]\n libc.so.6(gsignal+0x35) [0x32210325e5]\n libc.so.6(abort+0x175) [0x3221033dc5]\n mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]\n mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]\n mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]\n mongod(+0x4D1A17) [0x8d1a17]\n mongod(+0x4D34D6) [0x8d34d6]\n mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]\n mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]\n mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]\n mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]\n mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]\n mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]\n mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]\n libpthread.so.0(+0x7AA1) [0x3221407aa1]\n libc.so.6(clone+0x6D) [0x32210e8aad]\n-----  END BACKTRACE  -----\n\n```\n\n除了`Got signal: 6 (Aborted)`还有点意义，下面的这些trace，完全不知所云。\n\n## 二、查询分析\n\n找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，[>>传送门](https://jira.mongodb.org/browse/SERVER-28001)，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的`ulimit`中的配置，并给出了配置的文档说明，[>>>传送门](https://docs.mongodb.com/manual/reference/ulimit/)，下面简单的总结一下——\n\n大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即`ulimit`，用于避免单用户使用过多的系统资源，当然，有些时候`ulimit`的一些默认值相对较低，所以会影响一些正常的MongoDB操作。\n\n简单的看一下如何设置资源限制——我们可以使用`ulimit`命令来检查目前的配置，例如：\n```\n[root@mongodb-master ~]# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 63706\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 10240\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 63706\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n在使用`ulimit`修改具体某个配置项的值时，例如修改open file时，语法为`ulimit -n <value>`。修改时还要注意，有`hard`和`soft`两个选项：\n\n|选项|含义|例子|\n|:---|:---|:---|\n|-H|设置硬资源限制，一旦设置不能增加|ulimit -Hs 64，限制硬资源，线程栈大小为64K|\n|-S|设置软资源限制，设置后可以增加，但是不能超过硬资源设置|ulimit -Sn 32，限制软资源，32个文件描述符|\n\nMongoDB官方手册中给出的`mongod`和`mongos`的设置推荐值为：\n* -f (file size): unlimited\n* -t (cpu time): unlimited\n* -v (virtual memory): unlimited \n* -n (open files): 64000\n* -m (memory size): unlimited \n* -u (processes/threads): 64000\n\n所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读[手册](https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits)获得帮助。\n\n>注：修改后需要对应重启`mongod`服务。\n\n## 三、延伸\n\nulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看`ulimit -a`会发现open file的值看起来像“恢复原状”（revert）一样。\n\n那么问题来了，刚才我们的设置是否生效还如何检查呢？\n首先，我们要知道修改后重启的`mongod`服务的PID，然后使用命令：`cat /proc/<PID>/limits`来查看当前进程的`ulimit`配置：\n```\n[root@mongodb-master ~]# ps -ef | grep mongo\nroot      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf\nroot     29337 28455  0 15:17 pts/0    00:00:00 grep mongo\n\n[root@mongodb-master ~]# cat /proc/4802/limits\nLimit                     Soft Limit           Hard Limit           Units     \nMax cpu time              unlimited            unlimited            seconds   \nMax file size             unlimited            unlimited            bytes     \nMax data size             unlimited            unlimited            bytes     \nMax stack size            10485760             unlimited            bytes     \nMax core file size        0                    unlimited            bytes     \nMax resident set          unlimited            unlimited            bytes     \nMax processes             63706                63706                processes \nMax open files            64000                64000                files     \nMax locked memory         65536                65536                bytes     \nMax address space         unlimited            unlimited            bytes     \nMax file locks            unlimited            unlimited            locks     \nMax pending signals       63706                63706                signals   \nMax msgqueue size         819200               819200               bytes     \nMax nice priority         0                    0                    \nMax realtime priority     0                    0                    \nMax realtime timeout      unlimited            unlimited            us        \n\n```\n可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。\n\n那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的`/etc/security/limits.conf`配置文件，格式如下：\n```\n<domain>      <type>  <item>         <value>\n```\n其中，`<domain>`表示用户或者组的名字，还可以使用`*`作为通配符，不过**通配符对`root`用户可是不生效的**，切记。\n\n不过我尝试各种软硬修改配置文件后，并没有发现`ulimit -a`有丝毫的变化，真的是扎铁了，老心，也许因为我用的是`root`用户？欢迎邮件交流：[zh.f@outlook.com](mailto:zh.f@outlook.com)\n\n## 四、参考\n\n[[1].Mongodb Crashed with the Got signal: 6 (Aborted)](https://jira.mongodb.org/browse/SERVER-28001)\n[[2].Unix ulimit Settings](https://docs.mongodb.com/manual/reference/ulimit/)\n[[3].How do I change the number of open files limit in Linux?](https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)\n[[4].Linux ulimit命令](http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html)\n[[5].ulimit -n not changing - values limits.conf has no effect](https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect)\n\n\n\n","slug":"mongodb-crashed-with-the-Got-signal-6-Aborted","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxa000ixu2zcp02nt30","content":"<h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——<br><a id=\"more\"></a><br>发现，在日志中，有如下的一段backtrace：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).</span><br><span class=\"line\"></span><br><span class=\"line\"> 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad</span><br><span class=\"line\">----- BEGIN BACKTRACE -----</span><br><span class=\"line\">&#123;&quot;backtrace&quot;:[&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E669&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5DCE2&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E096&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;32660&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;325E5&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;33DC5&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;9A0C59&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DD622&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DE181&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4B31D7&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D1A17&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D34D6&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BDC64&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BEBED&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BF8FB&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;79340A&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;6A3480&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;3E99FD&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B1BADB&quot;&#125;,&#123;&quot;b&quot;:&quot;3221400000&quot;,&quot;o&quot;:&quot;7AA1&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;E8AAD&quot;&#125;],&quot;processInfo&quot;:&#123; &quot;mongodbVersion&quot; : &quot;3.0.6&quot;, &quot;gitVersion&quot; : &quot;1ef45a23a4c5e3480ac919b28afcba3c615488f2&quot;, &quot;uname&quot; : &#123; &quot;sysname&quot; : &quot;Linux&quot;, &quot;release&quot; : &quot;2.6.32-642.6.2.el6.x86_64&quot;, &quot;version&quot; : &quot;#1 SMP Wed Oct 26 06:52:09 UTC 2016&quot;, &quot;machine&quot; : &quot;x86_64&quot; &#125;, &quot;somap&quot; : [ &#123; &quot;elfType&quot; : 2, &quot;b&quot; : &quot;400000&quot; &#125;, &#123; &quot;b&quot; : &quot;7FFC4BCCC000&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libpthread.so.0&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/librt.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libdl.so.2&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/usr/lib64/libstdc++.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libm.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libgcc_s.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libc.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/ld-linux-x86-64.so.2&quot;, &quot;elfType&quot; : 3 &#125; ] &#125;&#125;</span><br><span class=\"line\"> mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]</span><br><span class=\"line\"> mongod(+0xB5DCE2) [0xf5dce2]</span><br><span class=\"line\"> mongod(+0xB5E096) [0xf5e096]</span><br><span class=\"line\"> libc.so.6(+0x32660) [0x3221032660]</span><br><span class=\"line\"> libc.so.6(gsignal+0x35) [0x32210325e5]</span><br><span class=\"line\"> libc.so.6(abort+0x175) [0x3221033dc5]</span><br><span class=\"line\"> mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]</span><br><span class=\"line\"> mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]</span><br><span class=\"line\"> mongod(+0x4D1A17) [0x8d1a17]</span><br><span class=\"line\"> mongod(+0x4D34D6) [0x8d34d6]</span><br><span class=\"line\"> mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]</span><br><span class=\"line\"> mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]</span><br><span class=\"line\"> mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]</span><br><span class=\"line\"> mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]</span><br><span class=\"line\"> mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]</span><br><span class=\"line\"> mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]</span><br><span class=\"line\"> mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]</span><br><span class=\"line\"> libpthread.so.0(+0x7AA1) [0x3221407aa1]</span><br><span class=\"line\"> libc.so.6(clone+0x6D) [0x32210e8aad]</span><br><span class=\"line\">-----  END BACKTRACE  -----</span><br></pre></td></tr></table></figure></p>\n<p>除了<code>Got signal: 6 (Aborted)</code>还有点意义，下面的这些trace，完全不知所云。</p>\n<h2 id=\"二、查询分析\"><a href=\"#二、查询分析\" class=\"headerlink\" title=\"二、查询分析\"></a>二、查询分析</h2><p>找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，<a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的<code>ulimit</code>中的配置，并给出了配置的文档说明，<a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>，下面简单的总结一下——</p>\n<p>大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即<code>ulimit</code>，用于避免单用户使用过多的系统资源，当然，有些时候<code>ulimit</code>的一些默认值相对较低，所以会影响一些正常的MongoDB操作。</p>\n<p>简单的看一下如何设置资源限制——我们可以使用<code>ulimit</code>命令来检查目前的配置，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ulimit -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 63706</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64</span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited</span><br><span class=\"line\">open files                      (-n) 1024</span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 10240</span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 63706</span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure></p>\n<p>在使用<code>ulimit</code>修改具体某个配置项的值时，例如修改open file时，语法为<code>ulimit -n &lt;value&gt;</code>。修改时还要注意，有<code>hard</code>和<code>soft</code>两个选项：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-H</td>\n<td style=\"text-align:left\">设置硬资源限制，一旦设置不能增加</td>\n<td style=\"text-align:left\">ulimit -Hs 64，限制硬资源，线程栈大小为64K</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-S</td>\n<td style=\"text-align:left\">设置软资源限制，设置后可以增加，但是不能超过硬资源设置</td>\n<td style=\"text-align:left\">ulimit -Sn 32，限制软资源，32个文件描述符</td>\n</tr>\n</tbody>\n</table>\n<p>MongoDB官方手册中给出的<code>mongod</code>和<code>mongos</code>的设置推荐值为：</p>\n<ul>\n<li>-f (file size): unlimited</li>\n<li>-t (cpu time): unlimited</li>\n<li>-v (virtual memory): unlimited </li>\n<li>-n (open files): 64000</li>\n<li>-m (memory size): unlimited </li>\n<li>-u (processes/threads): 64000</li>\n</ul>\n<p>所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读<a href=\"https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits\" target=\"_blank\" rel=\"noopener\">手册</a>获得帮助。</p>\n<blockquote>\n<p>注：修改后需要对应重启<code>mongod</code>服务。</p>\n</blockquote>\n<h2 id=\"三、延伸\"><a href=\"#三、延伸\" class=\"headerlink\" title=\"三、延伸\"></a>三、延伸</h2><p>ulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看<code>ulimit -a</code>会发现open file的值看起来像“恢复原状”（revert）一样。</p>\n<p>那么问题来了，刚才我们的设置是否生效还如何检查呢？<br>首先，我们要知道修改后重启的<code>mongod</code>服务的PID，然后使用命令：<code>cat /proc/&lt;PID&gt;/limits</code>来查看当前进程的<code>ulimit</code>配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ps -ef | grep mongo</span><br><span class=\"line\">root      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf</span><br><span class=\"line\">root     29337 28455  0 15:17 pts/0    00:00:00 grep mongo</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mongodb-master ~]# cat /proc/4802/limits</span><br><span class=\"line\">Limit                     Soft Limit           Hard Limit           Units     </span><br><span class=\"line\">Max cpu time              unlimited            unlimited            seconds   </span><br><span class=\"line\">Max file size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max data size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max stack size            10485760             unlimited            bytes     </span><br><span class=\"line\">Max core file size        0                    unlimited            bytes     </span><br><span class=\"line\">Max resident set          unlimited            unlimited            bytes     </span><br><span class=\"line\">Max processes             63706                63706                processes </span><br><span class=\"line\">Max open files            64000                64000                files     </span><br><span class=\"line\">Max locked memory         65536                65536                bytes     </span><br><span class=\"line\">Max address space         unlimited            unlimited            bytes     </span><br><span class=\"line\">Max file locks            unlimited            unlimited            locks     </span><br><span class=\"line\">Max pending signals       63706                63706                signals   </span><br><span class=\"line\">Max msgqueue size         819200               819200               bytes     </span><br><span class=\"line\">Max nice priority         0                    0                    </span><br><span class=\"line\">Max realtime priority     0                    0                    </span><br><span class=\"line\">Max realtime timeout      unlimited            unlimited            us</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。</p>\n<p>那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的<code>/etc/security/limits.conf</code>配置文件，格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其中，<code>&lt;domain&gt;</code>表示用户或者组的名字，还可以使用<code>*</code>作为通配符，不过<strong>通配符对<code>root</code>用户可是不生效的</strong>，切记。</p>\n<p>不过我尝试各种软硬修改配置文件后，并没有发现<code>ulimit -a</code>有丝毫的变化，真的是扎铁了，老心，也许因为我用的是<code>root</code>用户？欢迎邮件交流：<a href=\"mailto:zh.f@outlook.com\" target=\"_blank\" rel=\"noopener\">zh.f@outlook.com</a></p>\n<h2 id=\"四、参考\"><a href=\"#四、参考\" class=\"headerlink\" title=\"四、参考\"></a>四、参考</h2><p><a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"noopener\">[1].Mongodb Crashed with the Got signal: 6 (Aborted)</a><br><a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"noopener\">[2].Unix ulimit Settings</a><br><a href=\"https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux\" target=\"_blank\" rel=\"noopener\">[3].How do I change the number of open files limit in Linux?</a><br><a href=\"http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html\" target=\"_blank\" rel=\"noopener\">[4].Linux ulimit命令</a><br><a href=\"https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect\" target=\"_blank\" rel=\"noopener\">[5].ulimit -n not changing - values limits.conf has no effect</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h2><p>近日，同事在对MongoDB的读写压力进行测试，再插入大量数据时，常会遇到MongoDB服务莫名崩溃。于是，这边对日志进行了分析——<br>","more":"<br>发现，在日志中，有如下的一段backtrace：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017-06-21T11:59:31.290+0800 F -        [conn963] Got signal: 6 (Aborted).</span><br><span class=\"line\"></span><br><span class=\"line\"> 0xf5e669 0xf5dce2 0xf5e096 0x3221032660 0x32210325e5 0x3221033dc5 0xda0c59 0x8dd622 0x8de181 0x8b31d7 0x8d1a17 0x8d34d6 0x9bdc64 0x9bebed 0x9bf8fb 0xb9340a 0xaa3480 0x7e99fd 0xf1badb 0x3221407aa1 0x32210e8aad</span><br><span class=\"line\">----- BEGIN BACKTRACE -----</span><br><span class=\"line\">&#123;&quot;backtrace&quot;:[&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E669&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5DCE2&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B5E096&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;32660&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;325E5&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;33DC5&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;9A0C59&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DD622&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4DE181&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4B31D7&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D1A17&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;4D34D6&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BDC64&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BEBED&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;5BF8FB&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;79340A&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;6A3480&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;3E99FD&quot;&#125;,&#123;&quot;b&quot;:&quot;400000&quot;,&quot;o&quot;:&quot;B1BADB&quot;&#125;,&#123;&quot;b&quot;:&quot;3221400000&quot;,&quot;o&quot;:&quot;7AA1&quot;&#125;,&#123;&quot;b&quot;:&quot;3221000000&quot;,&quot;o&quot;:&quot;E8AAD&quot;&#125;],&quot;processInfo&quot;:&#123; &quot;mongodbVersion&quot; : &quot;3.0.6&quot;, &quot;gitVersion&quot; : &quot;1ef45a23a4c5e3480ac919b28afcba3c615488f2&quot;, &quot;uname&quot; : &#123; &quot;sysname&quot; : &quot;Linux&quot;, &quot;release&quot; : &quot;2.6.32-642.6.2.el6.x86_64&quot;, &quot;version&quot; : &quot;#1 SMP Wed Oct 26 06:52:09 UTC 2016&quot;, &quot;machine&quot; : &quot;x86_64&quot; &#125;, &quot;somap&quot; : [ &#123; &quot;elfType&quot; : 2, &quot;b&quot; : &quot;400000&quot; &#125;, &#123; &quot;b&quot; : &quot;7FFC4BCCC000&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libpthread.so.0&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/librt.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libdl.so.2&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/usr/lib64/libstdc++.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libm.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libgcc_s.so.1&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/libc.so.6&quot;, &quot;elfType&quot; : 3 &#125;, &#123; &quot;path&quot; : &quot;/lib64/ld-linux-x86-64.so.2&quot;, &quot;elfType&quot; : 3 &#125; ] &#125;&#125;</span><br><span class=\"line\"> mongod(_ZN5mongo15printStackTraceERSo+0x29) [0xf5e669]</span><br><span class=\"line\"> mongod(+0xB5DCE2) [0xf5dce2]</span><br><span class=\"line\"> mongod(+0xB5E096) [0xf5e096]</span><br><span class=\"line\"> libc.so.6(+0x32660) [0x3221032660]</span><br><span class=\"line\"> libc.so.6(gsignal+0x35) [0x32210325e5]</span><br><span class=\"line\"> libc.so.6(abort+0x175) [0x3221033dc5]</span><br><span class=\"line\"> mongod(_ZN5mongo12SecureRandom6createEv+0x1B9) [0xda0c59]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation10_firstStepERSt6vectorISsSaISsEEPSs+0x16F2) [0x8dd622]</span><br><span class=\"line\"> mongod(_ZN5mongo31SaslSCRAMSHA1ServerConversation4stepERKNS_10StringDataEPSs+0x2F1) [0x8de181]</span><br><span class=\"line\"> mongod(_ZN5mongo31NativeSaslAuthenticationSession4stepERKNS_10StringDataEPSs+0x27) [0x8b31d7]</span><br><span class=\"line\"> mongod(+0x4D1A17) [0x8d1a17]</span><br><span class=\"line\"> mongod(+0x4D34D6) [0x8d34d6]</span><br><span class=\"line\"> mongod(_ZN5mongo12_execCommandEPNS_16OperationContextEPNS_7CommandERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x34) [0x9bdc64]</span><br><span class=\"line\"> mongod(_ZN5mongo7Command11execCommandEPNS_16OperationContextEPS0_iPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xC1D) [0x9bebed]</span><br><span class=\"line\"> mongod(_ZN5mongo12_runCommandsEPNS_16OperationContextEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x28B) [0x9bf8fb]</span><br><span class=\"line\"> mongod(_ZN5mongo8runQueryEPNS_16OperationContextERNS_7MessageERNS_12QueryMessageERKNS_15NamespaceStringERNS_5CurOpES3_+0x77A) [0xb9340a]</span><br><span class=\"line\"> mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0xB10) [0xaa3480]</span><br><span class=\"line\"> mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0xDD) [0x7e99fd]</span><br><span class=\"line\"> mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x34B) [0xf1badb]</span><br><span class=\"line\"> libpthread.so.0(+0x7AA1) [0x3221407aa1]</span><br><span class=\"line\"> libc.so.6(clone+0x6D) [0x32210e8aad]</span><br><span class=\"line\">-----  END BACKTRACE  -----</span><br></pre></td></tr></table></figure></p>\n<p>除了<code>Got signal: 6 (Aborted)</code>还有点意义，下面的这些trace，完全不知所云。</p>\n<h2 id=\"二、查询分析\"><a href=\"#二、查询分析\" class=\"headerlink\" title=\"二、查询分析\"></a>二、查询分析</h2><p>找到关键词之后，查询这件事情就很简单的了，Google一下，发现在MongoDB的JIRA上，有人提问相同的问题，<a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>，在下面的回复中，提到了，原因是因为我们在插入数据时，打开的文件数量超过了操作系统的<code>ulimit</code>中的配置，并给出了配置的文档说明，<a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"noopener\">&gt;&gt;&gt;传送门</a>，下面简单的总结一下——</p>\n<p>大多数类Unix的操作系统，如Linux和Mac OS X，提供了一些限制和控制系统资源使用的机制，这里的系统资源比如说：线程、文件、网络连接数等等。这个控制即<code>ulimit</code>，用于避免单用户使用过多的系统资源，当然，有些时候<code>ulimit</code>的一些默认值相对较低，所以会影响一些正常的MongoDB操作。</p>\n<p>简单的看一下如何设置资源限制——我们可以使用<code>ulimit</code>命令来检查目前的配置，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ulimit -a</span><br><span class=\"line\">core file size          (blocks, -c) 0</span><br><span class=\"line\">data seg size           (kbytes, -d) unlimited</span><br><span class=\"line\">scheduling priority             (-e) 0</span><br><span class=\"line\">file size               (blocks, -f) unlimited</span><br><span class=\"line\">pending signals                 (-i) 63706</span><br><span class=\"line\">max locked memory       (kbytes, -l) 64</span><br><span class=\"line\">max memory size         (kbytes, -m) unlimited</span><br><span class=\"line\">open files                      (-n) 1024</span><br><span class=\"line\">pipe size            (512 bytes, -p) 8</span><br><span class=\"line\">POSIX message queues     (bytes, -q) 819200</span><br><span class=\"line\">real-time priority              (-r) 0</span><br><span class=\"line\">stack size              (kbytes, -s) 10240</span><br><span class=\"line\">cpu time               (seconds, -t) unlimited</span><br><span class=\"line\">max user processes              (-u) 63706</span><br><span class=\"line\">virtual memory          (kbytes, -v) unlimited</span><br><span class=\"line\">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure></p>\n<p>在使用<code>ulimit</code>修改具体某个配置项的值时，例如修改open file时，语法为<code>ulimit -n &lt;value&gt;</code>。修改时还要注意，有<code>hard</code>和<code>soft</code>两个选项：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">含义</th>\n<th style=\"text-align:left\">例子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-H</td>\n<td style=\"text-align:left\">设置硬资源限制，一旦设置不能增加</td>\n<td style=\"text-align:left\">ulimit -Hs 64，限制硬资源，线程栈大小为64K</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-S</td>\n<td style=\"text-align:left\">设置软资源限制，设置后可以增加，但是不能超过硬资源设置</td>\n<td style=\"text-align:left\">ulimit -Sn 32，限制软资源，32个文件描述符</td>\n</tr>\n</tbody>\n</table>\n<p>MongoDB官方手册中给出的<code>mongod</code>和<code>mongos</code>的设置推荐值为：</p>\n<ul>\n<li>-f (file size): unlimited</li>\n<li>-t (cpu time): unlimited</li>\n<li>-v (virtual memory): unlimited </li>\n<li>-n (open files): 64000</li>\n<li>-m (memory size): unlimited </li>\n<li>-u (processes/threads): 64000</li>\n</ul>\n<p>所以对照推荐值，修改我们mongodb-master的ulimit配置即可。具体配置的语法，根据不同的Linux发行版本可能不同，可以阅读<a href=\"https://docs.mongodb.com/manual/reference/ulimit/#review-and-set-resource-limits\" target=\"_blank\" rel=\"noopener\">手册</a>获得帮助。</p>\n<blockquote>\n<p>注：修改后需要对应重启<code>mongod</code>服务。</p>\n</blockquote>\n<h2 id=\"三、延伸\"><a href=\"#三、延伸\" class=\"headerlink\" title=\"三、延伸\"></a>三、延伸</h2><p>ulimit作为对资源使用限制的一种方式，是有其作用范围的，它的作用对象是当前shell进程以及其派生的子进程，也就是说，上面我们配置完open file的值后，如果再打开一个shell终端，再次查看<code>ulimit -a</code>会发现open file的值看起来像“恢复原状”（revert）一样。</p>\n<p>那么问题来了，刚才我们的设置是否生效还如何检查呢？<br>首先，我们要知道修改后重启的<code>mongod</code>服务的PID，然后使用命令：<code>cat /proc/&lt;PID&gt;/limits</code>来查看当前进程的<code>ulimit</code>配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@mongodb-master ~]# ps -ef | grep mongo</span><br><span class=\"line\">root      4802     1 42 Jun21 ?        20:52:00 /root/mongodb-linux-x86_64-3.0.6/bin/mongod -f /root/mongodb-linux-x86_64-3.0.6/master.conf</span><br><span class=\"line\">root     29337 28455  0 15:17 pts/0    00:00:00 grep mongo</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mongodb-master ~]# cat /proc/4802/limits</span><br><span class=\"line\">Limit                     Soft Limit           Hard Limit           Units     </span><br><span class=\"line\">Max cpu time              unlimited            unlimited            seconds   </span><br><span class=\"line\">Max file size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max data size             unlimited            unlimited            bytes     </span><br><span class=\"line\">Max stack size            10485760             unlimited            bytes     </span><br><span class=\"line\">Max core file size        0                    unlimited            bytes     </span><br><span class=\"line\">Max resident set          unlimited            unlimited            bytes     </span><br><span class=\"line\">Max processes             63706                63706                processes </span><br><span class=\"line\">Max open files            64000                64000                files     </span><br><span class=\"line\">Max locked memory         65536                65536                bytes     </span><br><span class=\"line\">Max address space         unlimited            unlimited            bytes     </span><br><span class=\"line\">Max file locks            unlimited            unlimited            locks     </span><br><span class=\"line\">Max pending signals       63706                63706                signals   </span><br><span class=\"line\">Max msgqueue size         819200               819200               bytes     </span><br><span class=\"line\">Max nice priority         0                    0                    </span><br><span class=\"line\">Max realtime priority     0                    0                    </span><br><span class=\"line\">Max realtime timeout      unlimited            unlimited            us</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，这里我们的配置是生效的，如果服务重启后，对应是否生效，还需要检查和验证。</p>\n<p>那么，是否有针对某个具体用户的资源加以限制的方法呢？对于CentOS6来说，可以修改系统的<code>/etc/security/limits.conf</code>配置文件，格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span><br></pre></td></tr></table></figure></p>\n<p>其中，<code>&lt;domain&gt;</code>表示用户或者组的名字，还可以使用<code>*</code>作为通配符，不过<strong>通配符对<code>root</code>用户可是不生效的</strong>，切记。</p>\n<p>不过我尝试各种软硬修改配置文件后，并没有发现<code>ulimit -a</code>有丝毫的变化，真的是扎铁了，老心，也许因为我用的是<code>root</code>用户？欢迎邮件交流：<a href=\"mailto:zh.f@outlook.com\" target=\"_blank\" rel=\"noopener\">zh.f@outlook.com</a></p>\n<h2 id=\"四、参考\"><a href=\"#四、参考\" class=\"headerlink\" title=\"四、参考\"></a>四、参考</h2><p><a href=\"https://jira.mongodb.org/browse/SERVER-28001\" target=\"_blank\" rel=\"noopener\">[1].Mongodb Crashed with the Got signal: 6 (Aborted)</a><br><a href=\"https://docs.mongodb.com/manual/reference/ulimit/\" target=\"_blank\" rel=\"noopener\">[2].Unix ulimit Settings</a><br><a href=\"https://stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux\" target=\"_blank\" rel=\"noopener\">[3].How do I change the number of open files limit in Linux?</a><br><a href=\"http://www.cnblogs.com/wangkangluo1/archive/2012/06/06/2537677.html\" target=\"_blank\" rel=\"noopener\">[4].Linux ulimit命令</a><br><a href=\"https://serverfault.com/questions/569288/ulimit-n-not-changing-values-limits-conf-has-no-effect\" target=\"_blank\" rel=\"noopener\">[5].ulimit -n not changing - values limits.conf has no effect</a></p>"},{"title":"从Python中内嵌列表复制说起","date":"2017-03-29T02:00:31.000Z","_content":"\n## 写在前面\n\n在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。\n<!--more-->\n## 内嵌列表和列表拷贝中的问题\n\nPython中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：\n```python\n>>> m = [[0, 1, 2], [10, 11, 12], [20, 21, 22]]\n>>> m[0]\n[0, 1, 2]\n>>> m[0][1]\n1\n>>> m[2]\n[20, 21, 22]\n>>> m[2][2]\n22\n```\n当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。\n\n大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。\n\n\n创建一个含有内嵌列表的列表`original`：\n```python\n>>> nested = [0]\n>>> original = [nested, 1]\n>>> original\n[[0], 1]\n```\n列表`original`的第一个元素指向了列表`nested`，如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-01.png)\n\n列表`nested`的修改可以通过直接修改其本身，也可以通过修改列表`original`来实现，即：\n```python\n>>> nested[0] = 'zero'\n>>> original\n[['zero'], 1]\n>>> original[0][0] = 0\n>>> nested\n[0]\n>>> original\n[[0], 1]\n```\n\n如果我们将`nested`赋值为其他列表，则`nested`和`original`之间的连接就会断掉，即：\n```python\n>>> nested = [2]\n>>> original\n[[0], 1]\n```\n如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-02.png)\n\n除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——\n* 全切片(full slice)\n```python\n>>> x = [0, 1, 2]\n>>> y = x[:]\n>>> y\n[0, 1, 2]\n```\n* `+`或`*`运算符\n```python\n>>> x = [0, 1, 2]\n>>> y = x + []\n>>> y\n[0, 1, 2]\n>>> z = x * 1\n>>> z\n[0, 1, 2]\n```\n\n但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即*shallow copy*，与之相对的，是“深拷贝”，即*deep copy*。\n\n## 对列表的深拷贝\n\n对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用`copy`模块的`deepcopy`功能。\n\n```python\n>>> original = [[0], 1]\n>>> shallow = original[:]\n>>> import copy\n>>> deep = copy.deepcopy(original)\n```\n复制后两个列表的构成其实如下图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-03.png)\n\n在得到列表`shallow`和列表`deep`后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：\n```python\n>>> shallow[1]=2 #更改列表中非内嵌列表的值，原列表值不变\n>>> shallow\n[[0], 2]\n>>> original\n[[0], 1]\n>>> shallow[0][0]='zero' #更改内嵌列表的值，原列表内嵌列表值改变\n>>> shallow\n[['zero'], 2]\n>>> original\n[['zero'], 1]\n>>> \n>>> \n>>> deep[0][0]=5 #对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表\n>>> deep\n[[5], 1]\n>>> original\n[['zero'], 1]\n>>> \n```\n\n此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。\n\n## 总结和引申思考\n\n首先，明确一点，*deep copy*和*shallow copy*并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。\n\n根据维基百科中的[Object copying](https://en.wikipedia.org/wiki/Object_copying)中的描述，我们总结如下：\n\n![](http://elbarco.eos.eayun.com/imgs/shallow-copy.png)\n\n我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。\n\n![](http://elbarco.eos.eayun.com/imgs/deep-copy.png)\n\n我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。\n\n其他语言，如Java，可以参见StackOverFlow上的这一个讨论：[How do I copy an object in Java](http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java)，后面有机会再详细的梳理一下。\n\n\n\n## 参考\n\n1.[What's the difference between a deep copy and a shallow copy](http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy)\n2.[Object copying](https://en.wikipedia.org/wiki/Object_copying)\n3.[Shallow and deep copy](http://www.python-course.eu/deep_copy.php)\n4.[The Quick Python Book, 2nd Edition. Chapter 5.6](https://item.jd.com/19176803.html)\n\n\n\n\n\n\n\n","source":"_posts/nested-lists-and-deep-copies.md","raw":"---\ntitle: 从Python中内嵌列表复制说起\ndate: 2017-03-29 10:00:31\ntags: [Python, Deep Copy, Shallow Copy]\n---\n\n## 写在前面\n\n在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。\n<!--more-->\n## 内嵌列表和列表拷贝中的问题\n\nPython中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：\n```python\n>>> m = [[0, 1, 2], [10, 11, 12], [20, 21, 22]]\n>>> m[0]\n[0, 1, 2]\n>>> m[0][1]\n1\n>>> m[2]\n[20, 21, 22]\n>>> m[2][2]\n22\n```\n当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。\n\n大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。\n\n\n创建一个含有内嵌列表的列表`original`：\n```python\n>>> nested = [0]\n>>> original = [nested, 1]\n>>> original\n[[0], 1]\n```\n列表`original`的第一个元素指向了列表`nested`，如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-01.png)\n\n列表`nested`的修改可以通过直接修改其本身，也可以通过修改列表`original`来实现，即：\n```python\n>>> nested[0] = 'zero'\n>>> original\n[['zero'], 1]\n>>> original[0][0] = 0\n>>> nested\n[0]\n>>> original\n[[0], 1]\n```\n\n如果我们将`nested`赋值为其他列表，则`nested`和`original`之间的连接就会断掉，即：\n```python\n>>> nested = [2]\n>>> original\n[[0], 1]\n```\n如图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-02.png)\n\n除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——\n* 全切片(full slice)\n```python\n>>> x = [0, 1, 2]\n>>> y = x[:]\n>>> y\n[0, 1, 2]\n```\n* `+`或`*`运算符\n```python\n>>> x = [0, 1, 2]\n>>> y = x + []\n>>> y\n[0, 1, 2]\n>>> z = x * 1\n>>> z\n[0, 1, 2]\n```\n\n但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即*shallow copy*，与之相对的，是“深拷贝”，即*deep copy*。\n\n## 对列表的深拷贝\n\n对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用`copy`模块的`deepcopy`功能。\n\n```python\n>>> original = [[0], 1]\n>>> shallow = original[:]\n>>> import copy\n>>> deep = copy.deepcopy(original)\n```\n复制后两个列表的构成其实如下图所示：\n![](http://elbarco.eos.eayun.com/imgs/nested-list-03.png)\n\n在得到列表`shallow`和列表`deep`后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：\n```python\n>>> shallow[1]=2 #更改列表中非内嵌列表的值，原列表值不变\n>>> shallow\n[[0], 2]\n>>> original\n[[0], 1]\n>>> shallow[0][0]='zero' #更改内嵌列表的值，原列表内嵌列表值改变\n>>> shallow\n[['zero'], 2]\n>>> original\n[['zero'], 1]\n>>> \n>>> \n>>> deep[0][0]=5 #对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表\n>>> deep\n[[5], 1]\n>>> original\n[['zero'], 1]\n>>> \n```\n\n此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。\n\n## 总结和引申思考\n\n首先，明确一点，*deep copy*和*shallow copy*并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。\n\n根据维基百科中的[Object copying](https://en.wikipedia.org/wiki/Object_copying)中的描述，我们总结如下：\n\n![](http://elbarco.eos.eayun.com/imgs/shallow-copy.png)\n\n我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。\n\n![](http://elbarco.eos.eayun.com/imgs/deep-copy.png)\n\n我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。\n\n其他语言，如Java，可以参见StackOverFlow上的这一个讨论：[How do I copy an object in Java](http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java)，后面有机会再详细的梳理一下。\n\n\n\n## 参考\n\n1.[What's the difference between a deep copy and a shallow copy](http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy)\n2.[Object copying](https://en.wikipedia.org/wiki/Object_copying)\n3.[Shallow and deep copy](http://www.python-course.eu/deep_copy.php)\n4.[The Quick Python Book, 2nd Edition. Chapter 5.6](https://item.jd.com/19176803.html)\n\n\n\n\n\n\n\n","slug":"nested-lists-and-deep-copies","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxc000lxu2z6udddto2","content":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。<br><a id=\"more\"></a></p>\n<h2 id=\"内嵌列表和列表拷贝中的问题\"><a href=\"#内嵌列表和列表拷贝中的问题\" class=\"headerlink\" title=\"内嵌列表和列表拷贝中的问题\"></a>内嵌列表和列表拷贝中的问题</h2><p>Python中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m = [[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>]</span><br><span class=\"line\">[<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"number\">22</span></span><br></pre></td></tr></table></figure></p>\n<p>当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。</p>\n<p>大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。</p>\n<p>创建一个含有内嵌列表的列表<code>original</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [nested, <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>列表<code>original</code>的第一个元素指向了列表<code>nested</code>，如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-01.png\" alt=\"\"></p>\n<p>列表<code>nested</code>的修改可以通过直接修改其本身，也可以通过修改列表<code>original</code>来实现，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested[<span class=\"number\">0</span>] = <span class=\"string\">'zero'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested</span><br><span class=\"line\">[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如果我们将<code>nested</code>赋值为其他列表，则<code>nested</code>和<code>original</code>之间的连接就会断掉，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-02.png\" alt=\"\"></p>\n<p>除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——</p>\n<ul>\n<li><p>全切片(full slice)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>+</code>或<code>*</code>运算符</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x + []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x * <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即<em>shallow copy</em>，与之相对的，是“深拷贝”，即<em>deep copy</em>。</p>\n<h2 id=\"对列表的深拷贝\"><a href=\"#对列表的深拷贝\" class=\"headerlink\" title=\"对列表的深拷贝\"></a>对列表的深拷贝</h2><p>对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用<code>copy</code>模块的<code>deepcopy</code>功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow = original[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep = copy.deepcopy(original)</span><br></pre></td></tr></table></figure>\n<p>复制后两个列表的构成其实如下图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-03.png\" alt=\"\"></p>\n<p>在得到列表<code>shallow</code>和列表<code>deep</code>后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">1</span>]=<span class=\"number\">2</span> <span class=\"comment\">#更改列表中非内嵌列表的值，原列表值不变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"string\">'zero'</span> <span class=\"comment\">#更改内嵌列表的值，原列表内嵌列表值改变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"number\">5</span> <span class=\"comment\">#对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep</span><br><span class=\"line\">[[<span class=\"number\">5</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。</p>\n<h2 id=\"总结和引申思考\"><a href=\"#总结和引申思考\" class=\"headerlink\" title=\"总结和引申思考\"></a>总结和引申思考</h2><p>首先，明确一点，<em>deep copy</em>和<em>shallow copy</em>并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。</p>\n<p>根据维基百科中的<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"noopener\">Object copying</a>中的描述，我们总结如下：</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/shallow-copy.png\" alt=\"\"></p>\n<p>我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/deep-copy.png\" alt=\"\"></p>\n<p>我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。</p>\n<p>其他语言，如Java，可以参见StackOverFlow上的这一个讨论：<a href=\"http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java\" target=\"_blank\" rel=\"noopener\">How do I copy an object in Java</a>，后面有机会再详细的梳理一下。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy\" target=\"_blank\" rel=\"noopener\">What’s the difference between a deep copy and a shallow copy</a><br>2.<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"noopener\">Object copying</a><br>3.<a href=\"http://www.python-course.eu/deep_copy.php\" target=\"_blank\" rel=\"noopener\">Shallow and deep copy</a><br>4.<a href=\"https://item.jd.com/19176803.html\" target=\"_blank\" rel=\"noopener\">The Quick Python Book, 2nd Edition. Chapter 5.6</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>在学习Python3时，看到了列表的拷贝，于是把这个小课题整理在这里，以作记录。<br>","more":"</p>\n<h2 id=\"内嵌列表和列表拷贝中的问题\"><a href=\"#内嵌列表和列表拷贝中的问题\" class=\"headerlink\" title=\"内嵌列表和列表拷贝中的问题\"></a>内嵌列表和列表拷贝中的问题</h2><p>Python中的列表是可以嵌入列表的，这个特性的应用场景之一便是用于表示二维矩阵。如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m = [[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>], [<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>]</span><br><span class=\"line\">[<span class=\"number\">20</span>, <span class=\"number\">21</span>, <span class=\"number\">22</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>m[<span class=\"number\">2</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"number\">22</span></span><br></pre></td></tr></table></figure></p>\n<p>当然，这一特性可以用于按照我们自己的方式扩展到更多维的矩阵。</p>\n<p>大部分情况下，内嵌列表如果只是这样使用，我们需要关心的也就到此为止了。但是因为有变量引用对象，而对象本身又是可被修改的情况，比如列表中内嵌列表，而内嵌列表本身是可被修改的，我们还会遇到下面提到的问题，我们通过例子来演示。</p>\n<p>创建一个含有内嵌列表的列表<code>original</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [nested, <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>列表<code>original</code>的第一个元素指向了列表<code>nested</code>，如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-01.png\" alt=\"\"></p>\n<p>列表<code>nested</code>的修改可以通过直接修改其本身，也可以通过修改列表<code>original</code>来实现，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested[<span class=\"number\">0</span>] = <span class=\"string\">'zero'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested</span><br><span class=\"line\">[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如果我们将<code>nested</code>赋值为其他列表，则<code>nested</code>和<code>original</code>之间的连接就会断掉，即：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>nested = [<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure></p>\n<p>如图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-02.png\" alt=\"\"></p>\n<p>除了上面提到的直接赋值的方式，列表的拷贝我们还可以使用——</p>\n<ul>\n<li><p>全切片(full slice)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>+</code>或<code>*</code>运算符</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x + []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x * <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z</span><br><span class=\"line\">[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>但是无论上面哪种复制方式，只要列表中存在嵌入列表，就会存在这种问题，我们把这种复制称之为“浅拷贝”，即<em>shallow copy</em>，与之相对的，是“深拷贝”，即<em>deep copy</em>。</p>\n<h2 id=\"对列表的深拷贝\"><a href=\"#对列表的深拷贝\" class=\"headerlink\" title=\"对列表的深拷贝\"></a>对列表的深拷贝</h2><p>对于含有内嵌列表的列表来讲，如果我们需要把内嵌列表也一并拷贝，则需要使用<code>copy</code>模块的<code>deepcopy</code>功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original = [[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow = original[:]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep = copy.deepcopy(original)</span><br></pre></td></tr></table></figure>\n<p>复制后两个列表的构成其实如下图所示：<br><img src=\"http://elbarco.eos.eayun.com/imgs/nested-list-03.png\" alt=\"\"></p>\n<p>在得到列表<code>shallow</code>和列表<code>deep</code>后，我们去尝试修改列表中的值和内嵌列表的值，并看看效果如何：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">1</span>]=<span class=\"number\">2</span> <span class=\"comment\">#更改列表中非内嵌列表的值，原列表值不变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"number\">0</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"string\">'zero'</span> <span class=\"comment\">#更改内嵌列表的值，原列表内嵌列表值改变</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>shallow</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep[<span class=\"number\">0</span>][<span class=\"number\">0</span>]=<span class=\"number\">5</span> <span class=\"comment\">#对于deep copy的列表，即使修改内嵌列表的值也不会影响原列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>deep</span><br><span class=\"line\">[[<span class=\"number\">5</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>original</span><br><span class=\"line\">[[<span class=\"string\">'zero'</span>], <span class=\"number\">1</span>]</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>此外，对于Python来讲，任何列表中嵌入的对象是可修改的，如字典，都会存在这样的问题。</p>\n<h2 id=\"总结和引申思考\"><a href=\"#总结和引申思考\" class=\"headerlink\" title=\"总结和引申思考\"></a>总结和引申思考</h2><p>首先，明确一点，<em>deep copy</em>和<em>shallow copy</em>并不是Python中特有的概念，而是一个与复制对象时对象的成员是否被复制有关的通用的概念。</p>\n<p>根据维基百科中的<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"noopener\">Object copying</a>中的描述，我们总结如下：</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/shallow-copy.png\" alt=\"\"></p>\n<p>我们有变量A和变量B指向不同的内存地址，当B被赋值为A时，两个变量指向了同样的内存地址，之后无论是修改A还是B的内容，都会在另一个变量中立即体现出来，因为两者共享内容。</p>\n<p><img src=\"http://elbarco.eos.eayun.com/imgs/deep-copy.png\" alt=\"\"></p>\n<p>我们有变量A和B指向了不同的内容地址，当B被赋值为A时，指向A内存地址的内容被复制到B的内存中，之后无论是修改A还是B的内容，A和B都是保持独立的，因为两者不共享内存，即不共享内容。</p>\n<p>其他语言，如Java，可以参见StackOverFlow上的这一个讨论：<a href=\"http://stackoverflow.com/questions/869033/how-do-i-copy-an-object-in-java\" target=\"_blank\" rel=\"noopener\">How do I copy an object in Java</a>，后面有机会再详细的梳理一下。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://stackoverflow.com/questions/184710/what-is-the-difference-between-a-deep-copy-and-a-shallow-copy\" target=\"_blank\" rel=\"noopener\">What’s the difference between a deep copy and a shallow copy</a><br>2.<a href=\"https://en.wikipedia.org/wiki/Object_copying\" target=\"_blank\" rel=\"noopener\">Object copying</a><br>3.<a href=\"http://www.python-course.eu/deep_copy.php\" target=\"_blank\" rel=\"noopener\">Shallow and deep copy</a><br>4.<a href=\"https://item.jd.com/19176803.html\" target=\"_blank\" rel=\"noopener\">The Quick Python Book, 2nd Edition. Chapter 5.6</a></p>"},{"title":"Python中的元组和Packing/Unpacking","date":"2017-03-30T03:02:31.000Z","_content":"\n## 什么是元组\n\n元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号`()`包起来，如：\n<!--more-->\n```python\n>>> x = ('a','b','c') #具有三个元素的元组\n>>> y = ('a',) #只有一个元素的元组，注意，必须有一个逗号来标识\n>>> z = () #空元组\n```\n元组的操作跟列表非常类似，如`+`，`*`，切片等，在元组中同样适用：\n```python\n>>> a = (1,2,3)\n>>> a[:2]\n(1, 2)\n>>> a * 1\n(1, 2, 3)\n>>> a + (4,5)\n(1, 2, 3, 4, 5)\n```\n\n## 元组的Packing/Unpacking\n\nPython中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：\n```python\n>>> (a,b,c,d) = (1,2,3,4)\n>>> a\n1\n>>> c\n3\n```\n上面的写法还可以简化为:\n```python\n>>> a,b,c,d = 1,2,3,4\n```\n这个用法还可以非常方便的完成交换两个变量的值：\n```python\n>>> var1, var2 = var2, var1\n```\n\n在Python3中，还提供了一个扩展的unpacking特性——使用`*`来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：\n```python\n>>> x = (1,2,3,4)\n>>> a, b, *c = x\n>>> a, b, c\n(1, 2, [3, 4])\n>>> a, *b, c = x\n>>> a, b, c\n(1, [2, 3], 4)\n>>> *a, b, c = x\n>>> a, b, c\n([1, 2], 3, 4)\n>>> a, b, c, d, *e = x\n>>> a, b, c, d, e\n(1, 2, 3, 4, [])\n```\n被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。\n\n## Python中的Packing/Unpacking应用\n\nPython中，我们可以使用`*`（对元组来说）和`**`（对字典来说）的Packing和Unpacking函数的参数。\n\n### * for tuples\n从下面这个例子说起，我们有一个函数`fun()`接收四个函数，并打印出来：\n```python\ndef fun(a, b, c, d):\n    print(a, b, c, d)\n```\n\n假设我们有一个list：\n```\n>>> my_list = [1, 2, 3, 4]\n```\n调用函数`fun()`：\n```python\n>>> my_list = [1,2,3,4]\n>>> fun(my_list)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: fun() missing 3 required positional arguments: 'b', 'c', and 'd'\n>>> \n```\n会得到报错信息，函数认为我们的`my_list`是单独的一个参数，而函数还需要额外的三个参数。\n\n这时候，我们可以使用`*`来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：\n```python\n>>> fun(*my_list)\n1 2 3 4\n```\n这里还有另一个例子，使用内置的`range()`函数，来演示解包列表的操作：\n>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值\n\n```python\n>>> list(range(3,7))\n[3, 4, 5, 6]\n>>> args = [3,7]\n>>> list(range(args))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'list' object cannot be interpreted as an integer\n>>> list(range(*args))\n[3, 4, 5, 6]\n```\n当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。\n\n我们有函数`iSum()`来做求和操作\n```python\ndef iSum(*args):\n    sum=0\n    print(args) #把args打印出来，看是否被打包为一个元组\n    for i in range(0, len(args)):\n        sum = sum + args[i]\n    return sum\n\n```\n测试时，传参个数不等，得到的输出如下：\n```python\n>>> print(iSum(1,2,3,4,5))\n(1, 2, 3, 4, 5)\n15\n>>> print(iSum(10,20,30))\n(10, 20, 30)\n60\n```\n\n可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。\n\n如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。\n我们有函数`func1()`用于打印入参，`func2()`用户修改入参的值：\n```python\n>>> def func1(a,b,c):\n...     print(a,b,c)\n... \n>>> def func2(*args):\n...     args = list(args)\n...     args[0] = 'elbarco.cn'\n...     args[1] = 'awesome'\n...     func1(*args)\n...\n```\n调用`func2()`，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：\n```python\n>>> func2('Hello','nice','visitors')\nelbarco.cn awesome visitors\n```\n### ** for dictionaries\n\n对于字典（Dictionary），Packing/Unpacking操作使用`**`。\n\n还是使用上面的`func1()`，如果要打印字典的值，则需要使用`**`来解包：\n```\n>>> dict = {'a':1,'b':3,'c':5}\n>>> func1(**dict)\n1 3 5\n```\n\n下面来一个打包的例子：\n```\n>>> def func3(**elbarco):\n...     print(type(elbarco))\n...     for key in elbarco:\n...         print(\"%s = %s\" % (key, elbarco[key]))\n... \n```\n传几个参数，用`func3()`将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：\n```python\n>>> func3(name='elbarco', location='Beijing', language='Java/Python')\n<class 'dict'>\nname = elbarco\nlocation = Beijing\nlanguage = Java/Python\n```\n\n以上。\n\n## 参考\n\n1.[The Quick Python Book 2nd Edition.Chaptor 5.7.3]()\n2.[Packing and Unpacking Arguments in Python](http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/)\n3.[Packing and Unpacking Arguments in Python](https://hangar.runway7.net/python/packing-unpacking-arguments)\n4.[Python’s range() Function Explained](http://pythoncentral.io/pythons-range-function-explained/)\n","source":"_posts/packing-and-unpacking-tuples.md","raw":"---\ntitle: Python中的元组和Packing/Unpacking\ndate: 2017-03-30 11:02:31\ntags: [Python, Tuple]\n---\n\n## 什么是元组\n\n元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号`()`包起来，如：\n<!--more-->\n```python\n>>> x = ('a','b','c') #具有三个元素的元组\n>>> y = ('a',) #只有一个元素的元组，注意，必须有一个逗号来标识\n>>> z = () #空元组\n```\n元组的操作跟列表非常类似，如`+`，`*`，切片等，在元组中同样适用：\n```python\n>>> a = (1,2,3)\n>>> a[:2]\n(1, 2)\n>>> a * 1\n(1, 2, 3)\n>>> a + (4,5)\n(1, 2, 3, 4, 5)\n```\n\n## 元组的Packing/Unpacking\n\nPython中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：\n```python\n>>> (a,b,c,d) = (1,2,3,4)\n>>> a\n1\n>>> c\n3\n```\n上面的写法还可以简化为:\n```python\n>>> a,b,c,d = 1,2,3,4\n```\n这个用法还可以非常方便的完成交换两个变量的值：\n```python\n>>> var1, var2 = var2, var1\n```\n\n在Python3中，还提供了一个扩展的unpacking特性——使用`*`来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：\n```python\n>>> x = (1,2,3,4)\n>>> a, b, *c = x\n>>> a, b, c\n(1, 2, [3, 4])\n>>> a, *b, c = x\n>>> a, b, c\n(1, [2, 3], 4)\n>>> *a, b, c = x\n>>> a, b, c\n([1, 2], 3, 4)\n>>> a, b, c, d, *e = x\n>>> a, b, c, d, e\n(1, 2, 3, 4, [])\n```\n被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。\n\n## Python中的Packing/Unpacking应用\n\nPython中，我们可以使用`*`（对元组来说）和`**`（对字典来说）的Packing和Unpacking函数的参数。\n\n### * for tuples\n从下面这个例子说起，我们有一个函数`fun()`接收四个函数，并打印出来：\n```python\ndef fun(a, b, c, d):\n    print(a, b, c, d)\n```\n\n假设我们有一个list：\n```\n>>> my_list = [1, 2, 3, 4]\n```\n调用函数`fun()`：\n```python\n>>> my_list = [1,2,3,4]\n>>> fun(my_list)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: fun() missing 3 required positional arguments: 'b', 'c', and 'd'\n>>> \n```\n会得到报错信息，函数认为我们的`my_list`是单独的一个参数，而函数还需要额外的三个参数。\n\n这时候，我们可以使用`*`来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：\n```python\n>>> fun(*my_list)\n1 2 3 4\n```\n这里还有另一个例子，使用内置的`range()`函数，来演示解包列表的操作：\n>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值\n\n```python\n>>> list(range(3,7))\n[3, 4, 5, 6]\n>>> args = [3,7]\n>>> list(range(args))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'list' object cannot be interpreted as an integer\n>>> list(range(*args))\n[3, 4, 5, 6]\n```\n当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。\n\n我们有函数`iSum()`来做求和操作\n```python\ndef iSum(*args):\n    sum=0\n    print(args) #把args打印出来，看是否被打包为一个元组\n    for i in range(0, len(args)):\n        sum = sum + args[i]\n    return sum\n\n```\n测试时，传参个数不等，得到的输出如下：\n```python\n>>> print(iSum(1,2,3,4,5))\n(1, 2, 3, 4, 5)\n15\n>>> print(iSum(10,20,30))\n(10, 20, 30)\n60\n```\n\n可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。\n\n如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。\n我们有函数`func1()`用于打印入参，`func2()`用户修改入参的值：\n```python\n>>> def func1(a,b,c):\n...     print(a,b,c)\n... \n>>> def func2(*args):\n...     args = list(args)\n...     args[0] = 'elbarco.cn'\n...     args[1] = 'awesome'\n...     func1(*args)\n...\n```\n调用`func2()`，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：\n```python\n>>> func2('Hello','nice','visitors')\nelbarco.cn awesome visitors\n```\n### ** for dictionaries\n\n对于字典（Dictionary），Packing/Unpacking操作使用`**`。\n\n还是使用上面的`func1()`，如果要打印字典的值，则需要使用`**`来解包：\n```\n>>> dict = {'a':1,'b':3,'c':5}\n>>> func1(**dict)\n1 3 5\n```\n\n下面来一个打包的例子：\n```\n>>> def func3(**elbarco):\n...     print(type(elbarco))\n...     for key in elbarco:\n...         print(\"%s = %s\" % (key, elbarco[key]))\n... \n```\n传几个参数，用`func3()`将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：\n```python\n>>> func3(name='elbarco', location='Beijing', language='Java/Python')\n<class 'dict'>\nname = elbarco\nlocation = Beijing\nlanguage = Java/Python\n```\n\n以上。\n\n## 参考\n\n1.[The Quick Python Book 2nd Edition.Chaptor 5.7.3]()\n2.[Packing and Unpacking Arguments in Python](http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/)\n3.[Packing and Unpacking Arguments in Python](https://hangar.runway7.net/python/packing-unpacking-arguments)\n4.[Python’s range() Function Explained](http://pythoncentral.io/pythons-range-function-explained/)\n","slug":"packing-and-unpacking-tuples","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxc000nxu2zjgukk6ew","content":"<h2 id=\"什么是元组\"><a href=\"#什么是元组\" class=\"headerlink\" title=\"什么是元组\"></a>什么是元组</h2><p>元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号<code>()</code>包起来，如：<br><a id=\"more\"></a><br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>) <span class=\"comment\">#具有三个元素的元组</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = (<span class=\"string\">'a'</span>,) <span class=\"comment\">#只有一个元素的元组，注意，必须有一个逗号来标识</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = () <span class=\"comment\">#空元组</span></span><br></pre></td></tr></table></figure></p>\n<p>元组的操作跟列表非常类似，如<code>+</code>，<code>*</code>，切片等，在元组中同样适用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a[:<span class=\"number\">2</span>]</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a * <span class=\"number\">1</span></span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a + (<span class=\"number\">4</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"元组的Packing-Unpacking\"><a href=\"#元组的Packing-Unpacking\" class=\"headerlink\" title=\"元组的Packing/Unpacking\"></a>元组的Packing/Unpacking</h2><p>Python中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>(a,b,c,d) = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>c</span><br><span class=\"line\"><span class=\"number\">3</span></span><br></pre></td></tr></table></figure></p>\n<p>上面的写法还可以简化为:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a,b,c,d = <span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这个用法还可以非常方便的完成交换两个变量的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>var1, var2 = var2, var1</span><br></pre></td></tr></table></figure></p>\n<p>在Python3中，还提供了一个扩展的unpacking特性——使用<code>*</code>来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, *c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, [<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, *b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, [<span class=\"number\">2</span>, <span class=\"number\">3</span>], <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>*a, b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">([<span class=\"number\">1</span>, <span class=\"number\">2</span>], <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, *e = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, e</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, [])</span><br></pre></td></tr></table></figure></p>\n<p>被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。</p>\n<h2 id=\"Python中的Packing-Unpacking应用\"><a href=\"#Python中的Packing-Unpacking应用\" class=\"headerlink\" title=\"Python中的Packing/Unpacking应用\"></a>Python中的Packing/Unpacking应用</h2><p>Python中，我们可以使用<code>*</code>（对元组来说）和<code>**</code>（对字典来说）的Packing和Unpacking函数的参数。</p>\n<h3 id=\"for-tuples\"><a href=\"#for-tuples\" class=\"headerlink\" title=\"* for tuples\"></a>* for tuples</h3><p>从下面这个例子说起，我们有一个函数<code>fun()</code>接收四个函数，并打印出来：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(a, b, c, d)</span>:</span></span><br><span class=\"line\">    print(a, b, c, d)</span><br></pre></td></tr></table></figure></p>\n<p>假设我们有一个list：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; my_list = [1, 2, 3, 4]</span><br></pre></td></tr></table></figure></p>\n<p>调用函数<code>fun()</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_list = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(my_list)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: fun() missing <span class=\"number\">3</span> required positional arguments: <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"keyword\">and</span> <span class=\"string\">'d'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>会得到报错信息，函数认为我们的<code>my_list</code>是单独的一个参数，而函数还需要额外的三个参数。</p>\n<p>这时候，我们可以使用<code>*</code>来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(*my_list)</span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这里还有另一个例子，使用内置的<code>range()</code>函数，来演示解包列表的操作：</p>\n<blockquote>\n<p>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(<span class=\"number\">3</span>,<span class=\"number\">7</span>))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>args = [<span class=\"number\">3</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(args))</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: <span class=\"string\">'list'</span> object cannot be interpreted <span class=\"keyword\">as</span> an integer</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(*args))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br></pre></td></tr></table></figure>\n<p>当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。</p>\n<p>我们有函数<code>iSum()</code>来做求和操作<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iSum</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\">    sum=<span class=\"number\">0</span></span><br><span class=\"line\">    print(args) <span class=\"comment\">#把args打印出来，看是否被打包为一个元组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(args)):</span><br><span class=\"line\">        sum = sum + args[i]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sum</span><br></pre></td></tr></table></figure></p>\n<p>测试时，传参个数不等，得到的输出如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>))</span><br><span class=\"line\">(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"number\">60</span></span><br></pre></td></tr></table></figure></p>\n<p>可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。</p>\n<p>如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。<br>我们有函数<code>func1()</code>用于打印入参，<code>func2()</code>用户修改入参的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func1</span><span class=\"params\">(a,b,c)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    print(a,b,c)</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func2</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args = list(args)</span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">0</span>] = <span class=\"string\">'elbarco.cn'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">1</span>] = <span class=\"string\">'awesome'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    func1(*args)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>调用<code>func2()</code>，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func2(<span class=\"string\">'Hello'</span>,<span class=\"string\">'nice'</span>,<span class=\"string\">'visitors'</span>)</span><br><span class=\"line\">elbarco.cn awesome visitors</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"for-dictionaries\"><a href=\"#for-dictionaries\" class=\"headerlink\" title=\"** for dictionaries\"></a>** for dictionaries</h3><p>对于字典（Dictionary），Packing/Unpacking操作使用<code>**</code>。</p>\n<p>还是使用上面的<code>func1()</code>，如果要打印字典的值，则需要使用<code>**</code>来解包：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; dict = &#123;&apos;a&apos;:1,&apos;b&apos;:3,&apos;c&apos;:5&#125;</span><br><span class=\"line\">&gt;&gt;&gt; func1(**dict)</span><br><span class=\"line\">1 3 5</span><br></pre></td></tr></table></figure></p>\n<p>下面来一个打包的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; def func3(**elbarco):</span><br><span class=\"line\">...     print(type(elbarco))</span><br><span class=\"line\">...     for key in elbarco:</span><br><span class=\"line\">...         print(&quot;%s = %s&quot; % (key, elbarco[key]))</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>传几个参数，用<code>func3()</code>将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func3(name=<span class=\"string\">'elbarco'</span>, location=<span class=\"string\">'Beijing'</span>, language=<span class=\"string\">'Java/Python'</span>)</span><br><span class=\"line\">&lt;<span class=\"class\"><span class=\"keyword\">class</span> '<span class=\"title\">dict</span>'&gt;</span></span><br><span class=\"line\">name = elbarco</span><br><span class=\"line\">location = Beijing</span><br><span class=\"line\">language = Java/Python</span><br></pre></td></tr></table></figure></p>\n<p>以上。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"\">The Quick Python Book 2nd Edition.Chaptor 5.7.3</a><br>2.<a href=\"http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/\" target=\"_blank\" rel=\"noopener\">Packing and Unpacking Arguments in Python</a><br>3.<a href=\"https://hangar.runway7.net/python/packing-unpacking-arguments\" target=\"_blank\" rel=\"noopener\">Packing and Unpacking Arguments in Python</a><br>4.<a href=\"http://pythoncentral.io/pythons-range-function-explained/\" target=\"_blank\" rel=\"noopener\">Python’s range() Function Explained</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"什么是元组\"><a href=\"#什么是元组\" class=\"headerlink\" title=\"什么是元组\"></a>什么是元组</h2><p>元组（Tuple）是与列表类似的数据结构，只可被创建，不可被修改，用一对圆括号<code>()</code>包起来，如：<br>","more":"<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>) <span class=\"comment\">#具有三个元素的元组</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = (<span class=\"string\">'a'</span>,) <span class=\"comment\">#只有一个元素的元组，注意，必须有一个逗号来标识</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = () <span class=\"comment\">#空元组</span></span><br></pre></td></tr></table></figure></p>\n<p>元组的操作跟列表非常类似，如<code>+</code>，<code>*</code>，切片等，在元组中同样适用：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a[:<span class=\"number\">2</span>]</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a * <span class=\"number\">1</span></span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a + (<span class=\"number\">4</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"元组的Packing-Unpacking\"><a href=\"#元组的Packing-Unpacking\" class=\"headerlink\" title=\"元组的Packing/Unpacking\"></a>元组的Packing/Unpacking</h2><p>Python中允许元组出现在赋值运算符的左侧，这样元组中的每个变量就可以被赋值为右侧对应位置的值，如：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>(a,b,c,d) = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>c</span><br><span class=\"line\"><span class=\"number\">3</span></span><br></pre></td></tr></table></figure></p>\n<p>上面的写法还可以简化为:<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a,b,c,d = <span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这个用法还可以非常方便的完成交换两个变量的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>var1, var2 = var2, var1</span><br></pre></td></tr></table></figure></p>\n<p>在Python3中，还提供了一个扩展的unpacking特性——使用<code>*</code>来标注元素来吸收与其他元素不匹配的任何数量的元素，举例如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = (<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, *c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, [<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, *b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">(<span class=\"number\">1</span>, [<span class=\"number\">2</span>, <span class=\"number\">3</span>], <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>*a, b, c = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c</span><br><span class=\"line\">([<span class=\"number\">1</span>, <span class=\"number\">2</span>], <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, *e = x</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a, b, c, d, e</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, [])</span><br></pre></td></tr></table></figure></p>\n<p>被标星的元素接收多余的元素作为一个列表，如果没有多余的元素，则会接收一个空列表。</p>\n<h2 id=\"Python中的Packing-Unpacking应用\"><a href=\"#Python中的Packing-Unpacking应用\" class=\"headerlink\" title=\"Python中的Packing/Unpacking应用\"></a>Python中的Packing/Unpacking应用</h2><p>Python中，我们可以使用<code>*</code>（对元组来说）和<code>**</code>（对字典来说）的Packing和Unpacking函数的参数。</p>\n<h3 id=\"for-tuples\"><a href=\"#for-tuples\" class=\"headerlink\" title=\"* for tuples\"></a>* for tuples</h3><p>从下面这个例子说起，我们有一个函数<code>fun()</code>接收四个函数，并打印出来：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(a, b, c, d)</span>:</span></span><br><span class=\"line\">    print(a, b, c, d)</span><br></pre></td></tr></table></figure></p>\n<p>假设我们有一个list：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; my_list = [1, 2, 3, 4]</span><br></pre></td></tr></table></figure></p>\n<p>调用函数<code>fun()</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_list = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(my_list)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: fun() missing <span class=\"number\">3</span> required positional arguments: <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"keyword\">and</span> <span class=\"string\">'d'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>会得到报错信息，函数认为我们的<code>my_list</code>是单独的一个参数，而函数还需要额外的三个参数。</p>\n<p>这时候，我们可以使用<code>*</code>来<strong>解包（Unpacking）</strong>列表，使之作为四个参数：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fun(*my_list)</span><br><span class=\"line\"><span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span></span><br></pre></td></tr></table></figure></p>\n<p>这里还有另一个例子，使用内置的<code>range()</code>函数，来演示解包列表的操作：</p>\n<blockquote>\n<p>注，这里使用的是Python3.x，range(3,7)不会直接打印区间的所有值</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(<span class=\"number\">3</span>,<span class=\"number\">7</span>))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>args = [<span class=\"number\">3</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(args))</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: <span class=\"string\">'list'</span> object cannot be interpreted <span class=\"keyword\">as</span> an integer</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>list(range(*args))</span><br><span class=\"line\">[<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]</span><br></pre></td></tr></table></figure>\n<p>当我们不知道究竟要传递多少参数给函数时，我们可以使用<strong>打包（Packing）</strong>把所有的参数打包到一个元组中，用下面的例子来演示打包操作。</p>\n<p>我们有函数<code>iSum()</code>来做求和操作<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">iSum</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\">    sum=<span class=\"number\">0</span></span><br><span class=\"line\">    print(args) <span class=\"comment\">#把args打印出来，看是否被打包为一个元组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(args)):</span><br><span class=\"line\">        sum = sum + args[i]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sum</span><br></pre></td></tr></table></figure></p>\n<p>测试时，传参个数不等，得到的输出如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(iSum(<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>))</span><br><span class=\"line\">(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"number\">60</span></span><br></pre></td></tr></table></figure></p>\n<p>可以看到入参确实被打包成了一个元组，然后循环遍历元组求和。</p>\n<p>如果打包后我们想修改参数，由于元组不可修改，所以需要先转换成列表。下面展示一个打包和解包混合使用的例子。<br>我们有函数<code>func1()</code>用于打印入参，<code>func2()</code>用户修改入参的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func1</span><span class=\"params\">(a,b,c)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    print(a,b,c)</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">func2</span><span class=\"params\">(*args)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args = list(args)</span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">0</span>] = <span class=\"string\">'elbarco.cn'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    args[<span class=\"number\">1</span>] = <span class=\"string\">'awesome'</span></span><br><span class=\"line\"><span class=\"meta\">... </span>    func1(*args)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>调用<code>func2()</code>，传递的三个参数，首先打包为一个元组，然后将元组转换为列表，并修改前两个元素的值，再解包为三个参数，打印出结果，如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func2(<span class=\"string\">'Hello'</span>,<span class=\"string\">'nice'</span>,<span class=\"string\">'visitors'</span>)</span><br><span class=\"line\">elbarco.cn awesome visitors</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"for-dictionaries\"><a href=\"#for-dictionaries\" class=\"headerlink\" title=\"** for dictionaries\"></a>** for dictionaries</h3><p>对于字典（Dictionary），Packing/Unpacking操作使用<code>**</code>。</p>\n<p>还是使用上面的<code>func1()</code>，如果要打印字典的值，则需要使用<code>**</code>来解包：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; dict = &#123;&apos;a&apos;:1,&apos;b&apos;:3,&apos;c&apos;:5&#125;</span><br><span class=\"line\">&gt;&gt;&gt; func1(**dict)</span><br><span class=\"line\">1 3 5</span><br></pre></td></tr></table></figure></p>\n<p>下面来一个打包的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; def func3(**elbarco):</span><br><span class=\"line\">...     print(type(elbarco))</span><br><span class=\"line\">...     for key in elbarco:</span><br><span class=\"line\">...         print(&quot;%s = %s&quot; % (key, elbarco[key]))</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>传几个参数，用<code>func3()</code>将入参打包为字典，然后在函数中把key和value输出出来，结果如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>func3(name=<span class=\"string\">'elbarco'</span>, location=<span class=\"string\">'Beijing'</span>, language=<span class=\"string\">'Java/Python'</span>)</span><br><span class=\"line\">&lt;<span class=\"class\"><span class=\"keyword\">class</span> '<span class=\"title\">dict</span>'&gt;</span></span><br><span class=\"line\">name = elbarco</span><br><span class=\"line\">location = Beijing</span><br><span class=\"line\">language = Java/Python</span><br></pre></td></tr></table></figure></p>\n<p>以上。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"\">The Quick Python Book 2nd Edition.Chaptor 5.7.3</a><br>2.<a href=\"http://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/\" target=\"_blank\" rel=\"noopener\">Packing and Unpacking Arguments in Python</a><br>3.<a href=\"https://hangar.runway7.net/python/packing-unpacking-arguments\" target=\"_blank\" rel=\"noopener\">Packing and Unpacking Arguments in Python</a><br>4.<a href=\"http://pythoncentral.io/pythons-range-function-explained/\" target=\"_blank\" rel=\"noopener\">Python’s range() Function Explained</a></p>"},{"title":"Python中的Coroutine","date":"2017-10-18T08:15:00.000Z","_content":"\n在展开对`eventlet`的学习之前，我们先来学习一下Python的Coroutine。\n\n<!--more-->\n\n## 前情回顾\n\n在[这篇文章](https://elbarco.cn/2017/09/18/python-generators-and-yield-keyword/)中，已经学习过了Python中的Generator和yield关键字，如果对生成器和yield还有疑问，可以通过上面的连接回顾一下。\n\n\n## For...example?\n\n这里，就以一个生成器的例子来展开本篇的学习内容吧：\n```python\ndef grep(pattern):\n    print 'Looking for \"%s\"' % pattern\n    while True:\n        line = (yield)\n        if pattern in line:\n            print line\n```\n\n首先思考一个问题，执行上面的函数函数的输出是什么？\n\n\n### 协程的执行\n\n当我们常用yiled关键字的时候，不可避免的，总会遇到Coroutine，即协程。正如上面的例子，函数能做的不仅是生成值，还可以“消费”（consume）发送给它的值：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n```\n当我们直接调用`grep('python')`时，什么输出也没有产生，因为coroutine只对`next()`和`send()`方法进行响应。即，`g.next()`时，coroutine开始运行（或者通过`send(None)`来预启动协程），然后使协程提前执行到第一个yield表达式——`line = (yield)`，此时，协程已经准备好了接收一个值，当我们发送含有python的字符串时，就可以打印出这个字符串。\n\n不过，每次调用`.next()`有点太麻烦，我们可以用装饰器包装这个coroutine来解决：\n``` python\ndef coroutine(func):\n    def start(*args, **kwargs):\n        cr = func(*args, **kwargs)\n        cr.next()\n        return cr\n    return start\n\n@coroutine\ndef grep(pattern):\n    ...\n\n```\n\n### 协程的关闭\n\n协程可能会无限运行，我们可以使用`.close()`来关闭。另外，`close()`是可以被捕获的——通过`GeneratorExit`异常：\n```python\n@coroutine\ndef grep(pattern):\n    print 'Looking for \"%s\"' % pattern\n    try:\n        while True:\n            line = (yield)\n            if pattern in line:\n                print line\n    except GeneratorExit:\n        print 'Going away. Bye!'\n\n```\n不要忽略这个异常，通过上面的写法可以确保coroutine能够正常清理和退出。执行后效果如下：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n>>> g.close()\nGoing away. Bye!\n```\n\n### 协程中抛出异常\n\n在协程中，是允许抛出异常的：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n>>> g.throw(RuntimeError, \"It's a RuntimeError!\")\nTraceback (most recent call last):\n File \"<stdin>\", line 1, in <module>\n File \"<stdin>\", line 4, in grep\nRuntimeError: It's a RuntimeError!\n```\n注意，异常是在yield表达式处产生的，而且跟普通异常一样是可以被捕获和处理的。\n\n### 简单梳理一下\n\n经过上面的例子，我们可以简单的梳理如下：\n* Generator产生数据用于迭代\n* Coroutine是数据的消费者\n* 不要把这两个概念弄混\n\n## More, I want MORE!\n\n### 通通连起来\n\nCoroutine还可以用于构造pipeline（管道），即把好多coroutine连起来，通过`send()`方法来传递数据。\n\n对于pipeline来讲，我们需要一个函数来驱动，我们暂且称之为`source`。另外还需要一个端点（end-point）来终止整个管道，我们暂且称之为`sink`，下面举个例子，用coroutine写一个类似`tail -f`的功能：\n```python\ndef follow(the_file, target):\n    # Go to the end of the file\n    the_file.seek(0, 2)\n    while True:\n        line = the_file.readline()\n        if not line:\n            time.sleep(0.1)\n            continue\n        target.send(line)\n\n\n@coroutine\ndef printer():\n    while True:\n        line = (yield)\n        print line\n\nif __name__ == '__main__':\n    f = open(\"data.txt\")\n    follow(f, printer())\n```\n\n这样，我们在执行时，打开data.txt写入信息，就会在控制台看到输出。在这个例子中，`follow()`用于逐行读取，然后把数据发送到`printer()`协程中，过程如图：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline.png)\n\n在这里，`source`就是`follow()`，`sink`就是`printer()`。\n\n### 管道中的过滤器\n\n在这个例子基础上，我们还可增加一个协程用做过滤器（filter），只要对对前面的`grep()`稍作改造，然后调用的时候注意一下：\n```python\n@coroutine\ndef grep(pattern, target):\n    print 'Looking for \"%s\"' % pattern\n    try:\n        while True:\n            line = (yield)\n            if pattern in line:\n                target.send(line)\n    except GeneratorExit:\n        print 'Going away. Bye!'\n\n\nif __name__ == '__main__':\n    f = open(\"data.txt\")\n    follow(f, grep('python', printer()))\n```\n\n启动后，`grep()`这个协程负责只有在data.txt中写入行含有`python`才会把当前行数据发送到`printer()`，由其在控制台打印出来，过程如图：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-filter.png)\n\n> 注：coroutine和generator的关键区别在于生成器使用迭代器在管道中拉取数据；协程通过send()向管道中推送数据。\n\n### 管道连接更多的管道\n\n有了协程，我们可以将数据发送到更多的地方……\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-branchy.png)\n\n那么我们就来一个🌰，下列代码实现了一个广播的coroutine，将数据推送到批量的coroutines中：\n```python\n@coroutine\ndef broadcast(targets):\n    while True:\n        item = (yield)\n        for target in targets:\n            target.send(item)\n```\n根据调用方式的不同，实际上会产生两种效果广播的情况——\n①发送到不同的printer()\n```python\nfollow(f, broadcast([grep('python', printer()),\n                         grep('hello', printer()),\n                         grep('world', printer())])\n           )\n```\n![](http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-multiple-printer.png)\n\n②发送到相同的printer()\n```python\n    p = printer()\n    follow(f, broadcast([\n        grep('python', p),\n        grep('hello', p),\n        grep('world', p)]))\n```\n![](http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-one-printer.png)\n\n不过在本例中，效果是一样的……\n\n## 从数据处理到并发编程\n\n到目前为止，我们前面聊的coroutine的应用都是在处理数据，那么如果我们把数据发送给线程、发送给进程……协程程序自然而然就会涉及到线程和分布式系统的问题。\n\n看到这，估计也累了，那暂且先挖个坑，未完待续……\n\n## 参考\n\n[1].[A Curious Course on Coroutines and Concurrency](Cohttp://www.dabeaz.com/coroutines/Coroutines.pdf)\n\n\n","source":"_posts/python-coroutines.md","raw":"---\ntitle: Python中的Coroutine\ndate: 2017-10-18 16:15:00\ntags: [Python, Coroutines]\n---\n\n在展开对`eventlet`的学习之前，我们先来学习一下Python的Coroutine。\n\n<!--more-->\n\n## 前情回顾\n\n在[这篇文章](https://elbarco.cn/2017/09/18/python-generators-and-yield-keyword/)中，已经学习过了Python中的Generator和yield关键字，如果对生成器和yield还有疑问，可以通过上面的连接回顾一下。\n\n\n## For...example?\n\n这里，就以一个生成器的例子来展开本篇的学习内容吧：\n```python\ndef grep(pattern):\n    print 'Looking for \"%s\"' % pattern\n    while True:\n        line = (yield)\n        if pattern in line:\n            print line\n```\n\n首先思考一个问题，执行上面的函数函数的输出是什么？\n\n\n### 协程的执行\n\n当我们常用yiled关键字的时候，不可避免的，总会遇到Coroutine，即协程。正如上面的例子，函数能做的不仅是生成值，还可以“消费”（consume）发送给它的值：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n```\n当我们直接调用`grep('python')`时，什么输出也没有产生，因为coroutine只对`next()`和`send()`方法进行响应。即，`g.next()`时，coroutine开始运行（或者通过`send(None)`来预启动协程），然后使协程提前执行到第一个yield表达式——`line = (yield)`，此时，协程已经准备好了接收一个值，当我们发送含有python的字符串时，就可以打印出这个字符串。\n\n不过，每次调用`.next()`有点太麻烦，我们可以用装饰器包装这个coroutine来解决：\n``` python\ndef coroutine(func):\n    def start(*args, **kwargs):\n        cr = func(*args, **kwargs)\n        cr.next()\n        return cr\n    return start\n\n@coroutine\ndef grep(pattern):\n    ...\n\n```\n\n### 协程的关闭\n\n协程可能会无限运行，我们可以使用`.close()`来关闭。另外，`close()`是可以被捕获的——通过`GeneratorExit`异常：\n```python\n@coroutine\ndef grep(pattern):\n    print 'Looking for \"%s\"' % pattern\n    try:\n        while True:\n            line = (yield)\n            if pattern in line:\n                print line\n    except GeneratorExit:\n        print 'Going away. Bye!'\n\n```\n不要忽略这个异常，通过上面的写法可以确保coroutine能够正常清理和退出。执行后效果如下：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n>>> g.close()\nGoing away. Bye!\n```\n\n### 协程中抛出异常\n\n在协程中，是允许抛出异常的：\n```python\n>>> g = grep('python')\n>>> g.next()\nLooking for \"python\"\n>>> g.send('Awesome, it is dope!')\n>>> g.send('python generators rock!')\npython generators rock!\n>>> g.throw(RuntimeError, \"It's a RuntimeError!\")\nTraceback (most recent call last):\n File \"<stdin>\", line 1, in <module>\n File \"<stdin>\", line 4, in grep\nRuntimeError: It's a RuntimeError!\n```\n注意，异常是在yield表达式处产生的，而且跟普通异常一样是可以被捕获和处理的。\n\n### 简单梳理一下\n\n经过上面的例子，我们可以简单的梳理如下：\n* Generator产生数据用于迭代\n* Coroutine是数据的消费者\n* 不要把这两个概念弄混\n\n## More, I want MORE!\n\n### 通通连起来\n\nCoroutine还可以用于构造pipeline（管道），即把好多coroutine连起来，通过`send()`方法来传递数据。\n\n对于pipeline来讲，我们需要一个函数来驱动，我们暂且称之为`source`。另外还需要一个端点（end-point）来终止整个管道，我们暂且称之为`sink`，下面举个例子，用coroutine写一个类似`tail -f`的功能：\n```python\ndef follow(the_file, target):\n    # Go to the end of the file\n    the_file.seek(0, 2)\n    while True:\n        line = the_file.readline()\n        if not line:\n            time.sleep(0.1)\n            continue\n        target.send(line)\n\n\n@coroutine\ndef printer():\n    while True:\n        line = (yield)\n        print line\n\nif __name__ == '__main__':\n    f = open(\"data.txt\")\n    follow(f, printer())\n```\n\n这样，我们在执行时，打开data.txt写入信息，就会在控制台看到输出。在这个例子中，`follow()`用于逐行读取，然后把数据发送到`printer()`协程中，过程如图：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline.png)\n\n在这里，`source`就是`follow()`，`sink`就是`printer()`。\n\n### 管道中的过滤器\n\n在这个例子基础上，我们还可增加一个协程用做过滤器（filter），只要对对前面的`grep()`稍作改造，然后调用的时候注意一下：\n```python\n@coroutine\ndef grep(pattern, target):\n    print 'Looking for \"%s\"' % pattern\n    try:\n        while True:\n            line = (yield)\n            if pattern in line:\n                target.send(line)\n    except GeneratorExit:\n        print 'Going away. Bye!'\n\n\nif __name__ == '__main__':\n    f = open(\"data.txt\")\n    follow(f, grep('python', printer()))\n```\n\n启动后，`grep()`这个协程负责只有在data.txt中写入行含有`python`才会把当前行数据发送到`printer()`，由其在控制台打印出来，过程如图：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-filter.png)\n\n> 注：coroutine和generator的关键区别在于生成器使用迭代器在管道中拉取数据；协程通过send()向管道中推送数据。\n\n### 管道连接更多的管道\n\n有了协程，我们可以将数据发送到更多的地方……\n![](http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-branchy.png)\n\n那么我们就来一个🌰，下列代码实现了一个广播的coroutine，将数据推送到批量的coroutines中：\n```python\n@coroutine\ndef broadcast(targets):\n    while True:\n        item = (yield)\n        for target in targets:\n            target.send(item)\n```\n根据调用方式的不同，实际上会产生两种效果广播的情况——\n①发送到不同的printer()\n```python\nfollow(f, broadcast([grep('python', printer()),\n                         grep('hello', printer()),\n                         grep('world', printer())])\n           )\n```\n![](http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-multiple-printer.png)\n\n②发送到相同的printer()\n```python\n    p = printer()\n    follow(f, broadcast([\n        grep('python', p),\n        grep('hello', p),\n        grep('world', p)]))\n```\n![](http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-one-printer.png)\n\n不过在本例中，效果是一样的……\n\n## 从数据处理到并发编程\n\n到目前为止，我们前面聊的coroutine的应用都是在处理数据，那么如果我们把数据发送给线程、发送给进程……协程程序自然而然就会涉及到线程和分布式系统的问题。\n\n看到这，估计也累了，那暂且先挖个坑，未完待续……\n\n## 参考\n\n[1].[A Curious Course on Coroutines and Concurrency](Cohttp://www.dabeaz.com/coroutines/Coroutines.pdf)\n\n\n","slug":"python-coroutines","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxe000oxu2ziw2x4gxu","content":"<p>在展开对<code>eventlet</code>的学习之前，我们先来学习一下Python的Coroutine。</p>\n<a id=\"more\"></a>\n<h2 id=\"前情回顾\"><a href=\"#前情回顾\" class=\"headerlink\" title=\"前情回顾\"></a>前情回顾</h2><p>在<a href=\"https://elbarco.cn/2017/09/18/python-generators-and-yield-keyword/\">这篇文章</a>中，已经学习过了Python中的Generator和yield关键字，如果对生成器和yield还有疑问，可以通过上面的连接回顾一下。</p>\n<h2 id=\"For…example\"><a href=\"#For…example\" class=\"headerlink\" title=\"For…example?\"></a>For…example?</h2><p>这里，就以一个生成器的例子来展开本篇的学习内容吧：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> line</span><br></pre></td></tr></table></figure></p>\n<p>首先思考一个问题，执行上面的函数函数的输出是什么？</p>\n<h3 id=\"协程的执行\"><a href=\"#协程的执行\" class=\"headerlink\" title=\"协程的执行\"></a>协程的执行</h3><p>当我们常用yiled关键字的时候，不可避免的，总会遇到Coroutine，即协程。正如上面的例子，函数能做的不仅是生成值，还可以“消费”（consume）发送给它的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br></pre></td></tr></table></figure></p>\n<p>当我们直接调用<code>grep(&#39;python&#39;)</code>时，什么输出也没有产生，因为coroutine只对<code>next()</code>和<code>send()</code>方法进行响应。即，<code>g.next()</code>时，coroutine开始运行（或者通过<code>send(None)</code>来预启动协程），然后使协程提前执行到第一个yield表达式——<code>line = (yield)</code>，此时，协程已经准备好了接收一个值，当我们发送含有python的字符串时，就可以打印出这个字符串。</p>\n<p>不过，每次调用<code>.next()</code>有点太麻烦，我们可以用装饰器包装这个coroutine来解决：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">coroutine</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        cr = func(*args, **kwargs)</span><br><span class=\"line\">        cr.next()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> cr</span><br><span class=\"line\">    <span class=\"keyword\">return</span> start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"协程的关闭\"><a href=\"#协程的关闭\" class=\"headerlink\" title=\"协程的关闭\"></a>协程的关闭</h3><p>协程可能会无限运行，我们可以使用<code>.close()</code>来关闭。另外，<code>close()</code>是可以被捕获的——通过<code>GeneratorExit</code>异常：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">                <span class=\"keyword\">print</span> line</span><br><span class=\"line\">    <span class=\"keyword\">except</span> GeneratorExit:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'Going away. Bye!'</span></span><br></pre></td></tr></table></figure></p>\n<p>不要忽略这个异常，通过上面的写法可以确保coroutine能够正常清理和退出。执行后效果如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.close()</span><br><span class=\"line\">Going away. Bye!</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"协程中抛出异常\"><a href=\"#协程中抛出异常\" class=\"headerlink\" title=\"协程中抛出异常\"></a>协程中抛出异常</h3><p>在协程中，是允许抛出异常的：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.throw(RuntimeError, <span class=\"string\">\"It's a RuntimeError!\"</span>)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\"> File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\"> File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">4</span>, <span class=\"keyword\">in</span> grep</span><br><span class=\"line\">RuntimeError: It<span class=\"string\">'s a RuntimeError!</span></span><br></pre></td></tr></table></figure></p>\n<p>注意，异常是在yield表达式处产生的，而且跟普通异常一样是可以被捕获和处理的。</p>\n<h3 id=\"简单梳理一下\"><a href=\"#简单梳理一下\" class=\"headerlink\" title=\"简单梳理一下\"></a>简单梳理一下</h3><p>经过上面的例子，我们可以简单的梳理如下：</p>\n<ul>\n<li>Generator产生数据用于迭代</li>\n<li>Coroutine是数据的消费者</li>\n<li>不要把这两个概念弄混</li>\n</ul>\n<h2 id=\"More-I-want-MORE\"><a href=\"#More-I-want-MORE\" class=\"headerlink\" title=\"More, I want MORE!\"></a>More, I want MORE!</h2><h3 id=\"通通连起来\"><a href=\"#通通连起来\" class=\"headerlink\" title=\"通通连起来\"></a>通通连起来</h3><p>Coroutine还可以用于构造pipeline（管道），即把好多coroutine连起来，通过<code>send()</code>方法来传递数据。</p>\n<p>对于pipeline来讲，我们需要一个函数来驱动，我们暂且称之为<code>source</code>。另外还需要一个端点（end-point）来终止整个管道，我们暂且称之为<code>sink</code>，下面举个例子，用coroutine写一个类似<code>tail -f</code>的功能：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">follow</span><span class=\"params\">(the_file, target)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Go to the end of the file</span></span><br><span class=\"line\">    the_file.seek(<span class=\"number\">0</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = the_file.readline()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> line:</span><br><span class=\"line\">            time.sleep(<span class=\"number\">0.1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        target.send(line)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printer</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> line</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    f = open(<span class=\"string\">\"data.txt\"</span>)</span><br><span class=\"line\">    follow(f, printer())</span><br></pre></td></tr></table></figure></p>\n<p>这样，我们在执行时，打开data.txt写入信息，就会在控制台看到输出。在这个例子中，<code>follow()</code>用于逐行读取，然后把数据发送到<code>printer()</code>协程中，过程如图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline.png\" alt=\"\"></p>\n<p>在这里，<code>source</code>就是<code>follow()</code>，<code>sink</code>就是<code>printer()</code>。</p>\n<h3 id=\"管道中的过滤器\"><a href=\"#管道中的过滤器\" class=\"headerlink\" title=\"管道中的过滤器\"></a>管道中的过滤器</h3><p>在这个例子基础上，我们还可增加一个协程用做过滤器（filter），只要对对前面的<code>grep()</code>稍作改造，然后调用的时候注意一下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern, target)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">                target.send(line)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> GeneratorExit:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'Going away. Bye!'</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    f = open(<span class=\"string\">\"data.txt\"</span>)</span><br><span class=\"line\">    follow(f, grep(<span class=\"string\">'python'</span>, printer()))</span><br></pre></td></tr></table></figure></p>\n<p>启动后，<code>grep()</code>这个协程负责只有在data.txt中写入行含有<code>python</code>才会把当前行数据发送到<code>printer()</code>，由其在控制台打印出来，过程如图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-filter.png\" alt=\"\"></p>\n<blockquote>\n<p>注：coroutine和generator的关键区别在于生成器使用迭代器在管道中拉取数据；协程通过send()向管道中推送数据。</p>\n</blockquote>\n<h3 id=\"管道连接更多的管道\"><a href=\"#管道连接更多的管道\" class=\"headerlink\" title=\"管道连接更多的管道\"></a>管道连接更多的管道</h3><p>有了协程，我们可以将数据发送到更多的地方……<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-branchy.png\" alt=\"\"></p>\n<p>那么我们就来一个🌰，下列代码实现了一个广播的coroutine，将数据推送到批量的coroutines中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">broadcast</span><span class=\"params\">(targets)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        item = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> target <span class=\"keyword\">in</span> targets:</span><br><span class=\"line\">            target.send(item)</span><br></pre></td></tr></table></figure></p>\n<p>根据调用方式的不同，实际上会产生两种效果广播的情况——<br>①发送到不同的printer()<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">follow(f, broadcast([grep(<span class=\"string\">'python'</span>, printer()),</span><br><span class=\"line\">                         grep(<span class=\"string\">'hello'</span>, printer()),</span><br><span class=\"line\">                         grep(<span class=\"string\">'world'</span>, printer())])</span><br><span class=\"line\">           )</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-multiple-printer.png\" alt=\"\"></p>\n<p>②发送到相同的printer()<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">p = printer()</span><br><span class=\"line\">follow(f, broadcast([</span><br><span class=\"line\">    grep(<span class=\"string\">'python'</span>, p),</span><br><span class=\"line\">    grep(<span class=\"string\">'hello'</span>, p),</span><br><span class=\"line\">    grep(<span class=\"string\">'world'</span>, p)]))</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-one-printer.png\" alt=\"\"></p>\n<p>不过在本例中，效果是一样的……</p>\n<h2 id=\"从数据处理到并发编程\"><a href=\"#从数据处理到并发编程\" class=\"headerlink\" title=\"从数据处理到并发编程\"></a>从数据处理到并发编程</h2><p>到目前为止，我们前面聊的coroutine的应用都是在处理数据，那么如果我们把数据发送给线程、发送给进程……协程程序自然而然就会涉及到线程和分布式系统的问题。</p>\n<p>看到这，估计也累了，那暂且先挖个坑，未完待续……</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"Cohttp://www.dabeaz.com/coroutines/Coroutines.pdf\" target=\"_blank\" rel=\"noopener\">A Curious Course on Coroutines and Concurrency</a></p>\n","site":{"data":{}},"excerpt":"<p>在展开对<code>eventlet</code>的学习之前，我们先来学习一下Python的Coroutine。</p>","more":"<h2 id=\"前情回顾\"><a href=\"#前情回顾\" class=\"headerlink\" title=\"前情回顾\"></a>前情回顾</h2><p>在<a href=\"https://elbarco.cn/2017/09/18/python-generators-and-yield-keyword/\">这篇文章</a>中，已经学习过了Python中的Generator和yield关键字，如果对生成器和yield还有疑问，可以通过上面的连接回顾一下。</p>\n<h2 id=\"For…example\"><a href=\"#For…example\" class=\"headerlink\" title=\"For…example?\"></a>For…example?</h2><p>这里，就以一个生成器的例子来展开本篇的学习内容吧：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> line</span><br></pre></td></tr></table></figure></p>\n<p>首先思考一个问题，执行上面的函数函数的输出是什么？</p>\n<h3 id=\"协程的执行\"><a href=\"#协程的执行\" class=\"headerlink\" title=\"协程的执行\"></a>协程的执行</h3><p>当我们常用yiled关键字的时候，不可避免的，总会遇到Coroutine，即协程。正如上面的例子，函数能做的不仅是生成值，还可以“消费”（consume）发送给它的值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br></pre></td></tr></table></figure></p>\n<p>当我们直接调用<code>grep(&#39;python&#39;)</code>时，什么输出也没有产生，因为coroutine只对<code>next()</code>和<code>send()</code>方法进行响应。即，<code>g.next()</code>时，coroutine开始运行（或者通过<code>send(None)</code>来预启动协程），然后使协程提前执行到第一个yield表达式——<code>line = (yield)</code>，此时，协程已经准备好了接收一个值，当我们发送含有python的字符串时，就可以打印出这个字符串。</p>\n<p>不过，每次调用<code>.next()</code>有点太麻烦，我们可以用装饰器包装这个coroutine来解决：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">coroutine</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        cr = func(*args, **kwargs)</span><br><span class=\"line\">        cr.next()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> cr</span><br><span class=\"line\">    <span class=\"keyword\">return</span> start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"协程的关闭\"><a href=\"#协程的关闭\" class=\"headerlink\" title=\"协程的关闭\"></a>协程的关闭</h3><p>协程可能会无限运行，我们可以使用<code>.close()</code>来关闭。另外，<code>close()</code>是可以被捕获的——通过<code>GeneratorExit</code>异常：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">                <span class=\"keyword\">print</span> line</span><br><span class=\"line\">    <span class=\"keyword\">except</span> GeneratorExit:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'Going away. Bye!'</span></span><br></pre></td></tr></table></figure></p>\n<p>不要忽略这个异常，通过上面的写法可以确保coroutine能够正常清理和退出。执行后效果如下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.close()</span><br><span class=\"line\">Going away. Bye!</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"协程中抛出异常\"><a href=\"#协程中抛出异常\" class=\"headerlink\" title=\"协程中抛出异常\"></a>协程中抛出异常</h3><p>在协程中，是允许抛出异常的：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g = grep(<span class=\"string\">'python'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.next()</span><br><span class=\"line\">Looking <span class=\"keyword\">for</span> <span class=\"string\">\"python\"</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'Awesome, it is dope!'</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.send(<span class=\"string\">'python generators rock!'</span>)</span><br><span class=\"line\">python generators rock!</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>g.throw(RuntimeError, <span class=\"string\">\"It's a RuntimeError!\"</span>)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\"> File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\"> File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">4</span>, <span class=\"keyword\">in</span> grep</span><br><span class=\"line\">RuntimeError: It<span class=\"string\">'s a RuntimeError!</span></span><br></pre></td></tr></table></figure></p>\n<p>注意，异常是在yield表达式处产生的，而且跟普通异常一样是可以被捕获和处理的。</p>\n<h3 id=\"简单梳理一下\"><a href=\"#简单梳理一下\" class=\"headerlink\" title=\"简单梳理一下\"></a>简单梳理一下</h3><p>经过上面的例子，我们可以简单的梳理如下：</p>\n<ul>\n<li>Generator产生数据用于迭代</li>\n<li>Coroutine是数据的消费者</li>\n<li>不要把这两个概念弄混</li>\n</ul>\n<h2 id=\"More-I-want-MORE\"><a href=\"#More-I-want-MORE\" class=\"headerlink\" title=\"More, I want MORE!\"></a>More, I want MORE!</h2><h3 id=\"通通连起来\"><a href=\"#通通连起来\" class=\"headerlink\" title=\"通通连起来\"></a>通通连起来</h3><p>Coroutine还可以用于构造pipeline（管道），即把好多coroutine连起来，通过<code>send()</code>方法来传递数据。</p>\n<p>对于pipeline来讲，我们需要一个函数来驱动，我们暂且称之为<code>source</code>。另外还需要一个端点（end-point）来终止整个管道，我们暂且称之为<code>sink</code>，下面举个例子，用coroutine写一个类似<code>tail -f</code>的功能：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">follow</span><span class=\"params\">(the_file, target)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Go to the end of the file</span></span><br><span class=\"line\">    the_file.seek(<span class=\"number\">0</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = the_file.readline()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> line:</span><br><span class=\"line\">            time.sleep(<span class=\"number\">0.1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        target.send(line)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printer</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> line</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    f = open(<span class=\"string\">\"data.txt\"</span>)</span><br><span class=\"line\">    follow(f, printer())</span><br></pre></td></tr></table></figure></p>\n<p>这样，我们在执行时，打开data.txt写入信息，就会在控制台看到输出。在这个例子中，<code>follow()</code>用于逐行读取，然后把数据发送到<code>printer()</code>协程中，过程如图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline.png\" alt=\"\"></p>\n<p>在这里，<code>source</code>就是<code>follow()</code>，<code>sink</code>就是<code>printer()</code>。</p>\n<h3 id=\"管道中的过滤器\"><a href=\"#管道中的过滤器\" class=\"headerlink\" title=\"管道中的过滤器\"></a>管道中的过滤器</h3><p>在这个例子基础上，我们还可增加一个协程用做过滤器（filter），只要对对前面的<code>grep()</code>稍作改造，然后调用的时候注意一下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(pattern, target)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Looking for \"%s\"'</span> % pattern</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            line = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> pattern <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">                target.send(line)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> GeneratorExit:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'Going away. Bye!'</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    f = open(<span class=\"string\">\"data.txt\"</span>)</span><br><span class=\"line\">    follow(f, grep(<span class=\"string\">'python'</span>, printer()))</span><br></pre></td></tr></table></figure></p>\n<p>启动后，<code>grep()</code>这个协程负责只有在data.txt中写入行含有<code>python</code>才会把当前行数据发送到<code>printer()</code>，由其在控制台打印出来，过程如图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-filter.png\" alt=\"\"></p>\n<blockquote>\n<p>注：coroutine和generator的关键区别在于生成器使用迭代器在管道中拉取数据；协程通过send()向管道中推送数据。</p>\n</blockquote>\n<h3 id=\"管道连接更多的管道\"><a href=\"#管道连接更多的管道\" class=\"headerlink\" title=\"管道连接更多的管道\"></a>管道连接更多的管道</h3><p>有了协程，我们可以将数据发送到更多的地方……<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/coroutine-pipline-branchy.png\" alt=\"\"></p>\n<p>那么我们就来一个🌰，下列代码实现了一个广播的coroutine，将数据推送到批量的coroutines中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@coroutine</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">broadcast</span><span class=\"params\">(targets)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        item = (<span class=\"keyword\">yield</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> target <span class=\"keyword\">in</span> targets:</span><br><span class=\"line\">            target.send(item)</span><br></pre></td></tr></table></figure></p>\n<p>根据调用方式的不同，实际上会产生两种效果广播的情况——<br>①发送到不同的printer()<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">follow(f, broadcast([grep(<span class=\"string\">'python'</span>, printer()),</span><br><span class=\"line\">                         grep(<span class=\"string\">'hello'</span>, printer()),</span><br><span class=\"line\">                         grep(<span class=\"string\">'world'</span>, printer())])</span><br><span class=\"line\">           )</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-multiple-printer.png\" alt=\"\"></p>\n<p>②发送到相同的printer()<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">p = printer()</span><br><span class=\"line\">follow(f, broadcast([</span><br><span class=\"line\">    grep(<span class=\"string\">'python'</span>, p),</span><br><span class=\"line\">    grep(<span class=\"string\">'hello'</span>, p),</span><br><span class=\"line\">    grep(<span class=\"string\">'world'</span>, p)]))</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://7xq1r1.com1.z0.glb.clouddn.com/broadcast-one-printer.png\" alt=\"\"></p>\n<p>不过在本例中，效果是一样的……</p>\n<h2 id=\"从数据处理到并发编程\"><a href=\"#从数据处理到并发编程\" class=\"headerlink\" title=\"从数据处理到并发编程\"></a>从数据处理到并发编程</h2><p>到目前为止，我们前面聊的coroutine的应用都是在处理数据，那么如果我们把数据发送给线程、发送给进程……协程程序自然而然就会涉及到线程和分布式系统的问题。</p>\n<p>看到这，估计也累了，那暂且先挖个坑，未完待续……</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"Cohttp://www.dabeaz.com/coroutines/Coroutines.pdf\" target=\"_blank\" rel=\"noopener\">A Curious Course on Coroutines and Concurrency</a></p>"},{"title":"Python中的装饰器——装饰器参数篇","date":"2017-09-20T08:52:14.000Z","_content":"\n## 先举个例子\n\n在[上一篇文章](https://elbarco.cn/2017/09/20/python-introduction-to-decorators-with-examples/)中，我们提到的装饰器的例子有一个共同的特点，就是<!--more-->只接收被装饰的方法作为参数。但是在很多时候，装饰器本身接收更多的参数是非常有用的。但是如何做到呢？我们先回想一下基本的装饰器，它在内部声明一个方法，然后将这个内部方法返回，即被装饰器返回的callable。如果要使装饰器接收更多的参数，我们就要再包装一层——即接收参数的\"装饰器\"并不是真正的装饰器，而是一个返回装饰器的函数，而真正的装饰器负责接收被装饰的方法作为参数，然后装饰方法，返回一个callable。 还是用前面`json_output`的例子，简单改造一下：\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(indent=None, sort_keys=False):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n\n    def actual_decorator(decorated):\n        @functools.wraps(decorated)\n        def inner(*args, **kwargs):\n            try:\n                result = decorated(*args, **kwargs)\n            except JSONOutputError as ex:\n                result = {\n                    'state': 'error',\n                    'message': str(ex),\n                }\n            return json.dumps(result, indent=indent, sort_keys=sort_keys)\n\n        return inner\n\n    return actual_decorator\n```\n\n可以看到，在`json_output`中，传入了两个参数`indent`和`sort_keys`, 返回的是装饰器`actual_decorator`，而在`inner`中用到了传入的两个参数，用于JSON格式化时的缩进和Key的排序展示，来看这个装饰器的效果：\n```python\n@json_output(indent=4, sort_keys=True)\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\n# output \n{\n    \"a\": \"1\", \n    \"status\": \"done\"\n}\n```\n\n## 还有这种操作？\n\n通过上面的例子，可以看到，装饰器是`actual_decorator`而不是`json_output`，那么问题来了，如果`json_output`不是装饰器而只是一个返回装饰器的函数，为什么可以像装饰器一样使用？\n\n问题的关键在于操作的顺序。具体来说，`json_output(indent=4,sort_keys=True)`的调用在前，@操作符应用在后，那么这个函数的结果就会被当作装饰器使用。即先调用`json_output`，其中定义了装饰器`actual_decorator`，并且由`json_output`返回，则此时再应用@操作符就等价于：\n```python\n@actual_decorator\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n```\n这不就相当于在一个函数上应用装饰器嘛！\n\n重要的一点是要意识到，当我们引入新的`json_output`函数时，实际上引入了一个后向不兼容的修改。\n\n为什么这么说？因为现在这里有一个预期的额外函数调用。如果这里我们不想给`json_output`传递参数，那么我们依然要**调用**这个函数，即程序必须这么写：\n```python\n@json_output()\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n```\n>号外：一定要注意**圆括号**！因为这表示函数是被调用，然后函数结果被应用@。\n\n上面的代码，不等同于，注意，是不等同于下面的写法：\n```python\n@json_output\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\n# print do_nothing() output\nTypeError: actual_decorator() takes exactly 1 argument (0 given)\n```\n这里有两个问题：其一是比较让人疑惑，因为一旦习惯于见到没有括号的装饰器，见到类似`json_output`这种就会觉得反常；其二是如果旧的装饰器已经应用了其他很多地方，如果修改了这个装饰器类似上面的例子，那么其他应用的地方要一并修改，因为这是一个后向不兼容的更改。\n\n理想情况下，我们希望装饰器在程序中对于下列三种应用方式都能兼容：\n* @json_output\n* @json_output()\n* @json_output(indent=4, sort_keys=True)\n\n实时证明，这是可行的，只需要让装饰器根据参数来改变其行为即可。下面，我们改写一下`json_output`：\n```python\ndef json_output(decorated_=None, indent=None, sort_keys=False):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    if decorated_ and (indent or sort_keys):\n        raise RuntimeError('Unexpected arguments.')\n\n    def actual_decorator(func):\n        @functools.wraps(func)\n        def inner(*args, **kwargs):\n            try:\n                result = func(*args, **kwargs)\n            except JSONOutputError as ex:\n                result = {\n                    'state': 'error',\n                    'message': str(ex),\n                }\n            return json.dumps(result, indent=indent, sort_keys=sort_keys)\n\n        return inner\n    if decorated_:\n        return actual_decorator(decorated_)\n    else:\n        return actual_decorator\n```\n注意，我们为`json_output`增加了一个入参，`decorated_=None`，因为我们不希望同时传递被装饰的方法和关键字参数，所以在`json_output`中先做检查，来确保我们要么只传递被装饰的方法作为参数，要么只传递关键字参数。接着，`actual_decorator`是实际的装饰器。最终，如果设置了`decorated_`，即采用`@json_output`这种方式去修饰do_nothing方法（等价于`do_nothing = json_output(decorated_=do_nothing)`），则此时的`json_output`就是一个装饰器，那么我们应该返回的是`actual_decorator(decorated_)`；如果没有设置`decorated_`，则这就是一个方法，即可以通过`@json_output()`或`@json_output(indent=4)`的方式应用到`do_nothing()`上去——\n```python\n# 1\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\ndo_nothing = json_output(decorated_=do_nothing)\nprint do_nothing()\n# 1 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 2\n@json_output\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 2 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 3\n@json_output()\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 3 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 4\n@json_output(indent=4, sort_keys=True)\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 4 - output\n{\n    \"a\": \"1\", \n    \"status\": \"done\"\n}\n\n# 5\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\ndo_nothing = json_output(decorated_=do_nothing, indent=4)\nprint do_nothing()\n# 5 - output\nTraceback (most recent call last):\n  File \"/decorators/output.py\", line 77, in <module>\n    do_nothing = json_output(decorated_=do_nothing, indent=4)\n  File \"/decorators/output.py\", line 18, in json_output\n    raise RuntimeError('Unexpected arguments.')\nRuntimeError: Unexpected arguments.\n```\n\n1、2等价，json_output就是一个实实在在的装饰器；3、4中的json_output则是一个带参数的装饰器。\n\n## 结语\n\n本篇中，我们知道了如何给\"装饰器\"传递更多的参数，同时也学到了如何让\"装饰器\"更灵活，以适应不同的应用形式。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/python-introduction-to-decorator-arguments.md","raw":"---\ntitle: Python中的装饰器——装饰器参数篇\ndate: 2017-09-20 16:52:14\ntags: [Python, decorator]\n---\n\n## 先举个例子\n\n在[上一篇文章](https://elbarco.cn/2017/09/20/python-introduction-to-decorators-with-examples/)中，我们提到的装饰器的例子有一个共同的特点，就是<!--more-->只接收被装饰的方法作为参数。但是在很多时候，装饰器本身接收更多的参数是非常有用的。但是如何做到呢？我们先回想一下基本的装饰器，它在内部声明一个方法，然后将这个内部方法返回，即被装饰器返回的callable。如果要使装饰器接收更多的参数，我们就要再包装一层——即接收参数的\"装饰器\"并不是真正的装饰器，而是一个返回装饰器的函数，而真正的装饰器负责接收被装饰的方法作为参数，然后装饰方法，返回一个callable。 还是用前面`json_output`的例子，简单改造一下：\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(indent=None, sort_keys=False):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n\n    def actual_decorator(decorated):\n        @functools.wraps(decorated)\n        def inner(*args, **kwargs):\n            try:\n                result = decorated(*args, **kwargs)\n            except JSONOutputError as ex:\n                result = {\n                    'state': 'error',\n                    'message': str(ex),\n                }\n            return json.dumps(result, indent=indent, sort_keys=sort_keys)\n\n        return inner\n\n    return actual_decorator\n```\n\n可以看到，在`json_output`中，传入了两个参数`indent`和`sort_keys`, 返回的是装饰器`actual_decorator`，而在`inner`中用到了传入的两个参数，用于JSON格式化时的缩进和Key的排序展示，来看这个装饰器的效果：\n```python\n@json_output(indent=4, sort_keys=True)\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\n# output \n{\n    \"a\": \"1\", \n    \"status\": \"done\"\n}\n```\n\n## 还有这种操作？\n\n通过上面的例子，可以看到，装饰器是`actual_decorator`而不是`json_output`，那么问题来了，如果`json_output`不是装饰器而只是一个返回装饰器的函数，为什么可以像装饰器一样使用？\n\n问题的关键在于操作的顺序。具体来说，`json_output(indent=4,sort_keys=True)`的调用在前，@操作符应用在后，那么这个函数的结果就会被当作装饰器使用。即先调用`json_output`，其中定义了装饰器`actual_decorator`，并且由`json_output`返回，则此时再应用@操作符就等价于：\n```python\n@actual_decorator\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n```\n这不就相当于在一个函数上应用装饰器嘛！\n\n重要的一点是要意识到，当我们引入新的`json_output`函数时，实际上引入了一个后向不兼容的修改。\n\n为什么这么说？因为现在这里有一个预期的额外函数调用。如果这里我们不想给`json_output`传递参数，那么我们依然要**调用**这个函数，即程序必须这么写：\n```python\n@json_output()\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n```\n>号外：一定要注意**圆括号**！因为这表示函数是被调用，然后函数结果被应用@。\n\n上面的代码，不等同于，注意，是不等同于下面的写法：\n```python\n@json_output\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\n# print do_nothing() output\nTypeError: actual_decorator() takes exactly 1 argument (0 given)\n```\n这里有两个问题：其一是比较让人疑惑，因为一旦习惯于见到没有括号的装饰器，见到类似`json_output`这种就会觉得反常；其二是如果旧的装饰器已经应用了其他很多地方，如果修改了这个装饰器类似上面的例子，那么其他应用的地方要一并修改，因为这是一个后向不兼容的更改。\n\n理想情况下，我们希望装饰器在程序中对于下列三种应用方式都能兼容：\n* @json_output\n* @json_output()\n* @json_output(indent=4, sort_keys=True)\n\n实时证明，这是可行的，只需要让装饰器根据参数来改变其行为即可。下面，我们改写一下`json_output`：\n```python\ndef json_output(decorated_=None, indent=None, sort_keys=False):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    if decorated_ and (indent or sort_keys):\n        raise RuntimeError('Unexpected arguments.')\n\n    def actual_decorator(func):\n        @functools.wraps(func)\n        def inner(*args, **kwargs):\n            try:\n                result = func(*args, **kwargs)\n            except JSONOutputError as ex:\n                result = {\n                    'state': 'error',\n                    'message': str(ex),\n                }\n            return json.dumps(result, indent=indent, sort_keys=sort_keys)\n\n        return inner\n    if decorated_:\n        return actual_decorator(decorated_)\n    else:\n        return actual_decorator\n```\n注意，我们为`json_output`增加了一个入参，`decorated_=None`，因为我们不希望同时传递被装饰的方法和关键字参数，所以在`json_output`中先做检查，来确保我们要么只传递被装饰的方法作为参数，要么只传递关键字参数。接着，`actual_decorator`是实际的装饰器。最终，如果设置了`decorated_`，即采用`@json_output`这种方式去修饰do_nothing方法（等价于`do_nothing = json_output(decorated_=do_nothing)`），则此时的`json_output`就是一个装饰器，那么我们应该返回的是`actual_decorator(decorated_)`；如果没有设置`decorated_`，则这就是一个方法，即可以通过`@json_output()`或`@json_output(indent=4)`的方式应用到`do_nothing()`上去——\n```python\n# 1\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\ndo_nothing = json_output(decorated_=do_nothing)\nprint do_nothing()\n# 1 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 2\n@json_output\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 2 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 3\n@json_output()\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 3 - output\n{\"status\": \"done\", \"a\": \"1\"}\n\n# 4\n@json_output(indent=4, sort_keys=True)\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\nprint do_nothing()\n# 4 - output\n{\n    \"a\": \"1\", \n    \"status\": \"done\"\n}\n\n# 5\ndef do_nothing():\n    return {'status': 'done','a': '1'}\n\ndo_nothing = json_output(decorated_=do_nothing, indent=4)\nprint do_nothing()\n# 5 - output\nTraceback (most recent call last):\n  File \"/decorators/output.py\", line 77, in <module>\n    do_nothing = json_output(decorated_=do_nothing, indent=4)\n  File \"/decorators/output.py\", line 18, in json_output\n    raise RuntimeError('Unexpected arguments.')\nRuntimeError: Unexpected arguments.\n```\n\n1、2等价，json_output就是一个实实在在的装饰器；3、4中的json_output则是一个带参数的装饰器。\n\n## 结语\n\n本篇中，我们知道了如何给\"装饰器\"传递更多的参数，同时也学到了如何让\"装饰器\"更灵活，以适应不同的应用形式。\n\n\n\n\n\n\n\n\n\n\n","slug":"python-introduction-to-decorator-arguments","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxh000rxu2z9tyurutk","content":"<h2 id=\"先举个例子\"><a href=\"#先举个例子\" class=\"headerlink\" title=\"先举个例子\"></a>先举个例子</h2><p>在<a href=\"https://elbarco.cn/2017/09/20/python-introduction-to-decorators-with-examples/\">上一篇文章</a>中，我们提到的装饰器的例子有一个共同的特点，就是<a id=\"more\"></a>只接收被装饰的方法作为参数。但是在很多时候，装饰器本身接收更多的参数是非常有用的。但是如何做到呢？我们先回想一下基本的装饰器，它在内部声明一个方法，然后将这个内部方法返回，即被装饰器返回的callable。如果要使装饰器接收更多的参数，我们就要再包装一层——即接收参数的”装饰器”并不是真正的装饰器，而是一个返回装饰器的函数，而真正的装饰器负责接收被装饰的方法作为参数，然后装饰方法，返回一个callable。 还是用前面<code>json_output</code>的例子，简单改造一下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(indent=None, sort_keys=False)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">actual_decorator</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">        @functools.wraps(decorated)</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                result = decorated(*args, **kwargs)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">                result = &#123;</span><br><span class=\"line\">                    <span class=\"string\">'state'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                    <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> json.dumps(result, indent=indent, sort_keys=sort_keys)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> actual_decorator</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，在<code>json_output</code>中，传入了两个参数<code>indent</code>和<code>sort_keys</code>, 返回的是装饰器<code>actual_decorator</code>，而在<code>inner</code>中用到了传入的两个参数，用于JSON格式化时的缩进和Key的排序展示，来看这个装饰器的效果：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output(indent=4, sort_keys=True)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>, </span><br><span class=\"line\">    <span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"还有这种操作？\"><a href=\"#还有这种操作？\" class=\"headerlink\" title=\"还有这种操作？\"></a>还有这种操作？</h2><p>通过上面的例子，可以看到，装饰器是<code>actual_decorator</code>而不是<code>json_output</code>，那么问题来了，如果<code>json_output</code>不是装饰器而只是一个返回装饰器的函数，为什么可以像装饰器一样使用？</p>\n<p>问题的关键在于操作的顺序。具体来说，<code>json_output(indent=4,sort_keys=True)</code>的调用在前，@操作符应用在后，那么这个函数的结果就会被当作装饰器使用。即先调用<code>json_output</code>，其中定义了装饰器<code>actual_decorator</code>，并且由<code>json_output</code>返回，则此时再应用@操作符就等价于：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@actual_decorator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这不就相当于在一个函数上应用装饰器嘛！</p>\n<p>重要的一点是要意识到，当我们引入新的<code>json_output</code>函数时，实际上引入了一个后向不兼容的修改。</p>\n<p>为什么这么说？因为现在这里有一个预期的额外函数调用。如果这里我们不想给<code>json_output</code>传递参数，那么我们依然要<strong>调用</strong>这个函数，即程序必须这么写：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output()</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>号外：一定要注意<strong>圆括号</strong>！因为这表示函数是被调用，然后函数结果被应用@。</p>\n</blockquote>\n<p>上面的代码，不等同于，注意，是不等同于下面的写法：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print do_nothing() output</span></span><br><span class=\"line\">TypeError: actual_decorator() takes exactly <span class=\"number\">1</span> argument (<span class=\"number\">0</span> given)</span><br></pre></td></tr></table></figure></p>\n<p>这里有两个问题：其一是比较让人疑惑，因为一旦习惯于见到没有括号的装饰器，见到类似<code>json_output</code>这种就会觉得反常；其二是如果旧的装饰器已经应用了其他很多地方，如果修改了这个装饰器类似上面的例子，那么其他应用的地方要一并修改，因为这是一个后向不兼容的更改。</p>\n<p>理想情况下，我们希望装饰器在程序中对于下列三种应用方式都能兼容：</p>\n<ul>\n<li>@json_output</li>\n<li>@json_output()</li>\n<li>@json_output(indent=4, sort_keys=True)</li>\n</ul>\n<p>实时证明，这是可行的，只需要让装饰器根据参数来改变其行为即可。下面，我们改写一下<code>json_output</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated_=None, indent=None, sort_keys=False)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> decorated_ <span class=\"keyword\">and</span> (indent <span class=\"keyword\">or</span> sort_keys):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> RuntimeError(<span class=\"string\">'Unexpected arguments.'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">actual_decorator</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">        @functools.wraps(func)</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                result = func(*args, **kwargs)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">                result = &#123;</span><br><span class=\"line\">                    <span class=\"string\">'state'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                    <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> json.dumps(result, indent=indent, sort_keys=sort_keys)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">if</span> decorated_:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> actual_decorator(decorated_)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> actual_decorator</span><br></pre></td></tr></table></figure></p>\n<p>注意，我们为<code>json_output</code>增加了一个入参，<code>decorated_=None</code>，因为我们不希望同时传递被装饰的方法和关键字参数，所以在<code>json_output</code>中先做检查，来确保我们要么只传递被装饰的方法作为参数，要么只传递关键字参数。接着，<code>actual_decorator</code>是实际的装饰器。最终，如果设置了<code>decorated_</code>，即采用<code>@json_output</code>这种方式去修饰do_nothing方法（等价于<code>do_nothing = json_output(decorated_=do_nothing)</code>），则此时的<code>json_output</code>就是一个装饰器，那么我们应该返回的是<code>actual_decorator(decorated_)</code>；如果没有设置<code>decorated_</code>，则这就是一个方法，即可以通过<code>@json_output()</code>或<code>@json_output(indent=4)</code>的方式应用到<code>do_nothing()</code>上去——<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">do_nothing = json_output(decorated_=do_nothing)</span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 1 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 2 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3</span></span><br><span class=\"line\"><span class=\"meta\">@json_output()</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 3 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4</span></span><br><span class=\"line\"><span class=\"meta\">@json_output(indent=4, sort_keys=True)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 4 - output</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>, </span><br><span class=\"line\">    <span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">do_nothing = json_output(decorated_=do_nothing, indent=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 5 - output</span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"/decorators/output.py\"</span>, line <span class=\"number\">77</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    do_nothing = json_output(decorated_=do_nothing, indent=<span class=\"number\">4</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"/decorators/output.py\"</span>, line <span class=\"number\">18</span>, <span class=\"keyword\">in</span> json_output</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> RuntimeError(<span class=\"string\">'Unexpected arguments.'</span>)</span><br><span class=\"line\">RuntimeError: Unexpected arguments.</span><br></pre></td></tr></table></figure></p>\n<p>1、2等价，json_output就是一个实实在在的装饰器；3、4中的json_output则是一个带参数的装饰器。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>本篇中，我们知道了如何给”装饰器”传递更多的参数，同时也学到了如何让”装饰器”更灵活，以适应不同的应用形式。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"先举个例子\"><a href=\"#先举个例子\" class=\"headerlink\" title=\"先举个例子\"></a>先举个例子</h2><p>在<a href=\"https://elbarco.cn/2017/09/20/python-introduction-to-decorators-with-examples/\">上一篇文章</a>中，我们提到的装饰器的例子有一个共同的特点，就是","more":"只接收被装饰的方法作为参数。但是在很多时候，装饰器本身接收更多的参数是非常有用的。但是如何做到呢？我们先回想一下基本的装饰器，它在内部声明一个方法，然后将这个内部方法返回，即被装饰器返回的callable。如果要使装饰器接收更多的参数，我们就要再包装一层——即接收参数的”装饰器”并不是真正的装饰器，而是一个返回装饰器的函数，而真正的装饰器负责接收被装饰的方法作为参数，然后装饰方法，返回一个callable。 还是用前面<code>json_output</code>的例子，简单改造一下：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(indent=None, sort_keys=False)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">actual_decorator</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">        @functools.wraps(decorated)</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                result = decorated(*args, **kwargs)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">                result = &#123;</span><br><span class=\"line\">                    <span class=\"string\">'state'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                    <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> json.dumps(result, indent=indent, sort_keys=sort_keys)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> actual_decorator</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，在<code>json_output</code>中，传入了两个参数<code>indent</code>和<code>sort_keys</code>, 返回的是装饰器<code>actual_decorator</code>，而在<code>inner</code>中用到了传入的两个参数，用于JSON格式化时的缩进和Key的排序展示，来看这个装饰器的效果：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output(indent=4, sort_keys=True)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>, </span><br><span class=\"line\">    <span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"还有这种操作？\"><a href=\"#还有这种操作？\" class=\"headerlink\" title=\"还有这种操作？\"></a>还有这种操作？</h2><p>通过上面的例子，可以看到，装饰器是<code>actual_decorator</code>而不是<code>json_output</code>，那么问题来了，如果<code>json_output</code>不是装饰器而只是一个返回装饰器的函数，为什么可以像装饰器一样使用？</p>\n<p>问题的关键在于操作的顺序。具体来说，<code>json_output(indent=4,sort_keys=True)</code>的调用在前，@操作符应用在后，那么这个函数的结果就会被当作装饰器使用。即先调用<code>json_output</code>，其中定义了装饰器<code>actual_decorator</code>，并且由<code>json_output</code>返回，则此时再应用@操作符就等价于：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@actual_decorator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这不就相当于在一个函数上应用装饰器嘛！</p>\n<p>重要的一点是要意识到，当我们引入新的<code>json_output</code>函数时，实际上引入了一个后向不兼容的修改。</p>\n<p>为什么这么说？因为现在这里有一个预期的额外函数调用。如果这里我们不想给<code>json_output</code>传递参数，那么我们依然要<strong>调用</strong>这个函数，即程序必须这么写：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output()</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>号外：一定要注意<strong>圆括号</strong>！因为这表示函数是被调用，然后函数结果被应用@。</p>\n</blockquote>\n<p>上面的代码，不等同于，注意，是不等同于下面的写法：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print do_nothing() output</span></span><br><span class=\"line\">TypeError: actual_decorator() takes exactly <span class=\"number\">1</span> argument (<span class=\"number\">0</span> given)</span><br></pre></td></tr></table></figure></p>\n<p>这里有两个问题：其一是比较让人疑惑，因为一旦习惯于见到没有括号的装饰器，见到类似<code>json_output</code>这种就会觉得反常；其二是如果旧的装饰器已经应用了其他很多地方，如果修改了这个装饰器类似上面的例子，那么其他应用的地方要一并修改，因为这是一个后向不兼容的更改。</p>\n<p>理想情况下，我们希望装饰器在程序中对于下列三种应用方式都能兼容：</p>\n<ul>\n<li>@json_output</li>\n<li>@json_output()</li>\n<li>@json_output(indent=4, sort_keys=True)</li>\n</ul>\n<p>实时证明，这是可行的，只需要让装饰器根据参数来改变其行为即可。下面，我们改写一下<code>json_output</code>：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated_=None, indent=None, sort_keys=False)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> decorated_ <span class=\"keyword\">and</span> (indent <span class=\"keyword\">or</span> sort_keys):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> RuntimeError(<span class=\"string\">'Unexpected arguments.'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">actual_decorator</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">        @functools.wraps(func)</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                result = func(*args, **kwargs)</span><br><span class=\"line\">            <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">                result = &#123;</span><br><span class=\"line\">                    <span class=\"string\">'state'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                    <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> json.dumps(result, indent=indent, sort_keys=sort_keys)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">if</span> decorated_:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> actual_decorator(decorated_)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> actual_decorator</span><br></pre></td></tr></table></figure></p>\n<p>注意，我们为<code>json_output</code>增加了一个入参，<code>decorated_=None</code>，因为我们不希望同时传递被装饰的方法和关键字参数，所以在<code>json_output</code>中先做检查，来确保我们要么只传递被装饰的方法作为参数，要么只传递关键字参数。接着，<code>actual_decorator</code>是实际的装饰器。最终，如果设置了<code>decorated_</code>，即采用<code>@json_output</code>这种方式去修饰do_nothing方法（等价于<code>do_nothing = json_output(decorated_=do_nothing)</code>），则此时的<code>json_output</code>就是一个装饰器，那么我们应该返回的是<code>actual_decorator(decorated_)</code>；如果没有设置<code>decorated_</code>，则这就是一个方法，即可以通过<code>@json_output()</code>或<code>@json_output(indent=4)</code>的方式应用到<code>do_nothing()</code>上去——<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">do_nothing = json_output(decorated_=do_nothing)</span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 1 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 2 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3</span></span><br><span class=\"line\"><span class=\"meta\">@json_output()</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 3 - output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span>, <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4</span></span><br><span class=\"line\"><span class=\"meta\">@json_output(indent=4, sort_keys=True)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 4 - output</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"a\"</span>: <span class=\"string\">\"1\"</span>, </span><br><span class=\"line\">    <span class=\"string\">\"status\"</span>: <span class=\"string\">\"done\"</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>,<span class=\"string\">'a'</span>: <span class=\"string\">'1'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">do_nothing = json_output(decorated_=do_nothing, indent=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> do_nothing()</span><br><span class=\"line\"><span class=\"comment\"># 5 - output</span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"/decorators/output.py\"</span>, line <span class=\"number\">77</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    do_nothing = json_output(decorated_=do_nothing, indent=<span class=\"number\">4</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"/decorators/output.py\"</span>, line <span class=\"number\">18</span>, <span class=\"keyword\">in</span> json_output</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> RuntimeError(<span class=\"string\">'Unexpected arguments.'</span>)</span><br><span class=\"line\">RuntimeError: Unexpected arguments.</span><br></pre></td></tr></table></figure></p>\n<p>1、2等价，json_output就是一个实实在在的装饰器；3、4中的json_output则是一个带参数的装饰器。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>本篇中，我们知道了如何给”装饰器”传递更多的参数，同时也学到了如何让”装饰器”更灵活，以适应不同的应用形式。</p>"},{"title":"Python中的生成器和yield关键字","date":"2017-09-18T08:49:46.000Z","_content":"## 前言\n\n我们都知道`yield`语句用于定义生成器，替代函数的`return`语句来向其调用者提供结果，并且不破坏局部变量。<!--more-->与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。\n\n## 关于Python生成器\n\nPython中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：\n```python\n>>> # 定义列表\n>>> the_list = [2**i for i in range(5)]\n>>> # 类型检查，确实是一个列表\n>>> type(the_list)\n<type 'list'>\n>>> for j in the_list:\n...     print j\n... \n1\n2\n4\n8\n16\n>>> # 列表长度为5\n>>> len(the_list)\n5\n>>> # 定义一个生成器，注意是'()'而不是'[]'\n>>> the_gen = (x+x for x in range(5))\n>>> # 类型检查，确实是一个生成器\n>>> type(the_gen)\n<type 'generator'>\n>>> # 遍历生成器中的元素，并打印\n>>> for j in the_gen:\n...     print j\n... \n0\n2\n4\n6\n8\n>>> # 看起来好像跟列表似的，那如果我们来检查一下长度……\n>>> len(the_gen)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: object of type 'generator' has no len()\n>>> \n\n```\n从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。\n\n正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。\n\n## 使用Python的`yield`关键字\n\n这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？\n\n这里我们就可以使用`yield`关键字/语句来定义一个生成器。`yield`指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：\n```python\ndef search(keyword, filename):\n    print 'Generator started'\n    f = open(filename,'r')\n    for line in f:\n        if keyword in line:\n            yield line\n    f.close()\n\n# 在data.txt中搜索yield关键字\nthe_gen = search('yield', 'data.txt')\n# 检查the_gen的类型\nprint type(the_gen)\n# 也可以用the_gen.next()或next(the_gen)遍历\nfor i in the_gen:\n    print i\n\n```\n最终，我们得到的the_gen的类型是`<type 'generator'>`，遍历the_gen得到`data.txt`中包含`yield`关键字的每一行，输出结果为：\n```\n<type 'generator'>\nGenerator started\nUsing the Python \"yield\" keyword\n\nThe yield instruction should be put into a place... \n\nSince the yield keyword is only used with generators...\n```\n## 更多的例子\n\n生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：\n```python\ndef buffered_read():\n    while True:\n        buffer = fetch_big_chunk()\n        for small_chunk in buffer:\n            yield small_chunk\n```\n\n最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：\n```python\ndef fibonacci(n):\n    curr = 1\n    prev = 0\n    counter = 0\n    while counter < n:\n        yield curr\n        prev, curr = curr, prev + curr\n        counter += 1\n\nf = fibonacci(6)\n    for i in f:\n        print i\n1\n1\n2\n3\n5\n8\n```\n直到`counter = n`，停止while循环。\n\n## 参考\n\n[1].[Python generators and the yield keyword](http://pythoncentral.io/python-generators-and-yield-keyword/)\n[2].[What does the “yield” keyword do?](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do)\n","source":"_posts/python-generators-and-yield-keyword.md","raw":"---\ntitle: Python中的生成器和yield关键字\ndate: 2017-09-18 16:49:46\ntags: [Python, yield]\n---\n## 前言\n\n我们都知道`yield`语句用于定义生成器，替代函数的`return`语句来向其调用者提供结果，并且不破坏局部变量。<!--more-->与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。\n\n## 关于Python生成器\n\nPython中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：\n```python\n>>> # 定义列表\n>>> the_list = [2**i for i in range(5)]\n>>> # 类型检查，确实是一个列表\n>>> type(the_list)\n<type 'list'>\n>>> for j in the_list:\n...     print j\n... \n1\n2\n4\n8\n16\n>>> # 列表长度为5\n>>> len(the_list)\n5\n>>> # 定义一个生成器，注意是'()'而不是'[]'\n>>> the_gen = (x+x for x in range(5))\n>>> # 类型检查，确实是一个生成器\n>>> type(the_gen)\n<type 'generator'>\n>>> # 遍历生成器中的元素，并打印\n>>> for j in the_gen:\n...     print j\n... \n0\n2\n4\n6\n8\n>>> # 看起来好像跟列表似的，那如果我们来检查一下长度……\n>>> len(the_gen)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: object of type 'generator' has no len()\n>>> \n\n```\n从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。\n\n正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。\n\n## 使用Python的`yield`关键字\n\n这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？\n\n这里我们就可以使用`yield`关键字/语句来定义一个生成器。`yield`指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：\n```python\ndef search(keyword, filename):\n    print 'Generator started'\n    f = open(filename,'r')\n    for line in f:\n        if keyword in line:\n            yield line\n    f.close()\n\n# 在data.txt中搜索yield关键字\nthe_gen = search('yield', 'data.txt')\n# 检查the_gen的类型\nprint type(the_gen)\n# 也可以用the_gen.next()或next(the_gen)遍历\nfor i in the_gen:\n    print i\n\n```\n最终，我们得到的the_gen的类型是`<type 'generator'>`，遍历the_gen得到`data.txt`中包含`yield`关键字的每一行，输出结果为：\n```\n<type 'generator'>\nGenerator started\nUsing the Python \"yield\" keyword\n\nThe yield instruction should be put into a place... \n\nSince the yield keyword is only used with generators...\n```\n## 更多的例子\n\n生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：\n```python\ndef buffered_read():\n    while True:\n        buffer = fetch_big_chunk()\n        for small_chunk in buffer:\n            yield small_chunk\n```\n\n最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：\n```python\ndef fibonacci(n):\n    curr = 1\n    prev = 0\n    counter = 0\n    while counter < n:\n        yield curr\n        prev, curr = curr, prev + curr\n        counter += 1\n\nf = fibonacci(6)\n    for i in f:\n        print i\n1\n1\n2\n3\n5\n8\n```\n直到`counter = n`，停止while循环。\n\n## 参考\n\n[1].[Python generators and the yield keyword](http://pythoncentral.io/python-generators-and-yield-keyword/)\n[2].[What does the “yield” keyword do?](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do)\n","slug":"python-generators-and-yield-keyword","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxk000txu2z8fw5hq9x","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>我们都知道<code>yield</code>语句用于定义生成器，替代函数的<code>return</code>语句来向其调用者提供结果，并且不破坏局部变量。<a id=\"more\"></a>与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。</p>\n<h2 id=\"关于Python生成器\"><a href=\"#关于Python生成器\" class=\"headerlink\" title=\"关于Python生成器\"></a>关于Python生成器</h2><p>Python中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_list = [<span class=\"number\">2</span>**i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_list)</span><br><span class=\"line\">&lt;type <span class=\"string\">'list'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_list:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"number\">16</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 列表长度为5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_list)</span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义一个生成器，注意是'()'而不是'[]'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_gen = (x+x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个生成器</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_gen)</span><br><span class=\"line\">&lt;type <span class=\"string\">'generator'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 遍历生成器中的元素，并打印</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">6</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 看起来好像跟列表似的，那如果我们来检查一下长度……</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_gen)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: object of type <span class=\"string\">'generator'</span> has no len()</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。</p>\n<p>正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。</p>\n<h2 id=\"使用Python的yield关键字\"><a href=\"#使用Python的yield关键字\" class=\"headerlink\" title=\"使用Python的yield关键字\"></a>使用Python的<code>yield</code>关键字</h2><p>这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？</p>\n<p>这里我们就可以使用<code>yield</code>关键字/语句来定义一个生成器。<code>yield</code>指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">search</span><span class=\"params\">(keyword, filename)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Generator started'</span></span><br><span class=\"line\">    f = open(filename,<span class=\"string\">'r'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> keyword <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> line</span><br><span class=\"line\">    f.close()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在data.txt中搜索yield关键字</span></span><br><span class=\"line\">the_gen = search(<span class=\"string\">'yield'</span>, <span class=\"string\">'data.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 检查the_gen的类型</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> type(the_gen)</span><br><span class=\"line\"><span class=\"comment\"># 也可以用the_gen.next()或next(the_gen)遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> i</span><br></pre></td></tr></table></figure></p>\n<p>最终，我们得到的the_gen的类型是<code>&lt;type &#39;generator&#39;&gt;</code>，遍历the_gen得到<code>data.txt</code>中包含<code>yield</code>关键字的每一行，输出结果为：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;type &apos;generator&apos;&gt;</span><br><span class=\"line\">Generator started</span><br><span class=\"line\">Using the Python &quot;yield&quot; keyword</span><br><span class=\"line\"></span><br><span class=\"line\">The yield instruction should be put into a place... </span><br><span class=\"line\"></span><br><span class=\"line\">Since the yield keyword is only used with generators...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更多的例子\"><a href=\"#更多的例子\" class=\"headerlink\" title=\"更多的例子\"></a>更多的例子</h2><p>生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buffered_read</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        buffer = fetch_big_chunk()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_chunk <span class=\"keyword\">in</span> buffer:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> small_chunk</span><br></pre></td></tr></table></figure></p>\n<p>最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fibonacci</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    curr = <span class=\"number\">1</span></span><br><span class=\"line\">    prev = <span class=\"number\">0</span></span><br><span class=\"line\">    counter = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> counter &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> curr</span><br><span class=\"line\">        prev, curr = curr, prev + curr</span><br><span class=\"line\">        counter += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = fibonacci(<span class=\"number\">6</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> i</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br></pre></td></tr></table></figure></p>\n<p>直到<code>counter = n</code>，停止while循环。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://pythoncentral.io/python-generators-and-yield-keyword/\" target=\"_blank\" rel=\"noopener\">Python generators and the yield keyword</a><br>[2].<a href=\"https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\" target=\"_blank\" rel=\"noopener\">What does the “yield” keyword do?</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>我们都知道<code>yield</code>语句用于定义生成器，替代函数的<code>return</code>语句来向其调用者提供结果，并且不破坏局部变量。","more":"与函数不同的是，每次调用时，生成器会以新的变量集开始，继续执行它被关闭的执行。</p>\n<h2 id=\"关于Python生成器\"><a href=\"#关于Python生成器\" class=\"headerlink\" title=\"关于Python生成器\"></a>关于Python生成器</h2><p>Python中的生成器的目的是能够即时的按照我们的要求逐个计算一系列结果。举个最简单的例子，生成器可以用作列表，列表中的每个元素会在用到的时候的方式被计算（lazily）：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_list = [<span class=\"number\">2</span>**i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个列表</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_list)</span><br><span class=\"line\">&lt;type <span class=\"string\">'list'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_list:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"number\">16</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 列表长度为5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_list)</span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 定义一个生成器，注意是'()'而不是'[]'</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>the_gen = (x+x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 类型检查，确实是一个生成器</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>type(the_gen)</span><br><span class=\"line\">&lt;type <span class=\"string\">'generator'</span>&gt;</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 遍历生成器中的元素，并打印</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\"><span class=\"meta\">... </span>    <span class=\"keyword\">print</span> j</span><br><span class=\"line\"><span class=\"meta\">... </span></span><br><span class=\"line\"><span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"number\">6</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 看起来好像跟列表似的，那如果我们来检查一下长度……</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>len(the_gen)</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">TypeError: object of type <span class=\"string\">'generator'</span> has no len()</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>从上面的例子，可以看出，遍历列表和遍历生成器是一样的。不过，尽管生成器可遍历的，但是却不是一个数据集合，因此没有长度的属性。数据集合（比如列表、元组、集合等）将数据存储在内存中，所以我们需要时就可以获得；生成器即时的计算结果，然后下一次迭代时就把上一次结果“忘掉了”，所以生成器没有对自己结果集的任何概述。</p>\n<p>正因为生成器有这个特性——不需要同时在内存中保留数据集合中的全部元素——所以非常适合内存敏感的任务。当我们不需要完整的结果时，逐个的计算结果值的做法就显得十分有用，对调用者即时的返回中间结果，直到满足一些要求然后停止处理。</p>\n<h2 id=\"使用Python的yield关键字\"><a href=\"#使用Python的yield关键字\" class=\"headerlink\" title=\"使用Python的yield关键字\"></a>使用Python的<code>yield</code>关键字</h2><p>这里我们有一个很好的例子，就是当我们在搜索时，我们不需要等所有的结果都被查找出来。比如在文件系统中搜索时，用户更希望能即时的看到结果，而不是等搜索工具遍历每个文件，然后返回所有的结果。再比如，用Google搜索的用户会一直翻到最后一页吗？</p>\n<p>这里我们就可以使用<code>yield</code>关键字/语句来定义一个生成器。<code>yield</code>指令应当放在生成器立即返回结果给调用者并且等待下次调用发生的地方。举个例子，我们先定义一个用于在大文件中逐行搜索关键字的生成器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">search</span><span class=\"params\">(keyword, filename)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'Generator started'</span></span><br><span class=\"line\">    f = open(filename,<span class=\"string\">'r'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> keyword <span class=\"keyword\">in</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> line</span><br><span class=\"line\">    f.close()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在data.txt中搜索yield关键字</span></span><br><span class=\"line\">the_gen = search(<span class=\"string\">'yield'</span>, <span class=\"string\">'data.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 检查the_gen的类型</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> type(the_gen)</span><br><span class=\"line\"><span class=\"comment\"># 也可以用the_gen.next()或next(the_gen)遍历</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> the_gen:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> i</span><br></pre></td></tr></table></figure></p>\n<p>最终，我们得到的the_gen的类型是<code>&lt;type &#39;generator&#39;&gt;</code>，遍历the_gen得到<code>data.txt</code>中包含<code>yield</code>关键字的每一行，输出结果为：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;type &apos;generator&apos;&gt;</span><br><span class=\"line\">Generator started</span><br><span class=\"line\">Using the Python &quot;yield&quot; keyword</span><br><span class=\"line\"></span><br><span class=\"line\">The yield instruction should be put into a place... </span><br><span class=\"line\"></span><br><span class=\"line\">Since the yield keyword is only used with generators...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更多的例子\"><a href=\"#更多的例子\" class=\"headerlink\" title=\"更多的例子\"></a>更多的例子</h2><p>生成器的应用有很多，比如扮演传送带的角色，一个比较好的例子即缓冲区：获取大量的数据并将其以小数据块进行处理：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">buffered_read</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        buffer = fetch_big_chunk()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_chunk <span class=\"keyword\">in</span> buffer:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> small_chunk</span><br></pre></td></tr></table></figure></p>\n<p>最后我们再看一个经典例子——给定数字N，使用生成器给出前N个斐波那契序列（Fibonacci）数字：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fibonacci</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    curr = <span class=\"number\">1</span></span><br><span class=\"line\">    prev = <span class=\"number\">0</span></span><br><span class=\"line\">    counter = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> counter &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> curr</span><br><span class=\"line\">        prev, curr = curr, prev + curr</span><br><span class=\"line\">        counter += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = fibonacci(<span class=\"number\">6</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> i</span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"number\">8</span></span><br></pre></td></tr></table></figure></p>\n<p>直到<code>counter = n</code>，停止while循环。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"http://pythoncentral.io/python-generators-and-yield-keyword/\" target=\"_blank\" rel=\"noopener\">Python generators and the yield keyword</a><br>[2].<a href=\"https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\" target=\"_blank\" rel=\"noopener\">What does the “yield” keyword do?</a></p>"},{"title":"Nova Placement API与Nova调度全解析","date":"2018-02-23T08:47:50.000Z","_content":"<!-- more -->\n## 是什么\n\n由于历史遗留原因，Nova认为资源全部是由计算节点提供，所以在报告某些资源使用时，Nova仅仅通过查询数据库中不同计算节点的数据，简单的做累加计算得到使用量和可用资源情况，这一定不是严谨科学的做法，于是，在N版中，Nova引入了Placement API，这是一个单独的RESTful API和数据模型，用于管理和查询资源提供者的资源存量、使用情况、分配记录等等，以提供更好、更准确的资源跟踪、调度和分配的功能。\n\n## 有什么\n\n### 代码目录\n\n由于Nova Placement API是单独剥离出来的RESTful API，同时也有自己单独的Endpoint，并且与Nova API服务启动在不同的端口，单独提供服务，那么，在代码目录上来看，也是相对独立的，其代码实现均在`/nova/api/openstack/placement/`下，那么我看来看一下Nova Placement API的代码目录结构：\n\n```shell\nF:nova ZH.F$ tree  -C  api/openstack/placement\napi/openstack/placement\n├── __init__.py\n├── auth.py\n├── deploy.py\n├── handler.py\n├── handlers\n│   ├── __init__.py\n│   ├── aggregate.py\n│   ├── allocation.py\n│   ├── allocation_candidate.py\n│   ├── inventory.py\n│   ├── resource_class.py\n│   ├── resource_provider.py\n│   ├── root.py\n│   ├── trait.py\n│   └── usage.py\n├── lib.py\n├── microversion.py\n├── policy.py\n├── requestlog.py\n├── rest_api_version_history.rst\n├── schemas\n│   ├── __init__.py\n│   ├── aggregate.py\n│   ├── allocation.py\n│   ├── allocation_candidate.py\n│   ├── inventory.py\n│   ├── resource_class.py\n│   ├── trait.py\n│   └── usage.py\n├── util.py\n├── wsgi.py\n└── wsgi_wrapper.py\n```\n其中，在`api/openstack/placement/schemas`目录下，可以看到基本数据模型的schema，不过`resource privoder`的schema定义在了`api/openstack/placement/handlers/resource_provider.py`中。下面，对照schema，我们对其中的一些概念进行了解。\n\n### Nova Placement API中的一些概念\n\n#### Resource Provider\n\n即资源提供者，通过其schema可以看到结构比较简单，只包含UUID和RP（Resource Provider简写，下同）的一些基本信息，比如name：\n\n```python\nGET_RPS_SCHEMA_1_0 = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\n            \"type\": \"string\"\n        },\n        \"uuid\": {\n            \"type\": \"string\",\n            \"format\": \"uuid\"\n        }\n    },\n    \"additionalProperties\": False,\n}\n```\n资源提供者可能是一个计算节点，也可能是一个共享存储池或者一个IP分配池子，那么不同的RP，提供的资源多种多样，于是就引入了Resource Class，即资源类型的概念。\n\n#### Resource Class\n\n即资源类型，比如计算节点提供的资源可能是CPU、内存、PCI设备、本地临时磁盘等等。每种被消费的资源都会按照类别进行标注和跟踪。\n\n之所以引入这个概念，目的是解决Nova中hard-coded的资源类型扩展性问题，比如CPU资源，可能记录在Instance对象的*vcpus*字段中，那么之后再增加新的资源类型，都需要修改数据表，而修改数据表的过程都会停机维护，给系统带来许多downtime，这是不可接受的。\n\nPlacement API提供了一些标准资源类别，如：\n\n* VCPU\n* MEMORY_MB\n* DISK_GB\n* PCI_DEVICE\n* NUMA_SOCKET\n* NUMA_CORE\n* NUMA_THREAD\n* IPV4_ADDRESS\n* ...\n\n注：数据来自[BP:Introduce resource classes](https://specs.openstack.org/openstack/nova-specs/specs/mitaka/implemented/resource-classes.html)\n\n除了以上标准资源类别，Placement API还在O版中为RP增加了自定义Resource Class的能力，比如自动以的FPGA、裸机调度等等。\n\n#### Inventory\n\n即库存，存量。用于记录超配比、资源总量、存量、步长（step_size）、最小和最大单位等信息，可以看一下它的schema：\n\n```python\nBASE_INVENTORY_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"resource_provider_generation\": {\n            \"type\": \"integer\"\n        },\n        \"total\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1,\n        },\n        \"reserved\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 0,\n        },\n        \"min_unit\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"max_unit\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"step_size\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"allocation_ratio\": {\n            \"type\": \"number\",\n            \"maximum\": db.SQL_SP_FLOAT_MAX\n        },\n    },\n    \"required\": [\n        \"total\",\n        \"resource_provider_generation\"\n    ],\n    \"additionalProperties\": False\n}\n```\n其中的`resource_provider_generation `字段，是一个一致性视图的标志位，在获取RP列表时的`generation`功能是相同的，这就是CAS（Compare and swap），即乐观锁技术——当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。\n\n#### Usage\n\n即用量，使用情况。可以查看某个RP的使用情况，也可以查看项目下某用户的资源使用情况。\n\n#### Aggregate\n\n在Ocata版本，社区开始将nova-scheduler服务与Placement API进行集成，并在scheduler进行了一些修改，使用Placement API进行满足一些基本资源请求条件的计算节点过滤。添加了aggregates，来提供resource provider的分组机制。\n\n#### Allocation\n\n即已分配量，某一个RP对某一个资源消费者（即某个实例）所分配的资源。\n\n#### Allocation-candidate\n\n即分配的候选者（资源提供者），举个例子，用户说，我需要1个VCPU，512MB内存，1GB磁盘的资源，Placement你帮我找找看看，有没有合适的资源。然后Placement就要做各种处理，反馈给用户，哪些是可以分配的候选资源提供者。\n\n#### Trait\n\n字面意思，特征，特性。ResourceProvider和Allocation可以在定量的角度，控制和管理boot虚机请求，然而我们还需要从定性的角度来区分资源，最经典的例子是当我们创建虚机时，需要向不同的RP请求磁盘资源，用户可能请求80GB的磁盘，但也可能请求80GB的SSD。这就是Trait的意义。\n\n### 数据库及数据表\n\n目前我安装的Pike版本的Packstack环境中，能看到有一个`nova_placement`数据库，但是没有任何表（也许是社区希望能把placement相关的表放到这个数据库中？），Placement对应的数据库用的还是`nova_api`：\n\n```\nMariaDB [nova_placement]> use nova_api;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nMariaDB [nova_api]> show tables;\n+------------------------------+\n| Tables_in_nova_api           |\n+------------------------------+\n| aggregate_hosts              |\n| aggregate_metadata           |\n| aggregates                   |\n| allocations                  |\n| build_requests               |\n| cell_mappings                |\n| consumers                    |\n| flavor_extra_specs           |\n| flavor_projects              |\n| flavors                      |\n| host_mappings                |\n| instance_group_member        |\n| instance_group_policy        |\n| instance_groups              |\n| instance_mappings            |\n| inventories                  |\n| key_pairs                    |\n| migrate_version              |\n| placement_aggregates         |\n| project_user_quotas          |\n| projects                     |\n| quota_classes                |\n| quota_usages                 |\n| quotas                       |\n| request_specs                |\n| reservations                 |\n| resource_classes             |\n| resource_provider_aggregates |\n| resource_provider_traits     |\n| resource_providers           |\n| traits                       |\n| users                        |\n+------------------------------+\n```\n可以从表明上看到那些是Placement相关的表，这里就不展开了。\n\n### 初始化及加载方式\n\n我们前面提到Nova Placement API是单独的RESTful API，那么是如何进行初始化的呢？带着这个问题，我们先查看nova的`setup.cfg`，其中配置了wsgi_scripts如下：\n\n```\nwsgi_scripts =\n    nova-placement-api = nova.api.openstack.placement.wsgi:init_application\n    nova-api-wsgi = nova.api.openstack.compute.wsgi:init_application\n    nova-metadata-wsgi = nova.api.metadata.wsgi:init_application\n```\n其中可以看到nova-placement-api的初始化来自 `nova.api.openstack.placement.wsgi.init_application` ，代码如下：\n\n```python\ndef init_application():\n    # initialize the config system\n    conffile = _get_config_file()\n    config.parse_args([], default_config_files=[conffile])\n\n    # initialize the logging system\n    setup_logging(conf.CONF)\n\n    # dump conf if we're at debug\n    if conf.CONF.debug:\n        conf.CONF.log_opt_values(\n            logging.getLogger(__name__),\n            logging.DEBUG)\n\n    # build and return our WSGI app\n    return deploy.loadapp(conf.CONF)\n```\n其中在最后构造WSGI app并返回，即调用了deploy.loadapp(conf.CONF)：\n\n```python\ndef loadapp(config, project_name=NAME):\n    application = deploy(config, project_name)\n    return application\ndef deploy(conf, project_name):\n    \"\"\"Assemble the middleware pipeline leading to the placement app.\"\"\"\n    ...\n    application = handler.PlacementHandler()\n    ...\n    for middleware in (microversion_middleware,\n                       fault_wrap,\n                       request_log,\n                       context_middleware,\n                       auth_middleware,\n                       cors_middleware,\n                       req_id_middleware,\n                       ):\n        if middleware:\n            application = middleware(application)\n\n    return application\n```\n\n而这里的handler.PlacementHandler()就是我们的Placement的API入口：\n\n```python\nclass PlacementHandler(object):\n    \"\"\"Serve Placement API.\n    Dispatch to handlers defined in ROUTE_DECLARATIONS.\n    \"\"\"\n\n    def __init__(self, **local_config):\n        # NOTE(cdent): Local config currently unused.\n        self._map = make_map(ROUTE_DECLARATIONS)\n\n    def __call__(self, environ, start_response):\n        # All requests but '/' require admin.\n        if environ['PATH_INFO'] != '/':\n    ...\n```\n\n可以看到，PlacementHandler在`__init__`中根据路由定义构造了map，同时在`__call__`中对请求进行dispatch。这就是一个典型的WSGI应用：\n>WSGI application is a callable object (a function, method, class, or an instance with a `__call__` method) that accepts two positional arguments: WSGI environment variables and a callable with two required positional arguments which starts the response;\n\n找到了初始化，那么Placement API加载和启动是如何实现的？\n\n首先，nova-placement-api是单独的脚本，在httpd中启动，与keystone（在12年就完成了WSGI化，参见[>>传送门](http://adam.younglogic.com/2012/03/keystone-should-move-to-apache-httpd/)）类似，通过`systemctl status httpd `是可以看到的：\n\n```\n[root@f-packstack ~(keystone_admin)]# systemctl status httpd\n● httpd.service - The Apache HTTP Server\n   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)\n   Active: active (running) since Fri 2018-02-02 09:17:51 CST; 1 weeks 0 days ago\n     Docs: man:httpd(8)\n           man:apachectl(8)\n  Process: 4087 ExecReload=/usr/sbin/httpd $OPTIONS -k graceful (code=exited, status=0/SUCCESS)\n Main PID: 1309 (httpd)\n   Status: \"Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec\"\n   CGroup: /system.slice/httpd.service\n           ├─ 1309 /usr/sbin/httpd -DFOREGROUND\n           ├─ 4108 keystone-admin  -DFOREGROUND\n\n▽\n           ├─ 4109 keystone-admin  -DFOREGROUND\n           ├─ 4110 keystone-admin  -DFOREGROUND\n           ├─ 4111 keystone-admin  -DFOREGROUND\n\n▽\n           ├─ 4112 keystone-main   -DFOREGROUND\n           ├─ 4113 keystone-main   -DFOREGROUND\n           ├─ 4114 keystone-main   -DFOREGROUND\n           ├─ 4115 keystone-main   -DFOREGROUND\n           ├─ 4116 placement_wsgi  -DFOREGROUND\n           ├─ 4117 placement_wsgi  -DFOREGROUND\n           ├─ 4118 placement_wsgi  -DFOREGROUND\n           ├─ 4119 placement_wsgi  -DFOREGROUND\n           ├─ 4121 /usr/sbin/httpd -DFOREGROUND\n           ├─ 4122 /usr/sbin/httpd -DFOREGROUND\n…\n```\n知道是在httpd启动的，我们去查看配置文件目录：\n\n```shell\n[root@f-packstack ~(keystone_admin)]# ll /etc/httpd/conf.d/\ntotal 36\n-rw-r-----. 1 root root  136 Jan 12 17:46 00-nova-placement-api.conf\n-rw-r--r--. 1 root root  943 Jan 12 17:48 10-keystone_wsgi_admin.conf\n-rw-r--r--. 1 root root  938 Jan 12 17:48 10-keystone_wsgi_main.conf\n-rw-r--r--. 1 root root  941 Jan 12 17:49 10-placement_wsgi.conf\n-rw-r--r--. 1 root root  697 Jan 12 17:48 15-default.conf\n-rw-r--r--. 1 root root 2926 Oct 20 04:39 autoindex.conf\n-rw-r--r--. 1 root root  366 Oct 20 04:39 README\n-rw-r--r--. 1 root root 1252 Oct 20 00:44 userdir.conf\n-rw-r--r--. 1 root root  824 Oct 20 00:44 welcome.conf\n```\n其中，10-placement_wsgi.conf 中定义了WSGIScriptAllias：\n\n```\n...\n  WSGIProcessGroup placement-api\n  WSGIScriptAlias /placement \"/var/www/cgi-bin/nova/nova-placement-api”\n...\n```\n也就是说，url为`/placement/xxx`的请求会使得httpd服务运行定义在`/var/www/cgi-bin/nova/nova-placement-api`中的WSGI应用，在这个文件中，我们会看到：\n\n```python\nfrom nova.api.openstack.placement.wsgi import init_application\n\nif __name__ == \"__main__”:\n    import argparse\n    import socket\n    import sys\n    import wsgiref.simple_server as wss\n    …\n    server = wss.make_server(args.host, args.port, init_application())\n...\n```\n也就对应了前面提到的PlacementHandler中的`nova.api.openstack.placement.wsgi.init_application`，至此，我们就了解了Nova Placement API的初始化和加载方式。\n\n### API路由定义\n\n上一小节提到了PlacementHandler初始化时，根据路由定义构造了map映射，我们就来看下文件`api/openstack/placement/handler.py`中的API`ROUTE_DECLARATIONS`:\n\n```python\n# URLs and Handlers\n# NOTE(cdent): When adding URLs here, do not use regex patterns in\n# the path parameters (e.g. {uuid:[0-9a-zA-Z-]+}) as that will lead\n# to 404s that are controlled outside of the individual resources\n# and thus do not include specific information on the why of the 404.\nROUTE_DECLARATIONS = {\n    '/': {\n        'GET': root.home,\n    },\n    # NOTE(cdent): This allows '/placement/' and '/placement' to\n    # both work as the root of the service, which we probably want\n    # for those situations where the service is mounted under a\n    # prefix (as it is in devstack). While weird, an empty string is\n    # a legit key in a dictionary and matches as desired in Routes.\n    '': {\n        'GET': root.home,\n    },\n    '/resource_classes': {\n        'GET': resource_class.list_resource_classes,\n        'POST': resource_class.create_resource_class\n    },\n    '/resource_classes/{name}': {\n        'GET': resource_class.get_resource_class,\n        'PUT': resource_class.update_resource_class,\n        'DELETE': resource_class.delete_resource_class,\n    },\n    '/resource_providers': {\n        'GET': resource_provider.list_resource_providers,\n        'POST': resource_provider.create_resource_provider\n    },\n    '/resource_providers/{uuid}': {\n        'GET': resource_provider.get_resource_provider,\n        'DELETE': resource_provider.delete_resource_provider,\n        'PUT': resource_provider.update_resource_provider\n    },\n    '/resource_providers/{uuid}/inventories': {\n        'GET': inventory.get_inventories,\n        'POST': inventory.create_inventory,\n        'PUT': inventory.set_inventories,\n        'DELETE': inventory.delete_inventories\n    },\n    '/resource_providers/{uuid}/inventories/{resource_class}': {\n        'GET': inventory.get_inventory,\n        'PUT': inventory.update_inventory,\n        'DELETE': inventory.delete_inventory\n    },\n    '/resource_providers/{uuid}/usages': {\n        'GET': usage.list_usages\n    },\n    '/resource_providers/{uuid}/aggregates': {\n        'GET': aggregate.get_aggregates,\n        'PUT': aggregate.set_aggregates\n    },\n    '/resource_providers/{uuid}/allocations': {\n        'GET': allocation.list_for_resource_provider,\n    },\n    '/allocations': {\n        'POST': allocation.set_allocations,\n    },\n    '/allocations/{consumer_uuid}': {\n        'GET': allocation.list_for_consumer,\n        'PUT': allocation.set_allocations_for_consumer,\n        'DELETE': allocation.delete_allocations,\n    },\n    '/allocation_candidates': {\n        'GET': allocation_candidate.list_allocation_candidates,\n    },\n    '/traits': {\n        'GET': trait.list_traits,\n    },\n    '/traits/{name}': {\n        'GET': trait.get_trait,\n        'PUT': trait.put_trait,\n        'DELETE': trait.delete_trait,\n    },\n    '/resource_providers/{uuid}/traits': {\n        'GET': trait.list_traits_for_resource_provider,\n        'PUT': trait.update_traits_for_resource_provider,\n        'DELETE': trait.delete_traits_for_resource_provider\n    },\n    '/usages': {\n        'GET': usage.get_total_usages,\n    },\n}\n```\n\n## 怎么用\n\n### 如何部署\n\n在官方文档中提到，placement api服务必须在升级到14.0.0，即N版后，升级到15.0.0，即O版之前进行部署。nova-compute服务中的resource tracker需要获取placement的资源提供者存量和分配信息（这部分信息将在O版中由nova-scheduler使用）。\n\n1. 部署API服务 - Placement API目前还是在nova中进行开发，但是设计上是相对独立的，以便将来分离出来成为单独的项目。作为一个单独的WSGI应用，可使用Apahce2或者Nginx部署API服务。\n2. 同步数据库 - 升级N版时，需要手动执行` nova-manage api_db sync`命令进行数据库同步，这样Placement相关的数据表就会被创建出来\n3. 在keystone中创建具有admin角色的placement service user，同时更新服务目录，配置单独的endpoint.\n4. 配置nova.conf中[placement]部分，并重启nova-compute服务。不过对于我们P版，经过了O版的一系列功能补齐，尤其是在O版中，如果在`nova.conf`中不配置`[placement]`部分的内容，就无法启动`nova-compute`服务。\n\n>The nova-compute service will fail to start in Ocata unless the [placement] section of nova.conf on the compute is configured.\n\n更多部署相关的可参见官方文档，[>>传送门](https://docs.openstack.org/nova/latest/user/placement.html#deployment)。\n\n### OSC Placement Plugin\n\n从前面的API路由定义，我们可以看到，目前支持了这么些功能，那么我们可以简单的用一下，第一个想到的是cURL命令，我们可以使用该命令模拟发起请求，调用Placement API，比如查看resource providers list，首先我们获取token：\n\n```json\n# 首先得到auth token\ncurl -d '{\"auth\": {\"tenantName\": \"admin\", \"passwordCredentials\": {\"username\": \"admin\", \"password\": \"1234qwer\"}}}' \\\n-H \"Content-type: application/json\" \\\nhttp://localhost:5000/v2.0/tokens\n\n...\n{\n    \"issued_at\": \"2018-02-07T07:40:07.000000Z\",\n    \"expires\": \"2018-02-07T08:40:07.000000Z\",\n    \"id\": \"gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itnL6Q-TSWhOn7uZpdQsYqqJDmwgtzCm-hcpg17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE\",\n    \"tenant\": {\n        \"description\": \"admin tenant\",\n        \"enabled\": true,\n        \"id\": \"6387fc88b3064149a12eb5b58669e0b2\",\n        \"name\": \"admin\"\n    }\n}\n\n# token的获取方式，还可以用OSC命令：\nopenstack token issue | grep ' id' | awk '{print $4}'\n...\n\n\n#得到token之后，构造请求，查看resource providers list：\ncurl -X GET /\n-H 'x-auth-token:gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itn17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE’ /\nhttp://192.168.122.105:8778/placement/resource_providers\n\n#得到resources providers list\n{\n    \"resource_providers\": [\n        {\n            \"generation\": 30,\n            \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\",\n            \"links\": [\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\",\n                    \"rel\": \"self\"\n                },\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\",\n                    \"rel\": \"inventories\"\n                },\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\",\n                    \"rel\": \"usages\"\n                }\n            ],\n            \"name\": \"f-packstack\"\n        }\n    ]\n}\n```\n其中的`generation`字段，是一个一致性视图的标志位，跟获取RP的inventories中的`resource_provider_generation`功能是相同的，其实算作是乐观锁技术，即CAS，Compare and swap，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。\n\n下面来一个获取aggregate和inventories的示例，注意，aggregate的API是在1.1版本中实现的，所以要在请求头指定`OpenStack-API-Version: placement 1.1`：\n\n```json\ncurl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/aggregates \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H \"X-Auth-Token: gAAAAABaf5nafUZyFTl_pztozfB65wkP0c26HQqrxRgAiJGsxY8g743LxFOZEI3bF_l37xh0UajbF5nQ1kLYGAonOGphV4AivXgYMUOJ84uGrHjpC60NlmNzzQ3lJGVJb-pNxQw74WsMOc9I0D2B5Mzmf2OgDeictae5f0UFgTR9DFb_vaWCWQ4\" \\\n-H \"OpenStack-API-Version: placement 1.1\"\nHTTP/1.1 200 OK\nDate: Fri, 15 Sep 2017 09:35:21 GMT\nServer: Apache/2.4.18 (Ubuntu)\nContent-Length: 18\nContent-Type: application/json\nOpenStack-API-Version: placement 1.1\nvary: OpenStack-API-Version\nx-openstack-request-id: req-ab28194f-8389-40a1-9a2b-a94dbc792573\nConnection: close\n\n{\"aggregates\": []}\n\n\ncurl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H 'x-auth-token:gAAAAABae6lX26bp4PEVHCac0cjFnNl18W8DjeQKXDYvuKP4drRJ8t6DC-9uzcCm4E9Xf7NjqSqkRX6WGsE3qHmpAt7GmIu1SrLCtyEOVM2IQP5XLNrwMekGGrzQ_ADOaSTc9XpPpCYyYwzT-zCAvWG-T9T6Ip4l3zHWLwNBBPrm35gBZVZeslQ' \\\n\n{\n    \"resource_provider_generation\": 30,\n    \"inventories\": {\n        \"VCPU\": {\n            \"allocation_ratio\": 16,\n            \"total\": 4,\n            \"reserved\": 0,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 128\n        },\n        \"MEMORY_MB\": {\n            \"allocation_ratio\": 1.5,\n            \"total\": 8095,\n            \"reserved\": 512,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 8095\n        },\n        \"DISK_GB\": {\n            \"allocation_ratio\": 1,\n            \"total\": 49,\n            \"reserved\": 0,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 49\n        }\n    }\n}\n```\n\n贴心的社区妥妥的想到了如何可以方便用户操作Placement API，所以开发了一个OpenStackClient Plugin，即[osc-placement](https://github.com/openstack/osc-placement)，需要我们手动安装使用：\n\n```\n$ pip install osc-placement\n```\n有了OSC placement commands，我们不再需要使用curl命令模拟HTTP请求，并且可以非常轻松的进行操作：\n\n```shell\n[root@f-packstack ~(keystone_admin)]# openstack --debug resource provider list\n...\nhttp://192.168.122.105:8778 \"GET /placement/resource_providers HTTP/1.1\" 200 185\nRESP: [200] Date: Thu, 08 Feb 2018 05:59:56 GMT Server: Apache/2.4.6 (CentOS) OpenStack-API-Version: placement 1.0 vary: OpenStack-API-Version,Accept-Encoding x-openstack-request-id: req-c6077c19-ca05-4cab-95fa-6129ff989400 Content-Encoding: gzip Content-Length: 185 Keep-Alive: timeout=15, max=100 Connection: Keep-Alive Content-Type: application/json\nRESP BODY: {\"resource_providers\": [{\"generation\": 30, \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"links\": [{\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"rel\": \"self\"}, {\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\", \"rel\": \"inventories\"}, {\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\", \"rel\": \"usages\"}], \"name\": \"f-packstack\"}]}\n\nGET call to placement for http://192.168.122.105:8778/placement/resource_providers used request id req-c6077c19-ca05-4cab-95fa-6129ff989400\n+--------------------------------------+-------------+------------+\n| uuid                                 | name        | generation |\n+--------------------------------------+-------------+------------+\n| 4cae2ef8-30eb-4571-80c3-3289e86bd65c | f-packstack |         30 |\n+--------------------------------------+-------------+------------+\nclean_up ListResourceProvider:\nEND return value: 0\n```\n当然还有很多其他的命令，有兴趣的可以尝试玩一下。\n\n### 划重点：Nova调度与Placement API的结合\n\n首先来一张图，来认识一下在P版中，创建一台虚机过程中各个服务之间的调用/调度关系：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/boot-instance-pike.png)\n可以看到，在nova-scheduler与Placement API的交互过程中，有两部分：\n1. Get allocation candidates\n2. Claim Resources\n下面，我们结合代码详细的讲述一下调度过程。\n\n#### Get allocation candidates\n\n目前在调度时，nova-conductor在`nova.conductor.manager.ComputeTaskManager#_schedule_instances`中调用了方法`nova.scheduler.client.SchedulerClient#select_destinations`：\n\n```python\n    @utils.retry_select_destinations\n    def select_destinations(self, context, spec_obj, instance_uuids,\n            return_objects=False, return_alternates=False):\n        return self.queryclient.select_destinations(context, spec_obj,\n                instance_uuids, return_objects, return_alternates)\n```\n其中`SchedulerClient`又调用了`SchedulerQueryClient`，即调用了`nova.scheduler.client.query.SchedulerQueryClient#select_destinations`方法：\n\n```python\n    def select_destinations(self, context, spec_obj, instance_uuids,\n            return_objects=False, return_alternates=False):\n        return self.scheduler_rpcapi.select_destinations(context, spec_obj,\n                instance_uuids, return_objects, return_alternates)\n```\n在该方法中发起RPC调用，调用了`nova.scheduler.manager.SchedulerManager#select_destinations`方法：\n\n```python\n    @messaging.expected_exceptions(exception.NoValidHost)\n    def select_destinations(self, ctxt, request_spec=None,\n            filter_properties=None, spec_obj=_sentinel, instance_uuids=None,\n            return_objects=False, return_alternates=False):\n        LOG.debug(\"Starting to schedule for instances: %s\", instance_uuids)\n        ...\n        # 其中USES_ALLOCATION_CANDIDATES默认值为True，\n        # 即表示使用Nova Placement API来选取资源分配候选者\n        if self.driver.USES_ALLOCATION_CANDIDATES:\n            res = self.placement_client.get_allocation_candidates(ctxt,\n            if res is None:\n                alloc_reqs, provider_summaries, allocation_request_version = (\n                        None, None, None)\n            else:\n                (alloc_reqs, provider_summaries,\n                            allocation_request_version) = res\n            if not alloc_reqs:\n                LOG.debug(\"Got no allocation candidates from the Placement \"\n                          \"API. This may be a temporary occurrence as compute \"\n                          \"nodes start up and begin reporting inventory to \"\n                          \"the Placement service.\")\n                raise exception.NoValidHost(reason=\"\")\n            else:\n                # Build a dict of lists of allocation requests, keyed by\n                # provider UUID, so that when we attempt to claim resources for\n                # a host, we can grab an allocation request easily\n                alloc_reqs_by_rp_uuid = collections.defaultdict(list)\n                for ar in alloc_reqs:\n                    for rp_uuid in ar['allocations']:\n                        alloc_reqs_by_rp_uuid[rp_uuid].append(ar)\n\n        # Only return alternates if both return_objects and return_alternates\n        # are True.\n        return_alternates = return_alternates and return_objects\n        # self.driver在这里，我们配置使用的是FilterScheduler，\n        # 即又调用了nova.scheduler.filter_scheduler.FilterScheduler#select_destinations\n        # 这个我们后面会提到\n        selections = self.driver.select_destinations(ctxt, spec_obj,\n                instance_uuids, alloc_reqs_by_rp_uuid, provider_summaries,\n                allocation_request_version, return_alternates)\n        # If `return_objects` is False, we need to convert the selections to\n        # the older format, which is a list of host state dicts.\n        if not return_objects:\n            selection_dicts = [sel[0].to_dict() for sel in selections]\n            return jsonutils.to_primitive(selection_dicts)\n        return selections\n\n```\n我们先来说，这里调用的Placement API，发起一个GET请求，获取Allocation Candidates。\n\n> 注：没有找到这个API对应的OSC命令，所以我们使用curl命令进行模拟。<br/>\n> 另，Allocation candidates API requests are availiable starting from version `1.10`.\n\n```json\n# 获取token\n[root@f-packstack ~(keystone_admin)]# openstack token issue | grep ' id' | awk '{print $4}'\ngAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\n# 使用curl命令发起GET请求，请求参数是resources=DISK_GB:1,MEMORY_MB:512,VCPU:1\ncurl -g -i -X GET http://192.168.122.105:8778/placement/allocation_candidates?resources=DISK_GB:1,MEMORY_MB:512,VCPU:1 \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H \"X-Auth-Token: gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\" \\\n-H \"OpenStack-API-Version: placement 1.10\"\n\nHTTP/1.1 200 OK\nDate: Thu, 22 Feb 2018 08:55:27 GMT\nServer: Apache/2.4.6 (CentOS)\nOpenStack-API-Version: placement 1.10\nvary: OpenStack-API-Version,Accept-Encoding\nx-openstack-request-id: req-234db1eb-1386-4e89-99bd-c9269270c603\nContent-Length: 381\nContent-Type: application/json\n\n{\n    \"provider_summaries\": {\n        \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\": {\n            \"resources\": {\n                \"VCPU\": {\n                    \"used\": 2,\n                    \"capacity\": 64\n                },\n                \"MEMORY_MB\": {\n                    \"used\": 1024,\n                    \"capacity\": 11374\n                },\n                \"DISK_GB\": {\n                    \"used\": 2,\n                    \"capacity\": 49\n                }\n            }\n        }\n    },\n    \"allocation_requests\": [\n        {\n            \"allocations\": [\n                {\n                    \"resource_provider\": {\n                        \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"\n                    },\n                    \"resources\": {\n                        \"VCPU\": 1,\n                        \"MEMORY_MB\": 512,\n                        \"DISK_GB\": 1\n                    }\n                }\n            ]\n        }\n    ]\n}\n\n```\nPlacement经过一系列查询之后，返回了一些信息，其中`allocation_requests`就是我们的请求参数，即我们需要这么些资源，麻烦Placement给看看有合适的RP没？然后Placement帮我们找到了UUID为`4cae2ef8-30eb-4571-80c3-3289e86bd65c`的RP，还很贴心的在`provider_summaries`列出了这个RP当前使用的资源量以及存量。实际上这两个查询分别对应了下面的两个SQL语句：\n\n```sql\n-- 1.查询符合要求的Resource Provider\nSELECT rp.id\nFROM resource_providers AS rp\n    -- vcpu信息join\n    -- vcpu总存量信息\n    INNER JOIN inventories AS inv_vcpu\n        ON inv_vcpu.resource_provider_id = rp.id\n        AND inv_vcpu.resource_class_id = %(resource_class_id_1)s\n    -- vcpu已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n        sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_2)s\n        GROUP BY allocations.resource_provider_id\n    ) AS usage_vcpu\n        ON inv_vcpu.resource_provider_id = usage_vcpu.resource_provider_id\n    -- memory信息join\n    -- memory总存量信息\n    INNER JOIN inventories AS inv_memory_mb\n        ON inv_memory_mb.resource_provider_id = rp.id\n        AND inv_memory_mb.resource_class_id = %(resource_class_id_3)s\n    -- memory已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n            sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_4)s\n        GROUP BY allocations.resource_provider_id\n    ) AS usage_memory_mb\n        ON inv_memory_mb.resource_provider_id = usage_memory_mb.resource_provider_id\n    -- disk信息join\n    -- disk总存量信息\n    INNER JOIN inventories AS inv_disk_gb\n        ON inv_disk_gb.resource_provider_id = rp.id\n        AND inv_disk_gb.resource_class_id = %(resource_class_id_5)s\n    -- disk已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id\n        AS resource_provider_id, sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_6)s\n        GROUP BY allocations.resource_provider_id\n        ) AS usage_disk_gb\n            ON inv_disk_gb.resource_provider_id = usage_disk_gb.resource_provider_id\nWHERE\n-- vcpu满足上限/下限/步长条件\ncoalesce(usage_vcpu.used, %(coalesce_1)s) + %(coalesce_2)s <= (\ninv_vcpu.total - inv_vcpu.reserved) * inv_vcpu.allocation_ratio AND\ninv_vcpu.min_unit <= %(min_unit_1)s AND\ninv_vcpu.max_unit >= %(max_unit_1)s AND\n%(step_size_1)s % inv_vcpu.step_size = %(param_1)s AND\n-- memory满足上限/下限/步长条件\ncoalesce(usage_memory_mb.used, %(coalesce_3)s) + %(coalesce_4)s <= (\ninv_memory_mb.total - inv_memory_mb.reserved) * inv_memory_mb.allocation_ratio AND\ninv_memory_mb.min_unit <= %(min_unit_2)s AND\ninv_memory_mb.max_unit >= %(max_unit_2)s AND\n%(step_size_2)s % inv_memory_mb.step_size = %(param_2)s AND\n-- disk满足上限/下限/步长条件\ncoalesce(usage_disk_gb.used, %(coalesce_5)s) + %(coalesce_6)s <= (\ninv_disk_gb.total - inv_disk_gb.reserved) * inv_disk_gb.allocation_ratio AND\ninv_disk_gb.min_unit <= %(min_unit_3)s AND\ninv_disk_gb.max_unit >= %(max_unit_3)s AND\n%(step_size_3)s % inv_disk_gb.step_size = %(param_3)s\n\n-- 2.查询该Resource Provider的用量和存量\nSELECT rp.id AS resource_provider_id, rp.uuid AS resource_provider_uuid,\n    inv.resource_class_id, inv.total, inv.reserved, inv.allocation_ratio,\n    `usage`.used\nFROM resource_providers AS rp\n    -- inventory信息，每个rp的总量\n    INNER JOIN inventories AS inv\n        ON rp.id = inv.resource_provider_id\n    -- allocation信息\n    LEFT OUTER JOIN (\n        -- 每个rp和class的已使用量\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n        allocations.resource_class_id AS resource_class_id,\n        sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_provider_id IN (%(resource_provider_id_1)s) AND\n            allocations.resource_class_id IN (\n                %(resource_class_id_1)s,\n                %(resource_class_id_2)s,\n                %(resource_class_id_3)s\n            )\n        -- 按照rp_id和rp_class_id进行分组\n        GROUP BY allocations.resource_provider_id, allocations.resource_class_id\n    ) AS `usage`\n        ON `usage`.resource_provider_id = inv.resource_provider_id AND\n        `usage`.resource_class_id = inv.resource_class_id\n-- 查询指定id及class的resource\nWHERE rp.id IN (%(id_1)s) AND\n    inv.resource_class_id IN (\n        %(resource_class_id_4)s,\n        %(resource_class_id_5)s,\n        %(resource_class_id_6)s\n    )\n\n```\n#### Schedule by fitlers\n\n在nova-scheduler获取到allocation candidates之后，还需要使用`FilterScheduler`对选取的宿主（候选）节点根据启用的过滤器和权重进行计算和过滤。\n\n> 目前Nova中实现的调度器有以下几种：\n> \n> 1. FilterScheduler（过滤调度器）：默认载入的调度器，根据指定的过滤条件以及权重挑选最佳节点\n> 2. CachingScheduler：与FilterScheduler功能类似，只不过为了追求的更高的调度性能，将主机资源信息缓存到本地内存中，目前的master代码中标注为`[DEPRECATED]`\n> 3. ChanceScheduler（随机调度器）：随机选择，真·佛系。不过也在master代码中被标注了`[DEPRECATED]`\n> 4. FakeScheduler：用于测试，无实际功能\n\nBut how does filter scheduler work?\n\n我们依然从代码入手，来张序列图先看为敬：\n\n![FilterScheduler](http://7xrgsx.com1.z0.glb.clouddn.com/how%20filterscheduler%20works.jpg)\n\n在`FilterScheduler`的泳道中，可以看到，大体上分三步：\n\n1. 调度器缓存刷新、状态更新：通过`nova.scheduler.host_manager.HostState`来维护内存中一份主机状态，并返回可见的计算节点信息\n2. Filtering：实用配置文件指定各种的filters去过滤掉不符合条件的hosts。在配置文件中有两个配置`availale_filters`和`enabled_filters`，前者用于指定所有可用的filters，配置为`available_filters=nova.scheduler.filters.all_filters`；后者表示对于可用的filter，nova-scheduler会使用哪些，配置如`enabled_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,DiskFilter`等。O版中Nova支持的filters多达27个，实现均位于`nova/scheduler/filters`目录下，能够处理各类信息，比如主机可用资源、启动请求的参数（如镜像信息、请求重试次数等）、虚机亲和性和反亲和性（与其他虚机是否在同一宿主节点上）等\n3. Weighing：对所有符合条件的host计算权重并排序，从而选出最佳的一个宿主节点。所有的Weigher实现均位于`nova/scheduler/weights`目录下，比如DiskWeigher：\n\n```python\nclass DiskWeigher(weights.BaseHostWeigher):\n    # 可以设置maxval和minval属性指明权重的最大值和最小值\n    minval = 0\n    # 权重的系数，最终排序时需要将每种Weigher得到的权重分别乘上它对应的这个\n    # 系数，有多个Weigher时才有意义，这里的disk_weight_multiplier\n    # 配置文件默认值为 1.0 \n    def weight_multiplier(self):\n        return CONF.filter_scheduler.disk_weight_multiplier\n    # 计算权重值，按照注释描述，free_disk_mb更大者胜出\n    def _weigh_object(self, host_state, weight_properties):\n        \"\"\"Higher weights win.  We want spreading to be the default.\"\"\"\n        return host_state.free_disk_mb\n```\n\n\n#### Claim Resources\n\n前面我们提到，在获取到Allocation Candidates（即可用于资源分配的候选host）并经过过滤器过滤和权重计算之后，nova-scheduler开始尝试进行`Claim resources`，即在创建之前预先测试一下所指定的host的可用资源是否能够满足创建虚机的需求。\n我们来一起看一下`nova.scheduler.utils.claim_resources`的代码：\n\n```python\ndef claim_resources(ctx, client, spec_obj, instance_uuid, alloc_req,\n        allocation_request_version=None):\n    ...\n    return client.claim_resources(ctx, instance_uuid, alloc_req, project_id,\n            user_id, allocation_request_version=allocation_request_version)\n```\n在该方法中，最终调用的还是传入的client的`claim_resources()`方法，即`nova.scheduler.client.report.SchedulerReportClient#claim_resources`：\n\n```python\n    @safe_connect\n    @retries\n    def claim_resources(self, context, consumer_uuid, alloc_request,\n                        project_id, user_id, allocation_request_version=None):\n        \"\"\"Creates allocation records for the supplied instance UUID against\n        the supplied resource providers.\n        即对指定的实例创建该实例在指定RP上的分配记录\n        :param context: The security context\n        :param consumer_uuid: The instance's UUID.\n        :param alloc_request: The JSON body of the request to make to the\n                              placement's PUT /allocations API\n        :param project_id: The project_id associated with the allocations.\n        :param user_id: The user_id associated with the allocations.\n        :param allocation_request_version: The microversion used to request the\n                                           allocations.\n        :returns: True if the allocations were created, False otherwise.\n        \"\"\"\n        ar = copy.deepcopy(alloc_request)\n\n        # If the allocation_request_version less than 1.12, then convert the\n        # allocation array format to the dict format. This conversion can be\n        # remove in Rocky release.\n        if versionutils.convert_version_to_tuple(\n                allocation_request_version) < (1, 12):\n            ar = {\n                'allocations': {\n                    alloc['resource_provider']['uuid']: {\n                        'resources': alloc['resources']\n                    } for alloc in ar['allocations']\n                }\n            }\n            allocation_request_version = '1.12'\n\n        url = '/allocations/%s' % consumer_uuid\n\n        payload = ar\n\n        # We first need to determine if this is a move operation and if so\n        # create the \"doubled-up\" allocation that exists for the duration of\n        # the move operation against both the source and destination hosts\n        r = self.get(url, global_request_id=context.global_id)\n        if r.status_code == 200:\n            current_allocs = r.json()['allocations']\n            if current_allocs:\n                payload = _move_operation_alloc_request(current_allocs, ar)\n\n        payload['project_id'] = project_id\n        payload['user_id'] = user_id\n        r = self.put(url, payload, version=allocation_request_version,\n                     global_request_id=context.global_id)\n        if r.status_code != 204:\n            # NOTE(jaypipes): Yes, it sucks doing string comparison like this\n            # but we have no error codes, only error messages.\n            if 'concurrently updated' in r.text:\n                reason = ('another process changed the resource providers '\n                          'involved in our attempt to put allocations for '\n                          'consumer %s' % consumer_uuid)\n                raise Retry('claim_resources', reason)\n            else:\n                LOG.warning(\n                    'Unable to submit allocation for instance '\n                    '%(uuid)s (%(code)i %(text)s)',\n                    {'uuid': consumer_uuid,\n                     'code': r.status_code,\n                     'text': r.text})\n        return r.status_code == 204\n```\n在这里是发起了一个PUT请求，尝试为`consumer_id`先声明所需要的资源，并根据返回的HTTP status code来判断是否声明资源成功。一旦能成功声明所需要的资源，就等于找到将该虚机调度到哪一个宿主节点，可以继续后面实际资源的创建等一系列流程，Placement API的工作到这里就暂告一段落了。但是对于scheduler，还有去consumer host的资源，即更新host state等内存中的信息等等。\n\n\n### 目前社区Placement的发展\n\n通过订阅`openstack-dev`或者参加`nova`的weekly meeting，是可以非常及时的获取社区趋势和把握社区的开发进度。那么对Nova Schedule Team来讲，目前这两个月的进度，华为的[姜逸坤](http://yikun.github.io/)都给出了比较详尽的记录和整理：\n\n* [Nova Scheduler Team Meeting跟踪（一月）](https://github.com/Yikun/yikun.github.com/issues/66)\n* [Nova Scheduler Team Meeting跟踪（二月）](https://github.com/Yikun/yikun.github.com/issues/67)\n\n目前看起来，调度相关的team还在紧锣密鼓的继续完善Placement的功能，热火朝天向Rocky版本迈进。\n\n## 有哪些不足\n\n目前看起来不足主要集中在使用中的bug及功能的待完善。比如目前还在开发的Nested Resource Providers；为获取Allocation candidates增加limit，控制每次取到的资源候选分配者的数量等等；还有比如主机迁移失败导致两个RP中都有占用的情况等等。像把Placement单独抽离出来，这也是社区有意向要做的事情。\n\n## 参考\n\n[1].[Placement API](https://docs.openstack.org/nova/latest/user/placement.html)\n[2].[Placement API Reference](https://developer.openstack.org/api-ref/placement/)\n[3].[Yikun's blog](http://yikun.github.io/)\n","source":"_posts/nova-placement-api.md","raw":"---\ntitle: Nova Placement API与Nova调度全解析\ndate: 2018-02-23 16:47:50\ntags: [OpenStack, Nova]\n---\n<!-- more -->\n## 是什么\n\n由于历史遗留原因，Nova认为资源全部是由计算节点提供，所以在报告某些资源使用时，Nova仅仅通过查询数据库中不同计算节点的数据，简单的做累加计算得到使用量和可用资源情况，这一定不是严谨科学的做法，于是，在N版中，Nova引入了Placement API，这是一个单独的RESTful API和数据模型，用于管理和查询资源提供者的资源存量、使用情况、分配记录等等，以提供更好、更准确的资源跟踪、调度和分配的功能。\n\n## 有什么\n\n### 代码目录\n\n由于Nova Placement API是单独剥离出来的RESTful API，同时也有自己单独的Endpoint，并且与Nova API服务启动在不同的端口，单独提供服务，那么，在代码目录上来看，也是相对独立的，其代码实现均在`/nova/api/openstack/placement/`下，那么我看来看一下Nova Placement API的代码目录结构：\n\n```shell\nF:nova ZH.F$ tree  -C  api/openstack/placement\napi/openstack/placement\n├── __init__.py\n├── auth.py\n├── deploy.py\n├── handler.py\n├── handlers\n│   ├── __init__.py\n│   ├── aggregate.py\n│   ├── allocation.py\n│   ├── allocation_candidate.py\n│   ├── inventory.py\n│   ├── resource_class.py\n│   ├── resource_provider.py\n│   ├── root.py\n│   ├── trait.py\n│   └── usage.py\n├── lib.py\n├── microversion.py\n├── policy.py\n├── requestlog.py\n├── rest_api_version_history.rst\n├── schemas\n│   ├── __init__.py\n│   ├── aggregate.py\n│   ├── allocation.py\n│   ├── allocation_candidate.py\n│   ├── inventory.py\n│   ├── resource_class.py\n│   ├── trait.py\n│   └── usage.py\n├── util.py\n├── wsgi.py\n└── wsgi_wrapper.py\n```\n其中，在`api/openstack/placement/schemas`目录下，可以看到基本数据模型的schema，不过`resource privoder`的schema定义在了`api/openstack/placement/handlers/resource_provider.py`中。下面，对照schema，我们对其中的一些概念进行了解。\n\n### Nova Placement API中的一些概念\n\n#### Resource Provider\n\n即资源提供者，通过其schema可以看到结构比较简单，只包含UUID和RP（Resource Provider简写，下同）的一些基本信息，比如name：\n\n```python\nGET_RPS_SCHEMA_1_0 = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\n            \"type\": \"string\"\n        },\n        \"uuid\": {\n            \"type\": \"string\",\n            \"format\": \"uuid\"\n        }\n    },\n    \"additionalProperties\": False,\n}\n```\n资源提供者可能是一个计算节点，也可能是一个共享存储池或者一个IP分配池子，那么不同的RP，提供的资源多种多样，于是就引入了Resource Class，即资源类型的概念。\n\n#### Resource Class\n\n即资源类型，比如计算节点提供的资源可能是CPU、内存、PCI设备、本地临时磁盘等等。每种被消费的资源都会按照类别进行标注和跟踪。\n\n之所以引入这个概念，目的是解决Nova中hard-coded的资源类型扩展性问题，比如CPU资源，可能记录在Instance对象的*vcpus*字段中，那么之后再增加新的资源类型，都需要修改数据表，而修改数据表的过程都会停机维护，给系统带来许多downtime，这是不可接受的。\n\nPlacement API提供了一些标准资源类别，如：\n\n* VCPU\n* MEMORY_MB\n* DISK_GB\n* PCI_DEVICE\n* NUMA_SOCKET\n* NUMA_CORE\n* NUMA_THREAD\n* IPV4_ADDRESS\n* ...\n\n注：数据来自[BP:Introduce resource classes](https://specs.openstack.org/openstack/nova-specs/specs/mitaka/implemented/resource-classes.html)\n\n除了以上标准资源类别，Placement API还在O版中为RP增加了自定义Resource Class的能力，比如自动以的FPGA、裸机调度等等。\n\n#### Inventory\n\n即库存，存量。用于记录超配比、资源总量、存量、步长（step_size）、最小和最大单位等信息，可以看一下它的schema：\n\n```python\nBASE_INVENTORY_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"resource_provider_generation\": {\n            \"type\": \"integer\"\n        },\n        \"total\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1,\n        },\n        \"reserved\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 0,\n        },\n        \"min_unit\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"max_unit\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"step_size\": {\n            \"type\": \"integer\",\n            \"maximum\": db.MAX_INT,\n            \"minimum\": 1\n        },\n        \"allocation_ratio\": {\n            \"type\": \"number\",\n            \"maximum\": db.SQL_SP_FLOAT_MAX\n        },\n    },\n    \"required\": [\n        \"total\",\n        \"resource_provider_generation\"\n    ],\n    \"additionalProperties\": False\n}\n```\n其中的`resource_provider_generation `字段，是一个一致性视图的标志位，在获取RP列表时的`generation`功能是相同的，这就是CAS（Compare and swap），即乐观锁技术——当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。\n\n#### Usage\n\n即用量，使用情况。可以查看某个RP的使用情况，也可以查看项目下某用户的资源使用情况。\n\n#### Aggregate\n\n在Ocata版本，社区开始将nova-scheduler服务与Placement API进行集成，并在scheduler进行了一些修改，使用Placement API进行满足一些基本资源请求条件的计算节点过滤。添加了aggregates，来提供resource provider的分组机制。\n\n#### Allocation\n\n即已分配量，某一个RP对某一个资源消费者（即某个实例）所分配的资源。\n\n#### Allocation-candidate\n\n即分配的候选者（资源提供者），举个例子，用户说，我需要1个VCPU，512MB内存，1GB磁盘的资源，Placement你帮我找找看看，有没有合适的资源。然后Placement就要做各种处理，反馈给用户，哪些是可以分配的候选资源提供者。\n\n#### Trait\n\n字面意思，特征，特性。ResourceProvider和Allocation可以在定量的角度，控制和管理boot虚机请求，然而我们还需要从定性的角度来区分资源，最经典的例子是当我们创建虚机时，需要向不同的RP请求磁盘资源，用户可能请求80GB的磁盘，但也可能请求80GB的SSD。这就是Trait的意义。\n\n### 数据库及数据表\n\n目前我安装的Pike版本的Packstack环境中，能看到有一个`nova_placement`数据库，但是没有任何表（也许是社区希望能把placement相关的表放到这个数据库中？），Placement对应的数据库用的还是`nova_api`：\n\n```\nMariaDB [nova_placement]> use nova_api;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nMariaDB [nova_api]> show tables;\n+------------------------------+\n| Tables_in_nova_api           |\n+------------------------------+\n| aggregate_hosts              |\n| aggregate_metadata           |\n| aggregates                   |\n| allocations                  |\n| build_requests               |\n| cell_mappings                |\n| consumers                    |\n| flavor_extra_specs           |\n| flavor_projects              |\n| flavors                      |\n| host_mappings                |\n| instance_group_member        |\n| instance_group_policy        |\n| instance_groups              |\n| instance_mappings            |\n| inventories                  |\n| key_pairs                    |\n| migrate_version              |\n| placement_aggregates         |\n| project_user_quotas          |\n| projects                     |\n| quota_classes                |\n| quota_usages                 |\n| quotas                       |\n| request_specs                |\n| reservations                 |\n| resource_classes             |\n| resource_provider_aggregates |\n| resource_provider_traits     |\n| resource_providers           |\n| traits                       |\n| users                        |\n+------------------------------+\n```\n可以从表明上看到那些是Placement相关的表，这里就不展开了。\n\n### 初始化及加载方式\n\n我们前面提到Nova Placement API是单独的RESTful API，那么是如何进行初始化的呢？带着这个问题，我们先查看nova的`setup.cfg`，其中配置了wsgi_scripts如下：\n\n```\nwsgi_scripts =\n    nova-placement-api = nova.api.openstack.placement.wsgi:init_application\n    nova-api-wsgi = nova.api.openstack.compute.wsgi:init_application\n    nova-metadata-wsgi = nova.api.metadata.wsgi:init_application\n```\n其中可以看到nova-placement-api的初始化来自 `nova.api.openstack.placement.wsgi.init_application` ，代码如下：\n\n```python\ndef init_application():\n    # initialize the config system\n    conffile = _get_config_file()\n    config.parse_args([], default_config_files=[conffile])\n\n    # initialize the logging system\n    setup_logging(conf.CONF)\n\n    # dump conf if we're at debug\n    if conf.CONF.debug:\n        conf.CONF.log_opt_values(\n            logging.getLogger(__name__),\n            logging.DEBUG)\n\n    # build and return our WSGI app\n    return deploy.loadapp(conf.CONF)\n```\n其中在最后构造WSGI app并返回，即调用了deploy.loadapp(conf.CONF)：\n\n```python\ndef loadapp(config, project_name=NAME):\n    application = deploy(config, project_name)\n    return application\ndef deploy(conf, project_name):\n    \"\"\"Assemble the middleware pipeline leading to the placement app.\"\"\"\n    ...\n    application = handler.PlacementHandler()\n    ...\n    for middleware in (microversion_middleware,\n                       fault_wrap,\n                       request_log,\n                       context_middleware,\n                       auth_middleware,\n                       cors_middleware,\n                       req_id_middleware,\n                       ):\n        if middleware:\n            application = middleware(application)\n\n    return application\n```\n\n而这里的handler.PlacementHandler()就是我们的Placement的API入口：\n\n```python\nclass PlacementHandler(object):\n    \"\"\"Serve Placement API.\n    Dispatch to handlers defined in ROUTE_DECLARATIONS.\n    \"\"\"\n\n    def __init__(self, **local_config):\n        # NOTE(cdent): Local config currently unused.\n        self._map = make_map(ROUTE_DECLARATIONS)\n\n    def __call__(self, environ, start_response):\n        # All requests but '/' require admin.\n        if environ['PATH_INFO'] != '/':\n    ...\n```\n\n可以看到，PlacementHandler在`__init__`中根据路由定义构造了map，同时在`__call__`中对请求进行dispatch。这就是一个典型的WSGI应用：\n>WSGI application is a callable object (a function, method, class, or an instance with a `__call__` method) that accepts two positional arguments: WSGI environment variables and a callable with two required positional arguments which starts the response;\n\n找到了初始化，那么Placement API加载和启动是如何实现的？\n\n首先，nova-placement-api是单独的脚本，在httpd中启动，与keystone（在12年就完成了WSGI化，参见[>>传送门](http://adam.younglogic.com/2012/03/keystone-should-move-to-apache-httpd/)）类似，通过`systemctl status httpd `是可以看到的：\n\n```\n[root@f-packstack ~(keystone_admin)]# systemctl status httpd\n● httpd.service - The Apache HTTP Server\n   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)\n   Active: active (running) since Fri 2018-02-02 09:17:51 CST; 1 weeks 0 days ago\n     Docs: man:httpd(8)\n           man:apachectl(8)\n  Process: 4087 ExecReload=/usr/sbin/httpd $OPTIONS -k graceful (code=exited, status=0/SUCCESS)\n Main PID: 1309 (httpd)\n   Status: \"Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec\"\n   CGroup: /system.slice/httpd.service\n           ├─ 1309 /usr/sbin/httpd -DFOREGROUND\n           ├─ 4108 keystone-admin  -DFOREGROUND\n\n▽\n           ├─ 4109 keystone-admin  -DFOREGROUND\n           ├─ 4110 keystone-admin  -DFOREGROUND\n           ├─ 4111 keystone-admin  -DFOREGROUND\n\n▽\n           ├─ 4112 keystone-main   -DFOREGROUND\n           ├─ 4113 keystone-main   -DFOREGROUND\n           ├─ 4114 keystone-main   -DFOREGROUND\n           ├─ 4115 keystone-main   -DFOREGROUND\n           ├─ 4116 placement_wsgi  -DFOREGROUND\n           ├─ 4117 placement_wsgi  -DFOREGROUND\n           ├─ 4118 placement_wsgi  -DFOREGROUND\n           ├─ 4119 placement_wsgi  -DFOREGROUND\n           ├─ 4121 /usr/sbin/httpd -DFOREGROUND\n           ├─ 4122 /usr/sbin/httpd -DFOREGROUND\n…\n```\n知道是在httpd启动的，我们去查看配置文件目录：\n\n```shell\n[root@f-packstack ~(keystone_admin)]# ll /etc/httpd/conf.d/\ntotal 36\n-rw-r-----. 1 root root  136 Jan 12 17:46 00-nova-placement-api.conf\n-rw-r--r--. 1 root root  943 Jan 12 17:48 10-keystone_wsgi_admin.conf\n-rw-r--r--. 1 root root  938 Jan 12 17:48 10-keystone_wsgi_main.conf\n-rw-r--r--. 1 root root  941 Jan 12 17:49 10-placement_wsgi.conf\n-rw-r--r--. 1 root root  697 Jan 12 17:48 15-default.conf\n-rw-r--r--. 1 root root 2926 Oct 20 04:39 autoindex.conf\n-rw-r--r--. 1 root root  366 Oct 20 04:39 README\n-rw-r--r--. 1 root root 1252 Oct 20 00:44 userdir.conf\n-rw-r--r--. 1 root root  824 Oct 20 00:44 welcome.conf\n```\n其中，10-placement_wsgi.conf 中定义了WSGIScriptAllias：\n\n```\n...\n  WSGIProcessGroup placement-api\n  WSGIScriptAlias /placement \"/var/www/cgi-bin/nova/nova-placement-api”\n...\n```\n也就是说，url为`/placement/xxx`的请求会使得httpd服务运行定义在`/var/www/cgi-bin/nova/nova-placement-api`中的WSGI应用，在这个文件中，我们会看到：\n\n```python\nfrom nova.api.openstack.placement.wsgi import init_application\n\nif __name__ == \"__main__”:\n    import argparse\n    import socket\n    import sys\n    import wsgiref.simple_server as wss\n    …\n    server = wss.make_server(args.host, args.port, init_application())\n...\n```\n也就对应了前面提到的PlacementHandler中的`nova.api.openstack.placement.wsgi.init_application`，至此，我们就了解了Nova Placement API的初始化和加载方式。\n\n### API路由定义\n\n上一小节提到了PlacementHandler初始化时，根据路由定义构造了map映射，我们就来看下文件`api/openstack/placement/handler.py`中的API`ROUTE_DECLARATIONS`:\n\n```python\n# URLs and Handlers\n# NOTE(cdent): When adding URLs here, do not use regex patterns in\n# the path parameters (e.g. {uuid:[0-9a-zA-Z-]+}) as that will lead\n# to 404s that are controlled outside of the individual resources\n# and thus do not include specific information on the why of the 404.\nROUTE_DECLARATIONS = {\n    '/': {\n        'GET': root.home,\n    },\n    # NOTE(cdent): This allows '/placement/' and '/placement' to\n    # both work as the root of the service, which we probably want\n    # for those situations where the service is mounted under a\n    # prefix (as it is in devstack). While weird, an empty string is\n    # a legit key in a dictionary and matches as desired in Routes.\n    '': {\n        'GET': root.home,\n    },\n    '/resource_classes': {\n        'GET': resource_class.list_resource_classes,\n        'POST': resource_class.create_resource_class\n    },\n    '/resource_classes/{name}': {\n        'GET': resource_class.get_resource_class,\n        'PUT': resource_class.update_resource_class,\n        'DELETE': resource_class.delete_resource_class,\n    },\n    '/resource_providers': {\n        'GET': resource_provider.list_resource_providers,\n        'POST': resource_provider.create_resource_provider\n    },\n    '/resource_providers/{uuid}': {\n        'GET': resource_provider.get_resource_provider,\n        'DELETE': resource_provider.delete_resource_provider,\n        'PUT': resource_provider.update_resource_provider\n    },\n    '/resource_providers/{uuid}/inventories': {\n        'GET': inventory.get_inventories,\n        'POST': inventory.create_inventory,\n        'PUT': inventory.set_inventories,\n        'DELETE': inventory.delete_inventories\n    },\n    '/resource_providers/{uuid}/inventories/{resource_class}': {\n        'GET': inventory.get_inventory,\n        'PUT': inventory.update_inventory,\n        'DELETE': inventory.delete_inventory\n    },\n    '/resource_providers/{uuid}/usages': {\n        'GET': usage.list_usages\n    },\n    '/resource_providers/{uuid}/aggregates': {\n        'GET': aggregate.get_aggregates,\n        'PUT': aggregate.set_aggregates\n    },\n    '/resource_providers/{uuid}/allocations': {\n        'GET': allocation.list_for_resource_provider,\n    },\n    '/allocations': {\n        'POST': allocation.set_allocations,\n    },\n    '/allocations/{consumer_uuid}': {\n        'GET': allocation.list_for_consumer,\n        'PUT': allocation.set_allocations_for_consumer,\n        'DELETE': allocation.delete_allocations,\n    },\n    '/allocation_candidates': {\n        'GET': allocation_candidate.list_allocation_candidates,\n    },\n    '/traits': {\n        'GET': trait.list_traits,\n    },\n    '/traits/{name}': {\n        'GET': trait.get_trait,\n        'PUT': trait.put_trait,\n        'DELETE': trait.delete_trait,\n    },\n    '/resource_providers/{uuid}/traits': {\n        'GET': trait.list_traits_for_resource_provider,\n        'PUT': trait.update_traits_for_resource_provider,\n        'DELETE': trait.delete_traits_for_resource_provider\n    },\n    '/usages': {\n        'GET': usage.get_total_usages,\n    },\n}\n```\n\n## 怎么用\n\n### 如何部署\n\n在官方文档中提到，placement api服务必须在升级到14.0.0，即N版后，升级到15.0.0，即O版之前进行部署。nova-compute服务中的resource tracker需要获取placement的资源提供者存量和分配信息（这部分信息将在O版中由nova-scheduler使用）。\n\n1. 部署API服务 - Placement API目前还是在nova中进行开发，但是设计上是相对独立的，以便将来分离出来成为单独的项目。作为一个单独的WSGI应用，可使用Apahce2或者Nginx部署API服务。\n2. 同步数据库 - 升级N版时，需要手动执行` nova-manage api_db sync`命令进行数据库同步，这样Placement相关的数据表就会被创建出来\n3. 在keystone中创建具有admin角色的placement service user，同时更新服务目录，配置单独的endpoint.\n4. 配置nova.conf中[placement]部分，并重启nova-compute服务。不过对于我们P版，经过了O版的一系列功能补齐，尤其是在O版中，如果在`nova.conf`中不配置`[placement]`部分的内容，就无法启动`nova-compute`服务。\n\n>The nova-compute service will fail to start in Ocata unless the [placement] section of nova.conf on the compute is configured.\n\n更多部署相关的可参见官方文档，[>>传送门](https://docs.openstack.org/nova/latest/user/placement.html#deployment)。\n\n### OSC Placement Plugin\n\n从前面的API路由定义，我们可以看到，目前支持了这么些功能，那么我们可以简单的用一下，第一个想到的是cURL命令，我们可以使用该命令模拟发起请求，调用Placement API，比如查看resource providers list，首先我们获取token：\n\n```json\n# 首先得到auth token\ncurl -d '{\"auth\": {\"tenantName\": \"admin\", \"passwordCredentials\": {\"username\": \"admin\", \"password\": \"1234qwer\"}}}' \\\n-H \"Content-type: application/json\" \\\nhttp://localhost:5000/v2.0/tokens\n\n...\n{\n    \"issued_at\": \"2018-02-07T07:40:07.000000Z\",\n    \"expires\": \"2018-02-07T08:40:07.000000Z\",\n    \"id\": \"gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itnL6Q-TSWhOn7uZpdQsYqqJDmwgtzCm-hcpg17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE\",\n    \"tenant\": {\n        \"description\": \"admin tenant\",\n        \"enabled\": true,\n        \"id\": \"6387fc88b3064149a12eb5b58669e0b2\",\n        \"name\": \"admin\"\n    }\n}\n\n# token的获取方式，还可以用OSC命令：\nopenstack token issue | grep ' id' | awk '{print $4}'\n...\n\n\n#得到token之后，构造请求，查看resource providers list：\ncurl -X GET /\n-H 'x-auth-token:gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itn17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE’ /\nhttp://192.168.122.105:8778/placement/resource_providers\n\n#得到resources providers list\n{\n    \"resource_providers\": [\n        {\n            \"generation\": 30,\n            \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\",\n            \"links\": [\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\",\n                    \"rel\": \"self\"\n                },\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\",\n                    \"rel\": \"inventories\"\n                },\n                {\n                    \"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\",\n                    \"rel\": \"usages\"\n                }\n            ],\n            \"name\": \"f-packstack\"\n        }\n    ]\n}\n```\n其中的`generation`字段，是一个一致性视图的标志位，跟获取RP的inventories中的`resource_provider_generation`功能是相同的，其实算作是乐观锁技术，即CAS，Compare and swap，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。\n\n下面来一个获取aggregate和inventories的示例，注意，aggregate的API是在1.1版本中实现的，所以要在请求头指定`OpenStack-API-Version: placement 1.1`：\n\n```json\ncurl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/aggregates \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H \"X-Auth-Token: gAAAAABaf5nafUZyFTl_pztozfB65wkP0c26HQqrxRgAiJGsxY8g743LxFOZEI3bF_l37xh0UajbF5nQ1kLYGAonOGphV4AivXgYMUOJ84uGrHjpC60NlmNzzQ3lJGVJb-pNxQw74WsMOc9I0D2B5Mzmf2OgDeictae5f0UFgTR9DFb_vaWCWQ4\" \\\n-H \"OpenStack-API-Version: placement 1.1\"\nHTTP/1.1 200 OK\nDate: Fri, 15 Sep 2017 09:35:21 GMT\nServer: Apache/2.4.18 (Ubuntu)\nContent-Length: 18\nContent-Type: application/json\nOpenStack-API-Version: placement 1.1\nvary: OpenStack-API-Version\nx-openstack-request-id: req-ab28194f-8389-40a1-9a2b-a94dbc792573\nConnection: close\n\n{\"aggregates\": []}\n\n\ncurl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H 'x-auth-token:gAAAAABae6lX26bp4PEVHCac0cjFnNl18W8DjeQKXDYvuKP4drRJ8t6DC-9uzcCm4E9Xf7NjqSqkRX6WGsE3qHmpAt7GmIu1SrLCtyEOVM2IQP5XLNrwMekGGrzQ_ADOaSTc9XpPpCYyYwzT-zCAvWG-T9T6Ip4l3zHWLwNBBPrm35gBZVZeslQ' \\\n\n{\n    \"resource_provider_generation\": 30,\n    \"inventories\": {\n        \"VCPU\": {\n            \"allocation_ratio\": 16,\n            \"total\": 4,\n            \"reserved\": 0,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 128\n        },\n        \"MEMORY_MB\": {\n            \"allocation_ratio\": 1.5,\n            \"total\": 8095,\n            \"reserved\": 512,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 8095\n        },\n        \"DISK_GB\": {\n            \"allocation_ratio\": 1,\n            \"total\": 49,\n            \"reserved\": 0,\n            \"step_size\": 1,\n            \"min_unit\": 1,\n            \"max_unit\": 49\n        }\n    }\n}\n```\n\n贴心的社区妥妥的想到了如何可以方便用户操作Placement API，所以开发了一个OpenStackClient Plugin，即[osc-placement](https://github.com/openstack/osc-placement)，需要我们手动安装使用：\n\n```\n$ pip install osc-placement\n```\n有了OSC placement commands，我们不再需要使用curl命令模拟HTTP请求，并且可以非常轻松的进行操作：\n\n```shell\n[root@f-packstack ~(keystone_admin)]# openstack --debug resource provider list\n...\nhttp://192.168.122.105:8778 \"GET /placement/resource_providers HTTP/1.1\" 200 185\nRESP: [200] Date: Thu, 08 Feb 2018 05:59:56 GMT Server: Apache/2.4.6 (CentOS) OpenStack-API-Version: placement 1.0 vary: OpenStack-API-Version,Accept-Encoding x-openstack-request-id: req-c6077c19-ca05-4cab-95fa-6129ff989400 Content-Encoding: gzip Content-Length: 185 Keep-Alive: timeout=15, max=100 Connection: Keep-Alive Content-Type: application/json\nRESP BODY: {\"resource_providers\": [{\"generation\": 30, \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"links\": [{\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"rel\": \"self\"}, {\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\", \"rel\": \"inventories\"}, {\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\", \"rel\": \"usages\"}], \"name\": \"f-packstack\"}]}\n\nGET call to placement for http://192.168.122.105:8778/placement/resource_providers used request id req-c6077c19-ca05-4cab-95fa-6129ff989400\n+--------------------------------------+-------------+------------+\n| uuid                                 | name        | generation |\n+--------------------------------------+-------------+------------+\n| 4cae2ef8-30eb-4571-80c3-3289e86bd65c | f-packstack |         30 |\n+--------------------------------------+-------------+------------+\nclean_up ListResourceProvider:\nEND return value: 0\n```\n当然还有很多其他的命令，有兴趣的可以尝试玩一下。\n\n### 划重点：Nova调度与Placement API的结合\n\n首先来一张图，来认识一下在P版中，创建一台虚机过程中各个服务之间的调用/调度关系：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/boot-instance-pike.png)\n可以看到，在nova-scheduler与Placement API的交互过程中，有两部分：\n1. Get allocation candidates\n2. Claim Resources\n下面，我们结合代码详细的讲述一下调度过程。\n\n#### Get allocation candidates\n\n目前在调度时，nova-conductor在`nova.conductor.manager.ComputeTaskManager#_schedule_instances`中调用了方法`nova.scheduler.client.SchedulerClient#select_destinations`：\n\n```python\n    @utils.retry_select_destinations\n    def select_destinations(self, context, spec_obj, instance_uuids,\n            return_objects=False, return_alternates=False):\n        return self.queryclient.select_destinations(context, spec_obj,\n                instance_uuids, return_objects, return_alternates)\n```\n其中`SchedulerClient`又调用了`SchedulerQueryClient`，即调用了`nova.scheduler.client.query.SchedulerQueryClient#select_destinations`方法：\n\n```python\n    def select_destinations(self, context, spec_obj, instance_uuids,\n            return_objects=False, return_alternates=False):\n        return self.scheduler_rpcapi.select_destinations(context, spec_obj,\n                instance_uuids, return_objects, return_alternates)\n```\n在该方法中发起RPC调用，调用了`nova.scheduler.manager.SchedulerManager#select_destinations`方法：\n\n```python\n    @messaging.expected_exceptions(exception.NoValidHost)\n    def select_destinations(self, ctxt, request_spec=None,\n            filter_properties=None, spec_obj=_sentinel, instance_uuids=None,\n            return_objects=False, return_alternates=False):\n        LOG.debug(\"Starting to schedule for instances: %s\", instance_uuids)\n        ...\n        # 其中USES_ALLOCATION_CANDIDATES默认值为True，\n        # 即表示使用Nova Placement API来选取资源分配候选者\n        if self.driver.USES_ALLOCATION_CANDIDATES:\n            res = self.placement_client.get_allocation_candidates(ctxt,\n            if res is None:\n                alloc_reqs, provider_summaries, allocation_request_version = (\n                        None, None, None)\n            else:\n                (alloc_reqs, provider_summaries,\n                            allocation_request_version) = res\n            if not alloc_reqs:\n                LOG.debug(\"Got no allocation candidates from the Placement \"\n                          \"API. This may be a temporary occurrence as compute \"\n                          \"nodes start up and begin reporting inventory to \"\n                          \"the Placement service.\")\n                raise exception.NoValidHost(reason=\"\")\n            else:\n                # Build a dict of lists of allocation requests, keyed by\n                # provider UUID, so that when we attempt to claim resources for\n                # a host, we can grab an allocation request easily\n                alloc_reqs_by_rp_uuid = collections.defaultdict(list)\n                for ar in alloc_reqs:\n                    for rp_uuid in ar['allocations']:\n                        alloc_reqs_by_rp_uuid[rp_uuid].append(ar)\n\n        # Only return alternates if both return_objects and return_alternates\n        # are True.\n        return_alternates = return_alternates and return_objects\n        # self.driver在这里，我们配置使用的是FilterScheduler，\n        # 即又调用了nova.scheduler.filter_scheduler.FilterScheduler#select_destinations\n        # 这个我们后面会提到\n        selections = self.driver.select_destinations(ctxt, spec_obj,\n                instance_uuids, alloc_reqs_by_rp_uuid, provider_summaries,\n                allocation_request_version, return_alternates)\n        # If `return_objects` is False, we need to convert the selections to\n        # the older format, which is a list of host state dicts.\n        if not return_objects:\n            selection_dicts = [sel[0].to_dict() for sel in selections]\n            return jsonutils.to_primitive(selection_dicts)\n        return selections\n\n```\n我们先来说，这里调用的Placement API，发起一个GET请求，获取Allocation Candidates。\n\n> 注：没有找到这个API对应的OSC命令，所以我们使用curl命令进行模拟。<br/>\n> 另，Allocation candidates API requests are availiable starting from version `1.10`.\n\n```json\n# 获取token\n[root@f-packstack ~(keystone_admin)]# openstack token issue | grep ' id' | awk '{print $4}'\ngAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\n# 使用curl命令发起GET请求，请求参数是resources=DISK_GB:1,MEMORY_MB:512,VCPU:1\ncurl -g -i -X GET http://192.168.122.105:8778/placement/allocation_candidates?resources=DISK_GB:1,MEMORY_MB:512,VCPU:1 \\\n-H \"User-Agent: python-novaclient\" \\\n-H \"Accept: application/json\" \\\n-H \"X-Auth-Token: gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\" \\\n-H \"OpenStack-API-Version: placement 1.10\"\n\nHTTP/1.1 200 OK\nDate: Thu, 22 Feb 2018 08:55:27 GMT\nServer: Apache/2.4.6 (CentOS)\nOpenStack-API-Version: placement 1.10\nvary: OpenStack-API-Version,Accept-Encoding\nx-openstack-request-id: req-234db1eb-1386-4e89-99bd-c9269270c603\nContent-Length: 381\nContent-Type: application/json\n\n{\n    \"provider_summaries\": {\n        \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\": {\n            \"resources\": {\n                \"VCPU\": {\n                    \"used\": 2,\n                    \"capacity\": 64\n                },\n                \"MEMORY_MB\": {\n                    \"used\": 1024,\n                    \"capacity\": 11374\n                },\n                \"DISK_GB\": {\n                    \"used\": 2,\n                    \"capacity\": 49\n                }\n            }\n        }\n    },\n    \"allocation_requests\": [\n        {\n            \"allocations\": [\n                {\n                    \"resource_provider\": {\n                        \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"\n                    },\n                    \"resources\": {\n                        \"VCPU\": 1,\n                        \"MEMORY_MB\": 512,\n                        \"DISK_GB\": 1\n                    }\n                }\n            ]\n        }\n    ]\n}\n\n```\nPlacement经过一系列查询之后，返回了一些信息，其中`allocation_requests`就是我们的请求参数，即我们需要这么些资源，麻烦Placement给看看有合适的RP没？然后Placement帮我们找到了UUID为`4cae2ef8-30eb-4571-80c3-3289e86bd65c`的RP，还很贴心的在`provider_summaries`列出了这个RP当前使用的资源量以及存量。实际上这两个查询分别对应了下面的两个SQL语句：\n\n```sql\n-- 1.查询符合要求的Resource Provider\nSELECT rp.id\nFROM resource_providers AS rp\n    -- vcpu信息join\n    -- vcpu总存量信息\n    INNER JOIN inventories AS inv_vcpu\n        ON inv_vcpu.resource_provider_id = rp.id\n        AND inv_vcpu.resource_class_id = %(resource_class_id_1)s\n    -- vcpu已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n        sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_2)s\n        GROUP BY allocations.resource_provider_id\n    ) AS usage_vcpu\n        ON inv_vcpu.resource_provider_id = usage_vcpu.resource_provider_id\n    -- memory信息join\n    -- memory总存量信息\n    INNER JOIN inventories AS inv_memory_mb\n        ON inv_memory_mb.resource_provider_id = rp.id\n        AND inv_memory_mb.resource_class_id = %(resource_class_id_3)s\n    -- memory已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n            sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_4)s\n        GROUP BY allocations.resource_provider_id\n    ) AS usage_memory_mb\n        ON inv_memory_mb.resource_provider_id = usage_memory_mb.resource_provider_id\n    -- disk信息join\n    -- disk总存量信息\n    INNER JOIN inventories AS inv_disk_gb\n        ON inv_disk_gb.resource_provider_id = rp.id\n        AND inv_disk_gb.resource_class_id = %(resource_class_id_5)s\n    -- disk已使用量信息\n    LEFT OUTER JOIN (\n        SELECT allocations.resource_provider_id\n        AS resource_provider_id, sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_class_id = %(resource_class_id_6)s\n        GROUP BY allocations.resource_provider_id\n        ) AS usage_disk_gb\n            ON inv_disk_gb.resource_provider_id = usage_disk_gb.resource_provider_id\nWHERE\n-- vcpu满足上限/下限/步长条件\ncoalesce(usage_vcpu.used, %(coalesce_1)s) + %(coalesce_2)s <= (\ninv_vcpu.total - inv_vcpu.reserved) * inv_vcpu.allocation_ratio AND\ninv_vcpu.min_unit <= %(min_unit_1)s AND\ninv_vcpu.max_unit >= %(max_unit_1)s AND\n%(step_size_1)s % inv_vcpu.step_size = %(param_1)s AND\n-- memory满足上限/下限/步长条件\ncoalesce(usage_memory_mb.used, %(coalesce_3)s) + %(coalesce_4)s <= (\ninv_memory_mb.total - inv_memory_mb.reserved) * inv_memory_mb.allocation_ratio AND\ninv_memory_mb.min_unit <= %(min_unit_2)s AND\ninv_memory_mb.max_unit >= %(max_unit_2)s AND\n%(step_size_2)s % inv_memory_mb.step_size = %(param_2)s AND\n-- disk满足上限/下限/步长条件\ncoalesce(usage_disk_gb.used, %(coalesce_5)s) + %(coalesce_6)s <= (\ninv_disk_gb.total - inv_disk_gb.reserved) * inv_disk_gb.allocation_ratio AND\ninv_disk_gb.min_unit <= %(min_unit_3)s AND\ninv_disk_gb.max_unit >= %(max_unit_3)s AND\n%(step_size_3)s % inv_disk_gb.step_size = %(param_3)s\n\n-- 2.查询该Resource Provider的用量和存量\nSELECT rp.id AS resource_provider_id, rp.uuid AS resource_provider_uuid,\n    inv.resource_class_id, inv.total, inv.reserved, inv.allocation_ratio,\n    `usage`.used\nFROM resource_providers AS rp\n    -- inventory信息，每个rp的总量\n    INNER JOIN inventories AS inv\n        ON rp.id = inv.resource_provider_id\n    -- allocation信息\n    LEFT OUTER JOIN (\n        -- 每个rp和class的已使用量\n        SELECT allocations.resource_provider_id AS resource_provider_id,\n        allocations.resource_class_id AS resource_class_id,\n        sum(allocations.used) AS used\n        FROM allocations\n        WHERE allocations.resource_provider_id IN (%(resource_provider_id_1)s) AND\n            allocations.resource_class_id IN (\n                %(resource_class_id_1)s,\n                %(resource_class_id_2)s,\n                %(resource_class_id_3)s\n            )\n        -- 按照rp_id和rp_class_id进行分组\n        GROUP BY allocations.resource_provider_id, allocations.resource_class_id\n    ) AS `usage`\n        ON `usage`.resource_provider_id = inv.resource_provider_id AND\n        `usage`.resource_class_id = inv.resource_class_id\n-- 查询指定id及class的resource\nWHERE rp.id IN (%(id_1)s) AND\n    inv.resource_class_id IN (\n        %(resource_class_id_4)s,\n        %(resource_class_id_5)s,\n        %(resource_class_id_6)s\n    )\n\n```\n#### Schedule by fitlers\n\n在nova-scheduler获取到allocation candidates之后，还需要使用`FilterScheduler`对选取的宿主（候选）节点根据启用的过滤器和权重进行计算和过滤。\n\n> 目前Nova中实现的调度器有以下几种：\n> \n> 1. FilterScheduler（过滤调度器）：默认载入的调度器，根据指定的过滤条件以及权重挑选最佳节点\n> 2. CachingScheduler：与FilterScheduler功能类似，只不过为了追求的更高的调度性能，将主机资源信息缓存到本地内存中，目前的master代码中标注为`[DEPRECATED]`\n> 3. ChanceScheduler（随机调度器）：随机选择，真·佛系。不过也在master代码中被标注了`[DEPRECATED]`\n> 4. FakeScheduler：用于测试，无实际功能\n\nBut how does filter scheduler work?\n\n我们依然从代码入手，来张序列图先看为敬：\n\n![FilterScheduler](http://7xrgsx.com1.z0.glb.clouddn.com/how%20filterscheduler%20works.jpg)\n\n在`FilterScheduler`的泳道中，可以看到，大体上分三步：\n\n1. 调度器缓存刷新、状态更新：通过`nova.scheduler.host_manager.HostState`来维护内存中一份主机状态，并返回可见的计算节点信息\n2. Filtering：实用配置文件指定各种的filters去过滤掉不符合条件的hosts。在配置文件中有两个配置`availale_filters`和`enabled_filters`，前者用于指定所有可用的filters，配置为`available_filters=nova.scheduler.filters.all_filters`；后者表示对于可用的filter，nova-scheduler会使用哪些，配置如`enabled_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,DiskFilter`等。O版中Nova支持的filters多达27个，实现均位于`nova/scheduler/filters`目录下，能够处理各类信息，比如主机可用资源、启动请求的参数（如镜像信息、请求重试次数等）、虚机亲和性和反亲和性（与其他虚机是否在同一宿主节点上）等\n3. Weighing：对所有符合条件的host计算权重并排序，从而选出最佳的一个宿主节点。所有的Weigher实现均位于`nova/scheduler/weights`目录下，比如DiskWeigher：\n\n```python\nclass DiskWeigher(weights.BaseHostWeigher):\n    # 可以设置maxval和minval属性指明权重的最大值和最小值\n    minval = 0\n    # 权重的系数，最终排序时需要将每种Weigher得到的权重分别乘上它对应的这个\n    # 系数，有多个Weigher时才有意义，这里的disk_weight_multiplier\n    # 配置文件默认值为 1.0 \n    def weight_multiplier(self):\n        return CONF.filter_scheduler.disk_weight_multiplier\n    # 计算权重值，按照注释描述，free_disk_mb更大者胜出\n    def _weigh_object(self, host_state, weight_properties):\n        \"\"\"Higher weights win.  We want spreading to be the default.\"\"\"\n        return host_state.free_disk_mb\n```\n\n\n#### Claim Resources\n\n前面我们提到，在获取到Allocation Candidates（即可用于资源分配的候选host）并经过过滤器过滤和权重计算之后，nova-scheduler开始尝试进行`Claim resources`，即在创建之前预先测试一下所指定的host的可用资源是否能够满足创建虚机的需求。\n我们来一起看一下`nova.scheduler.utils.claim_resources`的代码：\n\n```python\ndef claim_resources(ctx, client, spec_obj, instance_uuid, alloc_req,\n        allocation_request_version=None):\n    ...\n    return client.claim_resources(ctx, instance_uuid, alloc_req, project_id,\n            user_id, allocation_request_version=allocation_request_version)\n```\n在该方法中，最终调用的还是传入的client的`claim_resources()`方法，即`nova.scheduler.client.report.SchedulerReportClient#claim_resources`：\n\n```python\n    @safe_connect\n    @retries\n    def claim_resources(self, context, consumer_uuid, alloc_request,\n                        project_id, user_id, allocation_request_version=None):\n        \"\"\"Creates allocation records for the supplied instance UUID against\n        the supplied resource providers.\n        即对指定的实例创建该实例在指定RP上的分配记录\n        :param context: The security context\n        :param consumer_uuid: The instance's UUID.\n        :param alloc_request: The JSON body of the request to make to the\n                              placement's PUT /allocations API\n        :param project_id: The project_id associated with the allocations.\n        :param user_id: The user_id associated with the allocations.\n        :param allocation_request_version: The microversion used to request the\n                                           allocations.\n        :returns: True if the allocations were created, False otherwise.\n        \"\"\"\n        ar = copy.deepcopy(alloc_request)\n\n        # If the allocation_request_version less than 1.12, then convert the\n        # allocation array format to the dict format. This conversion can be\n        # remove in Rocky release.\n        if versionutils.convert_version_to_tuple(\n                allocation_request_version) < (1, 12):\n            ar = {\n                'allocations': {\n                    alloc['resource_provider']['uuid']: {\n                        'resources': alloc['resources']\n                    } for alloc in ar['allocations']\n                }\n            }\n            allocation_request_version = '1.12'\n\n        url = '/allocations/%s' % consumer_uuid\n\n        payload = ar\n\n        # We first need to determine if this is a move operation and if so\n        # create the \"doubled-up\" allocation that exists for the duration of\n        # the move operation against both the source and destination hosts\n        r = self.get(url, global_request_id=context.global_id)\n        if r.status_code == 200:\n            current_allocs = r.json()['allocations']\n            if current_allocs:\n                payload = _move_operation_alloc_request(current_allocs, ar)\n\n        payload['project_id'] = project_id\n        payload['user_id'] = user_id\n        r = self.put(url, payload, version=allocation_request_version,\n                     global_request_id=context.global_id)\n        if r.status_code != 204:\n            # NOTE(jaypipes): Yes, it sucks doing string comparison like this\n            # but we have no error codes, only error messages.\n            if 'concurrently updated' in r.text:\n                reason = ('another process changed the resource providers '\n                          'involved in our attempt to put allocations for '\n                          'consumer %s' % consumer_uuid)\n                raise Retry('claim_resources', reason)\n            else:\n                LOG.warning(\n                    'Unable to submit allocation for instance '\n                    '%(uuid)s (%(code)i %(text)s)',\n                    {'uuid': consumer_uuid,\n                     'code': r.status_code,\n                     'text': r.text})\n        return r.status_code == 204\n```\n在这里是发起了一个PUT请求，尝试为`consumer_id`先声明所需要的资源，并根据返回的HTTP status code来判断是否声明资源成功。一旦能成功声明所需要的资源，就等于找到将该虚机调度到哪一个宿主节点，可以继续后面实际资源的创建等一系列流程，Placement API的工作到这里就暂告一段落了。但是对于scheduler，还有去consumer host的资源，即更新host state等内存中的信息等等。\n\n\n### 目前社区Placement的发展\n\n通过订阅`openstack-dev`或者参加`nova`的weekly meeting，是可以非常及时的获取社区趋势和把握社区的开发进度。那么对Nova Schedule Team来讲，目前这两个月的进度，华为的[姜逸坤](http://yikun.github.io/)都给出了比较详尽的记录和整理：\n\n* [Nova Scheduler Team Meeting跟踪（一月）](https://github.com/Yikun/yikun.github.com/issues/66)\n* [Nova Scheduler Team Meeting跟踪（二月）](https://github.com/Yikun/yikun.github.com/issues/67)\n\n目前看起来，调度相关的team还在紧锣密鼓的继续完善Placement的功能，热火朝天向Rocky版本迈进。\n\n## 有哪些不足\n\n目前看起来不足主要集中在使用中的bug及功能的待完善。比如目前还在开发的Nested Resource Providers；为获取Allocation candidates增加limit，控制每次取到的资源候选分配者的数量等等；还有比如主机迁移失败导致两个RP中都有占用的情况等等。像把Placement单独抽离出来，这也是社区有意向要做的事情。\n\n## 参考\n\n[1].[Placement API](https://docs.openstack.org/nova/latest/user/placement.html)\n[2].[Placement API Reference](https://developer.openstack.org/api-ref/placement/)\n[3].[Yikun's blog](http://yikun.github.io/)\n","slug":"nova-placement-api","published":1,"updated":"2018-02-27T03:17:44.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxm000wxu2zc5z4qiqw","content":"<a id=\"more\"></a>\n<h2 id=\"是什么\"><a href=\"#是什么\" class=\"headerlink\" title=\"是什么\"></a>是什么</h2><p>由于历史遗留原因，Nova认为资源全部是由计算节点提供，所以在报告某些资源使用时，Nova仅仅通过查询数据库中不同计算节点的数据，简单的做累加计算得到使用量和可用资源情况，这一定不是严谨科学的做法，于是，在N版中，Nova引入了Placement API，这是一个单独的RESTful API和数据模型，用于管理和查询资源提供者的资源存量、使用情况、分配记录等等，以提供更好、更准确的资源跟踪、调度和分配的功能。</p>\n<h2 id=\"有什么\"><a href=\"#有什么\" class=\"headerlink\" title=\"有什么\"></a>有什么</h2><h3 id=\"代码目录\"><a href=\"#代码目录\" class=\"headerlink\" title=\"代码目录\"></a>代码目录</h3><p>由于Nova Placement API是单独剥离出来的RESTful API，同时也有自己单独的Endpoint，并且与Nova API服务启动在不同的端口，单独提供服务，那么，在代码目录上来看，也是相对独立的，其代码实现均在<code>/nova/api/openstack/placement/</code>下，那么我看来看一下Nova Placement API的代码目录结构：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">F:nova ZH.F$ tree  -C  api/openstack/placement</span><br><span class=\"line\">api/openstack/placement</span><br><span class=\"line\">├── __init__.py</span><br><span class=\"line\">├── auth.py</span><br><span class=\"line\">├── deploy.py</span><br><span class=\"line\">├── handler.py</span><br><span class=\"line\">├── handlers</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   ├── aggregate.py</span><br><span class=\"line\">│   ├── allocation.py</span><br><span class=\"line\">│   ├── allocation_candidate.py</span><br><span class=\"line\">│   ├── inventory.py</span><br><span class=\"line\">│   ├── resource_class.py</span><br><span class=\"line\">│   ├── resource_provider.py</span><br><span class=\"line\">│   ├── root.py</span><br><span class=\"line\">│   ├── trait.py</span><br><span class=\"line\">│   └── usage.py</span><br><span class=\"line\">├── lib.py</span><br><span class=\"line\">├── microversion.py</span><br><span class=\"line\">├── policy.py</span><br><span class=\"line\">├── requestlog.py</span><br><span class=\"line\">├── rest_api_version_history.rst</span><br><span class=\"line\">├── schemas</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   ├── aggregate.py</span><br><span class=\"line\">│   ├── allocation.py</span><br><span class=\"line\">│   ├── allocation_candidate.py</span><br><span class=\"line\">│   ├── inventory.py</span><br><span class=\"line\">│   ├── resource_class.py</span><br><span class=\"line\">│   ├── trait.py</span><br><span class=\"line\">│   └── usage.py</span><br><span class=\"line\">├── util.py</span><br><span class=\"line\">├── wsgi.py</span><br><span class=\"line\">└── wsgi_wrapper.py</span><br></pre></td></tr></table></figure>\n<p>其中，在<code>api/openstack/placement/schemas</code>目录下，可以看到基本数据模型的schema，不过<code>resource privoder</code>的schema定义在了<code>api/openstack/placement/handlers/resource_provider.py</code>中。下面，对照schema，我们对其中的一些概念进行了解。</p>\n<h3 id=\"Nova-Placement-API中的一些概念\"><a href=\"#Nova-Placement-API中的一些概念\" class=\"headerlink\" title=\"Nova Placement API中的一些概念\"></a>Nova Placement API中的一些概念</h3><h4 id=\"Resource-Provider\"><a href=\"#Resource-Provider\" class=\"headerlink\" title=\"Resource Provider\"></a>Resource Provider</h4><p>即资源提供者，通过其schema可以看到结构比较简单，只包含UUID和RP（Resource Provider简写，下同）的一些基本信息，比如name：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">GET_RPS_SCHEMA_1_0 = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"object\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"properties\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"name\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"string\"</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"uuid\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"string\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"format\"</span>: <span class=\"string\">\"uuid\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"additionalProperties\"</span>: <span class=\"keyword\">False</span>,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>资源提供者可能是一个计算节点，也可能是一个共享存储池或者一个IP分配池子，那么不同的RP，提供的资源多种多样，于是就引入了Resource Class，即资源类型的概念。</p>\n<h4 id=\"Resource-Class\"><a href=\"#Resource-Class\" class=\"headerlink\" title=\"Resource Class\"></a>Resource Class</h4><p>即资源类型，比如计算节点提供的资源可能是CPU、内存、PCI设备、本地临时磁盘等等。每种被消费的资源都会按照类别进行标注和跟踪。</p>\n<p>之所以引入这个概念，目的是解决Nova中hard-coded的资源类型扩展性问题，比如CPU资源，可能记录在Instance对象的<em>vcpus</em>字段中，那么之后再增加新的资源类型，都需要修改数据表，而修改数据表的过程都会停机维护，给系统带来许多downtime，这是不可接受的。</p>\n<p>Placement API提供了一些标准资源类别，如：</p>\n<ul>\n<li>VCPU</li>\n<li>MEMORY_MB</li>\n<li>DISK_GB</li>\n<li>PCI_DEVICE</li>\n<li>NUMA_SOCKET</li>\n<li>NUMA_CORE</li>\n<li>NUMA_THREAD</li>\n<li>IPV4_ADDRESS</li>\n<li>…</li>\n</ul>\n<p>注：数据来自<a href=\"https://specs.openstack.org/openstack/nova-specs/specs/mitaka/implemented/resource-classes.html\" target=\"_blank\" rel=\"noopener\">BP:Introduce resource classes</a></p>\n<p>除了以上标准资源类别，Placement API还在O版中为RP增加了自定义Resource Class的能力，比如自动以的FPGA、裸机调度等等。</p>\n<h4 id=\"Inventory\"><a href=\"#Inventory\" class=\"headerlink\" title=\"Inventory\"></a>Inventory</h4><p>即库存，存量。用于记录超配比、资源总量、存量、步长（step_size）、最小和最大单位等信息，可以看一下它的schema：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">BASE_INVENTORY_SCHEMA = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"object\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"properties\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"resource_provider_generation\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"total\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"reserved\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"min_unit\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"max_unit\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"step_size\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"allocation_ratio\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"number\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.SQL_SP_FLOAT_MAX</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"required\"</span>: [</span><br><span class=\"line\">        <span class=\"string\">\"total\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"resource_provider_generation\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"additionalProperties\"</span>: <span class=\"keyword\">False</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中的<code>resource_provider_generation</code>字段，是一个一致性视图的标志位，在获取RP列表时的<code>generation</code>功能是相同的，这就是CAS（Compare and swap），即乐观锁技术——当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p>\n<h4 id=\"Usage\"><a href=\"#Usage\" class=\"headerlink\" title=\"Usage\"></a>Usage</h4><p>即用量，使用情况。可以查看某个RP的使用情况，也可以查看项目下某用户的资源使用情况。</p>\n<h4 id=\"Aggregate\"><a href=\"#Aggregate\" class=\"headerlink\" title=\"Aggregate\"></a>Aggregate</h4><p>在Ocata版本，社区开始将nova-scheduler服务与Placement API进行集成，并在scheduler进行了一些修改，使用Placement API进行满足一些基本资源请求条件的计算节点过滤。添加了aggregates，来提供resource provider的分组机制。</p>\n<h4 id=\"Allocation\"><a href=\"#Allocation\" class=\"headerlink\" title=\"Allocation\"></a>Allocation</h4><p>即已分配量，某一个RP对某一个资源消费者（即某个实例）所分配的资源。</p>\n<h4 id=\"Allocation-candidate\"><a href=\"#Allocation-candidate\" class=\"headerlink\" title=\"Allocation-candidate\"></a>Allocation-candidate</h4><p>即分配的候选者（资源提供者），举个例子，用户说，我需要1个VCPU，512MB内存，1GB磁盘的资源，Placement你帮我找找看看，有没有合适的资源。然后Placement就要做各种处理，反馈给用户，哪些是可以分配的候选资源提供者。</p>\n<h4 id=\"Trait\"><a href=\"#Trait\" class=\"headerlink\" title=\"Trait\"></a>Trait</h4><p>字面意思，特征，特性。ResourceProvider和Allocation可以在定量的角度，控制和管理boot虚机请求，然而我们还需要从定性的角度来区分资源，最经典的例子是当我们创建虚机时，需要向不同的RP请求磁盘资源，用户可能请求80GB的磁盘，但也可能请求80GB的SSD。这就是Trait的意义。</p>\n<h3 id=\"数据库及数据表\"><a href=\"#数据库及数据表\" class=\"headerlink\" title=\"数据库及数据表\"></a>数据库及数据表</h3><p>目前我安装的Pike版本的Packstack环境中，能看到有一个<code>nova_placement</code>数据库，但是没有任何表（也许是社区希望能把placement相关的表放到这个数据库中？），Placement对应的数据库用的还是<code>nova_api</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">MariaDB [nova_placement]&gt; use nova_api;</span><br><span class=\"line\">Reading table information for completion of table and column names</span><br><span class=\"line\">You can turn off this feature to get a quicker startup with -A</span><br><span class=\"line\"></span><br><span class=\"line\">Database changed</span><br><span class=\"line\">MariaDB [nova_api]&gt; show tables;</span><br><span class=\"line\">+------------------------------+</span><br><span class=\"line\">| Tables_in_nova_api           |</span><br><span class=\"line\">+------------------------------+</span><br><span class=\"line\">| aggregate_hosts              |</span><br><span class=\"line\">| aggregate_metadata           |</span><br><span class=\"line\">| aggregates                   |</span><br><span class=\"line\">| allocations                  |</span><br><span class=\"line\">| build_requests               |</span><br><span class=\"line\">| cell_mappings                |</span><br><span class=\"line\">| consumers                    |</span><br><span class=\"line\">| flavor_extra_specs           |</span><br><span class=\"line\">| flavor_projects              |</span><br><span class=\"line\">| flavors                      |</span><br><span class=\"line\">| host_mappings                |</span><br><span class=\"line\">| instance_group_member        |</span><br><span class=\"line\">| instance_group_policy        |</span><br><span class=\"line\">| instance_groups              |</span><br><span class=\"line\">| instance_mappings            |</span><br><span class=\"line\">| inventories                  |</span><br><span class=\"line\">| key_pairs                    |</span><br><span class=\"line\">| migrate_version              |</span><br><span class=\"line\">| placement_aggregates         |</span><br><span class=\"line\">| project_user_quotas          |</span><br><span class=\"line\">| projects                     |</span><br><span class=\"line\">| quota_classes                |</span><br><span class=\"line\">| quota_usages                 |</span><br><span class=\"line\">| quotas                       |</span><br><span class=\"line\">| request_specs                |</span><br><span class=\"line\">| reservations                 |</span><br><span class=\"line\">| resource_classes             |</span><br><span class=\"line\">| resource_provider_aggregates |</span><br><span class=\"line\">| resource_provider_traits     |</span><br><span class=\"line\">| resource_providers           |</span><br><span class=\"line\">| traits                       |</span><br><span class=\"line\">| users                        |</span><br><span class=\"line\">+------------------------------+</span><br></pre></td></tr></table></figure>\n<p>可以从表明上看到那些是Placement相关的表，这里就不展开了。</p>\n<h3 id=\"初始化及加载方式\"><a href=\"#初始化及加载方式\" class=\"headerlink\" title=\"初始化及加载方式\"></a>初始化及加载方式</h3><p>我们前面提到Nova Placement API是单独的RESTful API，那么是如何进行初始化的呢？带着这个问题，我们先查看nova的<code>setup.cfg</code>，其中配置了wsgi_scripts如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">wsgi_scripts =</span><br><span class=\"line\">    nova-placement-api = nova.api.openstack.placement.wsgi:init_application</span><br><span class=\"line\">    nova-api-wsgi = nova.api.openstack.compute.wsgi:init_application</span><br><span class=\"line\">    nova-metadata-wsgi = nova.api.metadata.wsgi:init_application</span><br></pre></td></tr></table></figure>\n<p>其中可以看到nova-placement-api的初始化来自 <code>nova.api.openstack.placement.wsgi.init_application</code> ，代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">init_application</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># initialize the config system</span></span><br><span class=\"line\">    conffile = _get_config_file()</span><br><span class=\"line\">    config.parse_args([], default_config_files=[conffile])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># initialize the logging system</span></span><br><span class=\"line\">    setup_logging(conf.CONF)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># dump conf if we're at debug</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> conf.CONF.debug:</span><br><span class=\"line\">        conf.CONF.log_opt_values(</span><br><span class=\"line\">            logging.getLogger(__name__),</span><br><span class=\"line\">            logging.DEBUG)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># build and return our WSGI app</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> deploy.loadapp(conf.CONF)</span><br></pre></td></tr></table></figure>\n<p>其中在最后构造WSGI app并返回，即调用了deploy.loadapp(conf.CONF)：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadapp</span><span class=\"params\">(config, project_name=NAME)</span>:</span></span><br><span class=\"line\">    application = deploy(config, project_name)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> application</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">deploy</span><span class=\"params\">(conf, project_name)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Assemble the middleware pipeline leading to the placement app.\"\"\"</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    application = handler.PlacementHandler()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">for</span> middleware <span class=\"keyword\">in</span> (microversion_middleware,</span><br><span class=\"line\">                       fault_wrap,</span><br><span class=\"line\">                       request_log,</span><br><span class=\"line\">                       context_middleware,</span><br><span class=\"line\">                       auth_middleware,</span><br><span class=\"line\">                       cors_middleware,</span><br><span class=\"line\">                       req_id_middleware,</span><br><span class=\"line\">                       ):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> middleware:</span><br><span class=\"line\">            application = middleware(application)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> application</span><br></pre></td></tr></table></figure>\n<p>而这里的handler.PlacementHandler()就是我们的Placement的API入口：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PlacementHandler</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Serve Placement API.</span></span><br><span class=\"line\"><span class=\"string\">    Dispatch to handlers defined in ROUTE_DECLARATIONS.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, **local_config)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># NOTE(cdent): Local config currently unused.</span></span><br><span class=\"line\">        self._map = make_map(ROUTE_DECLARATIONS)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span><span class=\"params\">(self, environ, start_response)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># All requests but '/' require admin.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> environ[<span class=\"string\">'PATH_INFO'</span>] != <span class=\"string\">'/'</span>:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<p>可以看到，PlacementHandler在<code>__init__</code>中根据路由定义构造了map，同时在<code>__call__</code>中对请求进行dispatch。这就是一个典型的WSGI应用：</p>\n<blockquote>\n<p>WSGI application is a callable object (a function, method, class, or an instance with a <code>__call__</code> method) that accepts two positional arguments: WSGI environment variables and a callable with two required positional arguments which starts the response;</p>\n</blockquote>\n<p>找到了初始化，那么Placement API加载和启动是如何实现的？</p>\n<p>首先，nova-placement-api是单独的脚本，在httpd中启动，与keystone（在12年就完成了WSGI化，参见<a href=\"http://adam.younglogic.com/2012/03/keystone-should-move-to-apache-httpd/\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>）类似，通过<code>systemctl status httpd</code>是可以看到的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# systemctl status httpd</span><br><span class=\"line\">● httpd.service - The Apache HTTP Server</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Fri 2018-02-02 09:17:51 CST; 1 weeks 0 days ago</span><br><span class=\"line\">     Docs: man:httpd(8)</span><br><span class=\"line\">           man:apachectl(8)</span><br><span class=\"line\">  Process: 4087 ExecReload=/usr/sbin/httpd $OPTIONS -k graceful (code=exited, status=0/SUCCESS)</span><br><span class=\"line\"> Main PID: 1309 (httpd)</span><br><span class=\"line\">   Status: &quot;Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec&quot;</span><br><span class=\"line\">   CGroup: /system.slice/httpd.service</span><br><span class=\"line\">           ├─ 1309 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">           ├─ 4108 keystone-admin  -DFOREGROUND</span><br><span class=\"line\"></span><br><span class=\"line\">▽</span><br><span class=\"line\">           ├─ 4109 keystone-admin  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4110 keystone-admin  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4111 keystone-admin  -DFOREGROUND</span><br><span class=\"line\"></span><br><span class=\"line\">▽</span><br><span class=\"line\">           ├─ 4112 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4113 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4114 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4115 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4116 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4117 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4118 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4119 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4121 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">           ├─ 4122 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">…</span><br></pre></td></tr></table></figure>\n<p>知道是在httpd启动的，我们去查看配置文件目录：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# ll /etc/httpd/conf.d/</span><br><span class=\"line\">total 36</span><br><span class=\"line\">-rw-r-----. 1 root root  136 Jan 12 17:46 00-nova-placement-api.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  943 Jan 12 17:48 10-keystone_wsgi_admin.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  938 Jan 12 17:48 10-keystone_wsgi_main.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  941 Jan 12 17:49 10-placement_wsgi.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  697 Jan 12 17:48 15-default.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root 2926 Oct 20 04:39 autoindex.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  366 Oct 20 04:39 README</span><br><span class=\"line\">-rw-r--r--. 1 root root 1252 Oct 20 00:44 userdir.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  824 Oct 20 00:44 welcome.conf</span><br></pre></td></tr></table></figure>\n<p>其中，10-placement_wsgi.conf 中定义了WSGIScriptAllias：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">  WSGIProcessGroup placement-api</span><br><span class=\"line\">  WSGIScriptAlias /placement &quot;/var/www/cgi-bin/nova/nova-placement-api”</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>也就是说，url为<code>/placement/xxx</code>的请求会使得httpd服务运行定义在<code>/var/www/cgi-bin/nova/nova-placement-api</code>中的WSGI应用，在这个文件中，我们会看到：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nova.api.openstack.placement.wsgi <span class=\"keyword\">import</span> init_application</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__”:</span></span><br><span class=\"line\"><span class=\"string\">    import argparse</span></span><br><span class=\"line\"><span class=\"string\">    import socket</span></span><br><span class=\"line\"><span class=\"string\">    import sys</span></span><br><span class=\"line\"><span class=\"string\">    import wsgiref.simple_server as wss</span></span><br><span class=\"line\"><span class=\"string\">    …</span></span><br><span class=\"line\"><span class=\"string\">    server = wss.make_server(args.host, args.port, init_application())</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>也就对应了前面提到的PlacementHandler中的<code>nova.api.openstack.placement.wsgi.init_application</code>，至此，我们就了解了Nova Placement API的初始化和加载方式。</p>\n<h3 id=\"API路由定义\"><a href=\"#API路由定义\" class=\"headerlink\" title=\"API路由定义\"></a>API路由定义</h3><p>上一小节提到了PlacementHandler初始化时，根据路由定义构造了map映射，我们就来看下文件<code>api/openstack/placement/handler.py</code>中的API<code>ROUTE_DECLARATIONS</code>:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># URLs and Handlers</span></span><br><span class=\"line\"><span class=\"comment\"># NOTE(cdent): When adding URLs here, do not use regex patterns in</span></span><br><span class=\"line\"><span class=\"comment\"># the path parameters (e.g. &#123;uuid:[0-9a-zA-Z-]+&#125;) as that will lead</span></span><br><span class=\"line\"><span class=\"comment\"># to 404s that are controlled outside of the individual resources</span></span><br><span class=\"line\"><span class=\"comment\"># and thus do not include specific information on the why of the 404.</span></span><br><span class=\"line\">ROUTE_DECLARATIONS = &#123;</span><br><span class=\"line\">    <span class=\"string\">'/'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: root.home,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"comment\"># NOTE(cdent): This allows '/placement/' and '/placement' to</span></span><br><span class=\"line\">    <span class=\"comment\"># both work as the root of the service, which we probably want</span></span><br><span class=\"line\">    <span class=\"comment\"># for those situations where the service is mounted under a</span></span><br><span class=\"line\">    <span class=\"comment\"># prefix (as it is in devstack). While weird, an empty string is</span></span><br><span class=\"line\">    <span class=\"comment\"># a legit key in a dictionary and matches as desired in Routes.</span></span><br><span class=\"line\">    <span class=\"string\">''</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: root.home,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_classes'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_class.list_resource_classes,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: resource_class.create_resource_class</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_classes/&#123;name&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_class.get_resource_class,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: resource_class.update_resource_class,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: resource_class.delete_resource_class,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_provider.list_resource_providers,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: resource_provider.create_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_provider.get_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: resource_provider.delete_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: resource_provider.update_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/inventories'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: inventory.get_inventories,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: inventory.create_inventory,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: inventory.set_inventories,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: inventory.delete_inventories</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/inventories/&#123;resource_class&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: inventory.get_inventory,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: inventory.update_inventory,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: inventory.delete_inventory</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/usages'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: usage.list_usages</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/aggregates'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: aggregate.get_aggregates,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: aggregate.set_aggregates</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/allocations'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation.list_for_resource_provider,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocations'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: allocation.set_allocations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocations/&#123;consumer_uuid&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation.list_for_consumer,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: allocation.set_allocations_for_consumer,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: allocation.delete_allocations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocation_candidates'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation_candidate.list_allocation_candidates,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/traits'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.list_traits,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/traits/&#123;name&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.get_trait,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: trait.put_trait,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: trait.delete_trait,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/traits'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.list_traits_for_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: trait.update_traits_for_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: trait.delete_traits_for_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/usages'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: usage.get_total_usages,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"怎么用\"><a href=\"#怎么用\" class=\"headerlink\" title=\"怎么用\"></a>怎么用</h2><h3 id=\"如何部署\"><a href=\"#如何部署\" class=\"headerlink\" title=\"如何部署\"></a>如何部署</h3><p>在官方文档中提到，placement api服务必须在升级到14.0.0，即N版后，升级到15.0.0，即O版之前进行部署。nova-compute服务中的resource tracker需要获取placement的资源提供者存量和分配信息（这部分信息将在O版中由nova-scheduler使用）。</p>\n<ol>\n<li>部署API服务 - Placement API目前还是在nova中进行开发，但是设计上是相对独立的，以便将来分离出来成为单独的项目。作为一个单独的WSGI应用，可使用Apahce2或者Nginx部署API服务。</li>\n<li>同步数据库 - 升级N版时，需要手动执行<code>nova-manage api_db sync</code>命令进行数据库同步，这样Placement相关的数据表就会被创建出来</li>\n<li>在keystone中创建具有admin角色的placement service user，同时更新服务目录，配置单独的endpoint.</li>\n<li>配置nova.conf中[placement]部分，并重启nova-compute服务。不过对于我们P版，经过了O版的一系列功能补齐，尤其是在O版中，如果在<code>nova.conf</code>中不配置<code>[placement]</code>部分的内容，就无法启动<code>nova-compute</code>服务。</li>\n</ol>\n<blockquote>\n<p>The nova-compute service will fail to start in Ocata unless the [placement] section of nova.conf on the compute is configured.</p>\n</blockquote>\n<p>更多部署相关的可参见官方文档，<a href=\"https://docs.openstack.org/nova/latest/user/placement.html#deployment\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>。</p>\n<h3 id=\"OSC-Placement-Plugin\"><a href=\"#OSC-Placement-Plugin\" class=\"headerlink\" title=\"OSC Placement Plugin\"></a>OSC Placement Plugin</h3><p>从前面的API路由定义，我们可以看到，目前支持了这么些功能，那么我们可以简单的用一下，第一个想到的是cURL命令，我们可以使用该命令模拟发起请求，调用Placement API，比如查看resource providers list，首先我们获取token：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 首先得到auth token</span><br><span class=\"line\">curl -d '&#123;\"auth\": &#123;\"tenantName\": \"admin\", \"passwordCredentials\": &#123;\"username\": \"admin\", \"password\": \"1234qwer\"&#125;&#125;&#125;' \\</span><br><span class=\"line\">-H \"Content-type: application/json\" \\</span><br><span class=\"line\">http://localhost:5000/v2.0/tokens</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"issued_at\"</span>: <span class=\"string\">\"2018-02-07T07:40:07.000000Z\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"expires\"</span>: <span class=\"string\">\"2018-02-07T08:40:07.000000Z\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itnL6Q-TSWhOn7uZpdQsYqqJDmwgtzCm-hcpg17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"tenant\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"admin tenant\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"enabled\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"6387fc88b3064149a12eb5b58669e0b2\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"admin\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># token的获取方式，还可以用OSC命令：</span><br><span class=\"line\">openstack token issue | grep ' id' | awk '&#123;print $4&#125;'</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#得到token之后，构造请求，查看resource providers list：</span><br><span class=\"line\">curl -X GET /</span><br><span class=\"line\">-H 'x-auth-token:gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itn17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE’ /</span><br><span class=\"line\">http://192.168.122.105:8778/placement/resource_providers</span><br><span class=\"line\"></span><br><span class=\"line\">#得到resources providers list</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"resource_providers\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"generation\"</span>: <span class=\"number\">30</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"uuid\"</span>: <span class=\"string\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"links\"</span>: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"self\"</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"inventories\"</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"usages\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"f-packstack\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中的<code>generation</code>字段，是一个一致性视图的标志位，跟获取RP的inventories中的<code>resource_provider_generation</code>功能是相同的，其实算作是乐观锁技术，即CAS，Compare and swap，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p>\n<p>下面来一个获取aggregate和inventories的示例，注意，aggregate的API是在1.1版本中实现的，所以要在请求头指定<code>OpenStack-API-Version: placement 1.1</code>：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/aggregates \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H \"X-Auth-Token: gAAAAABaf5nafUZyFTl_pztozfB65wkP0c26HQqrxRgAiJGsxY8g743LxFOZEI3bF_l37xh0UajbF5nQ1kLYGAonOGphV4AivXgYMUOJ84uGrHjpC60NlmNzzQ3lJGVJb-pNxQw74WsMOc9I0D2B5Mzmf2OgDeictae5f0UFgTR9DFb_vaWCWQ4\" \\</span><br><span class=\"line\">-H \"OpenStack-API-Version: placement 1.1\"</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Date: Fri, 15 Sep 2017 09:35:21 GMT</span><br><span class=\"line\">Server: Apache/2.4.18 (Ubuntu)</span><br><span class=\"line\">Content-Length: 18</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\">OpenStack-API-Version: placement 1.1</span><br><span class=\"line\">vary: OpenStack-API-Version</span><br><span class=\"line\">x-openstack-request-id: req-ab28194f-8389-40a1-9a2b-a94dbc792573</span><br><span class=\"line\">Connection: close</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;<span class=\"attr\">\"aggregates\"</span>: []&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H 'x-auth-token:gAAAAABae6lX26bp4PEVHCac0cjFnNl18W8DjeQKXDYvuKP4drRJ8t6DC-9uzcCm4E9Xf7NjqSqkRX6WGsE3qHmpAt7GmIu1SrLCtyEOVM2IQP5XLNrwMekGGrzQ_ADOaSTc9XpPpCYyYwzT-zCAvWG-T9T6Ip4l3zHWLwNBBPrm35gBZVZeslQ' \\</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"resource_provider_generation\"</span>: <span class=\"number\">30</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"inventories\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"VCPU\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">16</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">128</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"attr\">\"MEMORY_MB\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">1.5</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">8095</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">512</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">8095</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"attr\">\"DISK_GB\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">49</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">49</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>贴心的社区妥妥的想到了如何可以方便用户操作Placement API，所以开发了一个OpenStackClient Plugin，即<a href=\"https://github.com/openstack/osc-placement\" target=\"_blank\" rel=\"noopener\">osc-placement</a>，需要我们手动安装使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ pip install osc-placement</span><br></pre></td></tr></table></figure>\n<p>有了OSC placement commands，我们不再需要使用curl命令模拟HTTP请求，并且可以非常轻松的进行操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# openstack --debug resource provider list</span><br><span class=\"line\">...</span><br><span class=\"line\">http://192.168.122.105:8778 \"GET /placement/resource_providers HTTP/1.1\" 200 185</span><br><span class=\"line\">RESP: [200] Date: Thu, 08 Feb 2018 05:59:56 GMT Server: Apache/2.4.6 (CentOS) OpenStack-API-Version: placement 1.0 vary: OpenStack-API-Version,Accept-Encoding x-openstack-request-id: req-c6077c19-ca05-4cab-95fa-6129ff989400 Content-Encoding: gzip Content-Length: 185 Keep-Alive: timeout=15, max=100 Connection: Keep-Alive Content-Type: application/json</span><br><span class=\"line\">RESP BODY: &#123;\"resource_providers\": [&#123;\"generation\": 30, \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"links\": [&#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"rel\": \"self\"&#125;, &#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\", \"rel\": \"inventories\"&#125;, &#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\", \"rel\": \"usages\"&#125;], \"name\": \"f-packstack\"&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">GET call to placement for http://192.168.122.105:8778/placement/resource_providers used request id req-c6077c19-ca05-4cab-95fa-6129ff989400</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">| uuid                                 | name        | generation |</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">| 4cae2ef8-30eb-4571-80c3-3289e86bd65c | f-packstack |         30 |</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">clean_up ListResourceProvider:</span><br><span class=\"line\">END return value: 0</span><br></pre></td></tr></table></figure>\n<p>当然还有很多其他的命令，有兴趣的可以尝试玩一下。</p>\n<h3 id=\"划重点：Nova调度与Placement-API的结合\"><a href=\"#划重点：Nova调度与Placement-API的结合\" class=\"headerlink\" title=\"划重点：Nova调度与Placement API的结合\"></a>划重点：Nova调度与Placement API的结合</h3><p>首先来一张图，来认识一下在P版中，创建一台虚机过程中各个服务之间的调用/调度关系：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/boot-instance-pike.png\" alt=\"\"><br>可以看到，在nova-scheduler与Placement API的交互过程中，有两部分：</p>\n<ol>\n<li>Get allocation candidates</li>\n<li>Claim Resources<br>下面，我们结合代码详细的讲述一下调度过程。</li>\n</ol>\n<h4 id=\"Get-allocation-candidates\"><a href=\"#Get-allocation-candidates\" class=\"headerlink\" title=\"Get allocation candidates\"></a>Get allocation candidates</h4><p>目前在调度时，nova-conductor在<code>nova.conductor.manager.ComputeTaskManager#_schedule_instances</code>中调用了方法<code>nova.scheduler.client.SchedulerClient#select_destinations</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@utils.retry_select_destinations</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, context, spec_obj, instance_uuids,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.queryclient.select_destinations(context, spec_obj,</span><br><span class=\"line\">            instance_uuids, return_objects, return_alternates)</span><br></pre></td></tr></table></figure>\n<p>其中<code>SchedulerClient</code>又调用了<code>SchedulerQueryClient</code>，即调用了<code>nova.scheduler.client.query.SchedulerQueryClient#select_destinations</code>方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, context, spec_obj, instance_uuids,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.scheduler_rpcapi.select_destinations(context, spec_obj,</span><br><span class=\"line\">            instance_uuids, return_objects, return_alternates)</span><br></pre></td></tr></table></figure>\n<p>在该方法中发起RPC调用，调用了<code>nova.scheduler.manager.SchedulerManager#select_destinations</code>方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@messaging.expected_exceptions(exception.NoValidHost)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, ctxt, request_spec=None,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        filter_properties=None, spec_obj=_sentinel, instance_uuids=None,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    LOG.debug(<span class=\"string\">\"Starting to schedule for instances: %s\"</span>, instance_uuids)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\"># 其中USES_ALLOCATION_CANDIDATES默认值为True，</span></span><br><span class=\"line\">    <span class=\"comment\"># 即表示使用Nova Placement API来选取资源分配候选者</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.driver.USES_ALLOCATION_CANDIDATES:</span><br><span class=\"line\">        res = self.placement_client.get_allocation_candidates(ctxt,</span><br><span class=\"line\">        <span class=\"keyword\">if</span> res <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">            alloc_reqs, provider_summaries, allocation_request_version = (</span><br><span class=\"line\">                    <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            (alloc_reqs, provider_summaries,</span><br><span class=\"line\">                        allocation_request_version) = res</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> alloc_reqs:</span><br><span class=\"line\">            LOG.debug(<span class=\"string\">\"Got no allocation candidates from the Placement \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"API. This may be a temporary occurrence as compute \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"nodes start up and begin reporting inventory to \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"the Placement service.\"</span>)</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> exception.NoValidHost(reason=<span class=\"string\">\"\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># Build a dict of lists of allocation requests, keyed by</span></span><br><span class=\"line\">            <span class=\"comment\"># provider UUID, so that when we attempt to claim resources for</span></span><br><span class=\"line\">            <span class=\"comment\"># a host, we can grab an allocation request easily</span></span><br><span class=\"line\">            alloc_reqs_by_rp_uuid = collections.defaultdict(list)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> ar <span class=\"keyword\">in</span> alloc_reqs:</span><br><span class=\"line\">                <span class=\"keyword\">for</span> rp_uuid <span class=\"keyword\">in</span> ar[<span class=\"string\">'allocations'</span>]:</span><br><span class=\"line\">                    alloc_reqs_by_rp_uuid[rp_uuid].append(ar)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Only return alternates if both return_objects and return_alternates</span></span><br><span class=\"line\">    <span class=\"comment\"># are True.</span></span><br><span class=\"line\">    return_alternates = return_alternates <span class=\"keyword\">and</span> return_objects</span><br><span class=\"line\">    <span class=\"comment\"># self.driver在这里，我们配置使用的是FilterScheduler，</span></span><br><span class=\"line\">    <span class=\"comment\"># 即又调用了nova.scheduler.filter_scheduler.FilterScheduler#select_destinations</span></span><br><span class=\"line\">    <span class=\"comment\"># 这个我们后面会提到</span></span><br><span class=\"line\">    selections = self.driver.select_destinations(ctxt, spec_obj,</span><br><span class=\"line\">            instance_uuids, alloc_reqs_by_rp_uuid, provider_summaries,</span><br><span class=\"line\">            allocation_request_version, return_alternates)</span><br><span class=\"line\">    <span class=\"comment\"># If `return_objects` is False, we need to convert the selections to</span></span><br><span class=\"line\">    <span class=\"comment\"># the older format, which is a list of host state dicts.</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> return_objects:</span><br><span class=\"line\">        selection_dicts = [sel[<span class=\"number\">0</span>].to_dict() <span class=\"keyword\">for</span> sel <span class=\"keyword\">in</span> selections]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jsonutils.to_primitive(selection_dicts)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> selections</span><br></pre></td></tr></table></figure>\n<p>我们先来说，这里调用的Placement API，发起一个GET请求，获取Allocation Candidates。</p>\n<blockquote>\n<p>注：没有找到这个API对应的OSC命令，所以我们使用curl命令进行模拟。<br><br>另，Allocation candidates API requests are availiable starting from version <code>1.10</code>.</p>\n</blockquote>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 获取token</span><br><span class=\"line\">[root@f-packstack ~(keystone_admin)]# openstack token issue | grep ' id' | awk '&#123;print $4&#125;'</span><br><span class=\"line\">gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE</span><br><span class=\"line\"># 使用curl命令发起GET请求，请求参数是resources=DISK_GB:1,MEMORY_MB:512,VCPU:1</span><br><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/allocation_candidates?resources=DISK_GB:1,MEMORY_MB:512,VCPU:1 \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H \"X-Auth-Token: gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\" \\</span><br><span class=\"line\">-H \"OpenStack-API-Version: placement 1.10\"</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Date: Thu, 22 Feb 2018 08:55:27 GMT</span><br><span class=\"line\">Server: Apache/2.4.6 (CentOS)</span><br><span class=\"line\">OpenStack-API-Version: placement 1.10</span><br><span class=\"line\">vary: OpenStack-API-Version,Accept-Encoding</span><br><span class=\"line\">x-openstack-request-id: req-234db1eb-1386-4e89-99bd-c9269270c603</span><br><span class=\"line\">Content-Length: 381</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"provider_summaries\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"resources\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"VCPU\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">64</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"attr\">\"MEMORY_MB\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">1024</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">11374</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"attr\">\"DISK_GB\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">49</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"allocation_requests\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocations\"</span>: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"resource_provider\"</span>: &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"uuid\"</span>: <span class=\"string\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span></span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"attr\">\"resources\"</span>: &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"VCPU\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"MEMORY_MB\"</span>: <span class=\"number\">512</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"DISK_GB\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Placement经过一系列查询之后，返回了一些信息，其中<code>allocation_requests</code>就是我们的请求参数，即我们需要这么些资源，麻烦Placement给看看有合适的RP没？然后Placement帮我们找到了UUID为<code>4cae2ef8-30eb-4571-80c3-3289e86bd65c</code>的RP，还很贴心的在<code>provider_summaries</code>列出了这个RP当前使用的资源量以及存量。实际上这两个查询分别对应了下面的两个SQL语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- 1.查询符合要求的Resource Provider</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> rp.id</span><br><span class=\"line\"><span class=\"keyword\">FROM</span> resource_providers <span class=\"keyword\">AS</span> rp</span><br><span class=\"line\">    <span class=\"comment\">-- vcpu信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- vcpu总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_vcpu</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_vcpu.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_vcpu.resource_class_id = %(resource_class_id_1)s</span><br><span class=\"line\">    <span class=\"comment\">-- vcpu已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">        <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_2)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> usage_vcpu</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_vcpu.resource_provider_id = usage_vcpu.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- memory信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- memory总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_memory_mb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_memory_mb.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_memory_mb.resource_class_id = %(resource_class_id_3)s</span><br><span class=\"line\">    <span class=\"comment\">-- memory已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">            <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_4)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> usage_memory_mb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_memory_mb.resource_provider_id = usage_memory_mb.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- disk信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- disk总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_disk_gb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_disk_gb.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_disk_gb.resource_class_id = %(resource_class_id_5)s</span><br><span class=\"line\">    <span class=\"comment\">-- disk已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id</span><br><span class=\"line\">        <span class=\"keyword\">AS</span> resource_provider_id, <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_6)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">        ) <span class=\"keyword\">AS</span> usage_disk_gb</span><br><span class=\"line\">            <span class=\"keyword\">ON</span> inv_disk_gb.resource_provider_id = usage_disk_gb.resource_provider_id</span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\"><span class=\"comment\">-- vcpu满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_vcpu.used, %(coalesce_1)s) + %(coalesce_2)s &lt;= (</span><br><span class=\"line\">inv_vcpu.total - inv_vcpu.reserved) * inv_vcpu.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_vcpu.min_unit &lt;= %(min_unit_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_vcpu.max_unit &gt;= %(max_unit_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_1)s % inv_vcpu.step_size = %(param_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\"><span class=\"comment\">-- memory满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_memory_mb.used, %(coalesce_3)s) + %(coalesce_4)s &lt;= (</span><br><span class=\"line\">inv_memory_mb.total - inv_memory_mb.reserved) * inv_memory_mb.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_memory_mb.min_unit &lt;= %(min_unit_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_memory_mb.max_unit &gt;= %(max_unit_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_2)s % inv_memory_mb.step_size = %(param_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\"><span class=\"comment\">-- disk满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_disk_gb.used, %(coalesce_5)s) + %(coalesce_6)s &lt;= (</span><br><span class=\"line\">inv_disk_gb.total - inv_disk_gb.reserved) * inv_disk_gb.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_disk_gb.min_unit &lt;= %(min_unit_3)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_disk_gb.max_unit &gt;= %(max_unit_3)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_3)s % inv_disk_gb.step_size = %(param_3)s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- 2.查询该Resource Provider的用量和存量</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> rp.id <span class=\"keyword\">AS</span> resource_provider_id, rp.uuid <span class=\"keyword\">AS</span> resource_provider_uuid,</span><br><span class=\"line\">    inv.resource_class_id, inv.total, inv.reserved, inv.allocation_ratio,</span><br><span class=\"line\">    <span class=\"string\">`usage`</span>.used</span><br><span class=\"line\"><span class=\"keyword\">FROM</span> resource_providers <span class=\"keyword\">AS</span> rp</span><br><span class=\"line\">    <span class=\"comment\">-- inventory信息，每个rp的总量</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> rp.id = inv.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- allocation信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"comment\">-- 每个rp和class的已使用量</span></span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">        allocations.resource_class_id <span class=\"keyword\">AS</span> resource_class_id,</span><br><span class=\"line\">        <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_provider_id <span class=\"keyword\">IN</span> (%(resource_provider_id_1)s) <span class=\"keyword\">AND</span></span><br><span class=\"line\">            allocations.resource_class_id <span class=\"keyword\">IN</span> (</span><br><span class=\"line\">                %(resource_class_id_1)s,</span><br><span class=\"line\">                %(resource_class_id_2)s,</span><br><span class=\"line\">                %(resource_class_id_3)s</span><br><span class=\"line\">            )</span><br><span class=\"line\">        <span class=\"comment\">-- 按照rp_id和rp_class_id进行分组</span></span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id, allocations.resource_class_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> <span class=\"string\">`usage`</span></span><br><span class=\"line\">        <span class=\"keyword\">ON</span> <span class=\"string\">`usage`</span>.resource_provider_id = inv.resource_provider_id <span class=\"keyword\">AND</span></span><br><span class=\"line\">        <span class=\"string\">`usage`</span>.resource_class_id = inv.resource_class_id</span><br><span class=\"line\"><span class=\"comment\">-- 查询指定id及class的resource</span></span><br><span class=\"line\"><span class=\"keyword\">WHERE</span> rp.id <span class=\"keyword\">IN</span> (%(id_1)s) <span class=\"keyword\">AND</span></span><br><span class=\"line\">    inv.resource_class_id <span class=\"keyword\">IN</span> (</span><br><span class=\"line\">        %(resource_class_id_4)s,</span><br><span class=\"line\">        %(resource_class_id_5)s,</span><br><span class=\"line\">        %(resource_class_id_6)s</span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n<h4 id=\"Schedule-by-fitlers\"><a href=\"#Schedule-by-fitlers\" class=\"headerlink\" title=\"Schedule by fitlers\"></a>Schedule by fitlers</h4><p>在nova-scheduler获取到allocation candidates之后，还需要使用<code>FilterScheduler</code>对选取的宿主（候选）节点根据启用的过滤器和权重进行计算和过滤。</p>\n<blockquote>\n<p>目前Nova中实现的调度器有以下几种：</p>\n<ol>\n<li>FilterScheduler（过滤调度器）：默认载入的调度器，根据指定的过滤条件以及权重挑选最佳节点</li>\n<li>CachingScheduler：与FilterScheduler功能类似，只不过为了追求的更高的调度性能，将主机资源信息缓存到本地内存中，目前的master代码中标注为<code>[DEPRECATED]</code></li>\n<li>ChanceScheduler（随机调度器）：随机选择，真·佛系。不过也在master代码中被标注了<code>[DEPRECATED]</code></li>\n<li>FakeScheduler：用于测试，无实际功能</li>\n</ol>\n</blockquote>\n<p>But how does filter scheduler work?</p>\n<p>我们依然从代码入手，来张序列图先看为敬：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/how%20filterscheduler%20works.jpg\" alt=\"FilterScheduler\"></p>\n<p>在<code>FilterScheduler</code>的泳道中，可以看到，大体上分三步：</p>\n<ol>\n<li>调度器缓存刷新、状态更新：通过<code>nova.scheduler.host_manager.HostState</code>来维护内存中一份主机状态，并返回可见的计算节点信息</li>\n<li>Filtering：实用配置文件指定各种的filters去过滤掉不符合条件的hosts。在配置文件中有两个配置<code>availale_filters</code>和<code>enabled_filters</code>，前者用于指定所有可用的filters，配置为<code>available_filters=nova.scheduler.filters.all_filters</code>；后者表示对于可用的filter，nova-scheduler会使用哪些，配置如<code>enabled_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,DiskFilter</code>等。O版中Nova支持的filters多达27个，实现均位于<code>nova/scheduler/filters</code>目录下，能够处理各类信息，比如主机可用资源、启动请求的参数（如镜像信息、请求重试次数等）、虚机亲和性和反亲和性（与其他虚机是否在同一宿主节点上）等</li>\n<li>Weighing：对所有符合条件的host计算权重并排序，从而选出最佳的一个宿主节点。所有的Weigher实现均位于<code>nova/scheduler/weights</code>目录下，比如DiskWeigher：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DiskWeigher</span><span class=\"params\">(weights.BaseHostWeigher)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 可以设置maxval和minval属性指明权重的最大值和最小值</span></span><br><span class=\"line\">    minval = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 权重的系数，最终排序时需要将每种Weigher得到的权重分别乘上它对应的这个</span></span><br><span class=\"line\">    <span class=\"comment\"># 系数，有多个Weigher时才有意义，这里的disk_weight_multiplier</span></span><br><span class=\"line\">    <span class=\"comment\"># 配置文件默认值为 1.0 </span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">weight_multiplier</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> CONF.filter_scheduler.disk_weight_multiplier</span><br><span class=\"line\">    <span class=\"comment\"># 计算权重值，按照注释描述，free_disk_mb更大者胜出</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_weigh_object</span><span class=\"params\">(self, host_state, weight_properties)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"Higher weights win.  We want spreading to be the default.\"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> host_state.free_disk_mb</span><br></pre></td></tr></table></figure>\n<h4 id=\"Claim-Resources\"><a href=\"#Claim-Resources\" class=\"headerlink\" title=\"Claim Resources\"></a>Claim Resources</h4><p>前面我们提到，在获取到Allocation Candidates（即可用于资源分配的候选host）并经过过滤器过滤和权重计算之后，nova-scheduler开始尝试进行<code>Claim resources</code>，即在创建之前预先测试一下所指定的host的可用资源是否能够满足创建虚机的需求。<br>我们来一起看一下<code>nova.scheduler.utils.claim_resources</code>的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">claim_resources</span><span class=\"params\">(ctx, client, spec_obj, instance_uuid, alloc_req,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        allocation_request_version=None)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">return</span> client.claim_resources(ctx, instance_uuid, alloc_req, project_id,</span><br><span class=\"line\">            user_id, allocation_request_version=allocation_request_version)</span><br></pre></td></tr></table></figure>\n<p>在该方法中，最终调用的还是传入的client的<code>claim_resources()</code>方法，即<code>nova.scheduler.client.report.SchedulerReportClient#claim_resources</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@safe_connect</span></span><br><span class=\"line\"><span class=\"meta\">@retries</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">claim_resources</span><span class=\"params\">(self, context, consumer_uuid, alloc_request,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                    project_id, user_id, allocation_request_version=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Creates allocation records for the supplied instance UUID against</span></span><br><span class=\"line\"><span class=\"string\">    the supplied resource providers.</span></span><br><span class=\"line\"><span class=\"string\">    即对指定的实例创建该实例在指定RP上的分配记录</span></span><br><span class=\"line\"><span class=\"string\">    :param context: The security context</span></span><br><span class=\"line\"><span class=\"string\">    :param consumer_uuid: The instance's UUID.</span></span><br><span class=\"line\"><span class=\"string\">    :param alloc_request: The JSON body of the request to make to the</span></span><br><span class=\"line\"><span class=\"string\">                          placement's PUT /allocations API</span></span><br><span class=\"line\"><span class=\"string\">    :param project_id: The project_id associated with the allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :param user_id: The user_id associated with the allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :param allocation_request_version: The microversion used to request the</span></span><br><span class=\"line\"><span class=\"string\">                                       allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :returns: True if the allocations were created, False otherwise.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    ar = copy.deepcopy(alloc_request)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the allocation_request_version less than 1.12, then convert the</span></span><br><span class=\"line\">    <span class=\"comment\"># allocation array format to the dict format. This conversion can be</span></span><br><span class=\"line\">    <span class=\"comment\"># remove in Rocky release.</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> versionutils.convert_version_to_tuple(</span><br><span class=\"line\">            allocation_request_version) &lt; (<span class=\"number\">1</span>, <span class=\"number\">12</span>):</span><br><span class=\"line\">        ar = &#123;</span><br><span class=\"line\">            <span class=\"string\">'allocations'</span>: &#123;</span><br><span class=\"line\">                alloc[<span class=\"string\">'resource_provider'</span>][<span class=\"string\">'uuid'</span>]: &#123;</span><br><span class=\"line\">                    <span class=\"string\">'resources'</span>: alloc[<span class=\"string\">'resources'</span>]</span><br><span class=\"line\">                &#125; <span class=\"keyword\">for</span> alloc <span class=\"keyword\">in</span> ar[<span class=\"string\">'allocations'</span>]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        allocation_request_version = <span class=\"string\">'1.12'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    url = <span class=\"string\">'/allocations/%s'</span> % consumer_uuid</span><br><span class=\"line\"></span><br><span class=\"line\">    payload = ar</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># We first need to determine if this is a move operation and if so</span></span><br><span class=\"line\">    <span class=\"comment\"># create the \"doubled-up\" allocation that exists for the duration of</span></span><br><span class=\"line\">    <span class=\"comment\"># the move operation against both the source and destination hosts</span></span><br><span class=\"line\">    r = self.get(url, global_request_id=context.global_id)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.status_code == <span class=\"number\">200</span>:</span><br><span class=\"line\">        current_allocs = r.json()[<span class=\"string\">'allocations'</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> current_allocs:</span><br><span class=\"line\">            payload = _move_operation_alloc_request(current_allocs, ar)</span><br><span class=\"line\"></span><br><span class=\"line\">    payload[<span class=\"string\">'project_id'</span>] = project_id</span><br><span class=\"line\">    payload[<span class=\"string\">'user_id'</span>] = user_id</span><br><span class=\"line\">    r = self.put(url, payload, version=allocation_request_version,</span><br><span class=\"line\">                 global_request_id=context.global_id)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.status_code != <span class=\"number\">204</span>:</span><br><span class=\"line\">        <span class=\"comment\"># NOTE(jaypipes): Yes, it sucks doing string comparison like this</span></span><br><span class=\"line\">        <span class=\"comment\"># but we have no error codes, only error messages.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">'concurrently updated'</span> <span class=\"keyword\">in</span> r.text:</span><br><span class=\"line\">            reason = (<span class=\"string\">'another process changed the resource providers '</span></span><br><span class=\"line\">                      <span class=\"string\">'involved in our attempt to put allocations for '</span></span><br><span class=\"line\">                      <span class=\"string\">'consumer %s'</span> % consumer_uuid)</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> Retry(<span class=\"string\">'claim_resources'</span>, reason)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            LOG.warning(</span><br><span class=\"line\">                <span class=\"string\">'Unable to submit allocation for instance '</span></span><br><span class=\"line\">                <span class=\"string\">'%(uuid)s (%(code)i %(text)s)'</span>,</span><br><span class=\"line\">                &#123;<span class=\"string\">'uuid'</span>: consumer_uuid,</span><br><span class=\"line\">                 <span class=\"string\">'code'</span>: r.status_code,</span><br><span class=\"line\">                 <span class=\"string\">'text'</span>: r.text&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r.status_code == <span class=\"number\">204</span></span><br></pre></td></tr></table></figure>\n<p>在这里是发起了一个PUT请求，尝试为<code>consumer_id</code>先声明所需要的资源，并根据返回的HTTP status code来判断是否声明资源成功。一旦能成功声明所需要的资源，就等于找到将该虚机调度到哪一个宿主节点，可以继续后面实际资源的创建等一系列流程，Placement API的工作到这里就暂告一段落了。但是对于scheduler，还有去consumer host的资源，即更新host state等内存中的信息等等。</p>\n<h3 id=\"目前社区Placement的发展\"><a href=\"#目前社区Placement的发展\" class=\"headerlink\" title=\"目前社区Placement的发展\"></a>目前社区Placement的发展</h3><p>通过订阅<code>openstack-dev</code>或者参加<code>nova</code>的weekly meeting，是可以非常及时的获取社区趋势和把握社区的开发进度。那么对Nova Schedule Team来讲，目前这两个月的进度，华为的<a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">姜逸坤</a>都给出了比较详尽的记录和整理：</p>\n<ul>\n<li><a href=\"https://github.com/Yikun/yikun.github.com/issues/66\" target=\"_blank\" rel=\"noopener\">Nova Scheduler Team Meeting跟踪（一月）</a></li>\n<li><a href=\"https://github.com/Yikun/yikun.github.com/issues/67\" target=\"_blank\" rel=\"noopener\">Nova Scheduler Team Meeting跟踪（二月）</a></li>\n</ul>\n<p>目前看起来，调度相关的team还在紧锣密鼓的继续完善Placement的功能，热火朝天向Rocky版本迈进。</p>\n<h2 id=\"有哪些不足\"><a href=\"#有哪些不足\" class=\"headerlink\" title=\"有哪些不足\"></a>有哪些不足</h2><p>目前看起来不足主要集中在使用中的bug及功能的待完善。比如目前还在开发的Nested Resource Providers；为获取Allocation candidates增加limit，控制每次取到的资源候选分配者的数量等等；还有比如主机迁移失败导致两个RP中都有占用的情况等等。像把Placement单独抽离出来，这也是社区有意向要做的事情。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"https://docs.openstack.org/nova/latest/user/placement.html\" target=\"_blank\" rel=\"noopener\">Placement API</a><br>[2].<a href=\"https://developer.openstack.org/api-ref/placement/\" target=\"_blank\" rel=\"noopener\">Placement API Reference</a><br>[3].<a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">Yikun’s blog</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"是什么\"><a href=\"#是什么\" class=\"headerlink\" title=\"是什么\"></a>是什么</h2><p>由于历史遗留原因，Nova认为资源全部是由计算节点提供，所以在报告某些资源使用时，Nova仅仅通过查询数据库中不同计算节点的数据，简单的做累加计算得到使用量和可用资源情况，这一定不是严谨科学的做法，于是，在N版中，Nova引入了Placement API，这是一个单独的RESTful API和数据模型，用于管理和查询资源提供者的资源存量、使用情况、分配记录等等，以提供更好、更准确的资源跟踪、调度和分配的功能。</p>\n<h2 id=\"有什么\"><a href=\"#有什么\" class=\"headerlink\" title=\"有什么\"></a>有什么</h2><h3 id=\"代码目录\"><a href=\"#代码目录\" class=\"headerlink\" title=\"代码目录\"></a>代码目录</h3><p>由于Nova Placement API是单独剥离出来的RESTful API，同时也有自己单独的Endpoint，并且与Nova API服务启动在不同的端口，单独提供服务，那么，在代码目录上来看，也是相对独立的，其代码实现均在<code>/nova/api/openstack/placement/</code>下，那么我看来看一下Nova Placement API的代码目录结构：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">F:nova ZH.F$ tree  -C  api/openstack/placement</span><br><span class=\"line\">api/openstack/placement</span><br><span class=\"line\">├── __init__.py</span><br><span class=\"line\">├── auth.py</span><br><span class=\"line\">├── deploy.py</span><br><span class=\"line\">├── handler.py</span><br><span class=\"line\">├── handlers</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   ├── aggregate.py</span><br><span class=\"line\">│   ├── allocation.py</span><br><span class=\"line\">│   ├── allocation_candidate.py</span><br><span class=\"line\">│   ├── inventory.py</span><br><span class=\"line\">│   ├── resource_class.py</span><br><span class=\"line\">│   ├── resource_provider.py</span><br><span class=\"line\">│   ├── root.py</span><br><span class=\"line\">│   ├── trait.py</span><br><span class=\"line\">│   └── usage.py</span><br><span class=\"line\">├── lib.py</span><br><span class=\"line\">├── microversion.py</span><br><span class=\"line\">├── policy.py</span><br><span class=\"line\">├── requestlog.py</span><br><span class=\"line\">├── rest_api_version_history.rst</span><br><span class=\"line\">├── schemas</span><br><span class=\"line\">│   ├── __init__.py</span><br><span class=\"line\">│   ├── aggregate.py</span><br><span class=\"line\">│   ├── allocation.py</span><br><span class=\"line\">│   ├── allocation_candidate.py</span><br><span class=\"line\">│   ├── inventory.py</span><br><span class=\"line\">│   ├── resource_class.py</span><br><span class=\"line\">│   ├── trait.py</span><br><span class=\"line\">│   └── usage.py</span><br><span class=\"line\">├── util.py</span><br><span class=\"line\">├── wsgi.py</span><br><span class=\"line\">└── wsgi_wrapper.py</span><br></pre></td></tr></table></figure>\n<p>其中，在<code>api/openstack/placement/schemas</code>目录下，可以看到基本数据模型的schema，不过<code>resource privoder</code>的schema定义在了<code>api/openstack/placement/handlers/resource_provider.py</code>中。下面，对照schema，我们对其中的一些概念进行了解。</p>\n<h3 id=\"Nova-Placement-API中的一些概念\"><a href=\"#Nova-Placement-API中的一些概念\" class=\"headerlink\" title=\"Nova Placement API中的一些概念\"></a>Nova Placement API中的一些概念</h3><h4 id=\"Resource-Provider\"><a href=\"#Resource-Provider\" class=\"headerlink\" title=\"Resource Provider\"></a>Resource Provider</h4><p>即资源提供者，通过其schema可以看到结构比较简单，只包含UUID和RP（Resource Provider简写，下同）的一些基本信息，比如name：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">GET_RPS_SCHEMA_1_0 = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"object\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"properties\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"name\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"string\"</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"uuid\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"string\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"format\"</span>: <span class=\"string\">\"uuid\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"additionalProperties\"</span>: <span class=\"keyword\">False</span>,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>资源提供者可能是一个计算节点，也可能是一个共享存储池或者一个IP分配池子，那么不同的RP，提供的资源多种多样，于是就引入了Resource Class，即资源类型的概念。</p>\n<h4 id=\"Resource-Class\"><a href=\"#Resource-Class\" class=\"headerlink\" title=\"Resource Class\"></a>Resource Class</h4><p>即资源类型，比如计算节点提供的资源可能是CPU、内存、PCI设备、本地临时磁盘等等。每种被消费的资源都会按照类别进行标注和跟踪。</p>\n<p>之所以引入这个概念，目的是解决Nova中hard-coded的资源类型扩展性问题，比如CPU资源，可能记录在Instance对象的<em>vcpus</em>字段中，那么之后再增加新的资源类型，都需要修改数据表，而修改数据表的过程都会停机维护，给系统带来许多downtime，这是不可接受的。</p>\n<p>Placement API提供了一些标准资源类别，如：</p>\n<ul>\n<li>VCPU</li>\n<li>MEMORY_MB</li>\n<li>DISK_GB</li>\n<li>PCI_DEVICE</li>\n<li>NUMA_SOCKET</li>\n<li>NUMA_CORE</li>\n<li>NUMA_THREAD</li>\n<li>IPV4_ADDRESS</li>\n<li>…</li>\n</ul>\n<p>注：数据来自<a href=\"https://specs.openstack.org/openstack/nova-specs/specs/mitaka/implemented/resource-classes.html\" target=\"_blank\" rel=\"noopener\">BP:Introduce resource classes</a></p>\n<p>除了以上标准资源类别，Placement API还在O版中为RP增加了自定义Resource Class的能力，比如自动以的FPGA、裸机调度等等。</p>\n<h4 id=\"Inventory\"><a href=\"#Inventory\" class=\"headerlink\" title=\"Inventory\"></a>Inventory</h4><p>即库存，存量。用于记录超配比、资源总量、存量、步长（step_size）、最小和最大单位等信息，可以看一下它的schema：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">BASE_INVENTORY_SCHEMA = &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"object\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"properties\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"resource_provider_generation\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"total\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"reserved\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"min_unit\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"max_unit\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"step_size\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"integer\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.MAX_INT,</span><br><span class=\"line\">            <span class=\"string\">\"minimum\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"allocation_ratio\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"type\"</span>: <span class=\"string\">\"number\"</span>,</span><br><span class=\"line\">            <span class=\"string\">\"maximum\"</span>: db.SQL_SP_FLOAT_MAX</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"required\"</span>: [</span><br><span class=\"line\">        <span class=\"string\">\"total\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"resource_provider_generation\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"additionalProperties\"</span>: <span class=\"keyword\">False</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中的<code>resource_provider_generation</code>字段，是一个一致性视图的标志位，在获取RP列表时的<code>generation</code>功能是相同的，这就是CAS（Compare and swap），即乐观锁技术——当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p>\n<h4 id=\"Usage\"><a href=\"#Usage\" class=\"headerlink\" title=\"Usage\"></a>Usage</h4><p>即用量，使用情况。可以查看某个RP的使用情况，也可以查看项目下某用户的资源使用情况。</p>\n<h4 id=\"Aggregate\"><a href=\"#Aggregate\" class=\"headerlink\" title=\"Aggregate\"></a>Aggregate</h4><p>在Ocata版本，社区开始将nova-scheduler服务与Placement API进行集成，并在scheduler进行了一些修改，使用Placement API进行满足一些基本资源请求条件的计算节点过滤。添加了aggregates，来提供resource provider的分组机制。</p>\n<h4 id=\"Allocation\"><a href=\"#Allocation\" class=\"headerlink\" title=\"Allocation\"></a>Allocation</h4><p>即已分配量，某一个RP对某一个资源消费者（即某个实例）所分配的资源。</p>\n<h4 id=\"Allocation-candidate\"><a href=\"#Allocation-candidate\" class=\"headerlink\" title=\"Allocation-candidate\"></a>Allocation-candidate</h4><p>即分配的候选者（资源提供者），举个例子，用户说，我需要1个VCPU，512MB内存，1GB磁盘的资源，Placement你帮我找找看看，有没有合适的资源。然后Placement就要做各种处理，反馈给用户，哪些是可以分配的候选资源提供者。</p>\n<h4 id=\"Trait\"><a href=\"#Trait\" class=\"headerlink\" title=\"Trait\"></a>Trait</h4><p>字面意思，特征，特性。ResourceProvider和Allocation可以在定量的角度，控制和管理boot虚机请求，然而我们还需要从定性的角度来区分资源，最经典的例子是当我们创建虚机时，需要向不同的RP请求磁盘资源，用户可能请求80GB的磁盘，但也可能请求80GB的SSD。这就是Trait的意义。</p>\n<h3 id=\"数据库及数据表\"><a href=\"#数据库及数据表\" class=\"headerlink\" title=\"数据库及数据表\"></a>数据库及数据表</h3><p>目前我安装的Pike版本的Packstack环境中，能看到有一个<code>nova_placement</code>数据库，但是没有任何表（也许是社区希望能把placement相关的表放到这个数据库中？），Placement对应的数据库用的还是<code>nova_api</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">MariaDB [nova_placement]&gt; use nova_api;</span><br><span class=\"line\">Reading table information for completion of table and column names</span><br><span class=\"line\">You can turn off this feature to get a quicker startup with -A</span><br><span class=\"line\"></span><br><span class=\"line\">Database changed</span><br><span class=\"line\">MariaDB [nova_api]&gt; show tables;</span><br><span class=\"line\">+------------------------------+</span><br><span class=\"line\">| Tables_in_nova_api           |</span><br><span class=\"line\">+------------------------------+</span><br><span class=\"line\">| aggregate_hosts              |</span><br><span class=\"line\">| aggregate_metadata           |</span><br><span class=\"line\">| aggregates                   |</span><br><span class=\"line\">| allocations                  |</span><br><span class=\"line\">| build_requests               |</span><br><span class=\"line\">| cell_mappings                |</span><br><span class=\"line\">| consumers                    |</span><br><span class=\"line\">| flavor_extra_specs           |</span><br><span class=\"line\">| flavor_projects              |</span><br><span class=\"line\">| flavors                      |</span><br><span class=\"line\">| host_mappings                |</span><br><span class=\"line\">| instance_group_member        |</span><br><span class=\"line\">| instance_group_policy        |</span><br><span class=\"line\">| instance_groups              |</span><br><span class=\"line\">| instance_mappings            |</span><br><span class=\"line\">| inventories                  |</span><br><span class=\"line\">| key_pairs                    |</span><br><span class=\"line\">| migrate_version              |</span><br><span class=\"line\">| placement_aggregates         |</span><br><span class=\"line\">| project_user_quotas          |</span><br><span class=\"line\">| projects                     |</span><br><span class=\"line\">| quota_classes                |</span><br><span class=\"line\">| quota_usages                 |</span><br><span class=\"line\">| quotas                       |</span><br><span class=\"line\">| request_specs                |</span><br><span class=\"line\">| reservations                 |</span><br><span class=\"line\">| resource_classes             |</span><br><span class=\"line\">| resource_provider_aggregates |</span><br><span class=\"line\">| resource_provider_traits     |</span><br><span class=\"line\">| resource_providers           |</span><br><span class=\"line\">| traits                       |</span><br><span class=\"line\">| users                        |</span><br><span class=\"line\">+------------------------------+</span><br></pre></td></tr></table></figure>\n<p>可以从表明上看到那些是Placement相关的表，这里就不展开了。</p>\n<h3 id=\"初始化及加载方式\"><a href=\"#初始化及加载方式\" class=\"headerlink\" title=\"初始化及加载方式\"></a>初始化及加载方式</h3><p>我们前面提到Nova Placement API是单独的RESTful API，那么是如何进行初始化的呢？带着这个问题，我们先查看nova的<code>setup.cfg</code>，其中配置了wsgi_scripts如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">wsgi_scripts =</span><br><span class=\"line\">    nova-placement-api = nova.api.openstack.placement.wsgi:init_application</span><br><span class=\"line\">    nova-api-wsgi = nova.api.openstack.compute.wsgi:init_application</span><br><span class=\"line\">    nova-metadata-wsgi = nova.api.metadata.wsgi:init_application</span><br></pre></td></tr></table></figure>\n<p>其中可以看到nova-placement-api的初始化来自 <code>nova.api.openstack.placement.wsgi.init_application</code> ，代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">init_application</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># initialize the config system</span></span><br><span class=\"line\">    conffile = _get_config_file()</span><br><span class=\"line\">    config.parse_args([], default_config_files=[conffile])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># initialize the logging system</span></span><br><span class=\"line\">    setup_logging(conf.CONF)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># dump conf if we're at debug</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> conf.CONF.debug:</span><br><span class=\"line\">        conf.CONF.log_opt_values(</span><br><span class=\"line\">            logging.getLogger(__name__),</span><br><span class=\"line\">            logging.DEBUG)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># build and return our WSGI app</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> deploy.loadapp(conf.CONF)</span><br></pre></td></tr></table></figure>\n<p>其中在最后构造WSGI app并返回，即调用了deploy.loadapp(conf.CONF)：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadapp</span><span class=\"params\">(config, project_name=NAME)</span>:</span></span><br><span class=\"line\">    application = deploy(config, project_name)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> application</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">deploy</span><span class=\"params\">(conf, project_name)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Assemble the middleware pipeline leading to the placement app.\"\"\"</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    application = handler.PlacementHandler()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">for</span> middleware <span class=\"keyword\">in</span> (microversion_middleware,</span><br><span class=\"line\">                       fault_wrap,</span><br><span class=\"line\">                       request_log,</span><br><span class=\"line\">                       context_middleware,</span><br><span class=\"line\">                       auth_middleware,</span><br><span class=\"line\">                       cors_middleware,</span><br><span class=\"line\">                       req_id_middleware,</span><br><span class=\"line\">                       ):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> middleware:</span><br><span class=\"line\">            application = middleware(application)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> application</span><br></pre></td></tr></table></figure>\n<p>而这里的handler.PlacementHandler()就是我们的Placement的API入口：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PlacementHandler</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Serve Placement API.</span></span><br><span class=\"line\"><span class=\"string\">    Dispatch to handlers defined in ROUTE_DECLARATIONS.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, **local_config)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># NOTE(cdent): Local config currently unused.</span></span><br><span class=\"line\">        self._map = make_map(ROUTE_DECLARATIONS)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span><span class=\"params\">(self, environ, start_response)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># All requests but '/' require admin.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> environ[<span class=\"string\">'PATH_INFO'</span>] != <span class=\"string\">'/'</span>:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<p>可以看到，PlacementHandler在<code>__init__</code>中根据路由定义构造了map，同时在<code>__call__</code>中对请求进行dispatch。这就是一个典型的WSGI应用：</p>\n<blockquote>\n<p>WSGI application is a callable object (a function, method, class, or an instance with a <code>__call__</code> method) that accepts two positional arguments: WSGI environment variables and a callable with two required positional arguments which starts the response;</p>\n</blockquote>\n<p>找到了初始化，那么Placement API加载和启动是如何实现的？</p>\n<p>首先，nova-placement-api是单独的脚本，在httpd中启动，与keystone（在12年就完成了WSGI化，参见<a href=\"http://adam.younglogic.com/2012/03/keystone-should-move-to-apache-httpd/\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>）类似，通过<code>systemctl status httpd</code>是可以看到的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# systemctl status httpd</span><br><span class=\"line\">● httpd.service - The Apache HTTP Server</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Fri 2018-02-02 09:17:51 CST; 1 weeks 0 days ago</span><br><span class=\"line\">     Docs: man:httpd(8)</span><br><span class=\"line\">           man:apachectl(8)</span><br><span class=\"line\">  Process: 4087 ExecReload=/usr/sbin/httpd $OPTIONS -k graceful (code=exited, status=0/SUCCESS)</span><br><span class=\"line\"> Main PID: 1309 (httpd)</span><br><span class=\"line\">   Status: &quot;Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec&quot;</span><br><span class=\"line\">   CGroup: /system.slice/httpd.service</span><br><span class=\"line\">           ├─ 1309 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">           ├─ 4108 keystone-admin  -DFOREGROUND</span><br><span class=\"line\"></span><br><span class=\"line\">▽</span><br><span class=\"line\">           ├─ 4109 keystone-admin  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4110 keystone-admin  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4111 keystone-admin  -DFOREGROUND</span><br><span class=\"line\"></span><br><span class=\"line\">▽</span><br><span class=\"line\">           ├─ 4112 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4113 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4114 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4115 keystone-main   -DFOREGROUND</span><br><span class=\"line\">           ├─ 4116 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4117 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4118 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4119 placement_wsgi  -DFOREGROUND</span><br><span class=\"line\">           ├─ 4121 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">           ├─ 4122 /usr/sbin/httpd -DFOREGROUND</span><br><span class=\"line\">…</span><br></pre></td></tr></table></figure>\n<p>知道是在httpd启动的，我们去查看配置文件目录：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# ll /etc/httpd/conf.d/</span><br><span class=\"line\">total 36</span><br><span class=\"line\">-rw-r-----. 1 root root  136 Jan 12 17:46 00-nova-placement-api.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  943 Jan 12 17:48 10-keystone_wsgi_admin.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  938 Jan 12 17:48 10-keystone_wsgi_main.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  941 Jan 12 17:49 10-placement_wsgi.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  697 Jan 12 17:48 15-default.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root 2926 Oct 20 04:39 autoindex.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  366 Oct 20 04:39 README</span><br><span class=\"line\">-rw-r--r--. 1 root root 1252 Oct 20 00:44 userdir.conf</span><br><span class=\"line\">-rw-r--r--. 1 root root  824 Oct 20 00:44 welcome.conf</span><br></pre></td></tr></table></figure>\n<p>其中，10-placement_wsgi.conf 中定义了WSGIScriptAllias：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">  WSGIProcessGroup placement-api</span><br><span class=\"line\">  WSGIScriptAlias /placement &quot;/var/www/cgi-bin/nova/nova-placement-api”</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>也就是说，url为<code>/placement/xxx</code>的请求会使得httpd服务运行定义在<code>/var/www/cgi-bin/nova/nova-placement-api</code>中的WSGI应用，在这个文件中，我们会看到：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nova.api.openstack.placement.wsgi <span class=\"keyword\">import</span> init_application</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__”:</span></span><br><span class=\"line\"><span class=\"string\">    import argparse</span></span><br><span class=\"line\"><span class=\"string\">    import socket</span></span><br><span class=\"line\"><span class=\"string\">    import sys</span></span><br><span class=\"line\"><span class=\"string\">    import wsgiref.simple_server as wss</span></span><br><span class=\"line\"><span class=\"string\">    …</span></span><br><span class=\"line\"><span class=\"string\">    server = wss.make_server(args.host, args.port, init_application())</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>也就对应了前面提到的PlacementHandler中的<code>nova.api.openstack.placement.wsgi.init_application</code>，至此，我们就了解了Nova Placement API的初始化和加载方式。</p>\n<h3 id=\"API路由定义\"><a href=\"#API路由定义\" class=\"headerlink\" title=\"API路由定义\"></a>API路由定义</h3><p>上一小节提到了PlacementHandler初始化时，根据路由定义构造了map映射，我们就来看下文件<code>api/openstack/placement/handler.py</code>中的API<code>ROUTE_DECLARATIONS</code>:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># URLs and Handlers</span></span><br><span class=\"line\"><span class=\"comment\"># NOTE(cdent): When adding URLs here, do not use regex patterns in</span></span><br><span class=\"line\"><span class=\"comment\"># the path parameters (e.g. &#123;uuid:[0-9a-zA-Z-]+&#125;) as that will lead</span></span><br><span class=\"line\"><span class=\"comment\"># to 404s that are controlled outside of the individual resources</span></span><br><span class=\"line\"><span class=\"comment\"># and thus do not include specific information on the why of the 404.</span></span><br><span class=\"line\">ROUTE_DECLARATIONS = &#123;</span><br><span class=\"line\">    <span class=\"string\">'/'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: root.home,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"comment\"># NOTE(cdent): This allows '/placement/' and '/placement' to</span></span><br><span class=\"line\">    <span class=\"comment\"># both work as the root of the service, which we probably want</span></span><br><span class=\"line\">    <span class=\"comment\"># for those situations where the service is mounted under a</span></span><br><span class=\"line\">    <span class=\"comment\"># prefix (as it is in devstack). While weird, an empty string is</span></span><br><span class=\"line\">    <span class=\"comment\"># a legit key in a dictionary and matches as desired in Routes.</span></span><br><span class=\"line\">    <span class=\"string\">''</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: root.home,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_classes'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_class.list_resource_classes,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: resource_class.create_resource_class</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_classes/&#123;name&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_class.get_resource_class,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: resource_class.update_resource_class,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: resource_class.delete_resource_class,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_provider.list_resource_providers,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: resource_provider.create_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: resource_provider.get_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: resource_provider.delete_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: resource_provider.update_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/inventories'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: inventory.get_inventories,</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: inventory.create_inventory,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: inventory.set_inventories,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: inventory.delete_inventories</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/inventories/&#123;resource_class&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: inventory.get_inventory,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: inventory.update_inventory,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: inventory.delete_inventory</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/usages'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: usage.list_usages</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/aggregates'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: aggregate.get_aggregates,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: aggregate.set_aggregates</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/allocations'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation.list_for_resource_provider,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocations'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'POST'</span>: allocation.set_allocations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocations/&#123;consumer_uuid&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation.list_for_consumer,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: allocation.set_allocations_for_consumer,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: allocation.delete_allocations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/allocation_candidates'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: allocation_candidate.list_allocation_candidates,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/traits'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.list_traits,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/traits/&#123;name&#125;'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.get_trait,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: trait.put_trait,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: trait.delete_trait,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/resource_providers/&#123;uuid&#125;/traits'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: trait.list_traits_for_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'PUT'</span>: trait.update_traits_for_resource_provider,</span><br><span class=\"line\">        <span class=\"string\">'DELETE'</span>: trait.delete_traits_for_resource_provider</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">'/usages'</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">'GET'</span>: usage.get_total_usages,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"怎么用\"><a href=\"#怎么用\" class=\"headerlink\" title=\"怎么用\"></a>怎么用</h2><h3 id=\"如何部署\"><a href=\"#如何部署\" class=\"headerlink\" title=\"如何部署\"></a>如何部署</h3><p>在官方文档中提到，placement api服务必须在升级到14.0.0，即N版后，升级到15.0.0，即O版之前进行部署。nova-compute服务中的resource tracker需要获取placement的资源提供者存量和分配信息（这部分信息将在O版中由nova-scheduler使用）。</p>\n<ol>\n<li>部署API服务 - Placement API目前还是在nova中进行开发，但是设计上是相对独立的，以便将来分离出来成为单独的项目。作为一个单独的WSGI应用，可使用Apahce2或者Nginx部署API服务。</li>\n<li>同步数据库 - 升级N版时，需要手动执行<code>nova-manage api_db sync</code>命令进行数据库同步，这样Placement相关的数据表就会被创建出来</li>\n<li>在keystone中创建具有admin角色的placement service user，同时更新服务目录，配置单独的endpoint.</li>\n<li>配置nova.conf中[placement]部分，并重启nova-compute服务。不过对于我们P版，经过了O版的一系列功能补齐，尤其是在O版中，如果在<code>nova.conf</code>中不配置<code>[placement]</code>部分的内容，就无法启动<code>nova-compute</code>服务。</li>\n</ol>\n<blockquote>\n<p>The nova-compute service will fail to start in Ocata unless the [placement] section of nova.conf on the compute is configured.</p>\n</blockquote>\n<p>更多部署相关的可参见官方文档，<a href=\"https://docs.openstack.org/nova/latest/user/placement.html#deployment\" target=\"_blank\" rel=\"noopener\">&gt;&gt;传送门</a>。</p>\n<h3 id=\"OSC-Placement-Plugin\"><a href=\"#OSC-Placement-Plugin\" class=\"headerlink\" title=\"OSC Placement Plugin\"></a>OSC Placement Plugin</h3><p>从前面的API路由定义，我们可以看到，目前支持了这么些功能，那么我们可以简单的用一下，第一个想到的是cURL命令，我们可以使用该命令模拟发起请求，调用Placement API，比如查看resource providers list，首先我们获取token：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 首先得到auth token</span><br><span class=\"line\">curl -d '&#123;\"auth\": &#123;\"tenantName\": \"admin\", \"passwordCredentials\": &#123;\"username\": \"admin\", \"password\": \"1234qwer\"&#125;&#125;&#125;' \\</span><br><span class=\"line\">-H \"Content-type: application/json\" \\</span><br><span class=\"line\">http://localhost:5000/v2.0/tokens</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"issued_at\"</span>: <span class=\"string\">\"2018-02-07T07:40:07.000000Z\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"expires\"</span>: <span class=\"string\">\"2018-02-07T08:40:07.000000Z\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itnL6Q-TSWhOn7uZpdQsYqqJDmwgtzCm-hcpg17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"tenant\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"admin tenant\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"enabled\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"6387fc88b3064149a12eb5b58669e0b2\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"admin\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># token的获取方式，还可以用OSC命令：</span><br><span class=\"line\">openstack token issue | grep ' id' | awk '&#123;print $4&#125;'</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#得到token之后，构造请求，查看resource providers list：</span><br><span class=\"line\">curl -X GET /</span><br><span class=\"line\">-H 'x-auth-token:gAAAAABaeq1XrNDoU_F_iRk8uC0lOxYpyzLMW_YRs_ggJHuF1OpGHBN-pymQut-Bp2Er-J4XkYfQkMdJbRlBIBhq4wfhZMHZvag1itn17IwN5FZSanCbcy6S96YZ0Zci5STWNka40861Mn8UQ2yRE’ /</span><br><span class=\"line\">http://192.168.122.105:8778/placement/resource_providers</span><br><span class=\"line\"></span><br><span class=\"line\">#得到resources providers list</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"resource_providers\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"generation\"</span>: <span class=\"number\">30</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"uuid\"</span>: <span class=\"string\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"links\"</span>: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"self\"</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"inventories\"</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"href\"</span>: <span class=\"string\">\"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\"</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"rel\"</span>: <span class=\"string\">\"usages\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"f-packstack\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中的<code>generation</code>字段，是一个一致性视图的标志位，跟获取RP的inventories中的<code>resource_provider_generation</code>功能是相同的，其实算作是乐观锁技术，即CAS，Compare and swap，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p>\n<p>下面来一个获取aggregate和inventories的示例，注意，aggregate的API是在1.1版本中实现的，所以要在请求头指定<code>OpenStack-API-Version: placement 1.1</code>：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/aggregates \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H \"X-Auth-Token: gAAAAABaf5nafUZyFTl_pztozfB65wkP0c26HQqrxRgAiJGsxY8g743LxFOZEI3bF_l37xh0UajbF5nQ1kLYGAonOGphV4AivXgYMUOJ84uGrHjpC60NlmNzzQ3lJGVJb-pNxQw74WsMOc9I0D2B5Mzmf2OgDeictae5f0UFgTR9DFb_vaWCWQ4\" \\</span><br><span class=\"line\">-H \"OpenStack-API-Version: placement 1.1\"</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Date: Fri, 15 Sep 2017 09:35:21 GMT</span><br><span class=\"line\">Server: Apache/2.4.18 (Ubuntu)</span><br><span class=\"line\">Content-Length: 18</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\">OpenStack-API-Version: placement 1.1</span><br><span class=\"line\">vary: OpenStack-API-Version</span><br><span class=\"line\">x-openstack-request-id: req-ab28194f-8389-40a1-9a2b-a94dbc792573</span><br><span class=\"line\">Connection: close</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;<span class=\"attr\">\"aggregates\"</span>: []&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H 'x-auth-token:gAAAAABae6lX26bp4PEVHCac0cjFnNl18W8DjeQKXDYvuKP4drRJ8t6DC-9uzcCm4E9Xf7NjqSqkRX6WGsE3qHmpAt7GmIu1SrLCtyEOVM2IQP5XLNrwMekGGrzQ_ADOaSTc9XpPpCYyYwzT-zCAvWG-T9T6Ip4l3zHWLwNBBPrm35gBZVZeslQ' \\</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"resource_provider_generation\"</span>: <span class=\"number\">30</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"inventories\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"VCPU\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">16</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">4</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">128</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"attr\">\"MEMORY_MB\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">1.5</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">8095</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">512</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">8095</span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"attr\">\"DISK_GB\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocation_ratio\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"total\"</span>: <span class=\"number\">49</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"reserved\"</span>: <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"step_size\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"min_unit\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">\"max_unit\"</span>: <span class=\"number\">49</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>贴心的社区妥妥的想到了如何可以方便用户操作Placement API，所以开发了一个OpenStackClient Plugin，即<a href=\"https://github.com/openstack/osc-placement\" target=\"_blank\" rel=\"noopener\">osc-placement</a>，需要我们手动安装使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ pip install osc-placement</span><br></pre></td></tr></table></figure>\n<p>有了OSC placement commands，我们不再需要使用curl命令模拟HTTP请求，并且可以非常轻松的进行操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@f-packstack ~(keystone_admin)]# openstack --debug resource provider list</span><br><span class=\"line\">...</span><br><span class=\"line\">http://192.168.122.105:8778 \"GET /placement/resource_providers HTTP/1.1\" 200 185</span><br><span class=\"line\">RESP: [200] Date: Thu, 08 Feb 2018 05:59:56 GMT Server: Apache/2.4.6 (CentOS) OpenStack-API-Version: placement 1.0 vary: OpenStack-API-Version,Accept-Encoding x-openstack-request-id: req-c6077c19-ca05-4cab-95fa-6129ff989400 Content-Encoding: gzip Content-Length: 185 Keep-Alive: timeout=15, max=100 Connection: Keep-Alive Content-Type: application/json</span><br><span class=\"line\">RESP BODY: &#123;\"resource_providers\": [&#123;\"generation\": 30, \"uuid\": \"4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"links\": [&#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c\", \"rel\": \"self\"&#125;, &#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/inventories\", \"rel\": \"inventories\"&#125;, &#123;\"href\": \"/placement/resource_providers/4cae2ef8-30eb-4571-80c3-3289e86bd65c/usages\", \"rel\": \"usages\"&#125;], \"name\": \"f-packstack\"&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">GET call to placement for http://192.168.122.105:8778/placement/resource_providers used request id req-c6077c19-ca05-4cab-95fa-6129ff989400</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">| uuid                                 | name        | generation |</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">| 4cae2ef8-30eb-4571-80c3-3289e86bd65c | f-packstack |         30 |</span><br><span class=\"line\">+--------------------------------------+-------------+------------+</span><br><span class=\"line\">clean_up ListResourceProvider:</span><br><span class=\"line\">END return value: 0</span><br></pre></td></tr></table></figure>\n<p>当然还有很多其他的命令，有兴趣的可以尝试玩一下。</p>\n<h3 id=\"划重点：Nova调度与Placement-API的结合\"><a href=\"#划重点：Nova调度与Placement-API的结合\" class=\"headerlink\" title=\"划重点：Nova调度与Placement API的结合\"></a>划重点：Nova调度与Placement API的结合</h3><p>首先来一张图，来认识一下在P版中，创建一台虚机过程中各个服务之间的调用/调度关系：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/boot-instance-pike.png\" alt=\"\"><br>可以看到，在nova-scheduler与Placement API的交互过程中，有两部分：</p>\n<ol>\n<li>Get allocation candidates</li>\n<li>Claim Resources<br>下面，我们结合代码详细的讲述一下调度过程。</li>\n</ol>\n<h4 id=\"Get-allocation-candidates\"><a href=\"#Get-allocation-candidates\" class=\"headerlink\" title=\"Get allocation candidates\"></a>Get allocation candidates</h4><p>目前在调度时，nova-conductor在<code>nova.conductor.manager.ComputeTaskManager#_schedule_instances</code>中调用了方法<code>nova.scheduler.client.SchedulerClient#select_destinations</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@utils.retry_select_destinations</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, context, spec_obj, instance_uuids,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.queryclient.select_destinations(context, spec_obj,</span><br><span class=\"line\">            instance_uuids, return_objects, return_alternates)</span><br></pre></td></tr></table></figure>\n<p>其中<code>SchedulerClient</code>又调用了<code>SchedulerQueryClient</code>，即调用了<code>nova.scheduler.client.query.SchedulerQueryClient#select_destinations</code>方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, context, spec_obj, instance_uuids,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.scheduler_rpcapi.select_destinations(context, spec_obj,</span><br><span class=\"line\">            instance_uuids, return_objects, return_alternates)</span><br></pre></td></tr></table></figure>\n<p>在该方法中发起RPC调用，调用了<code>nova.scheduler.manager.SchedulerManager#select_destinations</code>方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@messaging.expected_exceptions(exception.NoValidHost)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">select_destinations</span><span class=\"params\">(self, ctxt, request_spec=None,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        filter_properties=None, spec_obj=_sentinel, instance_uuids=None,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        return_objects=False, return_alternates=False)</span>:</span></span><br><span class=\"line\">    LOG.debug(<span class=\"string\">\"Starting to schedule for instances: %s\"</span>, instance_uuids)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\"># 其中USES_ALLOCATION_CANDIDATES默认值为True，</span></span><br><span class=\"line\">    <span class=\"comment\"># 即表示使用Nova Placement API来选取资源分配候选者</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.driver.USES_ALLOCATION_CANDIDATES:</span><br><span class=\"line\">        res = self.placement_client.get_allocation_candidates(ctxt,</span><br><span class=\"line\">        <span class=\"keyword\">if</span> res <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">            alloc_reqs, provider_summaries, allocation_request_version = (</span><br><span class=\"line\">                    <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            (alloc_reqs, provider_summaries,</span><br><span class=\"line\">                        allocation_request_version) = res</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> alloc_reqs:</span><br><span class=\"line\">            LOG.debug(<span class=\"string\">\"Got no allocation candidates from the Placement \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"API. This may be a temporary occurrence as compute \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"nodes start up and begin reporting inventory to \"</span></span><br><span class=\"line\">                      <span class=\"string\">\"the Placement service.\"</span>)</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> exception.NoValidHost(reason=<span class=\"string\">\"\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># Build a dict of lists of allocation requests, keyed by</span></span><br><span class=\"line\">            <span class=\"comment\"># provider UUID, so that when we attempt to claim resources for</span></span><br><span class=\"line\">            <span class=\"comment\"># a host, we can grab an allocation request easily</span></span><br><span class=\"line\">            alloc_reqs_by_rp_uuid = collections.defaultdict(list)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> ar <span class=\"keyword\">in</span> alloc_reqs:</span><br><span class=\"line\">                <span class=\"keyword\">for</span> rp_uuid <span class=\"keyword\">in</span> ar[<span class=\"string\">'allocations'</span>]:</span><br><span class=\"line\">                    alloc_reqs_by_rp_uuid[rp_uuid].append(ar)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Only return alternates if both return_objects and return_alternates</span></span><br><span class=\"line\">    <span class=\"comment\"># are True.</span></span><br><span class=\"line\">    return_alternates = return_alternates <span class=\"keyword\">and</span> return_objects</span><br><span class=\"line\">    <span class=\"comment\"># self.driver在这里，我们配置使用的是FilterScheduler，</span></span><br><span class=\"line\">    <span class=\"comment\"># 即又调用了nova.scheduler.filter_scheduler.FilterScheduler#select_destinations</span></span><br><span class=\"line\">    <span class=\"comment\"># 这个我们后面会提到</span></span><br><span class=\"line\">    selections = self.driver.select_destinations(ctxt, spec_obj,</span><br><span class=\"line\">            instance_uuids, alloc_reqs_by_rp_uuid, provider_summaries,</span><br><span class=\"line\">            allocation_request_version, return_alternates)</span><br><span class=\"line\">    <span class=\"comment\"># If `return_objects` is False, we need to convert the selections to</span></span><br><span class=\"line\">    <span class=\"comment\"># the older format, which is a list of host state dicts.</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> return_objects:</span><br><span class=\"line\">        selection_dicts = [sel[<span class=\"number\">0</span>].to_dict() <span class=\"keyword\">for</span> sel <span class=\"keyword\">in</span> selections]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jsonutils.to_primitive(selection_dicts)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> selections</span><br></pre></td></tr></table></figure>\n<p>我们先来说，这里调用的Placement API，发起一个GET请求，获取Allocation Candidates。</p>\n<blockquote>\n<p>注：没有找到这个API对应的OSC命令，所以我们使用curl命令进行模拟。<br><br>另，Allocation candidates API requests are availiable starting from version <code>1.10</code>.</p>\n</blockquote>\n<figure class=\"highlight json\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 获取token</span><br><span class=\"line\">[root@f-packstack ~(keystone_admin)]# openstack token issue | grep ' id' | awk '&#123;print $4&#125;'</span><br><span class=\"line\">gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE</span><br><span class=\"line\"># 使用curl命令发起GET请求，请求参数是resources=DISK_GB:1,MEMORY_MB:512,VCPU:1</span><br><span class=\"line\">curl -g -i -X GET http://192.168.122.105:8778/placement/allocation_candidates?resources=DISK_GB:1,MEMORY_MB:512,VCPU:1 \\</span><br><span class=\"line\">-H \"User-Agent: python-novaclient\" \\</span><br><span class=\"line\">-H \"Accept: application/json\" \\</span><br><span class=\"line\">-H \"X-Auth-Token: gAAAAABajn5nIXMCkZQBwcl7LdqeCV8pOuFSN4ltIUa9GcJ_PO4x920rpw5fwz43BZ8rkKIVlWF1OHfDNs1GRhqhoUHPNkEU6SRNK8G1BFKoHKD4nDJESGhSMrGwDGTIsYeaANqM2D_48tUo_pY0eqCD8iEcRDHi-QCH-c_t_m44So0cHvlXtdE\" \\</span><br><span class=\"line\">-H \"OpenStack-API-Version: placement 1.10\"</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Date: Thu, 22 Feb 2018 08:55:27 GMT</span><br><span class=\"line\">Server: Apache/2.4.6 (CentOS)</span><br><span class=\"line\">OpenStack-API-Version: placement 1.10</span><br><span class=\"line\">vary: OpenStack-API-Version,Accept-Encoding</span><br><span class=\"line\">x-openstack-request-id: req-234db1eb-1386-4e89-99bd-c9269270c603</span><br><span class=\"line\">Content-Length: 381</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"attr\">\"provider_summaries\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"resources\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"VCPU\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">64</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"attr\">\"MEMORY_MB\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">1024</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">11374</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"attr\">\"DISK_GB\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"used\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">                    <span class=\"attr\">\"capacity\"</span>: <span class=\"number\">49</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"allocation_requests\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"allocations\"</span>: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"attr\">\"resource_provider\"</span>: &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"uuid\"</span>: <span class=\"string\">\"4cae2ef8-30eb-4571-80c3-3289e86bd65c\"</span></span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"attr\">\"resources\"</span>: &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"VCPU\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"MEMORY_MB\"</span>: <span class=\"number\">512</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"DISK_GB\"</span>: <span class=\"number\">1</span></span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Placement经过一系列查询之后，返回了一些信息，其中<code>allocation_requests</code>就是我们的请求参数，即我们需要这么些资源，麻烦Placement给看看有合适的RP没？然后Placement帮我们找到了UUID为<code>4cae2ef8-30eb-4571-80c3-3289e86bd65c</code>的RP，还很贴心的在<code>provider_summaries</code>列出了这个RP当前使用的资源量以及存量。实际上这两个查询分别对应了下面的两个SQL语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">-- 1.查询符合要求的Resource Provider</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> rp.id</span><br><span class=\"line\"><span class=\"keyword\">FROM</span> resource_providers <span class=\"keyword\">AS</span> rp</span><br><span class=\"line\">    <span class=\"comment\">-- vcpu信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- vcpu总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_vcpu</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_vcpu.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_vcpu.resource_class_id = %(resource_class_id_1)s</span><br><span class=\"line\">    <span class=\"comment\">-- vcpu已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">        <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_2)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> usage_vcpu</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_vcpu.resource_provider_id = usage_vcpu.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- memory信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- memory总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_memory_mb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_memory_mb.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_memory_mb.resource_class_id = %(resource_class_id_3)s</span><br><span class=\"line\">    <span class=\"comment\">-- memory已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">            <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_4)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> usage_memory_mb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_memory_mb.resource_provider_id = usage_memory_mb.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- disk信息join</span></span><br><span class=\"line\">    <span class=\"comment\">-- disk总存量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv_disk_gb</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> inv_disk_gb.resource_provider_id = rp.id</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> inv_disk_gb.resource_class_id = %(resource_class_id_5)s</span><br><span class=\"line\">    <span class=\"comment\">-- disk已使用量信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id</span><br><span class=\"line\">        <span class=\"keyword\">AS</span> resource_provider_id, <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_class_id = %(resource_class_id_6)s</span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id</span><br><span class=\"line\">        ) <span class=\"keyword\">AS</span> usage_disk_gb</span><br><span class=\"line\">            <span class=\"keyword\">ON</span> inv_disk_gb.resource_provider_id = usage_disk_gb.resource_provider_id</span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\"><span class=\"comment\">-- vcpu满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_vcpu.used, %(coalesce_1)s) + %(coalesce_2)s &lt;= (</span><br><span class=\"line\">inv_vcpu.total - inv_vcpu.reserved) * inv_vcpu.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_vcpu.min_unit &lt;= %(min_unit_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_vcpu.max_unit &gt;= %(max_unit_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_1)s % inv_vcpu.step_size = %(param_1)s <span class=\"keyword\">AND</span></span><br><span class=\"line\"><span class=\"comment\">-- memory满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_memory_mb.used, %(coalesce_3)s) + %(coalesce_4)s &lt;= (</span><br><span class=\"line\">inv_memory_mb.total - inv_memory_mb.reserved) * inv_memory_mb.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_memory_mb.min_unit &lt;= %(min_unit_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_memory_mb.max_unit &gt;= %(max_unit_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_2)s % inv_memory_mb.step_size = %(param_2)s <span class=\"keyword\">AND</span></span><br><span class=\"line\"><span class=\"comment\">-- disk满足上限/下限/步长条件</span></span><br><span class=\"line\"><span class=\"keyword\">coalesce</span>(usage_disk_gb.used, %(coalesce_5)s) + %(coalesce_6)s &lt;= (</span><br><span class=\"line\">inv_disk_gb.total - inv_disk_gb.reserved) * inv_disk_gb.allocation_ratio <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_disk_gb.min_unit &lt;= %(min_unit_3)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">inv_disk_gb.max_unit &gt;= %(max_unit_3)s <span class=\"keyword\">AND</span></span><br><span class=\"line\">%(step_size_3)s % inv_disk_gb.step_size = %(param_3)s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">-- 2.查询该Resource Provider的用量和存量</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> rp.id <span class=\"keyword\">AS</span> resource_provider_id, rp.uuid <span class=\"keyword\">AS</span> resource_provider_uuid,</span><br><span class=\"line\">    inv.resource_class_id, inv.total, inv.reserved, inv.allocation_ratio,</span><br><span class=\"line\">    <span class=\"string\">`usage`</span>.used</span><br><span class=\"line\"><span class=\"keyword\">FROM</span> resource_providers <span class=\"keyword\">AS</span> rp</span><br><span class=\"line\">    <span class=\"comment\">-- inventory信息，每个rp的总量</span></span><br><span class=\"line\">    <span class=\"keyword\">INNER</span> <span class=\"keyword\">JOIN</span> inventories <span class=\"keyword\">AS</span> inv</span><br><span class=\"line\">        <span class=\"keyword\">ON</span> rp.id = inv.resource_provider_id</span><br><span class=\"line\">    <span class=\"comment\">-- allocation信息</span></span><br><span class=\"line\">    <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> (</span><br><span class=\"line\">        <span class=\"comment\">-- 每个rp和class的已使用量</span></span><br><span class=\"line\">        <span class=\"keyword\">SELECT</span> allocations.resource_provider_id <span class=\"keyword\">AS</span> resource_provider_id,</span><br><span class=\"line\">        allocations.resource_class_id <span class=\"keyword\">AS</span> resource_class_id,</span><br><span class=\"line\">        <span class=\"keyword\">sum</span>(allocations.used) <span class=\"keyword\">AS</span> used</span><br><span class=\"line\">        <span class=\"keyword\">FROM</span> allocations</span><br><span class=\"line\">        <span class=\"keyword\">WHERE</span> allocations.resource_provider_id <span class=\"keyword\">IN</span> (%(resource_provider_id_1)s) <span class=\"keyword\">AND</span></span><br><span class=\"line\">            allocations.resource_class_id <span class=\"keyword\">IN</span> (</span><br><span class=\"line\">                %(resource_class_id_1)s,</span><br><span class=\"line\">                %(resource_class_id_2)s,</span><br><span class=\"line\">                %(resource_class_id_3)s</span><br><span class=\"line\">            )</span><br><span class=\"line\">        <span class=\"comment\">-- 按照rp_id和rp_class_id进行分组</span></span><br><span class=\"line\">        <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> allocations.resource_provider_id, allocations.resource_class_id</span><br><span class=\"line\">    ) <span class=\"keyword\">AS</span> <span class=\"string\">`usage`</span></span><br><span class=\"line\">        <span class=\"keyword\">ON</span> <span class=\"string\">`usage`</span>.resource_provider_id = inv.resource_provider_id <span class=\"keyword\">AND</span></span><br><span class=\"line\">        <span class=\"string\">`usage`</span>.resource_class_id = inv.resource_class_id</span><br><span class=\"line\"><span class=\"comment\">-- 查询指定id及class的resource</span></span><br><span class=\"line\"><span class=\"keyword\">WHERE</span> rp.id <span class=\"keyword\">IN</span> (%(id_1)s) <span class=\"keyword\">AND</span></span><br><span class=\"line\">    inv.resource_class_id <span class=\"keyword\">IN</span> (</span><br><span class=\"line\">        %(resource_class_id_4)s,</span><br><span class=\"line\">        %(resource_class_id_5)s,</span><br><span class=\"line\">        %(resource_class_id_6)s</span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n<h4 id=\"Schedule-by-fitlers\"><a href=\"#Schedule-by-fitlers\" class=\"headerlink\" title=\"Schedule by fitlers\"></a>Schedule by fitlers</h4><p>在nova-scheduler获取到allocation candidates之后，还需要使用<code>FilterScheduler</code>对选取的宿主（候选）节点根据启用的过滤器和权重进行计算和过滤。</p>\n<blockquote>\n<p>目前Nova中实现的调度器有以下几种：</p>\n<ol>\n<li>FilterScheduler（过滤调度器）：默认载入的调度器，根据指定的过滤条件以及权重挑选最佳节点</li>\n<li>CachingScheduler：与FilterScheduler功能类似，只不过为了追求的更高的调度性能，将主机资源信息缓存到本地内存中，目前的master代码中标注为<code>[DEPRECATED]</code></li>\n<li>ChanceScheduler（随机调度器）：随机选择，真·佛系。不过也在master代码中被标注了<code>[DEPRECATED]</code></li>\n<li>FakeScheduler：用于测试，无实际功能</li>\n</ol>\n</blockquote>\n<p>But how does filter scheduler work?</p>\n<p>我们依然从代码入手，来张序列图先看为敬：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/how%20filterscheduler%20works.jpg\" alt=\"FilterScheduler\"></p>\n<p>在<code>FilterScheduler</code>的泳道中，可以看到，大体上分三步：</p>\n<ol>\n<li>调度器缓存刷新、状态更新：通过<code>nova.scheduler.host_manager.HostState</code>来维护内存中一份主机状态，并返回可见的计算节点信息</li>\n<li>Filtering：实用配置文件指定各种的filters去过滤掉不符合条件的hosts。在配置文件中有两个配置<code>availale_filters</code>和<code>enabled_filters</code>，前者用于指定所有可用的filters，配置为<code>available_filters=nova.scheduler.filters.all_filters</code>；后者表示对于可用的filter，nova-scheduler会使用哪些，配置如<code>enabled_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,DiskFilter</code>等。O版中Nova支持的filters多达27个，实现均位于<code>nova/scheduler/filters</code>目录下，能够处理各类信息，比如主机可用资源、启动请求的参数（如镜像信息、请求重试次数等）、虚机亲和性和反亲和性（与其他虚机是否在同一宿主节点上）等</li>\n<li>Weighing：对所有符合条件的host计算权重并排序，从而选出最佳的一个宿主节点。所有的Weigher实现均位于<code>nova/scheduler/weights</code>目录下，比如DiskWeigher：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DiskWeigher</span><span class=\"params\">(weights.BaseHostWeigher)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 可以设置maxval和minval属性指明权重的最大值和最小值</span></span><br><span class=\"line\">    minval = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 权重的系数，最终排序时需要将每种Weigher得到的权重分别乘上它对应的这个</span></span><br><span class=\"line\">    <span class=\"comment\"># 系数，有多个Weigher时才有意义，这里的disk_weight_multiplier</span></span><br><span class=\"line\">    <span class=\"comment\"># 配置文件默认值为 1.0 </span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">weight_multiplier</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> CONF.filter_scheduler.disk_weight_multiplier</span><br><span class=\"line\">    <span class=\"comment\"># 计算权重值，按照注释描述，free_disk_mb更大者胜出</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_weigh_object</span><span class=\"params\">(self, host_state, weight_properties)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"Higher weights win.  We want spreading to be the default.\"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> host_state.free_disk_mb</span><br></pre></td></tr></table></figure>\n<h4 id=\"Claim-Resources\"><a href=\"#Claim-Resources\" class=\"headerlink\" title=\"Claim Resources\"></a>Claim Resources</h4><p>前面我们提到，在获取到Allocation Candidates（即可用于资源分配的候选host）并经过过滤器过滤和权重计算之后，nova-scheduler开始尝试进行<code>Claim resources</code>，即在创建之前预先测试一下所指定的host的可用资源是否能够满足创建虚机的需求。<br>我们来一起看一下<code>nova.scheduler.utils.claim_resources</code>的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">claim_resources</span><span class=\"params\">(ctx, client, spec_obj, instance_uuid, alloc_req,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        allocation_request_version=None)</span>:</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">return</span> client.claim_resources(ctx, instance_uuid, alloc_req, project_id,</span><br><span class=\"line\">            user_id, allocation_request_version=allocation_request_version)</span><br></pre></td></tr></table></figure>\n<p>在该方法中，最终调用的还是传入的client的<code>claim_resources()</code>方法，即<code>nova.scheduler.client.report.SchedulerReportClient#claim_resources</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@safe_connect</span></span><br><span class=\"line\"><span class=\"meta\">@retries</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">claim_resources</span><span class=\"params\">(self, context, consumer_uuid, alloc_request,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                    project_id, user_id, allocation_request_version=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Creates allocation records for the supplied instance UUID against</span></span><br><span class=\"line\"><span class=\"string\">    the supplied resource providers.</span></span><br><span class=\"line\"><span class=\"string\">    即对指定的实例创建该实例在指定RP上的分配记录</span></span><br><span class=\"line\"><span class=\"string\">    :param context: The security context</span></span><br><span class=\"line\"><span class=\"string\">    :param consumer_uuid: The instance's UUID.</span></span><br><span class=\"line\"><span class=\"string\">    :param alloc_request: The JSON body of the request to make to the</span></span><br><span class=\"line\"><span class=\"string\">                          placement's PUT /allocations API</span></span><br><span class=\"line\"><span class=\"string\">    :param project_id: The project_id associated with the allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :param user_id: The user_id associated with the allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :param allocation_request_version: The microversion used to request the</span></span><br><span class=\"line\"><span class=\"string\">                                       allocations.</span></span><br><span class=\"line\"><span class=\"string\">    :returns: True if the allocations were created, False otherwise.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    ar = copy.deepcopy(alloc_request)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the allocation_request_version less than 1.12, then convert the</span></span><br><span class=\"line\">    <span class=\"comment\"># allocation array format to the dict format. This conversion can be</span></span><br><span class=\"line\">    <span class=\"comment\"># remove in Rocky release.</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> versionutils.convert_version_to_tuple(</span><br><span class=\"line\">            allocation_request_version) &lt; (<span class=\"number\">1</span>, <span class=\"number\">12</span>):</span><br><span class=\"line\">        ar = &#123;</span><br><span class=\"line\">            <span class=\"string\">'allocations'</span>: &#123;</span><br><span class=\"line\">                alloc[<span class=\"string\">'resource_provider'</span>][<span class=\"string\">'uuid'</span>]: &#123;</span><br><span class=\"line\">                    <span class=\"string\">'resources'</span>: alloc[<span class=\"string\">'resources'</span>]</span><br><span class=\"line\">                &#125; <span class=\"keyword\">for</span> alloc <span class=\"keyword\">in</span> ar[<span class=\"string\">'allocations'</span>]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        allocation_request_version = <span class=\"string\">'1.12'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    url = <span class=\"string\">'/allocations/%s'</span> % consumer_uuid</span><br><span class=\"line\"></span><br><span class=\"line\">    payload = ar</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># We first need to determine if this is a move operation and if so</span></span><br><span class=\"line\">    <span class=\"comment\"># create the \"doubled-up\" allocation that exists for the duration of</span></span><br><span class=\"line\">    <span class=\"comment\"># the move operation against both the source and destination hosts</span></span><br><span class=\"line\">    r = self.get(url, global_request_id=context.global_id)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.status_code == <span class=\"number\">200</span>:</span><br><span class=\"line\">        current_allocs = r.json()[<span class=\"string\">'allocations'</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> current_allocs:</span><br><span class=\"line\">            payload = _move_operation_alloc_request(current_allocs, ar)</span><br><span class=\"line\"></span><br><span class=\"line\">    payload[<span class=\"string\">'project_id'</span>] = project_id</span><br><span class=\"line\">    payload[<span class=\"string\">'user_id'</span>] = user_id</span><br><span class=\"line\">    r = self.put(url, payload, version=allocation_request_version,</span><br><span class=\"line\">                 global_request_id=context.global_id)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.status_code != <span class=\"number\">204</span>:</span><br><span class=\"line\">        <span class=\"comment\"># NOTE(jaypipes): Yes, it sucks doing string comparison like this</span></span><br><span class=\"line\">        <span class=\"comment\"># but we have no error codes, only error messages.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">'concurrently updated'</span> <span class=\"keyword\">in</span> r.text:</span><br><span class=\"line\">            reason = (<span class=\"string\">'another process changed the resource providers '</span></span><br><span class=\"line\">                      <span class=\"string\">'involved in our attempt to put allocations for '</span></span><br><span class=\"line\">                      <span class=\"string\">'consumer %s'</span> % consumer_uuid)</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> Retry(<span class=\"string\">'claim_resources'</span>, reason)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            LOG.warning(</span><br><span class=\"line\">                <span class=\"string\">'Unable to submit allocation for instance '</span></span><br><span class=\"line\">                <span class=\"string\">'%(uuid)s (%(code)i %(text)s)'</span>,</span><br><span class=\"line\">                &#123;<span class=\"string\">'uuid'</span>: consumer_uuid,</span><br><span class=\"line\">                 <span class=\"string\">'code'</span>: r.status_code,</span><br><span class=\"line\">                 <span class=\"string\">'text'</span>: r.text&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r.status_code == <span class=\"number\">204</span></span><br></pre></td></tr></table></figure>\n<p>在这里是发起了一个PUT请求，尝试为<code>consumer_id</code>先声明所需要的资源，并根据返回的HTTP status code来判断是否声明资源成功。一旦能成功声明所需要的资源，就等于找到将该虚机调度到哪一个宿主节点，可以继续后面实际资源的创建等一系列流程，Placement API的工作到这里就暂告一段落了。但是对于scheduler，还有去consumer host的资源，即更新host state等内存中的信息等等。</p>\n<h3 id=\"目前社区Placement的发展\"><a href=\"#目前社区Placement的发展\" class=\"headerlink\" title=\"目前社区Placement的发展\"></a>目前社区Placement的发展</h3><p>通过订阅<code>openstack-dev</code>或者参加<code>nova</code>的weekly meeting，是可以非常及时的获取社区趋势和把握社区的开发进度。那么对Nova Schedule Team来讲，目前这两个月的进度，华为的<a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">姜逸坤</a>都给出了比较详尽的记录和整理：</p>\n<ul>\n<li><a href=\"https://github.com/Yikun/yikun.github.com/issues/66\" target=\"_blank\" rel=\"noopener\">Nova Scheduler Team Meeting跟踪（一月）</a></li>\n<li><a href=\"https://github.com/Yikun/yikun.github.com/issues/67\" target=\"_blank\" rel=\"noopener\">Nova Scheduler Team Meeting跟踪（二月）</a></li>\n</ul>\n<p>目前看起来，调度相关的team还在紧锣密鼓的继续完善Placement的功能，热火朝天向Rocky版本迈进。</p>\n<h2 id=\"有哪些不足\"><a href=\"#有哪些不足\" class=\"headerlink\" title=\"有哪些不足\"></a>有哪些不足</h2><p>目前看起来不足主要集中在使用中的bug及功能的待完善。比如目前还在开发的Nested Resource Providers；为获取Allocation candidates增加limit，控制每次取到的资源候选分配者的数量等等；还有比如主机迁移失败导致两个RP中都有占用的情况等等。像把Placement单独抽离出来，这也是社区有意向要做的事情。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1].<a href=\"https://docs.openstack.org/nova/latest/user/placement.html\" target=\"_blank\" rel=\"noopener\">Placement API</a><br>[2].<a href=\"https://developer.openstack.org/api-ref/placement/\" target=\"_blank\" rel=\"noopener\">Placement API Reference</a><br>[3].<a href=\"http://yikun.github.io/\" target=\"_blank\" rel=\"noopener\">Yikun’s blog</a></p>"},{"title":"Python中的装饰器——初识篇","date":"2017-09-20T06:53:15.000Z","_content":"\n## 认识装饰器 \n\n装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<!--more-->（或称为callable，比如一个对象具有__call__方法），并且对被装饰的函数做些处理。举个例子：\n```python\ndef decorated_by(func):\n    func.__doc__ += '\\nDecorated by decorated_by.'\n    return func\n\n\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    add = decorated_by(add)\n    print add.__doc__\n\n# output \nReturn the sum of x and y.\nDecorated by decorated_by.\n\n```\n大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：\n```python\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\n# output\nReturn the sum of x and y.\nDecorated by decorated_by.\n```\n添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。\n\n## 装饰器应用的顺序\n\n当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：\n我们有另外的一个函数叫做also_decorated_by，也是在func.__doc__后面添加一段话，然后对add函数应用该装饰器：\n```python\ndef also_decorated_by(func):\n    func.__doc__ += '\\nAlso decorated by also_decorated_by.'\n    return func\n\n\n@also_decorated_by\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n```\n按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：\n```python\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\nReturn the sum of x and y.\nDecorated by decorated_by.\nAlso decorated by also_decorated_by.\n```\n## 装饰器的应用场景\n\n标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。\n常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。\n\n## 为什么要使用装饰器\n\n 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。\n在Python应用程序和模块中编写装饰器有几个非常好的用例——\n* 附加功能 - 在被装饰的方法前后执行额外的附加功能\n* 数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints\n* 功能注册\n \n## 动手写几个装饰器\n\n纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。\n\n### 功能注册\n\n先上代码打个样：\n\n```python\nclass Registry(object):\n    def __init__(self):\n        self._functions = []\n\n    def register(self, decorated):\n        self._functions.append(decorated)\n        return decorated\n\n    def run_all(self, *args, **kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args, **kwargs))\n        return return_values\n\n\na = Registry()\nb = Registry()\n\n\n@a.register\ndef foo(x=3):\n    return x\n\n\n@b.register\ndef bar(x=5):\n    return x\n\n\n@a.register\n@b.register\ndef baz(x=7):\n    return x\n\na_r = a.run_all() \t# [3, 7]\nb_r = b.run_all() \t# [5, 7]\na_r = a.run_all(x=4) \t# [4, 4]\n\n```\n\n### 运行时封装代码（wrap code）\n\n上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：\n\n#### 类型检查\n\n```python\ndef requires_int(decorated):\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n        for arg in list(args) + kwarg_values:\n            if not isinstance(arg, int):\n                raise TypeError('%s only accepts integers as arguments.' %\n                                decorated.__name__)\n        return decorated(*args, **kwargs)\n\n    return inner\n\n@requires_int\ndef foo(x,y):\n    \"\"\" Return the sum of x and y\"\"\"\n    return x+y\n\nif __name__ == '__main__':\n    print foo(1,y='a')\n\n# output \nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 17, in <module>\n    print foo(1,y='a')\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 7, in inner\n    decorated.__name__)\nTypeError: foo only accepts integers as arguments.\n\n```\n上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。\n\n如果此时我们执行help(foo)会发现，得到的结果是：\n```python\nHelp on function inner in module __main__:\n\ninner(*args, **kwargs)\n    Get any values that may have been sent as keyword arguments.\n```\n很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(*args, **kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。\n\n#### 保留原函数的帮助信息\n\n经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：\n```python\nimport functools\n\ndef requires_int(decorated):\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n...\n\n```\n那么此时查看help(foo)，我们得到的输出结果是：\n```python\nHelp on function foo in module __main__:\n\nfoo(*args, **kwargs)\n    Return the sum of x and y\n```\n> 注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是`foo(x, y)`。\n\n#### 用户校验\n\n```python\nimport functools\n\n\nclass User(object):\n    def __init__(self, username, email):\n        self.username = username\n        self.email = email\n\n\nclass AnonymousUser(User):\n    def __init__(self):\n        self.username = None\n        self.email = None\n\n    def __nonzero__(self):\n        return False\n\n\ndef require_user(func):\n    @functools.wraps(func)\n    def inner(user, *args, **kwargs):\n        if user and isinstance(user, User):\n            return func(user, *args, **kwargs)\n        else:\n            raise ValueError('A valid user is required to run this.')\n    return inner\n\n@require_user\ndef foo(user):\n    if user.username and user.email:\n        print user.username + ',' + user.email\n    else:\n        print 'None'\n\nif __name__ == '__main__':\n    user = User('Tom','tom.smith@tom.com')\n    a_user = AnonymousUser()\n    foo(user)\n    foo(a_user)\n\n# output\nTom,tom.smith@tom.com\nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/user.py\", line 39, in <module>\n    foo(a_user)\n  File \"F:/Test/PyTest/decorators/user.py\", line 25, in inner\n    raise ValueError('A valid user is required to run this.')\nValueError: A valid user is required to run this.\n```\n我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了__nonzero__方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了__nonzero__返回False，所以这里就没有办法通过if检查，从而rasie了异常。\n\n#### 格式化输出\n\n除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。\n\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(decorated):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        try:\n            result = decorated(*args, **kwargs)\n        except JSONOutputError as ex:\n            result = {\n                'status': 'error',\n                'message': str(ex),\n            }\n        return json.dumps(result)\n    return inner\n\n\n@json_output\ndef do_nothing():\n    return {'status': 'done'}\n\n\n@json_output\ndef error():\n    raise JSONOutputError('This function is erratic')\n\n\n@json_output\ndef other_error():\n    raise ValueError('The grass is always greener..')\n\nif __name__ == '__main__':\n    # print do_nothing()\n    print error()\n\n# output\n{\"status\": \"error\", \"message\": \"This function is erratic\"}\n```\n\n#### 打印日志\n\n最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：\n```python\nimport functools\nimport logging\nimport time\n\nlogging.basicConfig(evel=logging.DEBUG)\nLOG = logging.getLogger(__name__)\n\n\ndef logged(method):\n    @functools.wraps(method)\n    def inner(*args, **kwargs):\n        start = time.time()\n        return_value = method(*args, **kwargs)\n        end = time.time()\n        delta = end - start\n        LOG.warn('Called method %s at %.02f; execution time %.02f '\n                 'seconds; result %r.' %\n                 (method.__name__, start, delta, return_value))\n        return return_value\n\n    return inner\n\n\n@logged\ndef sleep_and_return(return_value):\n    time.sleep(2)\n    return return_value\n\n\nif __name__ == '__main__':\n    print sleep_and_return(27)\n\n# output \nWARNING:__main__:Called method sleep_and_return at 1505889774.61; execution time 2.00 seconds; result 27.\n27\n\n```\n\n## 小节结语\n\n本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。\n\n目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。\n","source":"_posts/python-introduction-to-decorators-with-examples.md","raw":"---\ntitle: Python中的装饰器——初识篇\ndate: 2017-09-20 14:53:15\ntags: [Python, decorator]\n---\n\n## 认识装饰器 \n\n装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<!--more-->（或称为callable，比如一个对象具有__call__方法），并且对被装饰的函数做些处理。举个例子：\n```python\ndef decorated_by(func):\n    func.__doc__ += '\\nDecorated by decorated_by.'\n    return func\n\n\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    add = decorated_by(add)\n    print add.__doc__\n\n# output \nReturn the sum of x and y.\nDecorated by decorated_by.\n\n```\n大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：\n```python\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\n# output\nReturn the sum of x and y.\nDecorated by decorated_by.\n```\n添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。\n\n## 装饰器应用的顺序\n\n当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：\n我们有另外的一个函数叫做also_decorated_by，也是在func.__doc__后面添加一段话，然后对add函数应用该装饰器：\n```python\ndef also_decorated_by(func):\n    func.__doc__ += '\\nAlso decorated by also_decorated_by.'\n    return func\n\n\n@also_decorated_by\n@decorated_by\ndef add(x, y):\n    \"\"\"Return the sum of x and y.\"\"\"\n    return x + y\n\n```\n按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：\n```python\nif __name__ == '__main__':\n    # add = decorated_by(add)\n    add(1, 2)\n    print add.__doc__\n\nReturn the sum of x and y.\nDecorated by decorated_by.\nAlso decorated by also_decorated_by.\n```\n## 装饰器的应用场景\n\n标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。\n常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。\n\n## 为什么要使用装饰器\n\n 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。\n在Python应用程序和模块中编写装饰器有几个非常好的用例——\n* 附加功能 - 在被装饰的方法前后执行额外的附加功能\n* 数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints\n* 功能注册\n \n## 动手写几个装饰器\n\n纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。\n\n### 功能注册\n\n先上代码打个样：\n\n```python\nclass Registry(object):\n    def __init__(self):\n        self._functions = []\n\n    def register(self, decorated):\n        self._functions.append(decorated)\n        return decorated\n\n    def run_all(self, *args, **kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args, **kwargs))\n        return return_values\n\n\na = Registry()\nb = Registry()\n\n\n@a.register\ndef foo(x=3):\n    return x\n\n\n@b.register\ndef bar(x=5):\n    return x\n\n\n@a.register\n@b.register\ndef baz(x=7):\n    return x\n\na_r = a.run_all() \t# [3, 7]\nb_r = b.run_all() \t# [5, 7]\na_r = a.run_all(x=4) \t# [4, 4]\n\n```\n\n### 运行时封装代码（wrap code）\n\n上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：\n\n#### 类型检查\n\n```python\ndef requires_int(decorated):\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n        for arg in list(args) + kwarg_values:\n            if not isinstance(arg, int):\n                raise TypeError('%s only accepts integers as arguments.' %\n                                decorated.__name__)\n        return decorated(*args, **kwargs)\n\n    return inner\n\n@requires_int\ndef foo(x,y):\n    \"\"\" Return the sum of x and y\"\"\"\n    return x+y\n\nif __name__ == '__main__':\n    print foo(1,y='a')\n\n# output \nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 17, in <module>\n    print foo(1,y='a')\n  File \"F:/Test/PyTest/decorators/typecheck.py\", line 7, in inner\n    decorated.__name__)\nTypeError: foo only accepts integers as arguments.\n\n```\n上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。\n\n如果此时我们执行help(foo)会发现，得到的结果是：\n```python\nHelp on function inner in module __main__:\n\ninner(*args, **kwargs)\n    Get any values that may have been sent as keyword arguments.\n```\n很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(*args, **kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。\n\n#### 保留原函数的帮助信息\n\n经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：\n```python\nimport functools\n\ndef requires_int(decorated):\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        \"\"\" Get any values that may have been sent as keyword arguments.\n        \"\"\"\n        kwarg_values = [i for i in kwargs.values()]\n...\n\n```\n那么此时查看help(foo)，我们得到的输出结果是：\n```python\nHelp on function foo in module __main__:\n\nfoo(*args, **kwargs)\n    Return the sum of x and y\n```\n> 注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是`foo(x, y)`。\n\n#### 用户校验\n\n```python\nimport functools\n\n\nclass User(object):\n    def __init__(self, username, email):\n        self.username = username\n        self.email = email\n\n\nclass AnonymousUser(User):\n    def __init__(self):\n        self.username = None\n        self.email = None\n\n    def __nonzero__(self):\n        return False\n\n\ndef require_user(func):\n    @functools.wraps(func)\n    def inner(user, *args, **kwargs):\n        if user and isinstance(user, User):\n            return func(user, *args, **kwargs)\n        else:\n            raise ValueError('A valid user is required to run this.')\n    return inner\n\n@require_user\ndef foo(user):\n    if user.username and user.email:\n        print user.username + ',' + user.email\n    else:\n        print 'None'\n\nif __name__ == '__main__':\n    user = User('Tom','tom.smith@tom.com')\n    a_user = AnonymousUser()\n    foo(user)\n    foo(a_user)\n\n# output\nTom,tom.smith@tom.com\nTraceback (most recent call last):\n  File \"F:/Test/PyTest/decorators/user.py\", line 39, in <module>\n    foo(a_user)\n  File \"F:/Test/PyTest/decorators/user.py\", line 25, in inner\n    raise ValueError('A valid user is required to run this.')\nValueError: A valid user is required to run this.\n```\n我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了__nonzero__方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了__nonzero__返回False，所以这里就没有办法通过if检查，从而rasie了异常。\n\n#### 格式化输出\n\n除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。\n\n```python\nimport functools\nimport json\n\n\nclass JSONOutputError(Exception):\n    def __init__(self, message):\n        self._message = message\n\n    def __str__(self):\n        return self._message\n\n\ndef json_output(decorated):\n    \"\"\"Run the decorated function, serialize the result of that function\n    to JSON, and return the JSON string.\n    \"\"\"\n    @functools.wraps(decorated)\n    def inner(*args, **kwargs):\n        try:\n            result = decorated(*args, **kwargs)\n        except JSONOutputError as ex:\n            result = {\n                'status': 'error',\n                'message': str(ex),\n            }\n        return json.dumps(result)\n    return inner\n\n\n@json_output\ndef do_nothing():\n    return {'status': 'done'}\n\n\n@json_output\ndef error():\n    raise JSONOutputError('This function is erratic')\n\n\n@json_output\ndef other_error():\n    raise ValueError('The grass is always greener..')\n\nif __name__ == '__main__':\n    # print do_nothing()\n    print error()\n\n# output\n{\"status\": \"error\", \"message\": \"This function is erratic\"}\n```\n\n#### 打印日志\n\n最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：\n```python\nimport functools\nimport logging\nimport time\n\nlogging.basicConfig(evel=logging.DEBUG)\nLOG = logging.getLogger(__name__)\n\n\ndef logged(method):\n    @functools.wraps(method)\n    def inner(*args, **kwargs):\n        start = time.time()\n        return_value = method(*args, **kwargs)\n        end = time.time()\n        delta = end - start\n        LOG.warn('Called method %s at %.02f; execution time %.02f '\n                 'seconds; result %r.' %\n                 (method.__name__, start, delta, return_value))\n        return return_value\n\n    return inner\n\n\n@logged\ndef sleep_and_return(return_value):\n    time.sleep(2)\n    return return_value\n\n\nif __name__ == '__main__':\n    print sleep_and_return(27)\n\n# output \nWARNING:__main__:Called method sleep_and_return at 1505889774.61; execution time 2.00 seconds; result 27.\n27\n\n```\n\n## 小节结语\n\n本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。\n\n目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。\n","slug":"python-introduction-to-decorators-with-examples","published":1,"updated":"2017-10-23T23:31:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxm000xxu2zwsunv60s","content":"<h2 id=\"认识装饰器\"><a href=\"#认识装饰器\" class=\"headerlink\" title=\"认识装饰器\"></a>认识装饰器</h2><p>装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数<a id=\"more\"></a>（或称为callable，比如一个对象具有<strong>call</strong>方法），并且对被装饰的函数做些处理。举个例子：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nDecorated by decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    add = decorated_by(add)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。</p>\n<h2 id=\"装饰器应用的顺序\"><a href=\"#装饰器应用的顺序\" class=\"headerlink\" title=\"装饰器应用的顺序\"></a>装饰器应用的顺序</h2><p>当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：<br>我们有另外的一个函数叫做also_decorated_by，也是在func.<strong>doc</strong>后面添加一段话，然后对add函数应用该装饰器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">also_decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nAlso decorated by also_decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@also_decorated_by</span></span><br><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br></pre></td></tr></table></figure></p>\n<p>按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br><span class=\"line\">Also decorated by also_decorated_by.</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"装饰器的应用场景\"><a href=\"#装饰器的应用场景\" class=\"headerlink\" title=\"装饰器的应用场景\"></a>装饰器的应用场景</h2><p>标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。<br>常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。</p>\n<h2 id=\"为什么要使用装饰器\"><a href=\"#为什么要使用装饰器\" class=\"headerlink\" title=\"为什么要使用装饰器\"></a>为什么要使用装饰器</h2><p> 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。<br>在Python应用程序和模块中编写装饰器有几个非常好的用例——</p>\n<ul>\n<li>附加功能 - 在被装饰的方法前后执行额外的附加功能</li>\n<li>数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints</li>\n<li>功能注册</li>\n</ul>\n<h2 id=\"动手写几个装饰器\"><a href=\"#动手写几个装饰器\" class=\"headerlink\" title=\"动手写几个装饰器\"></a>动手写几个装饰器</h2><p>纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。</p>\n<h3 id=\"功能注册\"><a href=\"#功能注册\" class=\"headerlink\" title=\"功能注册\"></a>功能注册</h3><p>先上代码打个样：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Registry</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self._functions = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, decorated)</span>:</span></span><br><span class=\"line\">        self._functions.append(decorated)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_all</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        return_values = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> func <span class=\"keyword\">in</span> self._functions:</span><br><span class=\"line\">            return_values.append(func(*args, **kwargs))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_values</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">a = Registry()</span><br><span class=\"line\">b = Registry()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x=<span class=\"number\">3</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bar</span><span class=\"params\">(x=<span class=\"number\">5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">baz</span><span class=\"params\">(x=<span class=\"number\">7</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">a_r = a.run_all() \t<span class=\"comment\"># [3, 7]</span></span><br><span class=\"line\">b_r = b.run_all() \t<span class=\"comment\"># [5, 7]</span></span><br><span class=\"line\">a_r = a.run_all(x=<span class=\"number\">4</span>) \t<span class=\"comment\"># [4, 4]</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"运行时封装代码（wrap-code）\"><a href=\"#运行时封装代码（wrap-code）\" class=\"headerlink\" title=\"运行时封装代码（wrap code）\"></a>运行时封装代码（wrap code）</h3><p>上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：</p>\n<h4 id=\"类型检查\"><a href=\"#类型检查\" class=\"headerlink\" title=\"类型检查\"></a>类型检查</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> list(args) + kwarg_values:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(arg, int):</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> TypeError(<span class=\"string\">'%s only accepts integers as arguments.'</span> %</span><br><span class=\"line\">                                decorated.__name__)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated(*args, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@requires_int</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" Return the sum of x and y\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x+y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">17</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">7</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    decorated.__name__)</span><br><span class=\"line\">TypeError: foo only accepts integers <span class=\"keyword\">as</span> arguments.</span><br></pre></td></tr></table></figure>\n<p>上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。</p>\n<p>如果此时我们执行help(foo)会发现，得到的结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function inner <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">inner(*args, **kwargs)</span><br><span class=\"line\">    Get any values that may have been sent <span class=\"keyword\">as</span> keyword arguments.</span><br></pre></td></tr></table></figure></p>\n<p>很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(<em>args, *</em>kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。</p>\n<h4 id=\"保留原函数的帮助信息\"><a href=\"#保留原函数的帮助信息\" class=\"headerlink\" title=\"保留原函数的帮助信息\"></a>保留原函数的帮助信息</h4><p>经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那么此时查看help(foo)，我们得到的输出结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function foo <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">foo(*args, **kwargs)</span><br><span class=\"line\">    Return the sum of x <span class=\"keyword\">and</span> y</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是<code>foo(x, y)</code>。</p>\n</blockquote>\n<h4 id=\"用户校验\"><a href=\"#用户校验\" class=\"headerlink\" title=\"用户校验\"></a>用户校验</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">User</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, username, email)</span>:</span></span><br><span class=\"line\">        self.username = username</span><br><span class=\"line\">        self.email = email</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnonymousUser</span><span class=\"params\">(User)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.username = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.email = <span class=\"keyword\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__nonzero__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">require_user</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(func)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(user, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> user <span class=\"keyword\">and</span> isinstance(user, User):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> func(user, *args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@require_user</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(user)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> user.username <span class=\"keyword\">and</span> user.email:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> user.username + <span class=\"string\">','</span> + user.email</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'None'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    user = User(<span class=\"string\">'Tom'</span>,<span class=\"string\">'tom.smith@tom.com'</span>)</span><br><span class=\"line\">    a_user = AnonymousUser()</span><br><span class=\"line\">    foo(user)</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Tom,tom.smith@tom.com</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">39</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">25</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">ValueError: A valid user <span class=\"keyword\">is</span> required to run this.</span><br></pre></td></tr></table></figure>\n<p>我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了<strong>nonzero</strong>方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了<strong>nonzero</strong>返回False，所以这里就没有办法通过if检查，从而rasie了异常。</p>\n<h4 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h4><p>除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            result = decorated(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">            result = &#123;</span><br><span class=\"line\">                <span class=\"string\">'status'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> JSONOutputError(<span class=\"string\">'This function is erratic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">other_error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'The grass is always greener..'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># print do_nothing()</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> error()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"error\"</span>, <span class=\"string\">\"message\"</span>: <span class=\"string\">\"This function is erratic\"</span>&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"打印日志\"><a href=\"#打印日志\" class=\"headerlink\" title=\"打印日志\"></a>打印日志</h4><p>最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> logging</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\">logging.basicConfig(evel=logging.DEBUG)</span><br><span class=\"line\">LOG = logging.getLogger(__name__)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">logged</span><span class=\"params\">(method)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(method)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        start = time.time()</span><br><span class=\"line\">        return_value = method(*args, **kwargs)</span><br><span class=\"line\">        end = time.time()</span><br><span class=\"line\">        delta = end - start</span><br><span class=\"line\">        LOG.warn(<span class=\"string\">'Called method %s at %.02f; execution time %.02f '</span></span><br><span class=\"line\">                 <span class=\"string\">'seconds; result %r.'</span> %</span><br><span class=\"line\">                 (method.__name__, start, delta, return_value))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@logged</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sleep_and_return</span><span class=\"params\">(return_value)</span>:</span></span><br><span class=\"line\">    time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> sleep_and_return(<span class=\"number\">27</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">WARNING:__main__:Called method sleep_and_return at <span class=\"number\">1505889774.61</span>; execution time <span class=\"number\">2.00</span> seconds; result <span class=\"number\">27.</span></span><br><span class=\"line\"><span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h2><p>本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。</p>\n<p>目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"认识装饰器\"><a href=\"#认识装饰器\" class=\"headerlink\" title=\"认识装饰器\"></a>认识装饰器</h2><p>装饰器简单来讲就是一个接收被装饰的函数作为固定参数的函数","more":"（或称为callable，比如一个对象具有<strong>call</strong>方法），并且对被装饰的函数做些处理。举个例子：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nDecorated by decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    add = decorated_by(add)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况下，我们只关心最终被装饰的函数，而持有装饰器函数的引用基本上是没必要的。所以，在Python 2.5中引入了对装饰器的特殊语法——装饰器的应用可以通过在被装饰的函数上面一行添加@字符，其后紧跟装饰器函数名的这种方式：比如针对上面的例子，我们就可以写作：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br></pre></td></tr></table></figure></p>\n<p>添加@+装饰器名的这种方式就等价于 add = decorated_by(add)。这种方式看起来更简洁明了。</p>\n<h2 id=\"装饰器应用的顺序\"><a href=\"#装饰器应用的顺序\" class=\"headerlink\" title=\"装饰器应用的顺序\"></a>装饰器应用的顺序</h2><p>当@语法被使用时，装饰器会在被装饰的callable被创建后立即调用（即装饰器的代码是在应用到被装饰的函数上时执行，而不是被装饰的函数调用时执行）。就上面的例子而言，就是add函数被创建后，紧接着decorated_by函数被应用。那么如果对于单个callable使用@语法应用多个装饰器时（Python中是支持这种场景的），装饰器的应用顺序有事怎样的？答案就是：从下往上，按顺序执行。举个例子：<br>我们有另外的一个函数叫做also_decorated_by，也是在func.<strong>doc</strong>后面添加一段话，然后对add函数应用该装饰器：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">also_decorated_by</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\">    func.__doc__ += <span class=\"string\">'\\nAlso decorated by also_decorated_by.'</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> func</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@also_decorated_by</span></span><br><span class=\"line\"><span class=\"meta\">@decorated_by</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Return the sum of x and y.\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x + y</span><br></pre></td></tr></table></figure></p>\n<p>按照从下往上的顺序，我们知道当我们调用add后，执行decorated_by相当于add = decorated_by(add) ，然后对此时的add应用also_decorated_by，就相当于add = also_decorated_by(decorated_by(add))。最终的结果正是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># add = decorated_by(add)</span></span><br><span class=\"line\">    add(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> add.__doc__</span><br><span class=\"line\"></span><br><span class=\"line\">Return the sum of x <span class=\"keyword\">and</span> y.</span><br><span class=\"line\">Decorated by decorated_by.</span><br><span class=\"line\">Also decorated by also_decorated_by.</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"装饰器的应用场景\"><a href=\"#装饰器的应用场景\" class=\"headerlink\" title=\"装饰器的应用场景\"></a>装饰器的应用场景</h2><p>标准库中的很多模块都包含有装饰器，许多常见的工具和框架都将其用于常见的功能。例如，如果要在类上创建一个方法，调用该方法时不需要该类的实例，则可以使用@classmethod或@staticmethod装饰器，这是标准库中的一个简单例子。<br>常用的工具中也是用装饰器，比如常见的Python Web框架Django中，使用@login_required作为装饰器允许开发者指定用户在访问特定页面时必须要登录。另外一个Web框架Flask中使用@app.route来注册指定的URI被访问到时要执行的函数。再比如，Celery中使用一个复杂的@task装饰器来标识一个函数为一个异步任务，这个装饰器的返回实际上是一个Task类的实例，展示出了如何用装饰器来制作方便快捷的API。</p>\n<h2 id=\"为什么要使用装饰器\"><a href=\"#为什么要使用装饰器\" class=\"headerlink\" title=\"为什么要使用装饰器\"></a>为什么要使用装饰器</h2><p> 有了装饰器，你就可以做到在某些特定的地方使用具体的、可复用的功能——如果代码写得好，装饰器就是模块化的、明确的。正是由于装饰器的模块化，使得它们非常适合避免重复的模版设置和拆解代码，同时由于装饰器仅与被装饰的函数本身有交互，所以非常擅长在其他地方注册功能。<br>在Python应用程序和模块中编写装饰器有几个非常好的用例——</p>\n<ul>\n<li>附加功能 - 在被装饰的方法前后执行额外的附加功能</li>\n<li>数据清洗或添加 - 对传入被装饰的函数的参数做一下清晰，确保参数类型一致性或者使参数值村从一定的模式，比如@requires_ints</li>\n<li>功能注册</li>\n</ul>\n<h2 id=\"动手写几个装饰器\"><a href=\"#动手写几个装饰器\" class=\"headerlink\" title=\"动手写几个装饰器\"></a>动手写几个装饰器</h2><p>纸上得来终觉浅，绝知此事要躬行。写下来就要动手写几个装饰器的例子。</p>\n<h3 id=\"功能注册\"><a href=\"#功能注册\" class=\"headerlink\" title=\"功能注册\"></a>功能注册</h3><p>先上代码打个样：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Registry</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self._functions = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, decorated)</span>:</span></span><br><span class=\"line\">        self._functions.append(decorated)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_all</span><span class=\"params\">(self, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        return_values = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> func <span class=\"keyword\">in</span> self._functions:</span><br><span class=\"line\">            return_values.append(func(*args, **kwargs))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_values</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">a = Registry()</span><br><span class=\"line\">b = Registry()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x=<span class=\"number\">3</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bar</span><span class=\"params\">(x=<span class=\"number\">5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@a.register</span></span><br><span class=\"line\"><span class=\"meta\">@b.register</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">baz</span><span class=\"params\">(x=<span class=\"number\">7</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">a_r = a.run_all() \t<span class=\"comment\"># [3, 7]</span></span><br><span class=\"line\">b_r = b.run_all() \t<span class=\"comment\"># [5, 7]</span></span><br><span class=\"line\">a_r = a.run_all(x=<span class=\"number\">4</span>) \t<span class=\"comment\"># [4, 4]</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"运行时封装代码（wrap-code）\"><a href=\"#运行时封装代码（wrap-code）\" class=\"headerlink\" title=\"运行时封装代码（wrap code）\"></a>运行时封装代码（wrap code）</h3><p>上面装饰器的例子比较简单，因为被装饰的函数作为参数传递过去时并没有被修改。然而，有些时候当我们运行被装饰的方法时，希望做些额外的功能，那么我们可以通过返回不同的可调用函数（callable）来添加相应的功能，并且（通常）在执行过程中调用装饰方法。举几个例子：</p>\n<h4 id=\"类型检查\"><a href=\"#类型检查\" class=\"headerlink\" title=\"类型检查\"></a>类型检查</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> list(args) + kwarg_values:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(arg, int):</span><br><span class=\"line\">                <span class=\"keyword\">raise</span> TypeError(<span class=\"string\">'%s only accepts integers as arguments.'</span> %</span><br><span class=\"line\">                                decorated.__name__)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> decorated(*args, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@requires_int</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(x,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" Return the sum of x and y\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x+y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">17</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    <span class=\"keyword\">print</span> foo(<span class=\"number\">1</span>,y=<span class=\"string\">'a'</span>)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/typecheck.py\"</span>, line <span class=\"number\">7</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    decorated.__name__)</span><br><span class=\"line\">TypeError: foo only accepts integers <span class=\"keyword\">as</span> arguments.</span><br></pre></td></tr></table></figure>\n<p>上面的例子中，我们使用装饰器@requires_int对foo的参数进行检查，如果入参中有任何不是int类型的参数，就抛出一个异常。</p>\n<p>如果此时我们执行help(foo)会发现，得到的结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function inner <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">inner(*args, **kwargs)</span><br><span class=\"line\">    Get any values that may have been sent <span class=\"keyword\">as</span> keyword arguments.</span><br></pre></td></tr></table></figure></p>\n<p>很奇怪吧，为什么显示的是inner的函数名及doc而不是foo呢？因为此时inner函数已经被赋值给了foo，如果我们执行foo，其实就是执行inner——首先执行了类型检查，然后运行被装饰的方法，因为inner通过return decorated(<em>args, *</em>kwargs)调用了被装饰的函数。如果没有return这个调用，被装饰的方法就会被忽略。</p>\n<h4 id=\"保留原函数的帮助信息\"><a href=\"#保留原函数的帮助信息\" class=\"headerlink\" title=\"保留原函数的帮助信息\"></a>保留原函数的帮助信息</h4><p>经过上面的例子，我们会自然而然的思考一问题，如果当我们运行help()去查看函数的帮助信息时，希望看到的是被装饰的原函数的文档，而不是装饰器的文档，该怎么做呢？这里，我们的解决方案就是使用装饰器@functools.wraps ，它可以将一个函数重要的内部元素拷贝到另一个函数中：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">requires_int</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Get any values that may have been sent as keyword arguments.</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        kwarg_values = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> kwargs.values()]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>那么此时查看help(foo)，我们得到的输出结果是：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Help on function foo <span class=\"keyword\">in</span> module __main__:</span><br><span class=\"line\"></span><br><span class=\"line\">foo(*args, **kwargs)</span><br><span class=\"line\">    Return the sum of x <span class=\"keyword\">and</span> y</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>注：我这里运行的是Python2.7，如果实在Python3下，看到的结果应该是<code>foo(x, y)</code>。</p>\n</blockquote>\n<h4 id=\"用户校验\"><a href=\"#用户校验\" class=\"headerlink\" title=\"用户校验\"></a>用户校验</h4><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">User</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, username, email)</span>:</span></span><br><span class=\"line\">        self.username = username</span><br><span class=\"line\">        self.email = email</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnonymousUser</span><span class=\"params\">(User)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.username = <span class=\"keyword\">None</span></span><br><span class=\"line\">        self.email = <span class=\"keyword\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__nonzero__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">require_user</span><span class=\"params\">(func)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(func)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(user, *args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> user <span class=\"keyword\">and</span> isinstance(user, User):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> func(user, *args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@require_user</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">(user)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> user.username <span class=\"keyword\">and</span> user.email:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> user.username + <span class=\"string\">','</span> + user.email</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'None'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    user = User(<span class=\"string\">'Tom'</span>,<span class=\"string\">'tom.smith@tom.com'</span>)</span><br><span class=\"line\">    a_user = AnonymousUser()</span><br><span class=\"line\">    foo(user)</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">Tom,tom.smith@tom.com</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">39</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    foo(a_user)</span><br><span class=\"line\">  File <span class=\"string\">\"F:/Test/PyTest/decorators/user.py\"</span>, line <span class=\"number\">25</span>, <span class=\"keyword\">in</span> inner</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'A valid user is required to run this.'</span>)</span><br><span class=\"line\">ValueError: A valid user <span class=\"keyword\">is</span> required to run this.</span><br></pre></td></tr></table></figure>\n<p>我们定义了一个User类，一个AnonymousUser类集成User类，注意，在AnonymousUser中，我们使用了<strong>nonzero</strong>方法，这个方法定义了对类的实例调用bool()时的行为，即在require_user的inner方法中，if user and isinstance(user, User)时的if user，相当于if bool(user)，因为在AnonymousUser中我们定义了<strong>nonzero</strong>返回False，所以这里就没有办法通过if检查，从而rasie了异常。</p>\n<h4 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h4><p>除了为函数的输入清理数据，装饰器的另一个作用就是清理/格式化输出数据。比如我们希望函数的输出以JSON格式，在每个相关的函数的最后手动去格式化输出为JSON显得特别冗余和笨重。此时，装饰器就站出来了。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JSONOutputError</span><span class=\"params\">(Exception)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, message)</span>:</span></span><br><span class=\"line\">        self._message = message</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._message</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">json_output</span><span class=\"params\">(decorated)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Run the decorated function, serialize the result of that function</span></span><br><span class=\"line\"><span class=\"string\">    to JSON, and return the JSON string.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(decorated)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            result = decorated(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> JSONOutputError <span class=\"keyword\">as</span> ex:</span><br><span class=\"line\">            result = &#123;</span><br><span class=\"line\">                <span class=\"string\">'status'</span>: <span class=\"string\">'error'</span>,</span><br><span class=\"line\">                <span class=\"string\">'message'</span>: str(ex),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_nothing</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">'status'</span>: <span class=\"string\">'done'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> JSONOutputError(<span class=\"string\">'This function is erratic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@json_output</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">other_error</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'The grass is always greener..'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\"># print do_nothing()</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> error()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output</span></span><br><span class=\"line\">&#123;<span class=\"string\">\"status\"</span>: <span class=\"string\">\"error\"</span>, <span class=\"string\">\"message\"</span>: <span class=\"string\">\"This function is erratic\"</span>&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"打印日志\"><a href=\"#打印日志\" class=\"headerlink\" title=\"打印日志\"></a>打印日志</h4><p>最后一个例子，打印日志，记录调用了哪个方法、什么时间调用、方法执行时长以及方法的返回值：<br><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> functools</span><br><span class=\"line\"><span class=\"keyword\">import</span> logging</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\">logging.basicConfig(evel=logging.DEBUG)</span><br><span class=\"line\">LOG = logging.getLogger(__name__)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">logged</span><span class=\"params\">(method)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @functools.wraps(method)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">inner</span><span class=\"params\">(*args, **kwargs)</span>:</span></span><br><span class=\"line\">        start = time.time()</span><br><span class=\"line\">        return_value = method(*args, **kwargs)</span><br><span class=\"line\">        end = time.time()</span><br><span class=\"line\">        delta = end - start</span><br><span class=\"line\">        LOG.warn(<span class=\"string\">'Called method %s at %.02f; execution time %.02f '</span></span><br><span class=\"line\">                 <span class=\"string\">'seconds; result %r.'</span> %</span><br><span class=\"line\">                 (method.__name__, start, delta, return_value))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> inner</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@logged</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sleep_and_return</span><span class=\"params\">(return_value)</span>:</span></span><br><span class=\"line\">    time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> return_value</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> sleep_and_return(<span class=\"number\">27</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># output </span></span><br><span class=\"line\">WARNING:__main__:Called method sleep_and_return at <span class=\"number\">1505889774.61</span>; execution time <span class=\"number\">2.00</span> seconds; result <span class=\"number\">27.</span></span><br><span class=\"line\"><span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h2><p>本篇文章的重点是简单的认识一下装饰器，了解一下装饰器的简单应用。</p>\n<p>目前上面的例子，装饰器除了被装饰的函数作为参数之外，都不接收其他的参数，但是很多情况下，装饰器本身接收其他参数是很有必要的。我们后面再展开。</p>"},{"title":"初识Virtio Balloon","date":"2018-07-16T03:22:07.000Z","_content":"\n> 原文地址：[Virtio balloon](https://rwmj.wordpress.com/2010/07/17/virtio-balloon/)\n原创翻译，转载请注明出处。\n\n本文主要介绍了什么是[KVM virtio balloon driver](https://github.com/torvalds/linux/blob/e241e3f2bf975788a1b70dff2eb5180ca395b28e/drivers/virtio/virtio_balloon.c)。<!-- more -->\n\n首先，如果你从没听过这个概念，那什么是balloon driver呢？它是一种给予guest实例或者从guest实例中获取RAM的方法。（理论上来讲），如果你的guest实例需要更多的RAM，你可以通过balloon driver给他分配更多的内存，或者如果宿主机需要在guest实例中取走一下内存，balloon driver也可以做到。这些操作的执行**不需要**暂停或者重启guest实例。\n\nvirtio_balloon是一个在guest实例中的内核驱动。这个driver表现的像一种奇怪的进程，要么扩展自己的内存使用，要么压缩自己的内存使用接近什么也没有，如下图所示：\n![balloon-expanded](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-expanded.png)\n\n![balloon-shrink](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-shrink.png)\n\n当balloon driver扩张时，运行在guest实例中的应用会突然少了很多可用内存，然后guest实例会像没有多少内存时做的那样，交换内存并启动OOM killer（balloon本身是不可交换并且不会被杀掉的）。\n\n那么这个“浪费”内存的内核驱动程序有什么意义呢？有两点——\n第一，驱动通过virtio通道与宿主机通讯，宿主机给其下发指令，比如扩展到指定的大小、现在开始缩小。guest实例配合操作，但是并不直接控制balloon。\n第二，balloon中的内存也从guest实例中取消映射，并传回宿主机，因此宿主机可以将这部分内存传递给其他的guest实例使用。看起来就像guest虚机的内存缺失了一块一样：\n\n![balloon-chunk](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-chunk.png)\n\nLibvirt有两个配置项，`currentMemory`和`maxMemory`（详见[Memory Allocation](https://libvirt.org/formatdomain.html#elementsMemoryAllocation)）：\n\n![balloon-labels](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-labels.png)\n\n`maxMemory`（或`<memory>`）是在guest实例启动阶段分配的内存。KVM和Xen的guest虚机目前（译者注：原文发布时间是2010-07-17 14:33）无法找过这个内存上限。`currentMemory`控制了请求分配给guest实例上应用程序的内存。balloon填充剩余的内存，并且把这部分内存还给宿主机，用于宿主机的在其他地方使用。\n\n该项配置可以手动调整，或者通过编辑XML文件，或者通过`virsh setmem`命令。\n","source":"_posts/virtio-balloon.md","raw":"---\ntitle: 初识Virtio Balloon\ndate: 2018-07-16 11:22:07\ntags: [Virtio, KVM, Virtualization]\n---\n\n> 原文地址：[Virtio balloon](https://rwmj.wordpress.com/2010/07/17/virtio-balloon/)\n原创翻译，转载请注明出处。\n\n本文主要介绍了什么是[KVM virtio balloon driver](https://github.com/torvalds/linux/blob/e241e3f2bf975788a1b70dff2eb5180ca395b28e/drivers/virtio/virtio_balloon.c)。<!-- more -->\n\n首先，如果你从没听过这个概念，那什么是balloon driver呢？它是一种给予guest实例或者从guest实例中获取RAM的方法。（理论上来讲），如果你的guest实例需要更多的RAM，你可以通过balloon driver给他分配更多的内存，或者如果宿主机需要在guest实例中取走一下内存，balloon driver也可以做到。这些操作的执行**不需要**暂停或者重启guest实例。\n\nvirtio_balloon是一个在guest实例中的内核驱动。这个driver表现的像一种奇怪的进程，要么扩展自己的内存使用，要么压缩自己的内存使用接近什么也没有，如下图所示：\n![balloon-expanded](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-expanded.png)\n\n![balloon-shrink](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-shrink.png)\n\n当balloon driver扩张时，运行在guest实例中的应用会突然少了很多可用内存，然后guest实例会像没有多少内存时做的那样，交换内存并启动OOM killer（balloon本身是不可交换并且不会被杀掉的）。\n\n那么这个“浪费”内存的内核驱动程序有什么意义呢？有两点——\n第一，驱动通过virtio通道与宿主机通讯，宿主机给其下发指令，比如扩展到指定的大小、现在开始缩小。guest实例配合操作，但是并不直接控制balloon。\n第二，balloon中的内存也从guest实例中取消映射，并传回宿主机，因此宿主机可以将这部分内存传递给其他的guest实例使用。看起来就像guest虚机的内存缺失了一块一样：\n\n![balloon-chunk](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-chunk.png)\n\nLibvirt有两个配置项，`currentMemory`和`maxMemory`（详见[Memory Allocation](https://libvirt.org/formatdomain.html#elementsMemoryAllocation)）：\n\n![balloon-labels](http://7xrgsx.com1.z0.glb.clouddn.com/balloon-labels.png)\n\n`maxMemory`（或`<memory>`）是在guest实例启动阶段分配的内存。KVM和Xen的guest虚机目前（译者注：原文发布时间是2010-07-17 14:33）无法找过这个内存上限。`currentMemory`控制了请求分配给guest实例上应用程序的内存。balloon填充剩余的内存，并且把这部分内存还给宿主机，用于宿主机的在其他地方使用。\n\n该项配置可以手动调整，或者通过编辑XML文件，或者通过`virsh setmem`命令。\n","slug":"virtio-balloon","published":1,"updated":"2018-07-17T09:18:09.756Z","_id":"cjjph9wxo000zxu2z993sslov","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>原文地址：<a href=\"https://rwmj.wordpress.com/2010/07/17/virtio-balloon/\" target=\"_blank\" rel=\"noopener\">Virtio balloon</a><br>原创翻译，转载请注明出处。</p>\n</blockquote>\n<p>本文主要介绍了什么是<a href=\"https://github.com/torvalds/linux/blob/e241e3f2bf975788a1b70dff2eb5180ca395b28e/drivers/virtio/virtio_balloon.c\" target=\"_blank\" rel=\"noopener\">KVM virtio balloon driver</a>。<a id=\"more\"></a></p>\n<p>首先，如果你从没听过这个概念，那什么是balloon driver呢？它是一种给予guest实例或者从guest实例中获取RAM的方法。（理论上来讲），如果你的guest实例需要更多的RAM，你可以通过balloon driver给他分配更多的内存，或者如果宿主机需要在guest实例中取走一下内存，balloon driver也可以做到。这些操作的执行<strong>不需要</strong>暂停或者重启guest实例。</p>\n<p>virtio_balloon是一个在guest实例中的内核驱动。这个driver表现的像一种奇怪的进程，要么扩展自己的内存使用，要么压缩自己的内存使用接近什么也没有，如下图所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-expanded.png\" alt=\"balloon-expanded\"></p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-shrink.png\" alt=\"balloon-shrink\"></p>\n<p>当balloon driver扩张时，运行在guest实例中的应用会突然少了很多可用内存，然后guest实例会像没有多少内存时做的那样，交换内存并启动OOM killer（balloon本身是不可交换并且不会被杀掉的）。</p>\n<p>那么这个“浪费”内存的内核驱动程序有什么意义呢？有两点——<br>第一，驱动通过virtio通道与宿主机通讯，宿主机给其下发指令，比如扩展到指定的大小、现在开始缩小。guest实例配合操作，但是并不直接控制balloon。<br>第二，balloon中的内存也从guest实例中取消映射，并传回宿主机，因此宿主机可以将这部分内存传递给其他的guest实例使用。看起来就像guest虚机的内存缺失了一块一样：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-chunk.png\" alt=\"balloon-chunk\"></p>\n<p>Libvirt有两个配置项，<code>currentMemory</code>和<code>maxMemory</code>（详见<a href=\"https://libvirt.org/formatdomain.html#elementsMemoryAllocation\" target=\"_blank\" rel=\"noopener\">Memory Allocation</a>）：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-labels.png\" alt=\"balloon-labels\"></p>\n<p><code>maxMemory</code>（或<code>&lt;memory&gt;</code>）是在guest实例启动阶段分配的内存。KVM和Xen的guest虚机目前（译者注：原文发布时间是2010-07-17 14:33）无法找过这个内存上限。<code>currentMemory</code>控制了请求分配给guest实例上应用程序的内存。balloon填充剩余的内存，并且把这部分内存还给宿主机，用于宿主机的在其他地方使用。</p>\n<p>该项配置可以手动调整，或者通过编辑XML文件，或者通过<code>virsh setmem</code>命令。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>原文地址：<a href=\"https://rwmj.wordpress.com/2010/07/17/virtio-balloon/\" target=\"_blank\" rel=\"noopener\">Virtio balloon</a><br>原创翻译，转载请注明出处。</p>\n</blockquote>\n<p>本文主要介绍了什么是<a href=\"https://github.com/torvalds/linux/blob/e241e3f2bf975788a1b70dff2eb5180ca395b28e/drivers/virtio/virtio_balloon.c\" target=\"_blank\" rel=\"noopener\">KVM virtio balloon driver</a>。","more":"</p>\n<p>首先，如果你从没听过这个概念，那什么是balloon driver呢？它是一种给予guest实例或者从guest实例中获取RAM的方法。（理论上来讲），如果你的guest实例需要更多的RAM，你可以通过balloon driver给他分配更多的内存，或者如果宿主机需要在guest实例中取走一下内存，balloon driver也可以做到。这些操作的执行<strong>不需要</strong>暂停或者重启guest实例。</p>\n<p>virtio_balloon是一个在guest实例中的内核驱动。这个driver表现的像一种奇怪的进程，要么扩展自己的内存使用，要么压缩自己的内存使用接近什么也没有，如下图所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-expanded.png\" alt=\"balloon-expanded\"></p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-shrink.png\" alt=\"balloon-shrink\"></p>\n<p>当balloon driver扩张时，运行在guest实例中的应用会突然少了很多可用内存，然后guest实例会像没有多少内存时做的那样，交换内存并启动OOM killer（balloon本身是不可交换并且不会被杀掉的）。</p>\n<p>那么这个“浪费”内存的内核驱动程序有什么意义呢？有两点——<br>第一，驱动通过virtio通道与宿主机通讯，宿主机给其下发指令，比如扩展到指定的大小、现在开始缩小。guest实例配合操作，但是并不直接控制balloon。<br>第二，balloon中的内存也从guest实例中取消映射，并传回宿主机，因此宿主机可以将这部分内存传递给其他的guest实例使用。看起来就像guest虚机的内存缺失了一块一样：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-chunk.png\" alt=\"balloon-chunk\"></p>\n<p>Libvirt有两个配置项，<code>currentMemory</code>和<code>maxMemory</code>（详见<a href=\"https://libvirt.org/formatdomain.html#elementsMemoryAllocation\" target=\"_blank\" rel=\"noopener\">Memory Allocation</a>）：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/balloon-labels.png\" alt=\"balloon-labels\"></p>\n<p><code>maxMemory</code>（或<code>&lt;memory&gt;</code>）是在guest实例启动阶段分配的内存。KVM和Xen的guest虚机目前（译者注：原文发布时间是2010-07-17 14:33）无法找过这个内存上限。<code>currentMemory</code>控制了请求分配给guest实例上应用程序的内存。balloon填充剩余的内存，并且把这部分内存还给宿主机，用于宿主机的在其他地方使用。</p>\n<p>该项配置可以手动调整，或者通过编辑XML文件，或者通过<code>virsh setmem</code>命令。</p>"},{"title":"Understanding message with RabbitMQ","date":"2017-12-01T10:17:31.000Z","_content":"\n本文为先导文章，对消息的一些概念，AMQP的架构、基本知识点进行一个梳理和学习，为OpenStack中基于AMQP实现RPC调用的后续文章做个铺垫。\n<!-- more -->\n\n## AMQP概述\n\nAMQP(Advanced Message Queuing Protocol)，即高级消息队列协议，是一种应用层网络协议，它为特定客户端应用(application)与消息中间件代理(messaging middleware broker)之间的通信提供支持。本文针对AMQP 0-9-1 模型作一个简单的介绍，该模型即rabbitmq所使用的模型。\n\n## RabbitMQ中的消息流\n\n用过RabbitMQ的同学肯定对下面这个图会非常理解：\n![message-flow](http://7xrgsx.com1.z0.glb.clouddn.com/msg-flow.png)\n总体来讲，消息的生产者，产生消息，将消息发到消息队列RabbitMQ；消息的消费者在队列中取得消息执行后续操作，这就是RabbitMQ中的消息流。\n\n然而在在将消息推送到MQ或者在MQ中消费时，我们要连接到MQ上。在连接的时候，客户端会创建一个TCP连接到RabbitMQ broker上。一旦连接成功，则客户端会创建一个AMQP channel。AMQP的channel是在TCP连接上的虚拟频道，当我们发布消息，订阅一个队列或者是接收消息，均在频道中完成——为什么需要AMQP channel呢？因为TCP会话的建立和销毁对于操作系统来讲，是十分昂贵的。我们假设说，我们的客户端连接到MQ上进行消息消费，短时间内产生大量的TCP连接，消费完成后，又要将这些TCP连接销毁，这不仅会造成了TCP连接的巨大浪费，而且操作系统每秒钟创建的连接数量有限。很快我们就会遇到性能瓶颈。于是，AMQP channel就诞生了，在一个TCP连接上使用多个频道，每个频道都会被分配一个唯一ID作为标识，在保证每个线程的私有连接的前提下，显著的提高性能，下面是一个生动的示意图：\n![amqp-channel](http://7xrgsx.com1.z0.glb.clouddn.com/amqp-channel.png)\n\n## 从队列说起\n\n现在，已经对消息整个的生产、消费过程有了大概的了解，我们再进到内部去看下，消息究竟在RabbitMQ内部是如何流转的。\n\n从概念上来讲，消息的成功流转离不开三部分：exchange，queue和binding：\n![amqp-stack](http://7xrgsx.com1.z0.glb.clouddn.com/amqp-stack.png)\n\n* Exchange是生产者发布消息的地方\n* Queue是消息结束并被消费者接收的地方\n* Binding就是消息如何从特定的Exchange被路由到指定队列的一系列规则\n\n### 获取队列中的消息\n\n我们先来说说队列。在队列中获取消息有两种方式：\n1. 使用AMQP命令`basic.consume`来启动一个队列的消费者（订阅者），如果你的消费者需要处理一个队列的大量消息或者要求一旦有消息达到队列能够立刻自动的接收到消息，则需要使用这种方式；\n2. 使用AMQP命令`basic.get`直接访问队列获取一条消息。使用该命令后会使得消费者接收队列的下一条消息，并且在下次调用`basic.get`之前不会再接收队列的消息，即订阅队列，接收单条消息，取消订阅。千万不要在循环中使用`basic.get`以求替代`basic.consume`，要合理的进行订阅来提高吞吐。\n\n### 消息队列无订阅者或有多个订阅者\n\n如果消息队列没有订阅的消费者，消息会在队列中等待。\n\n如果一个RabbitMQ消息队列有多个消费者，那么队列中的消息将以轮询的方式服务于消费者，即，每条消息只会发送给订阅该队列的**某一个**消费者。\n\n### 消息确认\n\n消费者接收到的每条消息都需要得到确认——每个消费者可以选择要么显示的通过使用AMQP命令`basic.ack`发送确认通知给RabbitMQ，或者可以选择在订阅到队列的时候设置参数`auto_ack`为`true`，指定了该参数后，RabbitMQ会在消费者接收到消息后自动认为消息已经确认收到了。注意，这里的消息确认，不是告知消息的发送者，而是告诉RabbitMQ消费者已经收到了消息，可以安全的将该消息在队列中移除了。\n\n如果处理消息比较集中和耗时，可以考虑延迟确认消息，直到处理结束。\n\n### 消息拒绝\n\n如果消费者在处理某条消息的时候没有发送确认信息（如断开连接等），则RabbitMQ会认为该消费者不具备接收消息的条件，会将该消息重新发送给下一个订阅者。但是这种消息拒绝的方式会增加服务器负担。\n\n我们还可以使用`basic.reject`来拒绝RabbitMQ发送给消费者的消息。\n\n>注：此外，对RabbitMQ来说，还可以使用`basic.nack`，这是RabbitMQ中对reject命令特殊的扩展实现。\n\n如果设置`reject`命令的参数`requeue`为`true`，则RabbitMQ会将消息发送给下一个订阅的消费者，否则RabbitMQ会立刻在队列中删除这条消息而不发送给新的消费者。\n\n当然，不想处理消息的时候还可以通过确认消息已收到来处理，在收到某些格式不正确的消息并确认没有消费者能处理时，这么操作十分有效。\n\n> 注，在RabbitMQ的某些新版本中，会支持一个特殊的[`dead letter`队列](https://www.rabbitmq.com/dlx.html)，即无法投递的消息队列。如果使用`reject`命令并设置参数`requeue`为`false`，则消息会被丢到该队列。\n\n### 创建队列\n\n消息的消费者或者生产者都可以使用AMQP命令`queue.declare`来创建队列。但是消费者不能在已经在相同频道上订阅到其他队列的前提下声明或创建队列，必须先取消订阅将频道至于一种“可传输”的模式。\n\n创建队列时，一般由消费者指定队列的名字，如果没有指定，则RabbitMQ会随机生成一个名字，在`queue.declare`的返回值中体现出来。随机队列名在一些临时的匿名队列场景下非常有用，比如基于AMQP应用的RPC调用。\n\n在创建队列时，有两个参数很有用：\n* `exclusive` - 设置为true，则队列会设置为私有状态，常用于控制队列只允许有一个消费者的情况；\n* `auto-delete` - 队列在最后一个消费者取消订阅后自动删除，如果只需要一个临时队列提供给一个消费者，结合`auto-delete`和`exclusive`两个参数，当消费者断开连接时，队列自动被删除。\n\n创建一个队列，恰好这个队列已经存在，RabbitMQ会直接返回成功。这个特性可以用于判断队列是否存在，在创建队列时，指定`queue.declare`的参数`passive`为`true`即可；如果队列不存在，则直接返回一个错误信息并不创建队列。\n\n### 小节结语\n\n队列是AMQP消息的基石——\n* 为等待被消费的消息提供了栖息地；\n* 完美的适用于负载均衡，只需要使很多消费者订阅同一个队列即可——因为RabbitMQ会使用轮询的方式处理消息；\n* RabbitMQ中所有消息的终点\n\n## 开，往消息队列开……\n\n前面我们对消息队列Queue进行了比较详尽的介绍，那现在的问题是，消息是怎么抵达消息队列的？这时候，就需要exchange和binding了。\n\n所有的消息均要先发送到exchang（路由），然后基于特定的规则，RabbitMQ会决定将消息发往哪个队列。这些规则被称为*routing keys*，一个队列可以说“通过一个*routing key*，*绑定*到一个exchange上”。\n\n如果遇到了多个队列该怎么办？这里就要提到四种exchange类型，分别是`direct`、`fanout`、`topic`和`headers`，每一种都实现了不同的路由算法。`headers`允许通过匹配AMQP消息的header而不是routing key，所以我们这里不去深究和探讨了。\n\n### Direct exchange\n\n字面意思，直接路由。如果routing key匹配，则消息会被发送到响应的队列中，如下图所示：\n![direct-exchange](http://7xrgsx.com1.z0.glb.clouddn.com/direct-exchange.png)\n\n所有的消息队列必须实现这种方式，包括创建一个名称为空字符串的exchange，如：\n```\n$channel->basic_publish($msg, '', 'queue-name');\n```\n第一个参数标识了要发送的消息，第二个参数，一个空字符串，标识了指向默认的exchange，第三个参数就是routing key，也就是声明队列所使用的名称。\n\n如果默认的direct exchange不能满足要求，可以使用`exchange.declare`命令创建自己所需要的exchange。\n\n### Fanout exchange\n\n扇区路由，示意图如下：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fanout-exchange.png)\n\n Exchange会将收到的消息组播（multicast）到绑定的消息队列中，即这种模式下，支持应用根据一个（only one）消息做出不同的反应。比如我们考虑这么一个用户场景，在用户上传完图片后，既要更新图片缓存，又要奖励用户操作，那么此时如果使用fanout exchange，只需要将两个consumer都绑定到这个exchange上即可。那么如果还需要在上传图片后增加新的处理，只需要写好消费者的功能代码绑定到exchange上即可，对于消息生产者来讲，代码是完全解耦的。\n\n### Topic exchange\n\n这种路由方式，可以实现来自不同消息源的消息到达同一队列，示意图如下：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/topic-exchange.png)\n\n`Topic exchange`与`Direct exchange有`些类似，都是通过匹配特定的routing key来讲消息发送给绑定到exchange上的queue中。但是对于`Topic exchange`来讲，有两个特殊的binding key：\n* *，星号，替代/匹配一个单词\n* #，井号，替代/匹配零个或者多个词\n\n>注：如果队列使用的routing key是一个`#`，则会收到所有消息，忽略routing key的话，这就类似绑定到一个`fanout exchange`上；如果在routing key中不使用`#`或者`*`，则与`direct exchange`无异。\n\n\n这里留一个小问题：`为什么OpenStack中使用Topic Exchange比较多？`\n\n## 多租户：虚拟主机（vhost）和隔离\n\n每个RabbitMQ server都有能力创建多个虚拟的消息代理，即virtual host，简称vhost。每个vhost都是一个迷你的RabbitMQ server，具有自己独有的Queue、Exchange和Binding，更重要是的是，具有自己的权限。这使得多个应用同时可以安全无忧的使用同一个RabbitMQ服务器。\n\n在RabbitMQ中，默认的vhost=/，在不需要多租户的场景下，默认值就足够了。在创建RabbitMQ用户的时候需要指定至少一个vhost。\n\n>注，通过vhost隔离的租户是绝对的，即你不能将vhost A的队列绑定到vhost B的exchange上。\n\n可以使用命令查看vhosts：\n```\n[root@rabbit1 ~]# rabbitmqctl list_vhosts\nListing vhosts ...\n/\n```\n使用命令创建一个vhost：\n```\n[root@rabbit1 ~]# rabbitmqctl add_vhost f\nCreating vhost \"f\" ...\n[root@rabbit1 ~]# rabbitmqctl list_vhosts\nListing vhosts ...\nf\n/\n```\n\n## 消息的持久化\n\n每个Queue和Exchange，都有一个`durable`属性，默认值为`false`，即默认情况下RabbitMQ不会在服务器宕机或者重启后重建Queue或Exchange，所以建议这个值一定要设置成`true`。\n\n此外，只有Queue和Exchange的`durable`还不完全够，消息的持久化还需要三个要点：\n1. 将其选项`delivery mode`要设置成`2`，即`persistent`，持久的；\n2. 消息被发布到`durable`的Exchange；\n3. 消息抵达一个`durable`的Queue\n\n满足上述三个条件，消息的持久化就稳了。\n\nRabbitMQ通过将持久化的消息写入磁盘日志文件来确保消息在重启时不是丢失，即当发布一个持久化的消息到持久化的exchange，在写入到日志文件之前是不会发送消息的响应。如果持久化的消息被路由到非持久化的队列，则会自动在持久化日志中移除，即无法保证消息在重启时不会丢失。\n\n然而持久化虽好，却不要“贪杯”。因为将消息持久化到磁盘上比直接存储在内存中要慢很多，这就会面临几个问题：\n1. 会减少RabbitMQ每秒处理的消息数量，这个降低的比例甚至能达到10倍或者更多；\n2. 持久化消息在RabbitMQ的内置集群中表现不佳；\n\n那到底应不应该使用persistent/durable消息呢？首先还是要评估一下性能需求。如果单节点的RabbitMQ需要每秒处理100,000+的数据，那么可能持久化信息就不是一个好的选择。\n\n## 解决事务的方案：发送方确认模式\n\n由于AMQP内部事务对性能有很大瓶颈，现采取发送方确认模式保证事务，将信道设置为confirm模式，所有在此信道上发布的消息都会有一个唯一的ID号，当被投递到匹配的队列时，信道就会发送一个发送方确认模式给生产者应用程序，这个模式是异步的，应用程序可以等待确认的同时继续发送下一条，但如果是持久化的消息，会在写入磁盘之后消息发出。\n\n如果发送内部错误而导致消息丢失，RabbitMQ会发送一条nack(not acknowledged,未确认)消息，这种模式下每分钟可追踪数以百万计的消息投递。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/understanding-message-with-rabbitmq.md","raw":"---\ntitle: Understanding message with RabbitMQ\ndate: 2017-12-01 18:17:31\ntags: [AMQP, RabbitMQ]\n---\n\n本文为先导文章，对消息的一些概念，AMQP的架构、基本知识点进行一个梳理和学习，为OpenStack中基于AMQP实现RPC调用的后续文章做个铺垫。\n<!-- more -->\n\n## AMQP概述\n\nAMQP(Advanced Message Queuing Protocol)，即高级消息队列协议，是一种应用层网络协议，它为特定客户端应用(application)与消息中间件代理(messaging middleware broker)之间的通信提供支持。本文针对AMQP 0-9-1 模型作一个简单的介绍，该模型即rabbitmq所使用的模型。\n\n## RabbitMQ中的消息流\n\n用过RabbitMQ的同学肯定对下面这个图会非常理解：\n![message-flow](http://7xrgsx.com1.z0.glb.clouddn.com/msg-flow.png)\n总体来讲，消息的生产者，产生消息，将消息发到消息队列RabbitMQ；消息的消费者在队列中取得消息执行后续操作，这就是RabbitMQ中的消息流。\n\n然而在在将消息推送到MQ或者在MQ中消费时，我们要连接到MQ上。在连接的时候，客户端会创建一个TCP连接到RabbitMQ broker上。一旦连接成功，则客户端会创建一个AMQP channel。AMQP的channel是在TCP连接上的虚拟频道，当我们发布消息，订阅一个队列或者是接收消息，均在频道中完成——为什么需要AMQP channel呢？因为TCP会话的建立和销毁对于操作系统来讲，是十分昂贵的。我们假设说，我们的客户端连接到MQ上进行消息消费，短时间内产生大量的TCP连接，消费完成后，又要将这些TCP连接销毁，这不仅会造成了TCP连接的巨大浪费，而且操作系统每秒钟创建的连接数量有限。很快我们就会遇到性能瓶颈。于是，AMQP channel就诞生了，在一个TCP连接上使用多个频道，每个频道都会被分配一个唯一ID作为标识，在保证每个线程的私有连接的前提下，显著的提高性能，下面是一个生动的示意图：\n![amqp-channel](http://7xrgsx.com1.z0.glb.clouddn.com/amqp-channel.png)\n\n## 从队列说起\n\n现在，已经对消息整个的生产、消费过程有了大概的了解，我们再进到内部去看下，消息究竟在RabbitMQ内部是如何流转的。\n\n从概念上来讲，消息的成功流转离不开三部分：exchange，queue和binding：\n![amqp-stack](http://7xrgsx.com1.z0.glb.clouddn.com/amqp-stack.png)\n\n* Exchange是生产者发布消息的地方\n* Queue是消息结束并被消费者接收的地方\n* Binding就是消息如何从特定的Exchange被路由到指定队列的一系列规则\n\n### 获取队列中的消息\n\n我们先来说说队列。在队列中获取消息有两种方式：\n1. 使用AMQP命令`basic.consume`来启动一个队列的消费者（订阅者），如果你的消费者需要处理一个队列的大量消息或者要求一旦有消息达到队列能够立刻自动的接收到消息，则需要使用这种方式；\n2. 使用AMQP命令`basic.get`直接访问队列获取一条消息。使用该命令后会使得消费者接收队列的下一条消息，并且在下次调用`basic.get`之前不会再接收队列的消息，即订阅队列，接收单条消息，取消订阅。千万不要在循环中使用`basic.get`以求替代`basic.consume`，要合理的进行订阅来提高吞吐。\n\n### 消息队列无订阅者或有多个订阅者\n\n如果消息队列没有订阅的消费者，消息会在队列中等待。\n\n如果一个RabbitMQ消息队列有多个消费者，那么队列中的消息将以轮询的方式服务于消费者，即，每条消息只会发送给订阅该队列的**某一个**消费者。\n\n### 消息确认\n\n消费者接收到的每条消息都需要得到确认——每个消费者可以选择要么显示的通过使用AMQP命令`basic.ack`发送确认通知给RabbitMQ，或者可以选择在订阅到队列的时候设置参数`auto_ack`为`true`，指定了该参数后，RabbitMQ会在消费者接收到消息后自动认为消息已经确认收到了。注意，这里的消息确认，不是告知消息的发送者，而是告诉RabbitMQ消费者已经收到了消息，可以安全的将该消息在队列中移除了。\n\n如果处理消息比较集中和耗时，可以考虑延迟确认消息，直到处理结束。\n\n### 消息拒绝\n\n如果消费者在处理某条消息的时候没有发送确认信息（如断开连接等），则RabbitMQ会认为该消费者不具备接收消息的条件，会将该消息重新发送给下一个订阅者。但是这种消息拒绝的方式会增加服务器负担。\n\n我们还可以使用`basic.reject`来拒绝RabbitMQ发送给消费者的消息。\n\n>注：此外，对RabbitMQ来说，还可以使用`basic.nack`，这是RabbitMQ中对reject命令特殊的扩展实现。\n\n如果设置`reject`命令的参数`requeue`为`true`，则RabbitMQ会将消息发送给下一个订阅的消费者，否则RabbitMQ会立刻在队列中删除这条消息而不发送给新的消费者。\n\n当然，不想处理消息的时候还可以通过确认消息已收到来处理，在收到某些格式不正确的消息并确认没有消费者能处理时，这么操作十分有效。\n\n> 注，在RabbitMQ的某些新版本中，会支持一个特殊的[`dead letter`队列](https://www.rabbitmq.com/dlx.html)，即无法投递的消息队列。如果使用`reject`命令并设置参数`requeue`为`false`，则消息会被丢到该队列。\n\n### 创建队列\n\n消息的消费者或者生产者都可以使用AMQP命令`queue.declare`来创建队列。但是消费者不能在已经在相同频道上订阅到其他队列的前提下声明或创建队列，必须先取消订阅将频道至于一种“可传输”的模式。\n\n创建队列时，一般由消费者指定队列的名字，如果没有指定，则RabbitMQ会随机生成一个名字，在`queue.declare`的返回值中体现出来。随机队列名在一些临时的匿名队列场景下非常有用，比如基于AMQP应用的RPC调用。\n\n在创建队列时，有两个参数很有用：\n* `exclusive` - 设置为true，则队列会设置为私有状态，常用于控制队列只允许有一个消费者的情况；\n* `auto-delete` - 队列在最后一个消费者取消订阅后自动删除，如果只需要一个临时队列提供给一个消费者，结合`auto-delete`和`exclusive`两个参数，当消费者断开连接时，队列自动被删除。\n\n创建一个队列，恰好这个队列已经存在，RabbitMQ会直接返回成功。这个特性可以用于判断队列是否存在，在创建队列时，指定`queue.declare`的参数`passive`为`true`即可；如果队列不存在，则直接返回一个错误信息并不创建队列。\n\n### 小节结语\n\n队列是AMQP消息的基石——\n* 为等待被消费的消息提供了栖息地；\n* 完美的适用于负载均衡，只需要使很多消费者订阅同一个队列即可——因为RabbitMQ会使用轮询的方式处理消息；\n* RabbitMQ中所有消息的终点\n\n## 开，往消息队列开……\n\n前面我们对消息队列Queue进行了比较详尽的介绍，那现在的问题是，消息是怎么抵达消息队列的？这时候，就需要exchange和binding了。\n\n所有的消息均要先发送到exchang（路由），然后基于特定的规则，RabbitMQ会决定将消息发往哪个队列。这些规则被称为*routing keys*，一个队列可以说“通过一个*routing key*，*绑定*到一个exchange上”。\n\n如果遇到了多个队列该怎么办？这里就要提到四种exchange类型，分别是`direct`、`fanout`、`topic`和`headers`，每一种都实现了不同的路由算法。`headers`允许通过匹配AMQP消息的header而不是routing key，所以我们这里不去深究和探讨了。\n\n### Direct exchange\n\n字面意思，直接路由。如果routing key匹配，则消息会被发送到响应的队列中，如下图所示：\n![direct-exchange](http://7xrgsx.com1.z0.glb.clouddn.com/direct-exchange.png)\n\n所有的消息队列必须实现这种方式，包括创建一个名称为空字符串的exchange，如：\n```\n$channel->basic_publish($msg, '', 'queue-name');\n```\n第一个参数标识了要发送的消息，第二个参数，一个空字符串，标识了指向默认的exchange，第三个参数就是routing key，也就是声明队列所使用的名称。\n\n如果默认的direct exchange不能满足要求，可以使用`exchange.declare`命令创建自己所需要的exchange。\n\n### Fanout exchange\n\n扇区路由，示意图如下：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fanout-exchange.png)\n\n Exchange会将收到的消息组播（multicast）到绑定的消息队列中，即这种模式下，支持应用根据一个（only one）消息做出不同的反应。比如我们考虑这么一个用户场景，在用户上传完图片后，既要更新图片缓存，又要奖励用户操作，那么此时如果使用fanout exchange，只需要将两个consumer都绑定到这个exchange上即可。那么如果还需要在上传图片后增加新的处理，只需要写好消费者的功能代码绑定到exchange上即可，对于消息生产者来讲，代码是完全解耦的。\n\n### Topic exchange\n\n这种路由方式，可以实现来自不同消息源的消息到达同一队列，示意图如下：\n![](http://7xrgsx.com1.z0.glb.clouddn.com/topic-exchange.png)\n\n`Topic exchange`与`Direct exchange有`些类似，都是通过匹配特定的routing key来讲消息发送给绑定到exchange上的queue中。但是对于`Topic exchange`来讲，有两个特殊的binding key：\n* *，星号，替代/匹配一个单词\n* #，井号，替代/匹配零个或者多个词\n\n>注：如果队列使用的routing key是一个`#`，则会收到所有消息，忽略routing key的话，这就类似绑定到一个`fanout exchange`上；如果在routing key中不使用`#`或者`*`，则与`direct exchange`无异。\n\n\n这里留一个小问题：`为什么OpenStack中使用Topic Exchange比较多？`\n\n## 多租户：虚拟主机（vhost）和隔离\n\n每个RabbitMQ server都有能力创建多个虚拟的消息代理，即virtual host，简称vhost。每个vhost都是一个迷你的RabbitMQ server，具有自己独有的Queue、Exchange和Binding，更重要是的是，具有自己的权限。这使得多个应用同时可以安全无忧的使用同一个RabbitMQ服务器。\n\n在RabbitMQ中，默认的vhost=/，在不需要多租户的场景下，默认值就足够了。在创建RabbitMQ用户的时候需要指定至少一个vhost。\n\n>注，通过vhost隔离的租户是绝对的，即你不能将vhost A的队列绑定到vhost B的exchange上。\n\n可以使用命令查看vhosts：\n```\n[root@rabbit1 ~]# rabbitmqctl list_vhosts\nListing vhosts ...\n/\n```\n使用命令创建一个vhost：\n```\n[root@rabbit1 ~]# rabbitmqctl add_vhost f\nCreating vhost \"f\" ...\n[root@rabbit1 ~]# rabbitmqctl list_vhosts\nListing vhosts ...\nf\n/\n```\n\n## 消息的持久化\n\n每个Queue和Exchange，都有一个`durable`属性，默认值为`false`，即默认情况下RabbitMQ不会在服务器宕机或者重启后重建Queue或Exchange，所以建议这个值一定要设置成`true`。\n\n此外，只有Queue和Exchange的`durable`还不完全够，消息的持久化还需要三个要点：\n1. 将其选项`delivery mode`要设置成`2`，即`persistent`，持久的；\n2. 消息被发布到`durable`的Exchange；\n3. 消息抵达一个`durable`的Queue\n\n满足上述三个条件，消息的持久化就稳了。\n\nRabbitMQ通过将持久化的消息写入磁盘日志文件来确保消息在重启时不是丢失，即当发布一个持久化的消息到持久化的exchange，在写入到日志文件之前是不会发送消息的响应。如果持久化的消息被路由到非持久化的队列，则会自动在持久化日志中移除，即无法保证消息在重启时不会丢失。\n\n然而持久化虽好，却不要“贪杯”。因为将消息持久化到磁盘上比直接存储在内存中要慢很多，这就会面临几个问题：\n1. 会减少RabbitMQ每秒处理的消息数量，这个降低的比例甚至能达到10倍或者更多；\n2. 持久化消息在RabbitMQ的内置集群中表现不佳；\n\n那到底应不应该使用persistent/durable消息呢？首先还是要评估一下性能需求。如果单节点的RabbitMQ需要每秒处理100,000+的数据，那么可能持久化信息就不是一个好的选择。\n\n## 解决事务的方案：发送方确认模式\n\n由于AMQP内部事务对性能有很大瓶颈，现采取发送方确认模式保证事务，将信道设置为confirm模式，所有在此信道上发布的消息都会有一个唯一的ID号，当被投递到匹配的队列时，信道就会发送一个发送方确认模式给生产者应用程序，这个模式是异步的，应用程序可以等待确认的同时继续发送下一条，但如果是持久化的消息，会在写入磁盘之后消息发出。\n\n如果发送内部错误而导致消息丢失，RabbitMQ会发送一条nack(not acknowledged,未确认)消息，这种模式下每分钟可追踪数以百万计的消息投递。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"understanding-message-with-rabbitmq","published":1,"updated":"2018-01-15T08:39:03.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxq0011xu2zdlt3a265","content":"<p>本文为先导文章，对消息的一些概念，AMQP的架构、基本知识点进行一个梳理和学习，为OpenStack中基于AMQP实现RPC调用的后续文章做个铺垫。<br><a id=\"more\"></a></p>\n<h2 id=\"AMQP概述\"><a href=\"#AMQP概述\" class=\"headerlink\" title=\"AMQP概述\"></a>AMQP概述</h2><p>AMQP(Advanced Message Queuing Protocol)，即高级消息队列协议，是一种应用层网络协议，它为特定客户端应用(application)与消息中间件代理(messaging middleware broker)之间的通信提供支持。本文针对AMQP 0-9-1 模型作一个简单的介绍，该模型即rabbitmq所使用的模型。</p>\n<h2 id=\"RabbitMQ中的消息流\"><a href=\"#RabbitMQ中的消息流\" class=\"headerlink\" title=\"RabbitMQ中的消息流\"></a>RabbitMQ中的消息流</h2><p>用过RabbitMQ的同学肯定对下面这个图会非常理解：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/msg-flow.png\" alt=\"message-flow\"><br>总体来讲，消息的生产者，产生消息，将消息发到消息队列RabbitMQ；消息的消费者在队列中取得消息执行后续操作，这就是RabbitMQ中的消息流。</p>\n<p>然而在在将消息推送到MQ或者在MQ中消费时，我们要连接到MQ上。在连接的时候，客户端会创建一个TCP连接到RabbitMQ broker上。一旦连接成功，则客户端会创建一个AMQP channel。AMQP的channel是在TCP连接上的虚拟频道，当我们发布消息，订阅一个队列或者是接收消息，均在频道中完成——为什么需要AMQP channel呢？因为TCP会话的建立和销毁对于操作系统来讲，是十分昂贵的。我们假设说，我们的客户端连接到MQ上进行消息消费，短时间内产生大量的TCP连接，消费完成后，又要将这些TCP连接销毁，这不仅会造成了TCP连接的巨大浪费，而且操作系统每秒钟创建的连接数量有限。很快我们就会遇到性能瓶颈。于是，AMQP channel就诞生了，在一个TCP连接上使用多个频道，每个频道都会被分配一个唯一ID作为标识，在保证每个线程的私有连接的前提下，显著的提高性能，下面是一个生动的示意图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/amqp-channel.png\" alt=\"amqp-channel\"></p>\n<h2 id=\"从队列说起\"><a href=\"#从队列说起\" class=\"headerlink\" title=\"从队列说起\"></a>从队列说起</h2><p>现在，已经对消息整个的生产、消费过程有了大概的了解，我们再进到内部去看下，消息究竟在RabbitMQ内部是如何流转的。</p>\n<p>从概念上来讲，消息的成功流转离不开三部分：exchange，queue和binding：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/amqp-stack.png\" alt=\"amqp-stack\"></p>\n<ul>\n<li>Exchange是生产者发布消息的地方</li>\n<li>Queue是消息结束并被消费者接收的地方</li>\n<li>Binding就是消息如何从特定的Exchange被路由到指定队列的一系列规则</li>\n</ul>\n<h3 id=\"获取队列中的消息\"><a href=\"#获取队列中的消息\" class=\"headerlink\" title=\"获取队列中的消息\"></a>获取队列中的消息</h3><p>我们先来说说队列。在队列中获取消息有两种方式：</p>\n<ol>\n<li>使用AMQP命令<code>basic.consume</code>来启动一个队列的消费者（订阅者），如果你的消费者需要处理一个队列的大量消息或者要求一旦有消息达到队列能够立刻自动的接收到消息，则需要使用这种方式；</li>\n<li>使用AMQP命令<code>basic.get</code>直接访问队列获取一条消息。使用该命令后会使得消费者接收队列的下一条消息，并且在下次调用<code>basic.get</code>之前不会再接收队列的消息，即订阅队列，接收单条消息，取消订阅。千万不要在循环中使用<code>basic.get</code>以求替代<code>basic.consume</code>，要合理的进行订阅来提高吞吐。</li>\n</ol>\n<h3 id=\"消息队列无订阅者或有多个订阅者\"><a href=\"#消息队列无订阅者或有多个订阅者\" class=\"headerlink\" title=\"消息队列无订阅者或有多个订阅者\"></a>消息队列无订阅者或有多个订阅者</h3><p>如果消息队列没有订阅的消费者，消息会在队列中等待。</p>\n<p>如果一个RabbitMQ消息队列有多个消费者，那么队列中的消息将以轮询的方式服务于消费者，即，每条消息只会发送给订阅该队列的<strong>某一个</strong>消费者。</p>\n<h3 id=\"消息确认\"><a href=\"#消息确认\" class=\"headerlink\" title=\"消息确认\"></a>消息确认</h3><p>消费者接收到的每条消息都需要得到确认——每个消费者可以选择要么显示的通过使用AMQP命令<code>basic.ack</code>发送确认通知给RabbitMQ，或者可以选择在订阅到队列的时候设置参数<code>auto_ack</code>为<code>true</code>，指定了该参数后，RabbitMQ会在消费者接收到消息后自动认为消息已经确认收到了。注意，这里的消息确认，不是告知消息的发送者，而是告诉RabbitMQ消费者已经收到了消息，可以安全的将该消息在队列中移除了。</p>\n<p>如果处理消息比较集中和耗时，可以考虑延迟确认消息，直到处理结束。</p>\n<h3 id=\"消息拒绝\"><a href=\"#消息拒绝\" class=\"headerlink\" title=\"消息拒绝\"></a>消息拒绝</h3><p>如果消费者在处理某条消息的时候没有发送确认信息（如断开连接等），则RabbitMQ会认为该消费者不具备接收消息的条件，会将该消息重新发送给下一个订阅者。但是这种消息拒绝的方式会增加服务器负担。</p>\n<p>我们还可以使用<code>basic.reject</code>来拒绝RabbitMQ发送给消费者的消息。</p>\n<blockquote>\n<p>注：此外，对RabbitMQ来说，还可以使用<code>basic.nack</code>，这是RabbitMQ中对reject命令特殊的扩展实现。</p>\n</blockquote>\n<p>如果设置<code>reject</code>命令的参数<code>requeue</code>为<code>true</code>，则RabbitMQ会将消息发送给下一个订阅的消费者，否则RabbitMQ会立刻在队列中删除这条消息而不发送给新的消费者。</p>\n<p>当然，不想处理消息的时候还可以通过确认消息已收到来处理，在收到某些格式不正确的消息并确认没有消费者能处理时，这么操作十分有效。</p>\n<blockquote>\n<p>注，在RabbitMQ的某些新版本中，会支持一个特殊的<a href=\"https://www.rabbitmq.com/dlx.html\" target=\"_blank\" rel=\"noopener\"><code>dead letter</code>队列</a>，即无法投递的消息队列。如果使用<code>reject</code>命令并设置参数<code>requeue</code>为<code>false</code>，则消息会被丢到该队列。</p>\n</blockquote>\n<h3 id=\"创建队列\"><a href=\"#创建队列\" class=\"headerlink\" title=\"创建队列\"></a>创建队列</h3><p>消息的消费者或者生产者都可以使用AMQP命令<code>queue.declare</code>来创建队列。但是消费者不能在已经在相同频道上订阅到其他队列的前提下声明或创建队列，必须先取消订阅将频道至于一种“可传输”的模式。</p>\n<p>创建队列时，一般由消费者指定队列的名字，如果没有指定，则RabbitMQ会随机生成一个名字，在<code>queue.declare</code>的返回值中体现出来。随机队列名在一些临时的匿名队列场景下非常有用，比如基于AMQP应用的RPC调用。</p>\n<p>在创建队列时，有两个参数很有用：</p>\n<ul>\n<li><code>exclusive</code> - 设置为true，则队列会设置为私有状态，常用于控制队列只允许有一个消费者的情况；</li>\n<li><code>auto-delete</code> - 队列在最后一个消费者取消订阅后自动删除，如果只需要一个临时队列提供给一个消费者，结合<code>auto-delete</code>和<code>exclusive</code>两个参数，当消费者断开连接时，队列自动被删除。</li>\n</ul>\n<p>创建一个队列，恰好这个队列已经存在，RabbitMQ会直接返回成功。这个特性可以用于判断队列是否存在，在创建队列时，指定<code>queue.declare</code>的参数<code>passive</code>为<code>true</code>即可；如果队列不存在，则直接返回一个错误信息并不创建队列。</p>\n<h3 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h3><p>队列是AMQP消息的基石——</p>\n<ul>\n<li>为等待被消费的消息提供了栖息地；</li>\n<li>完美的适用于负载均衡，只需要使很多消费者订阅同一个队列即可——因为RabbitMQ会使用轮询的方式处理消息；</li>\n<li>RabbitMQ中所有消息的终点</li>\n</ul>\n<h2 id=\"开，往消息队列开……\"><a href=\"#开，往消息队列开……\" class=\"headerlink\" title=\"开，往消息队列开……\"></a>开，往消息队列开……</h2><p>前面我们对消息队列Queue进行了比较详尽的介绍，那现在的问题是，消息是怎么抵达消息队列的？这时候，就需要exchange和binding了。</p>\n<p>所有的消息均要先发送到exchang（路由），然后基于特定的规则，RabbitMQ会决定将消息发往哪个队列。这些规则被称为<em>routing keys</em>，一个队列可以说“通过一个<em>routing key</em>，<em>绑定</em>到一个exchange上”。</p>\n<p>如果遇到了多个队列该怎么办？这里就要提到四种exchange类型，分别是<code>direct</code>、<code>fanout</code>、<code>topic</code>和<code>headers</code>，每一种都实现了不同的路由算法。<code>headers</code>允许通过匹配AMQP消息的header而不是routing key，所以我们这里不去深究和探讨了。</p>\n<h3 id=\"Direct-exchange\"><a href=\"#Direct-exchange\" class=\"headerlink\" title=\"Direct exchange\"></a>Direct exchange</h3><p>字面意思，直接路由。如果routing key匹配，则消息会被发送到响应的队列中，如下图所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/direct-exchange.png\" alt=\"direct-exchange\"></p>\n<p>所有的消息队列必须实现这种方式，包括创建一个名称为空字符串的exchange，如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$channel-&gt;basic_publish($msg, &apos;&apos;, &apos;queue-name&apos;);</span><br></pre></td></tr></table></figure></p>\n<p>第一个参数标识了要发送的消息，第二个参数，一个空字符串，标识了指向默认的exchange，第三个参数就是routing key，也就是声明队列所使用的名称。</p>\n<p>如果默认的direct exchange不能满足要求，可以使用<code>exchange.declare</code>命令创建自己所需要的exchange。</p>\n<h3 id=\"Fanout-exchange\"><a href=\"#Fanout-exchange\" class=\"headerlink\" title=\"Fanout exchange\"></a>Fanout exchange</h3><p>扇区路由，示意图如下：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fanout-exchange.png\" alt=\"\"></p>\n<p> Exchange会将收到的消息组播（multicast）到绑定的消息队列中，即这种模式下，支持应用根据一个（only one）消息做出不同的反应。比如我们考虑这么一个用户场景，在用户上传完图片后，既要更新图片缓存，又要奖励用户操作，那么此时如果使用fanout exchange，只需要将两个consumer都绑定到这个exchange上即可。那么如果还需要在上传图片后增加新的处理，只需要写好消费者的功能代码绑定到exchange上即可，对于消息生产者来讲，代码是完全解耦的。</p>\n<h3 id=\"Topic-exchange\"><a href=\"#Topic-exchange\" class=\"headerlink\" title=\"Topic exchange\"></a>Topic exchange</h3><p>这种路由方式，可以实现来自不同消息源的消息到达同一队列，示意图如下：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/topic-exchange.png\" alt=\"\"></p>\n<p><code>Topic exchange</code>与<code>Direct exchange有</code>些类似，都是通过匹配特定的routing key来讲消息发送给绑定到exchange上的queue中。但是对于<code>Topic exchange</code>来讲，有两个特殊的binding key：</p>\n<ul>\n<li>*，星号，替代/匹配一个单词</li>\n<li>#，井号，替代/匹配零个或者多个词</li>\n</ul>\n<blockquote>\n<p>注：如果队列使用的routing key是一个<code>#</code>，则会收到所有消息，忽略routing key的话，这就类似绑定到一个<code>fanout exchange</code>上；如果在routing key中不使用<code>#</code>或者<code>*</code>，则与<code>direct exchange</code>无异。</p>\n</blockquote>\n<p>这里留一个小问题：<code>为什么OpenStack中使用Topic Exchange比较多？</code></p>\n<h2 id=\"多租户：虚拟主机（vhost）和隔离\"><a href=\"#多租户：虚拟主机（vhost）和隔离\" class=\"headerlink\" title=\"多租户：虚拟主机（vhost）和隔离\"></a>多租户：虚拟主机（vhost）和隔离</h2><p>每个RabbitMQ server都有能力创建多个虚拟的消息代理，即virtual host，简称vhost。每个vhost都是一个迷你的RabbitMQ server，具有自己独有的Queue、Exchange和Binding，更重要是的是，具有自己的权限。这使得多个应用同时可以安全无忧的使用同一个RabbitMQ服务器。</p>\n<p>在RabbitMQ中，默认的vhost=/，在不需要多租户的场景下，默认值就足够了。在创建RabbitMQ用户的时候需要指定至少一个vhost。</p>\n<blockquote>\n<p>注，通过vhost隔离的租户是绝对的，即你不能将vhost A的队列绑定到vhost B的exchange上。</p>\n</blockquote>\n<p>可以使用命令查看vhosts：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl list_vhosts</span><br><span class=\"line\">Listing vhosts ...</span><br><span class=\"line\">/</span><br></pre></td></tr></table></figure></p>\n<p>使用命令创建一个vhost：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl add_vhost f</span><br><span class=\"line\">Creating vhost &quot;f&quot; ...</span><br><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl list_vhosts</span><br><span class=\"line\">Listing vhosts ...</span><br><span class=\"line\">f</span><br><span class=\"line\">/</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"消息的持久化\"><a href=\"#消息的持久化\" class=\"headerlink\" title=\"消息的持久化\"></a>消息的持久化</h2><p>每个Queue和Exchange，都有一个<code>durable</code>属性，默认值为<code>false</code>，即默认情况下RabbitMQ不会在服务器宕机或者重启后重建Queue或Exchange，所以建议这个值一定要设置成<code>true</code>。</p>\n<p>此外，只有Queue和Exchange的<code>durable</code>还不完全够，消息的持久化还需要三个要点：</p>\n<ol>\n<li>将其选项<code>delivery mode</code>要设置成<code>2</code>，即<code>persistent</code>，持久的；</li>\n<li>消息被发布到<code>durable</code>的Exchange；</li>\n<li>消息抵达一个<code>durable</code>的Queue</li>\n</ol>\n<p>满足上述三个条件，消息的持久化就稳了。</p>\n<p>RabbitMQ通过将持久化的消息写入磁盘日志文件来确保消息在重启时不是丢失，即当发布一个持久化的消息到持久化的exchange，在写入到日志文件之前是不会发送消息的响应。如果持久化的消息被路由到非持久化的队列，则会自动在持久化日志中移除，即无法保证消息在重启时不会丢失。</p>\n<p>然而持久化虽好，却不要“贪杯”。因为将消息持久化到磁盘上比直接存储在内存中要慢很多，这就会面临几个问题：</p>\n<ol>\n<li>会减少RabbitMQ每秒处理的消息数量，这个降低的比例甚至能达到10倍或者更多；</li>\n<li>持久化消息在RabbitMQ的内置集群中表现不佳；</li>\n</ol>\n<p>那到底应不应该使用persistent/durable消息呢？首先还是要评估一下性能需求。如果单节点的RabbitMQ需要每秒处理100,000+的数据，那么可能持久化信息就不是一个好的选择。</p>\n<h2 id=\"解决事务的方案：发送方确认模式\"><a href=\"#解决事务的方案：发送方确认模式\" class=\"headerlink\" title=\"解决事务的方案：发送方确认模式\"></a>解决事务的方案：发送方确认模式</h2><p>由于AMQP内部事务对性能有很大瓶颈，现采取发送方确认模式保证事务，将信道设置为confirm模式，所有在此信道上发布的消息都会有一个唯一的ID号，当被投递到匹配的队列时，信道就会发送一个发送方确认模式给生产者应用程序，这个模式是异步的，应用程序可以等待确认的同时继续发送下一条，但如果是持久化的消息，会在写入磁盘之后消息发出。</p>\n<p>如果发送内部错误而导致消息丢失，RabbitMQ会发送一条nack(not acknowledged,未确认)消息，这种模式下每分钟可追踪数以百万计的消息投递。</p>\n","site":{"data":{}},"excerpt":"<p>本文为先导文章，对消息的一些概念，AMQP的架构、基本知识点进行一个梳理和学习，为OpenStack中基于AMQP实现RPC调用的后续文章做个铺垫。<br>","more":"</p>\n<h2 id=\"AMQP概述\"><a href=\"#AMQP概述\" class=\"headerlink\" title=\"AMQP概述\"></a>AMQP概述</h2><p>AMQP(Advanced Message Queuing Protocol)，即高级消息队列协议，是一种应用层网络协议，它为特定客户端应用(application)与消息中间件代理(messaging middleware broker)之间的通信提供支持。本文针对AMQP 0-9-1 模型作一个简单的介绍，该模型即rabbitmq所使用的模型。</p>\n<h2 id=\"RabbitMQ中的消息流\"><a href=\"#RabbitMQ中的消息流\" class=\"headerlink\" title=\"RabbitMQ中的消息流\"></a>RabbitMQ中的消息流</h2><p>用过RabbitMQ的同学肯定对下面这个图会非常理解：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/msg-flow.png\" alt=\"message-flow\"><br>总体来讲，消息的生产者，产生消息，将消息发到消息队列RabbitMQ；消息的消费者在队列中取得消息执行后续操作，这就是RabbitMQ中的消息流。</p>\n<p>然而在在将消息推送到MQ或者在MQ中消费时，我们要连接到MQ上。在连接的时候，客户端会创建一个TCP连接到RabbitMQ broker上。一旦连接成功，则客户端会创建一个AMQP channel。AMQP的channel是在TCP连接上的虚拟频道，当我们发布消息，订阅一个队列或者是接收消息，均在频道中完成——为什么需要AMQP channel呢？因为TCP会话的建立和销毁对于操作系统来讲，是十分昂贵的。我们假设说，我们的客户端连接到MQ上进行消息消费，短时间内产生大量的TCP连接，消费完成后，又要将这些TCP连接销毁，这不仅会造成了TCP连接的巨大浪费，而且操作系统每秒钟创建的连接数量有限。很快我们就会遇到性能瓶颈。于是，AMQP channel就诞生了，在一个TCP连接上使用多个频道，每个频道都会被分配一个唯一ID作为标识，在保证每个线程的私有连接的前提下，显著的提高性能，下面是一个生动的示意图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/amqp-channel.png\" alt=\"amqp-channel\"></p>\n<h2 id=\"从队列说起\"><a href=\"#从队列说起\" class=\"headerlink\" title=\"从队列说起\"></a>从队列说起</h2><p>现在，已经对消息整个的生产、消费过程有了大概的了解，我们再进到内部去看下，消息究竟在RabbitMQ内部是如何流转的。</p>\n<p>从概念上来讲，消息的成功流转离不开三部分：exchange，queue和binding：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/amqp-stack.png\" alt=\"amqp-stack\"></p>\n<ul>\n<li>Exchange是生产者发布消息的地方</li>\n<li>Queue是消息结束并被消费者接收的地方</li>\n<li>Binding就是消息如何从特定的Exchange被路由到指定队列的一系列规则</li>\n</ul>\n<h3 id=\"获取队列中的消息\"><a href=\"#获取队列中的消息\" class=\"headerlink\" title=\"获取队列中的消息\"></a>获取队列中的消息</h3><p>我们先来说说队列。在队列中获取消息有两种方式：</p>\n<ol>\n<li>使用AMQP命令<code>basic.consume</code>来启动一个队列的消费者（订阅者），如果你的消费者需要处理一个队列的大量消息或者要求一旦有消息达到队列能够立刻自动的接收到消息，则需要使用这种方式；</li>\n<li>使用AMQP命令<code>basic.get</code>直接访问队列获取一条消息。使用该命令后会使得消费者接收队列的下一条消息，并且在下次调用<code>basic.get</code>之前不会再接收队列的消息，即订阅队列，接收单条消息，取消订阅。千万不要在循环中使用<code>basic.get</code>以求替代<code>basic.consume</code>，要合理的进行订阅来提高吞吐。</li>\n</ol>\n<h3 id=\"消息队列无订阅者或有多个订阅者\"><a href=\"#消息队列无订阅者或有多个订阅者\" class=\"headerlink\" title=\"消息队列无订阅者或有多个订阅者\"></a>消息队列无订阅者或有多个订阅者</h3><p>如果消息队列没有订阅的消费者，消息会在队列中等待。</p>\n<p>如果一个RabbitMQ消息队列有多个消费者，那么队列中的消息将以轮询的方式服务于消费者，即，每条消息只会发送给订阅该队列的<strong>某一个</strong>消费者。</p>\n<h3 id=\"消息确认\"><a href=\"#消息确认\" class=\"headerlink\" title=\"消息确认\"></a>消息确认</h3><p>消费者接收到的每条消息都需要得到确认——每个消费者可以选择要么显示的通过使用AMQP命令<code>basic.ack</code>发送确认通知给RabbitMQ，或者可以选择在订阅到队列的时候设置参数<code>auto_ack</code>为<code>true</code>，指定了该参数后，RabbitMQ会在消费者接收到消息后自动认为消息已经确认收到了。注意，这里的消息确认，不是告知消息的发送者，而是告诉RabbitMQ消费者已经收到了消息，可以安全的将该消息在队列中移除了。</p>\n<p>如果处理消息比较集中和耗时，可以考虑延迟确认消息，直到处理结束。</p>\n<h3 id=\"消息拒绝\"><a href=\"#消息拒绝\" class=\"headerlink\" title=\"消息拒绝\"></a>消息拒绝</h3><p>如果消费者在处理某条消息的时候没有发送确认信息（如断开连接等），则RabbitMQ会认为该消费者不具备接收消息的条件，会将该消息重新发送给下一个订阅者。但是这种消息拒绝的方式会增加服务器负担。</p>\n<p>我们还可以使用<code>basic.reject</code>来拒绝RabbitMQ发送给消费者的消息。</p>\n<blockquote>\n<p>注：此外，对RabbitMQ来说，还可以使用<code>basic.nack</code>，这是RabbitMQ中对reject命令特殊的扩展实现。</p>\n</blockquote>\n<p>如果设置<code>reject</code>命令的参数<code>requeue</code>为<code>true</code>，则RabbitMQ会将消息发送给下一个订阅的消费者，否则RabbitMQ会立刻在队列中删除这条消息而不发送给新的消费者。</p>\n<p>当然，不想处理消息的时候还可以通过确认消息已收到来处理，在收到某些格式不正确的消息并确认没有消费者能处理时，这么操作十分有效。</p>\n<blockquote>\n<p>注，在RabbitMQ的某些新版本中，会支持一个特殊的<a href=\"https://www.rabbitmq.com/dlx.html\" target=\"_blank\" rel=\"noopener\"><code>dead letter</code>队列</a>，即无法投递的消息队列。如果使用<code>reject</code>命令并设置参数<code>requeue</code>为<code>false</code>，则消息会被丢到该队列。</p>\n</blockquote>\n<h3 id=\"创建队列\"><a href=\"#创建队列\" class=\"headerlink\" title=\"创建队列\"></a>创建队列</h3><p>消息的消费者或者生产者都可以使用AMQP命令<code>queue.declare</code>来创建队列。但是消费者不能在已经在相同频道上订阅到其他队列的前提下声明或创建队列，必须先取消订阅将频道至于一种“可传输”的模式。</p>\n<p>创建队列时，一般由消费者指定队列的名字，如果没有指定，则RabbitMQ会随机生成一个名字，在<code>queue.declare</code>的返回值中体现出来。随机队列名在一些临时的匿名队列场景下非常有用，比如基于AMQP应用的RPC调用。</p>\n<p>在创建队列时，有两个参数很有用：</p>\n<ul>\n<li><code>exclusive</code> - 设置为true，则队列会设置为私有状态，常用于控制队列只允许有一个消费者的情况；</li>\n<li><code>auto-delete</code> - 队列在最后一个消费者取消订阅后自动删除，如果只需要一个临时队列提供给一个消费者，结合<code>auto-delete</code>和<code>exclusive</code>两个参数，当消费者断开连接时，队列自动被删除。</li>\n</ul>\n<p>创建一个队列，恰好这个队列已经存在，RabbitMQ会直接返回成功。这个特性可以用于判断队列是否存在，在创建队列时，指定<code>queue.declare</code>的参数<code>passive</code>为<code>true</code>即可；如果队列不存在，则直接返回一个错误信息并不创建队列。</p>\n<h3 id=\"小节结语\"><a href=\"#小节结语\" class=\"headerlink\" title=\"小节结语\"></a>小节结语</h3><p>队列是AMQP消息的基石——</p>\n<ul>\n<li>为等待被消费的消息提供了栖息地；</li>\n<li>完美的适用于负载均衡，只需要使很多消费者订阅同一个队列即可——因为RabbitMQ会使用轮询的方式处理消息；</li>\n<li>RabbitMQ中所有消息的终点</li>\n</ul>\n<h2 id=\"开，往消息队列开……\"><a href=\"#开，往消息队列开……\" class=\"headerlink\" title=\"开，往消息队列开……\"></a>开，往消息队列开……</h2><p>前面我们对消息队列Queue进行了比较详尽的介绍，那现在的问题是，消息是怎么抵达消息队列的？这时候，就需要exchange和binding了。</p>\n<p>所有的消息均要先发送到exchang（路由），然后基于特定的规则，RabbitMQ会决定将消息发往哪个队列。这些规则被称为<em>routing keys</em>，一个队列可以说“通过一个<em>routing key</em>，<em>绑定</em>到一个exchange上”。</p>\n<p>如果遇到了多个队列该怎么办？这里就要提到四种exchange类型，分别是<code>direct</code>、<code>fanout</code>、<code>topic</code>和<code>headers</code>，每一种都实现了不同的路由算法。<code>headers</code>允许通过匹配AMQP消息的header而不是routing key，所以我们这里不去深究和探讨了。</p>\n<h3 id=\"Direct-exchange\"><a href=\"#Direct-exchange\" class=\"headerlink\" title=\"Direct exchange\"></a>Direct exchange</h3><p>字面意思，直接路由。如果routing key匹配，则消息会被发送到响应的队列中，如下图所示：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/direct-exchange.png\" alt=\"direct-exchange\"></p>\n<p>所有的消息队列必须实现这种方式，包括创建一个名称为空字符串的exchange，如：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$channel-&gt;basic_publish($msg, &apos;&apos;, &apos;queue-name&apos;);</span><br></pre></td></tr></table></figure></p>\n<p>第一个参数标识了要发送的消息，第二个参数，一个空字符串，标识了指向默认的exchange，第三个参数就是routing key，也就是声明队列所使用的名称。</p>\n<p>如果默认的direct exchange不能满足要求，可以使用<code>exchange.declare</code>命令创建自己所需要的exchange。</p>\n<h3 id=\"Fanout-exchange\"><a href=\"#Fanout-exchange\" class=\"headerlink\" title=\"Fanout exchange\"></a>Fanout exchange</h3><p>扇区路由，示意图如下：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fanout-exchange.png\" alt=\"\"></p>\n<p> Exchange会将收到的消息组播（multicast）到绑定的消息队列中，即这种模式下，支持应用根据一个（only one）消息做出不同的反应。比如我们考虑这么一个用户场景，在用户上传完图片后，既要更新图片缓存，又要奖励用户操作，那么此时如果使用fanout exchange，只需要将两个consumer都绑定到这个exchange上即可。那么如果还需要在上传图片后增加新的处理，只需要写好消费者的功能代码绑定到exchange上即可，对于消息生产者来讲，代码是完全解耦的。</p>\n<h3 id=\"Topic-exchange\"><a href=\"#Topic-exchange\" class=\"headerlink\" title=\"Topic exchange\"></a>Topic exchange</h3><p>这种路由方式，可以实现来自不同消息源的消息到达同一队列，示意图如下：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/topic-exchange.png\" alt=\"\"></p>\n<p><code>Topic exchange</code>与<code>Direct exchange有</code>些类似，都是通过匹配特定的routing key来讲消息发送给绑定到exchange上的queue中。但是对于<code>Topic exchange</code>来讲，有两个特殊的binding key：</p>\n<ul>\n<li>*，星号，替代/匹配一个单词</li>\n<li>#，井号，替代/匹配零个或者多个词</li>\n</ul>\n<blockquote>\n<p>注：如果队列使用的routing key是一个<code>#</code>，则会收到所有消息，忽略routing key的话，这就类似绑定到一个<code>fanout exchange</code>上；如果在routing key中不使用<code>#</code>或者<code>*</code>，则与<code>direct exchange</code>无异。</p>\n</blockquote>\n<p>这里留一个小问题：<code>为什么OpenStack中使用Topic Exchange比较多？</code></p>\n<h2 id=\"多租户：虚拟主机（vhost）和隔离\"><a href=\"#多租户：虚拟主机（vhost）和隔离\" class=\"headerlink\" title=\"多租户：虚拟主机（vhost）和隔离\"></a>多租户：虚拟主机（vhost）和隔离</h2><p>每个RabbitMQ server都有能力创建多个虚拟的消息代理，即virtual host，简称vhost。每个vhost都是一个迷你的RabbitMQ server，具有自己独有的Queue、Exchange和Binding，更重要是的是，具有自己的权限。这使得多个应用同时可以安全无忧的使用同一个RabbitMQ服务器。</p>\n<p>在RabbitMQ中，默认的vhost=/，在不需要多租户的场景下，默认值就足够了。在创建RabbitMQ用户的时候需要指定至少一个vhost。</p>\n<blockquote>\n<p>注，通过vhost隔离的租户是绝对的，即你不能将vhost A的队列绑定到vhost B的exchange上。</p>\n</blockquote>\n<p>可以使用命令查看vhosts：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl list_vhosts</span><br><span class=\"line\">Listing vhosts ...</span><br><span class=\"line\">/</span><br></pre></td></tr></table></figure></p>\n<p>使用命令创建一个vhost：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl add_vhost f</span><br><span class=\"line\">Creating vhost &quot;f&quot; ...</span><br><span class=\"line\">[root@rabbit1 ~]# rabbitmqctl list_vhosts</span><br><span class=\"line\">Listing vhosts ...</span><br><span class=\"line\">f</span><br><span class=\"line\">/</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"消息的持久化\"><a href=\"#消息的持久化\" class=\"headerlink\" title=\"消息的持久化\"></a>消息的持久化</h2><p>每个Queue和Exchange，都有一个<code>durable</code>属性，默认值为<code>false</code>，即默认情况下RabbitMQ不会在服务器宕机或者重启后重建Queue或Exchange，所以建议这个值一定要设置成<code>true</code>。</p>\n<p>此外，只有Queue和Exchange的<code>durable</code>还不完全够，消息的持久化还需要三个要点：</p>\n<ol>\n<li>将其选项<code>delivery mode</code>要设置成<code>2</code>，即<code>persistent</code>，持久的；</li>\n<li>消息被发布到<code>durable</code>的Exchange；</li>\n<li>消息抵达一个<code>durable</code>的Queue</li>\n</ol>\n<p>满足上述三个条件，消息的持久化就稳了。</p>\n<p>RabbitMQ通过将持久化的消息写入磁盘日志文件来确保消息在重启时不是丢失，即当发布一个持久化的消息到持久化的exchange，在写入到日志文件之前是不会发送消息的响应。如果持久化的消息被路由到非持久化的队列，则会自动在持久化日志中移除，即无法保证消息在重启时不会丢失。</p>\n<p>然而持久化虽好，却不要“贪杯”。因为将消息持久化到磁盘上比直接存储在内存中要慢很多，这就会面临几个问题：</p>\n<ol>\n<li>会减少RabbitMQ每秒处理的消息数量，这个降低的比例甚至能达到10倍或者更多；</li>\n<li>持久化消息在RabbitMQ的内置集群中表现不佳；</li>\n</ol>\n<p>那到底应不应该使用persistent/durable消息呢？首先还是要评估一下性能需求。如果单节点的RabbitMQ需要每秒处理100,000+的数据，那么可能持久化信息就不是一个好的选择。</p>\n<h2 id=\"解决事务的方案：发送方确认模式\"><a href=\"#解决事务的方案：发送方确认模式\" class=\"headerlink\" title=\"解决事务的方案：发送方确认模式\"></a>解决事务的方案：发送方确认模式</h2><p>由于AMQP内部事务对性能有很大瓶颈，现采取发送方确认模式保证事务，将信道设置为confirm模式，所有在此信道上发布的消息都会有一个唯一的ID号，当被投递到匹配的队列时，信道就会发送一个发送方确认模式给生产者应用程序，这个模式是异步的，应用程序可以等待确认的同时继续发送下一条，但如果是持久化的消息，会在写入磁盘之后消息发出。</p>\n<p>如果发送内部错误而导致消息丢失，RabbitMQ会发送一条nack(not acknowledged,未确认)消息，这种模式下每分钟可追踪数以百万计的消息投递。</p>"},{"title":"一个成功的Git分支模型","date":"2016-03-08T02:29:22.000Z","_content":"\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/一个成功的Git分支模型.md","raw":"---\ntitle: 一个成功的Git分支模型\ndate: 2016-03-08 10:29:22\ntags: Git\n---\n\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"一个成功的Git分支模型","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxs0014xu2zzewm9682","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\" target=\"_blank\" rel=\"noopener\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\" target=\"_blank\" rel=\"noopener\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>\n<a id=\"more\"></a>\n<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch -d myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit -a -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\" target=\"_blank\" rel=\"noopener\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag -a 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch -d release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit -a -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag -a 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch -d hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\" target=\"_blank\" rel=\"noopener\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\" target=\"_blank\" rel=\"noopener\">@nvie</a> </p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\" target=\"_blank\" rel=\"noopener\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\" target=\"_blank\" rel=\"noopener\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>","more":"<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch -d myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit -a -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\" target=\"_blank\" rel=\"noopener\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag -a 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch -d release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit -a -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag -a 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch -d hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\" target=\"_blank\" rel=\"noopener\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\" target=\"_blank\" rel=\"noopener\">@nvie</a> </p>\n</blockquote>"},{"title":"使用Logrotate管理MongoDB日志-后记","date":"2016-07-01T07:23:11.000Z","_content":"\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/使用Logrotate管理MongoDB日志-后记.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志-后记\ndate: 2016-07-01 15:23:11\ntags: [Logrotate, MongoDB]\n---\n\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","slug":"使用Logrotate管理MongoDB日志-后记","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxv0015xu2z0nmu0k8v","content":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<a id=\"more\"></a></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> This file is auto-generated by libsemanage</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Do not edit directly.</span></span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！","more":"</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">!/bin/sh</span></span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> This file is auto-generated by libsemanage</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Do not edit directly.</span></span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>"},{"title":"使用Logrotate管理MongoDB日志","date":"2016-06-30T07:26:03.000Z","_content":"\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","source":"_posts/使用Logrotate管理MongoDB日志.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志\ndate: 2016-06-30 15:26:03\ntags: [Logrotate, MongoDB]\n---\n\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","slug":"使用Logrotate管理MongoDB日志","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxw0018xu2zpsumd8ak","content":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<a id=\"more\"></a></p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\" target=\"_blank\" rel=\"noopener\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\" target=\"_blank\" rel=\"noopener\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"noopener\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix '-20160630'</span><br><span class=\"line\">glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> This file is auto-generated by libsemanage</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Do not edit directly.</span></span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"noopener\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。","more":"</p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\" target=\"_blank\" rel=\"noopener\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\" target=\"_blank\" rel=\"noopener\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"noopener\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix '-20160630'</span><br><span class=\"line\">glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> This file is auto-generated by libsemanage</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Do not edit directly.</span></span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"noopener\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>"},{"title":"基于Redis的Tomcat集群Session共享","date":"2016-03-10T08:18:06.000Z","_content":"\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","source":"_posts/基于Redis的Tomcat集群Session共享.md","raw":"---\ntitle: 基于Redis的Tomcat集群Session共享\ndate: 2016-03-10 16:18:06\ntags: [Reids, Tomcat]\n---\n\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","slug":"基于Redis的Tomcat集群Session共享","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxx001axu2z02o9p691","content":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<a id=\"more\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\" target=\"_blank\" rel=\"noopener\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\" target=\"_blank\" rel=\"noopener\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\" target=\"_blank\" rel=\"noopener\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\" target=\"_blank\" rel=\"noopener\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</context></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p></p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p><p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\" target=\"_blank\" rel=\"noopener\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\" target=\"_blank\" rel=\"noopener\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\" target=\"_blank\" rel=\"noopener\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>\n","site":{"data":{}},"excerpt":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。","more":"</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\" target=\"_blank\" rel=\"noopener\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\" target=\"_blank\" rel=\"noopener\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\" target=\"_blank\" rel=\"noopener\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\" target=\"_blank\" rel=\"noopener\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</context></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span></span><br><span class=\"line\"><span class=\"tag\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p></p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p><p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\" target=\"_blank\" rel=\"noopener\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\" target=\"_blank\" rel=\"noopener\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\" target=\"_blank\" rel=\"noopener\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>"},{"title":"为CentOS6.5安装Kernel3.10","date":"2016-03-12T01:08:34.000Z","_content":"\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","source":"_posts/为CentOS6-5安装Kernel3-10.md","raw":"---\ntitle: 为CentOS6.5安装Kernel3.10\ndate: 2016-03-12 09:08:34\ntags: [Linux, CentOS6.5]\n---\n\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","slug":"为CentOS6-5安装Kernel3-10","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wxy001cxu2zfx25r6sk","content":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br><a id=\"more\"></a></p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\" target=\"_blank\" rel=\"noopener\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>\n","site":{"data":{}},"excerpt":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br>","more":"</p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\" target=\"_blank\" rel=\"noopener\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>"},{"title":"如何在CentOS7上安装和配置VNCServer","date":"2016-03-09T09:22:56.000Z","_content":"\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","source":"_posts/如何在CentOS7上安装和配置VNCServer.md","raw":"---\ntitle: 如何在CentOS7上安装和配置VNCServer\ndate: 2016-03-09 17:22:56\ntags: [Linux, CentOS7]\n---\n\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","slug":"如何在CentOS7上安装和配置VNCServer","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wy1001exu2z3j3mqusx","content":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\" target=\"_blank\" rel=\"noopener\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\" target=\"_blank\" rel=\"noopener\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"noopener\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"noopener\">VNC 服务器</a>。</p>\n<a id=\"more\"></a>\n<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\" target=\"_blank\" rel=\"noopener\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum check-update</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum groupinstall <span class=\"string\">\"X Window System\"</span></span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">## 设置默认启动图形界面</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> unlink /etc/systemd/system/default.target</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> reboot</span></span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum install tigervnc-server -y</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl daemon-reload</span></span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> su linoxide</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo vncpasswd</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl <span class=\"built_in\">enable</span> vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl start vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo firewall-cmd --permanent --add-service vnc-server</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl restart firewalld.service</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\" target=\"_blank\" rel=\"noopener\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\" target=\"_blank\" rel=\"noopener\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> curl -s checkip.dyndns.org|sed -e <span class=\"string\">'s/.*Current IP Address: //'</span> -e <span class=\"string\">'s/&lt;.*$//'</span></span></span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl stop vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl <span class=\"built_in\">disable</span> vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl stop firewalld.service</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\" target=\"_blank\" rel=\"noopener\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\" target=\"_blank\" rel=\"noopener\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"noopener\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"noopener\">VNC 服务器</a>。</p>","more":"<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\" target=\"_blank\" rel=\"noopener\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum check-update</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum groupinstall <span class=\"string\">\"X Window System\"</span></span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\">## 设置默认启动图形界面</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> unlink /etc/systemd/system/default.target</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> reboot</span></span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yum install tigervnc-server -y</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl daemon-reload</span></span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> su linoxide</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo vncpasswd</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl <span class=\"built_in\">enable</span> vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl start vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo firewall-cmd --permanent --add-service vnc-server</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> sudo systemctl restart firewalld.service</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\" target=\"_blank\" rel=\"noopener\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\" target=\"_blank\" rel=\"noopener\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> curl -s checkip.dyndns.org|sed -e <span class=\"string\">'s/.*Current IP Address: //'</span> -e <span class=\"string\">'s/&lt;.*$//'</span></span></span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl stop vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl <span class=\"built_in\">disable</span> vncserver@:1.service</span></span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> systemctl stop firewalld.service</span></span><br></pre></td></tr></table></figure>"},{"title":"开山第一篇","date":"2016-03-03T01:30:24.000Z","_content":"\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","source":"_posts/开山第一篇.md","raw":"---\ntitle: 开山第一篇\ndate: 2016-03-03 09:30:24\ntags: 杂\n---\n\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","slug":"开山第一篇","published":1,"updated":"2016-06-30T13:31:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wy3001fxu2zcj7qhio5","content":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\" target=\"_blank\" rel=\"noopener\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\" target=\"_blank\" rel=\"noopener\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\" target=\"_blank\" rel=\"noopener\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br><a id=\"more\"></a></p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\" target=\"_blank\" rel=\"noopener\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\" target=\"_blank\" rel=\"noopener\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\" target=\"_blank\" rel=\"noopener\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\" target=\"_blank\" rel=\"noopener\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\" target=\"_blank\" rel=\"noopener\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br>","more":"</p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\" target=\"_blank\" rel=\"noopener\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\" target=\"_blank\" rel=\"noopener\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>"},{"title":"英雄联盟中的随机行为优化","date":"2016-03-07T05:48:24.000Z","_content":"> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","source":"_posts/英雄联盟中的随机行为优化.md","raw":"---\ntitle: 英雄联盟中的随机行为优化\ndate: 2016-03-07 13:48:24\ntags: 翻译\n---\n> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","slug":"英雄联盟中的随机行为优化","published":1,"updated":"2017-07-01T03:04:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjjph9wy6001hxu2z8v54mfa1","content":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\" target=\"_blank\" rel=\"noopener\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br><a id=\"more\"></a><br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\" target=\"_blank\" rel=\"noopener\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\" target=\"_blank\" rel=\"noopener\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\" target=\"_blank\" rel=\"noopener\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\" target=\"_blank\" rel=\"noopener\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\" target=\"_blank\" rel=\"noopener\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariable</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariablePrecomputed</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariable</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Key</span></span></span><br><span class=\"line\"><span class=\"class\">    &#123;</span></span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\" target=\"_blank\" rel=\"noopener\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br>","more":"<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\" target=\"_blank\" rel=\"noopener\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\" target=\"_blank\" rel=\"noopener\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\" target=\"_blank\" rel=\"noopener\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\" target=\"_blank\" rel=\"noopener\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\" target=\"_blank\" rel=\"noopener\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariable</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariablePrecomputed</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AnimatedVariable</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Key</span></span></span><br><span class=\"line\"><span class=\"class\">    &#123;</span></span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjjph9wwa0000xu2zpw3kb75z","tag_id":"cjjph9wwn0004xu2z4tzb5vdj","_id":"cjjph9wwy0009xu2zk7b3qgck"},{"post_id":"cjjph9wwj0002xu2z82622otr","tag_id":"cjjph9wwx0008xu2z2c40lkaz","_id":"cjjph9wx5000exu2zx9dhyqe9"},{"post_id":"cjjph9wx8000hxu2zbjxt85qv","tag_id":"cjjph9wwn0004xu2z4tzb5vdj","_id":"cjjph9wxb000jxu2zl3blj5td"},{"post_id":"cjjph9wxa000ixu2zcp02nt30","tag_id":"cjjph9wwn0004xu2z4tzb5vdj","_id":"cjjph9wxc000mxu2zqjphdsfq"},{"post_id":"cjjph9wwr0005xu2z4eaq4tla","tag_id":"cjjph9wx4000cxu2z0owcc4y6","_id":"cjjph9wxh000qxu2z8lo3x9ay"},{"post_id":"cjjph9wwr0005xu2z4eaq4tla","tag_id":"cjjph9wx8000gxu2zeleersht","_id":"cjjph9wxk000sxu2zcpc0u6pk"},{"post_id":"cjjph9wwr0005xu2z4eaq4tla","tag_id":"cjjph9wxb000kxu2z4lr9pa2e","_id":"cjjph9wxl000vxu2z5dgv3kyr"},{"post_id":"cjjph9wwu0006xu2z177bw7i1","tag_id":"cjjph9wx4000cxu2z0owcc4y6","_id":"cjjph9wxq0010xu2zcx0w9oa6"},{"post_id":"cjjph9wwu0006xu2z177bw7i1","tag_id":"cjjph9wxl000uxu2zvbsjho06","_id":"cjjph9wxr0012xu2zd5pz2up0"},{"post_id":"cjjph9wxs0014xu2zzewm9682","tag_id":"cjjph9wxo000yxu2zpmzcz7rj","_id":"cjjph9wxw0016xu2zjxqph6ll"},{"post_id":"cjjph9wwx0007xu2z74cm8dxi","tag_id":"cjjph9wxo000yxu2zpmzcz7rj","_id":"cjjph9wxx0019xu2z4mt7arye"},{"post_id":"cjjph9wwx0007xu2z74cm8dxi","tag_id":"cjjph9wxr0013xu2zqvngmx94","_id":"cjjph9wxy001bxu2zn78azzex"},{"post_id":"cjjph9wx0000axu2z0qmpr84v","tag_id":"cjjph9wxw0017xu2zqb5xfzi4","_id":"cjjph9wy8001ixu2zmqn7cjuv"},{"post_id":"cjjph9wx0000axu2z0qmpr84v","tag_id":"cjjph9wxz001dxu2zbmdl4cn0","_id":"cjjph9wy8001jxu2z94th8v9c"},{"post_id":"cjjph9wx2000bxu2zwvmueij1","tag_id":"cjjph9wy5001gxu2z4o2bih92","_id":"cjjph9wya001nxu2z3ir1n2os"},{"post_id":"cjjph9wx2000bxu2zwvmueij1","tag_id":"cjjph9wy9001kxu2zteyag81m","_id":"cjjph9wyb001oxu2z75vd7cqn"},{"post_id":"cjjph9wx2000bxu2zwvmueij1","tag_id":"cjjph9wy9001lxu2z22xq5feq","_id":"cjjph9wyd001qxu2z8dk55u5x"},{"post_id":"cjjph9wx4000dxu2ztq7tmf8m","tag_id":"cjjph9wxw0017xu2zqb5xfzi4","_id":"cjjph9wyf001txu2ztsh2p9bo"},{"post_id":"cjjph9wx4000dxu2ztq7tmf8m","tag_id":"cjjph9wxz001dxu2zbmdl4cn0","_id":"cjjph9wyf001uxu2z5onxp5ah"},{"post_id":"cjjph9wx4000dxu2ztq7tmf8m","tag_id":"cjjph9wye001rxu2z72jxqs5p","_id":"cjjph9wyg001wxu2z93mo3iyx"},{"post_id":"cjjph9wx6000fxu2zvpa4wure","tag_id":"cjjph9wxw0017xu2zqb5xfzi4","_id":"cjjph9wyg001yxu2zylk4t4d1"},{"post_id":"cjjph9wx6000fxu2zvpa4wure","tag_id":"cjjph9wyf001vxu2zds5c23gt","_id":"cjjph9wyh001zxu2zin5ueqse"},{"post_id":"cjjph9wxc000lxu2z6udddto2","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wyj0023xu2zbcczl2fc"},{"post_id":"cjjph9wxc000lxu2z6udddto2","tag_id":"cjjph9wyi0020xu2zdenlglkh","_id":"cjjph9wyj0024xu2zqvtvm2f0"},{"post_id":"cjjph9wxc000lxu2z6udddto2","tag_id":"cjjph9wyi0021xu2za76zpzpp","_id":"cjjph9wyj0026xu2zmrm7p9s5"},{"post_id":"cjjph9wxc000nxu2zjgukk6ew","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wyk0028xu2z431lvzzi"},{"post_id":"cjjph9wxc000nxu2zjgukk6ew","tag_id":"cjjph9wyj0025xu2zauseumin","_id":"cjjph9wyl0029xu2z0coflatl"},{"post_id":"cjjph9wxe000oxu2ziw2x4gxu","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wyl002cxu2zedi8z5e9"},{"post_id":"cjjph9wxe000oxu2ziw2x4gxu","tag_id":"cjjph9wyl002axu2z33tyc74z","_id":"cjjph9wyl002dxu2zn1fx1aqe"},{"post_id":"cjjph9wxh000rxu2z9tyurutk","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wym002gxu2zsxsf7w0g"},{"post_id":"cjjph9wxh000rxu2z9tyurutk","tag_id":"cjjph9wyl002exu2zf0cw699q","_id":"cjjph9wym002hxu2zl2hqrqqt"},{"post_id":"cjjph9wxk000txu2z8fw5hq9x","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wyp002kxu2zljk6cnym"},{"post_id":"cjjph9wxk000txu2z8fw5hq9x","tag_id":"cjjph9wym002ixu2zmum0zdmj","_id":"cjjph9wyp002lxu2z1tot5aar"},{"post_id":"cjjph9wxm000wxu2zc5z4qiqw","tag_id":"cjjph9wxw0017xu2zqb5xfzi4","_id":"cjjph9wyq002oxu2zav9zqb9v"},{"post_id":"cjjph9wxm000wxu2zc5z4qiqw","tag_id":"cjjph9wyf001vxu2zds5c23gt","_id":"cjjph9wyq002pxu2zw3spokj8"},{"post_id":"cjjph9wxm000xxu2zwsunv60s","tag_id":"cjjph9wyg001xxu2zvo1d9dh8","_id":"cjjph9wyr002sxu2zymu0f5sh"},{"post_id":"cjjph9wxm000xxu2zwsunv60s","tag_id":"cjjph9wyl002exu2zf0cw699q","_id":"cjjph9wyr002txu2zmopus2m1"},{"post_id":"cjjph9wxo000zxu2z993sslov","tag_id":"cjjph9wyr002rxu2zhrbblxt7","_id":"cjjph9wyr002xxu2z6d7n0ssl"},{"post_id":"cjjph9wxo000zxu2z993sslov","tag_id":"cjjph9wyr002uxu2za9sh06ix","_id":"cjjph9wys002yxu2zdb4grhqo"},{"post_id":"cjjph9wxo000zxu2z993sslov","tag_id":"cjjph9wyr002vxu2zkjpj9d2a","_id":"cjjph9wys0030xu2zcfi78d06"},{"post_id":"cjjph9wxq0011xu2zdlt3a265","tag_id":"cjjph9wyr002wxu2z0zgxy33z","_id":"cjjph9wyt0032xu2zzly9tnal"},{"post_id":"cjjph9wxq0011xu2zdlt3a265","tag_id":"cjjph9wys002zxu2zs7xknktg","_id":"cjjph9wyt0033xu2z6tim72cp"},{"post_id":"cjjph9wxv0015xu2z0nmu0k8v","tag_id":"cjjph9wyt0031xu2zr3yevi3k","_id":"cjjph9wyt0035xu2zybtglfk4"},{"post_id":"cjjph9wxv0015xu2z0nmu0k8v","tag_id":"cjjph9wwn0004xu2z4tzb5vdj","_id":"cjjph9wyu0036xu2zdjfh3ifz"},{"post_id":"cjjph9wxw0018xu2zpsumd8ak","tag_id":"cjjph9wyt0031xu2zr3yevi3k","_id":"cjjph9wyu0038xu2zerkkoe89"},{"post_id":"cjjph9wxw0018xu2zpsumd8ak","tag_id":"cjjph9wwn0004xu2z4tzb5vdj","_id":"cjjph9wyu0039xu2za7awuxam"},{"post_id":"cjjph9wxx001axu2z02o9p691","tag_id":"cjjph9wyu0037xu2zihrb1pa5","_id":"cjjph9wyv003cxu2zaa1leyc5"},{"post_id":"cjjph9wxx001axu2z02o9p691","tag_id":"cjjph9wyu003axu2zr2bszp5k","_id":"cjjph9wyv003dxu2zpro89fdf"},{"post_id":"cjjph9wxy001cxu2zfx25r6sk","tag_id":"cjjph9wyu003bxu2z99c9vqo0","_id":"cjjph9wyv003gxu2zb07jixwx"},{"post_id":"cjjph9wxy001cxu2zfx25r6sk","tag_id":"cjjph9wyv003exu2zjyxfj3ul","_id":"cjjph9wyv003hxu2zc9jn67yn"},{"post_id":"cjjph9wy1001exu2z3j3mqusx","tag_id":"cjjph9wyu003bxu2z99c9vqo0","_id":"cjjph9wyw003kxu2zx3g0fmyr"},{"post_id":"cjjph9wy1001exu2z3j3mqusx","tag_id":"cjjph9wyw003ixu2zl9ufi9d4","_id":"cjjph9wyw003lxu2zg5y8iwa0"},{"post_id":"cjjph9wy3001fxu2zcj7qhio5","tag_id":"cjjph9wyw003jxu2zauxvjsb1","_id":"cjjph9wyx003nxu2zh63nc2af"},{"post_id":"cjjph9wy6001hxu2z8v54mfa1","tag_id":"cjjph9wyw003mxu2zwdf1bwgj","_id":"cjjph9wyy003oxu2zt1yntek7"}],"Tag":[{"name":"MongoDB","_id":"cjjph9wwn0004xu2z4tzb5vdj"},{"name":"Java","_id":"cjjph9wwx0008xu2z2c40lkaz"},{"name":"Concurrency","_id":"cjjph9wx4000cxu2z0owcc4y6"},{"name":"Parallelism","_id":"cjjph9wx8000gxu2zeleersht"},{"name":"Coroutine","_id":"cjjph9wxb000kxu2z4lr9pa2e"},{"name":"Actor Model","_id":"cjjph9wxl000uxu2zvbsjho06"},{"name":"Git","_id":"cjjph9wxo000yxu2zpmzcz7rj"},{"name":"rebase","_id":"cjjph9wxr0013xu2zqvngmx94"},{"name":"OpenStack","_id":"cjjph9wxw0017xu2zqb5xfzi4"},{"name":"Trove","_id":"cjjph9wxz001dxu2zbmdl4cn0"},{"name":"MySQL","_id":"cjjph9wy5001gxu2z4o2bih92"},{"name":"Galera Cluster","_id":"cjjph9wy9001kxu2zteyag81m"},{"name":"DB","_id":"cjjph9wy9001lxu2z22xq5feq"},{"name":"Translation","_id":"cjjph9wye001rxu2z72jxqs5p"},{"name":"Nova","_id":"cjjph9wyf001vxu2zds5c23gt"},{"name":"Python","_id":"cjjph9wyg001xxu2zvo1d9dh8"},{"name":"Deep Copy","_id":"cjjph9wyi0020xu2zdenlglkh"},{"name":"Shallow Copy","_id":"cjjph9wyi0021xu2za76zpzpp"},{"name":"Tuple","_id":"cjjph9wyj0025xu2zauseumin"},{"name":"Coroutines","_id":"cjjph9wyl002axu2z33tyc74z"},{"name":"decorator","_id":"cjjph9wyl002exu2zf0cw699q"},{"name":"yield","_id":"cjjph9wym002ixu2zmum0zdmj"},{"name":"Virtio","_id":"cjjph9wyr002rxu2zhrbblxt7"},{"name":"KVM","_id":"cjjph9wyr002uxu2za9sh06ix"},{"name":"Virtualization","_id":"cjjph9wyr002vxu2zkjpj9d2a"},{"name":"AMQP","_id":"cjjph9wyr002wxu2z0zgxy33z"},{"name":"RabbitMQ","_id":"cjjph9wys002zxu2zs7xknktg"},{"name":"Logrotate","_id":"cjjph9wyt0031xu2zr3yevi3k"},{"name":"Reids","_id":"cjjph9wyu0037xu2zihrb1pa5"},{"name":"Tomcat","_id":"cjjph9wyu003axu2zr2bszp5k"},{"name":"Linux","_id":"cjjph9wyu003bxu2z99c9vqo0"},{"name":"CentOS6.5","_id":"cjjph9wyv003exu2zjyxfj3ul"},{"name":"CentOS7","_id":"cjjph9wyw003ixu2zl9ufi9d4"},{"name":"杂","_id":"cjjph9wyw003jxu2zauxvjsb1"},{"name":"翻译","_id":"cjjph9wyw003mxu2zwdf1bwgj"}]}}