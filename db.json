{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/indigo/source/favicon.ico","path":"favicon.ico","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/style.less","path":"css/style.less","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/cc.png","path":"img/cc.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/brand.jpg","path":"img/brand.jpg","modified":0,"renderable":1},{"_id":"themes/indigo/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/indigo/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":0,"renderable":1},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/indigo/README.md","hash":"7666c83e3b7ba083723a7a37ad86e614ef6d0985","modified":1458891514437},{"_id":"themes/indigo/package.json","hash":"9c9d90b83a204a42178f6057c8c252c3af07a92e","modified":1458891514452},{"_id":"source/_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","hash":"cf9561b8c073b37987bf2b9a2daf735953a4822b","modified":1461719365521},{"_id":"themes/indigo/_config.yml","hash":"15848f2f607cff895ca3dc673945399bb71a65f8","modified":1476944253652},{"_id":"source/_posts/about-quartz-scheduler-misfire-instructions.md","hash":"9e58f3fbf7ca7fd4cc06e12a9d032916407b5fbd","modified":1473219087424},{"_id":"source/_posts/为CentOS6-5安装Kernel3-10.md","hash":"13db155cd009b89e283ecc2370c5e0de46b55707","modified":1458891513934},{"_id":"source/_posts/一个成功的Git分支模型.md","hash":"df0404690e3faf499afbb7c4ca9d6790781f267e","modified":1458891513684},{"_id":"source/_posts/基于Redis的Tomcat集群Session共享.md","hash":"27fba5918ad2bebca1c15bf4549267fb9bd62adb","modified":1458891514237},{"_id":"source/_posts/difference-between-stringbuilder-and-stringbuffer.md","hash":"a05e78a5240d0af72a1e75e56d9b4e38b44084ae","modified":1473064191499},{"_id":"source/_posts/如何在CentOS7上安装和配置VNCServer.md","hash":"7e9ed8b71146e195d9510740768f7c3c8bfd80c9","modified":1458891514329},{"_id":"source/_posts/开山第一篇.md","hash":"2beac7e8f1d38c9eabcfeb06c7080bb6667c78c1","modified":1458891514363},{"_id":"source/tags/index.md","hash":"34834066ebeca680acabc07f2049e291309a2e43","modified":1458891514437},{"_id":"source/well-known-pki-validation/index.md","hash":"4ac5a6719b945d6e82f1826bd4a5439c74a0f540","modified":1476872077951},{"_id":"source/links/index.md","hash":"be9dc101fd04456e99b3a2e04b73c9202ca1e894","modified":1482744907284},{"_id":"themes/indigo/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1458891514449},{"_id":"themes/indigo/layout/category.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1458891514449},{"_id":"themes/indigo/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1458891514449},{"_id":"themes/indigo/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1458891514450},{"_id":"themes/indigo/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1458891514451},{"_id":"themes/indigo/layout/layout.ejs","hash":"42349777b0a546b88ed50ae995f5b34c1c734877","modified":1458891514450},{"_id":"themes/indigo/layout/tag.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1458891514451},{"_id":"themes/indigo/source/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1458891514493},{"_id":"source/_posts/使用Logrotate管理MongoDB日志-后记.md","hash":"4428b09ca30a483231fa8d8bd96289bf40d42083","modified":1467360087447},{"_id":"themes/indigo/layout/_partial/archive-post.ejs","hash":"30f2db93230675cd9bc45ce5bd9cbc8bf270f983","modified":1458891514439},{"_id":"themes/indigo/layout/_partial/after-footer.ejs","hash":"71c92953b993bed98b0d55ca468e5547d37df2cc","modified":1467363172184},{"_id":"themes/indigo/layout/_partial/archive.ejs","hash":"42f668272bd30e59bcb4c7bac722b5e6c4205ae5","modified":1467363201641},{"_id":"themes/indigo/layout/_partial/article.ejs","hash":"b618e79dfabb7c4de6bfb27529af1612b6c99e64","modified":1467363226795},{"_id":"themes/indigo/layout/_partial/cnzz.ejs","hash":"dbee64698919aeaeb0923c44b3f8c5402c7b8fed","modified":1458891514440},{"_id":"source/_posts/使用Logrotate管理MongoDB日志.md","hash":"9a145f1c3af5669dbc6edd151e3afb0108b66300","modified":1467353533332},{"_id":"source/_posts/英雄联盟中的随机行为优化.md","hash":"5ce6504499852d2c9744551b4ff81d844c8d6d7f","modified":1476943577761},{"_id":"themes/indigo/layout/_partial/footer.ejs","hash":"b25d13571c1d7cd77ef8642d3803164fe82cfda4","modified":1458891514441},{"_id":"themes/indigo/layout/_partial/head.ejs","hash":"e480a778dcea02e7968cd7394c4e590d25a9a75e","modified":1467363287506},{"_id":"themes/indigo/layout/_partial/loading.ejs","hash":"8b3e037dd5f3d4564012689c5cd6f63caf73df0f","modified":1458891514444},{"_id":"themes/indigo/layout/_partial/header.ejs","hash":"71d2e3839782ec5b90ae79c9206b58e14729e74b","modified":1467363326322},{"_id":"themes/indigo/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1458891514442},{"_id":"themes/indigo/layout/_partial/left-col.ejs","hash":"8daadc9abdf0f66f7c4c12e1961148ddc6e559ee","modified":1467353488324},{"_id":"themes/indigo/layout/_partial/mathjax.ejs","hash":"c539b64a558513136f36a36ab1246a7884a59167","modified":1458891514444},{"_id":"themes/indigo/layout/_partial/menu.ejs","hash":"c3684980bcf4d2b32236c455b1b0748219cbe14b","modified":1467363397769},{"_id":"themes/indigo/layout/_partial/script.ejs","hash":"51164b27f562a9b043976c37298002e4e65e8420","modified":1467363477907},{"_id":"themes/indigo/layout/_partial/search.ejs","hash":"a405ab0bdf8a221ee4d83e33e94f6b9ab0f790b0","modified":1467363514144},{"_id":"themes/indigo/source/css/style.less","hash":"698e029bacc8387f46bab43123f93031d2b252c5","modified":1467363748149},{"_id":"themes/indigo/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1458891514496},{"_id":"themes/indigo/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1458891514496},{"_id":"themes/indigo/source/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1458891514496},{"_id":"themes/indigo/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1458891514497},{"_id":"themes/indigo/source/js/search.js","hash":"81f653c9a722b006a48a98aa34dffad4f66ab59c","modified":1467361989204},{"_id":"themes/indigo/source/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1458891514495},{"_id":"themes/indigo/layout/_partial/post/date.ejs","hash":"d388863c3fbdbaadce38a3dd33d7a537b14b8b82","modified":1458891514445},{"_id":"themes/indigo/layout/_partial/post/category.ejs","hash":"27fab3e6ccc41c075dc4c5ba3ca9e7f3b6247945","modified":1467361658837},{"_id":"themes/indigo/layout/_partial/post/tag.ejs","hash":"60139e37b41769d218e5cf6f6040c41bd2293728","modified":1458891514447},{"_id":"themes/indigo/layout/_partial/post/tags.ejs","hash":"f8e019f8183fc1771f18e344029bc8ecb86272e0","modified":1458891514448},{"_id":"themes/indigo/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1458891514445},{"_id":"themes/indigo/layout/_partial/post/share.ejs","hash":"d09cd22c2985f9e8a712970deb3a9d8290cc9108","modified":1458891514446},{"_id":"themes/indigo/source/js/main.js","hash":"f25ac3eed39f8a84b10ed52f84dde231c635547d","modified":1467362311044},{"_id":"themes/indigo/layout/_partial/post/title.ejs","hash":"47967f75b47c7fac22432a3d75c6978081ccd1cd","modified":1458891514448},{"_id":"themes/indigo/source/css/_partial/fontawesome.less","hash":"0e004a7b74c34e8a2db3366bb1e227f49c07b32d","modified":1467363621897},{"_id":"themes/indigo/source/css/_partial/gotop.less","hash":"bad63006b3bd4849bf53ad38482af0d9971061d3","modified":1458891514460},{"_id":"themes/indigo/source/css/_partial/archives.less","hash":"70792112a5d220416f136c161438f1959540d7bb","modified":1458891514458},{"_id":"themes/indigo/source/css/_partial/header.less","hash":"9398ee93315299aeb8144c0958e899f4ffea96d5","modified":1458891514460},{"_id":"themes/indigo/source/css/_partial/highlight.less","hash":"2bb977cd0b66e1237cb746e03b50c7db9940a98a","modified":1458891514461},{"_id":"themes/indigo/source/css/_partial/loading.less","hash":"0361039b2abdeb1b41e504fa437df962cda055d2","modified":1458891514462},{"_id":"themes/indigo/source/css/_partial/layout.less","hash":"8997666950d0ff2b68b769c23b01da7d52de2e39","modified":1467353488325},{"_id":"themes/indigo/source/css/_partial/roboto.less","hash":"3e457942995da8840e7662fa6cb551a7e12ea294","modified":1458891514463},{"_id":"themes/indigo/source/css/_partial/postlist.less","hash":"54a4553f6d2aac95d29285603d91a3a86d5fad99","modified":1458891514462},{"_id":"themes/indigo/source/css/_partial/search.less","hash":"19391bbf31fdcecd36baa950675344ac21709fbc","modified":1467362609218},{"_id":"themes/indigo/source/css/_partial/share.less","hash":"5c830c4b6a5c263acfc342f6e669b117a2745f81","modified":1458891514463},{"_id":"themes/indigo/source/css/_partial/tags.less","hash":"36e77ccb39b080aab19d9d87fd20882d5ac84ee9","modified":1458891514464},{"_id":"themes/indigo/source/css/_partial/variable.less","hash":"a4bed2993a51b9413338833b4b651bc10f9d2e52","modified":1467363704360},{"_id":"themes/indigo/source/css/_partial/waves.less","hash":"a8b41b0b0c8ff2f6cf95f7f9784611dd8c212ffe","modified":1458891514464},{"_id":"themes/indigo/layout/_partial/post/nav.ejs","hash":"164766e7c32530b62890d8e0e970a77f48727fa6","modified":1467361324938},{"_id":"themes/indigo/source/css/_partial/article.less","hash":"ca83395d5e0991af8da9b672405e77a82fe0ea60","modified":1467363597279},{"_id":"themes/indigo/source/img/avatar.png","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1458891514494},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1458891514477},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1458891514477},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1458891514474},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1458891514478},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1458891514481},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1458891514482},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1458891514485},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1458891514486},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1458891514483},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1458891514489},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1458891514485},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1458891514489},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1458891514491},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1458891514467},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1458891514473},{"_id":"themes/indigo/source/css/fonts/fontawesome/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1458891514466},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1458891514472},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1458891514476},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1458891514480},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1458891514484},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1458891514487},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1458891514492},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1458891514488},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1458891514471},{"_id":"themes/indigo/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1458891514490},{"_id":"themes/indigo/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"550ef5c1253c8376f2ead32b654eb58d3c106ca3","modified":1458891514470},{"_id":"public/content.json","hash":"8da2d55f3d004dbc215404ecc53a1aff91485e26","modified":1476943316450},{"_id":"public/tags/index.html","hash":"4557673dbc646dfb4194aa73d63abb2fd3632527","modified":1476944264480},{"_id":"public/links/index.html","hash":"b4fdadeced42e02483dec69c23e47715d01734ea","modified":1482744925733},{"_id":"public/2016/04/27/MongoDB复制集Secondary节点持续Recovering状态解决办法/index.html","hash":"f106a91050c0903d8b8eefa6ac319e7d377e0df5","modified":1476944264481},{"_id":"public/2016/03/12/为CentOS6-5安装Kernel3-10/index.html","hash":"122887e8d7736d8bce24d94483369c8021bb9409","modified":1476944264481},{"_id":"public/archives/index.html","hash":"47ab6381fe28536ebcdc39f533d9634492dd30bb","modified":1476944264481},{"_id":"public/archives/2016/index.html","hash":"a018480c8e390e653585c46101be18c0ad3a801a","modified":1476944264481},{"_id":"public/2016/03/03/开山第一篇/index.html","hash":"91f3560730f4e5c8444577750ecebf16c429cf21","modified":1476944264481},{"_id":"public/2016/09/05/difference-between-stringbuilder-and-stringbuffer/index.html","hash":"6744bf70e08792b19d9385c35e271c44c21abad8","modified":1476944264482},{"_id":"public/2016/07/01/使用Logrotate管理MongoDB日志-后记/index.html","hash":"bd0e640f8215056f2d23e922b258c4477580bbbd","modified":1476944264482},{"_id":"public/2016/06/30/使用Logrotate管理MongoDB日志/index.html","hash":"241e5227147784ace97b275f70719b545b5b6d66","modified":1476944264482},{"_id":"public/2016/03/09/如何在CentOS7上安装和配置VNCServer/index.html","hash":"0c39431fd26e12e5f13f2871c515e2aa6fb72c7b","modified":1476944264482},{"_id":"public/2016/03/07/英雄联盟中的随机行为优化/index.html","hash":"47f896857b0e53ee00b6c6536410e160eaf39c06","modified":1476944264483},{"_id":"public/2016/03/08/一个成功的Git分支模型/index.html","hash":"daf8b9b236e23b3104fcc90137a773a531f3963e","modified":1476944264482},{"_id":"public/well-known-pki-validation/index.html","hash":"6f5e7496b12dd61cbaca50aa11076ce43644e25f","modified":1476943316581},{"_id":"public/2016/09/07/about-quartz-scheduler-misfire-instructions/index.html","hash":"3ab565335b1e47beaf725e08a9508528516b8d42","modified":1476872086747},{"_id":"public/archives/page/2/index.html","hash":"bbb073a0259d9f4b0a08c29375e7c32e88310bbd","modified":1476872086747},{"_id":"public/archives/2016/03/index.html","hash":"d4859bce4e028a7221a980723fe20e4e877df612","modified":1476944264481},{"_id":"public/archives/2016/06/index.html","hash":"2fb79f09b6cacc8c3b5567a3e750b977ca444a77","modified":1476944264481},{"_id":"public/archives/2016/04/index.html","hash":"2b0361786db36502af184c9c4603170d8bbb555d","modified":1476944264481},{"_id":"public/archives/2016/07/index.html","hash":"29f6a6d00814fa2666f547eaccf2633f4316e00e","modified":1476944264481},{"_id":"public/archives/2016/09/index.html","hash":"3fc09712ad440465719276ee6fe130958de01ef5","modified":1476944264481},{"_id":"public/tags/MongoDB/index.html","hash":"aee4d6d4786ea57caa6038c0b51091327c6615a4","modified":1476944264481},{"_id":"public/tags/Java/index.html","hash":"d947e646c73dd9d5e643b3a88859fbbd4faa9c02","modified":1476944264481},{"_id":"public/tags/Linux/index.html","hash":"ccf43666c576cf4f7dafc62d42cb286b1d70c7d2","modified":1476944264481},{"_id":"public/tags/CentOS6-5/index.html","hash":"96261c20e698cfe35d39ba26e92e92e73bbe758e","modified":1476944264482},{"_id":"public/tags/Git/index.html","hash":"c8495ac8028307e96938fff800c5d293c62dfc93","modified":1476944264482},{"_id":"public/tags/Reids/index.html","hash":"07ec7bafa352b0dc18eb6c0646755f0a691140a2","modified":1476944264482},{"_id":"public/tags/Tomcat/index.html","hash":"f9021b8395f525618a7b40aa0f3df09f029c1bd0","modified":1476944264482},{"_id":"public/tags/杂/index.html","hash":"ed33db7eabbe7068b5beb0e16a03079b1813984b","modified":1476944264482},{"_id":"public/tags/Logrotate/index.html","hash":"dccef207b59cf9dbf24dac96f346cd3e36ae1858","modified":1476944264482},{"_id":"public/tags/CentOS7/index.html","hash":"7e62ea22a4a911e63a56623a925de79dff4d2057","modified":1476944264482},{"_id":"public/tags/翻译/index.html","hash":"6ef7a8fc720e5723938c52b2deec57fe1daf8d95","modified":1476944264482},{"_id":"public/2016/03/10/基于Redis的Tomcat集群Session共享/index.html","hash":"290dc3dcade9efc65ac71b6a7636653d3fed8eb6","modified":1476944264482},{"_id":"public/index.html","hash":"ef34d210ac7bfa0ba3cb42a1a94ed35f8ddb8ebd","modified":1476944264483},{"_id":"public/archives/2016/page/2/index.html","hash":"e04c6dfc7bdfb81b8af3b065468742429ef4426b","modified":1476872086757},{"_id":"public/page/2/index.html","hash":"5f90106bb17361f8cf9b4092a2e8049a4b34f72f","modified":1476872086758},{"_id":"public/tags/Quartz/index.html","hash":"a62d7a739c6bd3cc71dc2dd3125a2e5a1962b4a5","modified":1476872086758},{"_id":"public/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1476872086758},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1476872086758},{"_id":"public/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1476872086758},{"_id":"public/img/favicon.ico","hash":"2fe7741fee10e9016740bc4243d140a9fe706b0a","modified":1476872086758},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1476872086758},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1476872086758},{"_id":"public/img/brand.jpg","hash":"f86bc62db55040934b524a34624e55c552e6245f","modified":1476872086785},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1476872086785},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1476872086785},{"_id":"public/css/fonts/fontawesome/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1476872086785},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1476872086785},{"_id":"public/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1476872086785},{"_id":"public/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1476872086785},{"_id":"public/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1476872086785},{"_id":"public/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1476872086785},{"_id":"public/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1476872086785},{"_id":"public/js/search.js","hash":"44bbc79218a21540493fb872c2b71cd7fbf1ceae","modified":1476872086788},{"_id":"public/js/main.js","hash":"e64a4a2796e90018b616d917fd592635330c12d2","modified":1476872086788},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1476872086788},{"_id":"public/img/avatar.png","hash":"37946615e6cf6976b8e24fa6a089f89dfe1f4371","modified":1476872086790},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"550ef5c1253c8376f2ead32b654eb58d3c106ca3","modified":1476872086794},{"_id":"public/css/style.css","hash":"9d6f5f4ac8e169109cd47657057dc99748b62d70","modified":1476872086908}],"Category":[],"Data":[],"Page":[{"type":"tags","noDate":true,"comments":0,"_content":"","source":"tags/index.md","raw":"type: \"tags\"\nnoDate: true\ncomments: false\n---","date":"2016-06-30T08:09:35.332Z","updated":"2016-03-25T07:38:34.437Z","path":"tags/index.html","title":"","layout":"page","_id":"ciugriaja0001gghlrj7hjz8q","content":"","excerpt":"","more":""},{"noDate":true,"comments":1,"_content":"\n>排名不分先后\n\n### 良师益友\n\n* 郭建祥：[guojianxiang.com/](http://guojianxiang.com/)\n\n* 浩哥：[www.iyeele.com/](http://www.iyeele.com/)\n\n* WenCST：[www.wencst.com/](http://www.wencst.com/)\n\n* dwong：[www.dwong.in/](http://www.dwong.in/)\n\n* 致敬科神：[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)\n\n>欢迎各位看官交换链接~:)\n\n","source":"links/index.md","raw":"---\nnoDate: true\ncomments: true\n---\n\n>排名不分先后\n\n### 良师益友\n\n* 郭建祥：[guojianxiang.com/](http://guojianxiang.com/)\n\n* 浩哥：[www.iyeele.com/](http://www.iyeele.com/)\n\n* WenCST：[www.wencst.com/](http://www.wencst.com/)\n\n* dwong：[www.dwong.in/](http://www.dwong.in/)\n\n* 致敬科神：[www.cnblogs.com/ytu2010dt](http://www.cnblogs.com/ytu2010dt/)\n\n>欢迎各位看官交换链接~:)\n\n","date":"2016-12-26T09:35:07.284Z","updated":"2016-12-26T09:35:07.284Z","path":"links/index.html","_id":"ciugriaji0006gghlwunn427d","title":"","layout":"page","content":"<blockquote>\n<p>排名不分先后</p>\n</blockquote>\n<h3 id=\"良师益友\"><a href=\"#良师益友\" class=\"headerlink\" title=\"良师益友\"></a>良师益友</h3><ul>\n<li><p>郭建祥：<a href=\"http://guojianxiang.com/\" target=\"_blank\" rel=\"external\">guojianxiang.com/</a></p>\n</li>\n<li><p>浩哥：<a href=\"http://www.iyeele.com/\" target=\"_blank\" rel=\"external\">www.iyeele.com/</a></p>\n</li>\n<li><p>WenCST：<a href=\"http://www.wencst.com/\" target=\"_blank\" rel=\"external\">www.wencst.com/</a></p>\n</li>\n<li><p>dwong：<a href=\"http://www.dwong.in/\" target=\"_blank\" rel=\"external\">www.dwong.in/</a></p>\n</li>\n<li><p>致敬科神：<a href=\"http://www.cnblogs.com/ytu2010dt/\" target=\"_blank\" rel=\"external\">www.cnblogs.com/ytu2010dt</a></p>\n</li>\n</ul>\n<blockquote>\n<p>欢迎各位看官交换链接~:)</p>\n</blockquote>\n","excerpt":"","more":"<blockquote>\n<p>排名不分先后</p>\n</blockquote>\n<h3 id=\"良师益友\"><a href=\"#良师益友\" class=\"headerlink\" title=\"良师益友\"></a>良师益友</h3><ul>\n<li><p>郭建祥：<a href=\"http://guojianxiang.com/\">guojianxiang.com/</a></p>\n</li>\n<li><p>浩哥：<a href=\"http://www.iyeele.com/\">www.iyeele.com/</a></p>\n</li>\n<li><p>WenCST：<a href=\"http://www.wencst.com/\">www.wencst.com/</a></p>\n</li>\n<li><p>dwong：<a href=\"http://www.dwong.in/\">www.dwong.in/</a></p>\n</li>\n<li><p>致敬科神：<a href=\"http://www.cnblogs.com/ytu2010dt/\">www.cnblogs.com/ytu2010dt</a></p>\n</li>\n</ul>\n<blockquote>\n<p>欢迎各位看官交换链接~:)</p>\n</blockquote>\n"}],"Post":[{"title":"MongoDB复制集Secondary节点持续Recovering状态解决办法","date":"2016-04-26T21:51:27.000Z","_content":"\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","source":"_posts/MongoDB复制集Secondary节点持续Recovering状态解决办法.md","raw":"---\ntitle: MongoDB复制集Secondary节点持续Recovering状态解决办法\ndate: 2016-04-27 05:51:27\ntags: [MongoDB]\n---\n\n前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member)，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<!-- more -->当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。\n\n官方给出了两种执行重新同步的方式——\n\n* 完全清空数据目录然后重启mongod服务\n* 在其他成员的数据目录下拷贝最近的数据然后重启mongod服务\n\n这里，偷懒不想打包scp数据，索性采用了第一种方式：\n\n1. 停止mongod服务：可在mongo shell中执行`db.shutdownServer()`来关闭mongod服务，也可以在shell中直接敲`mongod --shutdown`，或者简单粗暴直接`kill -2 <PID>`（这里不推荐`-9`，会造成下次启动不起来的情况，需要删除dbPath目录下的`mongo.lock`再尝试重新启动）。\n2. 对旧的dbPath的目录重命名，以做备份\n3. 启动mongod，指向新的空的dbPath目录\n\n简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。\n\n第二种方式，利用其它成员的最近数据进行启动的操作可见[官方文档](https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying)，这里就不赘述了。\n","slug":"MongoDB复制集Secondary节点持续Recovering状态解决办法","published":1,"updated":"2016-04-27T01:09:25.521Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriaj60000gghlox3q5gql","content":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\" target=\"_blank\" rel=\"external\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……<a id=\"more\"></a>当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\" target=\"_blank\" rel=\"external\">官方文档</a>，这里就不赘述了。</p>\n","excerpt":"<p>前段时间发现MongoDB Replica Set中的某个Secondary节点一直持续Recovering状态，无法恢复，且上次操作时间（optimeDate）已经是N天前了，经过查看<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-auto-resync-stale-member\">官方文档</a>，得知出现这种情况的原因在于复制集中主节点（Primary）一直写入oplog，而从节点（Secondary）的复制过程远远落后，赶不上主节点的oplog写入，就像赌气的孩子跑步一样，赶不上前面的小伙伴，索性一赌气就不走了……","more":"当遇到这种情况的时候，是不可能指望从节点自己恢复的，需要我们手动重新同步（initial sync）。</p>\n<p>官方给出了两种执行重新同步的方式——</p>\n<ul>\n<li>完全清空数据目录然后重启mongod服务</li>\n<li>在其他成员的数据目录下拷贝最近的数据然后重启mongod服务</li>\n</ul>\n<p>这里，偷懒不想打包scp数据，索性采用了第一种方式：</p>\n<ol>\n<li>停止mongod服务：可在mongo shell中执行<code>db.shutdownServer()</code>来关闭mongod服务，也可以在shell中直接敲<code>mongod --shutdown</code>，或者简单粗暴直接<code>kill -2 &lt;PID&gt;</code>（这里不推荐<code>-9</code>，会造成下次启动不起来的情况，需要删除dbPath目录下的<code>mongo.lock</code>再尝试重新启动）。</li>\n<li>对旧的dbPath的目录重命名，以做备份</li>\n<li>启动mongod，指向新的空的dbPath目录</li>\n</ol>\n<p>简单三步，MongoDB就会重新进行初始化同步，受限于数据量和网络环境等因素的影响，重新同步时间有长有短。重新同步完毕后，打开mongo shell查看复制集状态，一般情况下，这个从节点状态就会恢复正常了。然后要做的就是验证主从数据一致性，确保没问题之后，重命名过的dbPath目录可以删除了。</p>\n<p>第二种方式，利用其它成员的最近数据进行启动的操作可见<a href=\"https://docs.mongodb.org/manual/tutorial/resync-replica-set-member/#replica-set-resync-by-copying\">官方文档</a>，这里就不赘述了。</p>"},{"title":"为CentOS6.5安装Kernel3.10","date":"2016-03-12T01:08:34.000Z","_content":"\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","source":"_posts/为CentOS6-5安装Kernel3-10.md","raw":"---\ntitle: 为CentOS6.5安装Kernel3.10\ndate: 2016-03-12 09:08:34\ntags: [Linux, CentOS6.5]\n---\n\n最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。\n<!--more-->\n\n我们并不需要自己编译安装，而是有小伙伴在在[ELRepo](http://elrepo.org/tiki/tiki-index.php)上为我们准备好了一个package，我们只关心如何安装就好了。\n\n## 启用ELRepo\n\n```bash\nrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  \nrpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm \n```\n\n## 安装Kernel\n\n```bash\nyum --enablerepo=elrepo-kernel install kernel-lt\n```\n\n## 配置grub\n\n需要编辑`/etc/grub.conf`来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：\n\n```\ndefault=0\ntimeout=5\nsplashimage=(hd0,0)/boot/grub/splash.xpm.gz\nhiddenmenu\ntitle CentOS (3.10.99-1.el6.elrepo.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img\ntitle CentOS (2.6.32-573.12.1.el6.x86_64)\n        root (hd0,0)\n        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet\n        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img\n...\n```\n\n## 重启并查看\n\n```\nreboot\n```\n重启后通过`uname -a`来查看内核版本\n```\n[root@iZ2853cmjatZ ~]# uname -a\nLinux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n大功告成！\n\n\n","slug":"为CentOS6-5安装Kernel3-10","published":1,"updated":"2016-03-25T07:38:33.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajg0005gghl8n35whsn","content":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br><a id=\"more\"></a></p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\" target=\"_blank\" rel=\"external\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>\n","excerpt":"<p>最近有想学习下Docker，在Linux下安装Docker对内核的要求至少是3.10以上，然而CentOS 6.5内核版本是2.6，所以首先要做的就是为CentOS 6.5安装3.10的Kernel。<br>","more":"</p>\n<p>我们并不需要自己编译安装，而是有小伙伴在在<a href=\"http://elrepo.org/tiki/tiki-index.php\">ELRepo</a>上为我们准备好了一个package，我们只关心如何安装就好了。</p>\n<h2 id=\"启用ELRepo\"><a href=\"#启用ELRepo\" class=\"headerlink\" title=\"启用ELRepo\"></a>启用ELRepo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  </span><br><span class=\"line\">rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kernel\"><a href=\"#安装Kernel\" class=\"headerlink\" title=\"安装Kernel\"></a>安装Kernel</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum --enablerepo=elrepo-kernel install kernel<span class=\"_\">-lt</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置grub\"><a href=\"#配置grub\" class=\"headerlink\" title=\"配置grub\"></a>配置grub</h2><p>需要编辑<code>/etc/grub.conf</code>来更改kernel顺序，将默认的1改为0.所以看起来应该是酱婶儿的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">default=0</span><br><span class=\"line\">timeout=5</span><br><span class=\"line\">splashimage=(hd0,0)/boot/grub/splash.xpm.gz</span><br><span class=\"line\">hiddenmenu</span><br><span class=\"line\">title CentOS (3.10.99-1.el6.elrepo.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-3.10.99-1.el6.elrepo.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-3.10.99-1.el6.elrepo.x86_64.img</span><br><span class=\"line\">title CentOS (2.6.32-573.12.1.el6.x86_64)</span><br><span class=\"line\">        root (hd0,0)</span><br><span class=\"line\">        kernel /boot/vmlinuz-2.6.32-573.12.1.el6.x86_64 ro root=UUID=94e4e384-0ace-437f-bc96-057dd64f42ee rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet</span><br><span class=\"line\">        initrd /boot/initramfs-2.6.32-573.12.1.el6.x86_64.img</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h2 id=\"重启并查看\"><a href=\"#重启并查看\" class=\"headerlink\" title=\"重启并查看\"></a>重启并查看</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">reboot</span><br></pre></td></tr></table></figure>\n<p>重启后通过<code>uname -a</code>来查看内核版本<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@iZ2853cmjatZ ~]# uname -a</span><br><span class=\"line\">Linux iZ2853cmjatZ 3.10.99-1.el6.elrepo.x86_64 #1 SMP Fri Mar 4 11:53:07 EST 2016 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure></p>\n<p>大功告成！</p>"},{"title":"一个成功的Git分支模型","date":"2016-03-08T02:29:22.000Z","_content":"\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/一个成功的Git分支模型.md","raw":"---\ntitle: 一个成功的Git分支模型\ndate: 2016-03-08 10:29:22\ntags: Git\n---\n\n## 前言\n\n从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。\n\n针对如何搭建私有Git服务器，我选用的是[GitLab](https://about.gitlab.com/)，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章[《A successful Git branching model》](http://nvie.com/posts/a-successful-git-branching-model/)讲述如何合理的使用Git branch进行开发和版本管理。\n\n<!--more-->\n\n先来张图：\n![分支模型全貌](http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png)\n\n\n## 详细展开\n\n### 主要分支\n\n在这个模型中，中央仓库持有两个生命周期无限长的主要分支：\n\n* `master`\n* `develop`\n\n![主要分支](http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png)\n\n我们认为，`origin/master`这个主要分支上，源码的`HEAD`永远保持生产就绪的状态。`origin/develop`这个主要分支的源码`HEAD`则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。\n\n当`develop`分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到`master`上，并且用版本号标注。具体操作后详细谈到。\n\n因此，每当变更最终合并到`master`分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到`master`，脚本自动将软件发布到成产环境。\n\n\n### 支持性分支\n\n在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。\n\n这里使用的三类分支分别是：\n\n* 功能特性分支（`Feature branches`）\n* 发布用分支（`Release branches`）\n* 补丁分支（`Hotfix branches`）\n\n这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。\n\n#### 功能特性分支\n\n> \n分支来源：`develop`\n合并目标：`develop`\n命名惯例：除`master`、`develop`、`release-*`或者`hotfix-*`之外的任何名字均可\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png)\n\n功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回`develop`（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。\n\n功能特性分支仅存在与开发的代码仓库，并不在`origin`。\n\n*创建一个功能特性分支*\n\n当着手开发新功能时，先在开发分支上检出新分支：\n\n```bash\n$ git checkout -b myfeature develop\nSwitched to a new branch \"myfeature\"\n```\n\n*将完成的功能合并到开发分支上*\n\n完成的功能特性被合并到`develop`分支上，表示该功能要添加到即将发布的版本中：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff myfeature\nUpdating ea1b82a..05e9557\n(Summary of changes)\n$ git branch -d myfeature\nDeleted branch myfeature (was 05e9557).\n$ git push origin develop\n```\n`--no-ff`表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png)\n\n显而易见，这就是证据啊，证据！:joy:\n\n#### 发布用分支\n\n> \n分支来源：`develop`\n合并目标：`develop`和`master`\n命名惯例：`release-*`\n\n发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，`develop`分支便可以为了下个大版本接受这些新功能了。\n\n将发布用分支从`develop`分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到`develop`上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。\n\n在发布用分支拉出时，就需要给其分配一个版本号。而此后的`develop`分支上的变更都将反映这个版本。\n\n*创建一个发布用分支*\n\n发布用分支在`develop`分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。`develop`分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：\n\n```bash\n$ git checkout -b release-1.2 develop\nSwitched to a new branch \"release-1.2\"\n$ ./bump-version.sh 1.2\nFiles modified successfully, version bumped to 1.2.\n$ git commit -a -m \"Bumped version number to 1.2\"\n[release-1.2 74d9424] Bumped version number to 1.2\n1 files changed, 1 insertions(+), 1 deletions(-)\n\n```\n\n创建完新分支之后，变更版本号（这里的[`bump-version.sh`](https://gist.github.com/pete-otaqui/4188238)脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。\n\n该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在`develop`上面）。在该分支上禁止添加新特性。最终，该分支必须合并到`develop`、\n\n*完成一个发布用分支*\n\n当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到`master`（切记，所以提交到`master`内容一定是一新版本）。接着，提交到`master`上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回`develop`，以保证将来的版本包含缺陷的修复。\n\n在Git中的前两步：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2\n```\n此时，版本已发布，并且已标记。\n\n>Tips: 你可以使用`-s`或者`-u <key>`来加密标记。\n\n为了保留发布用分支的变更，需要合并回`develop`分支：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff release-1.2\nMerge made by recursive.\n(Summary of changes)\n```\n这一步可能也会产生冲突，所以，解决冲突并且提交。\n\n此时，我们可以移除该发布用分支：\n\n```bash\n$ git branch -d release-1.2\nDeleted branch release-1.2 (was ff452fe)\n\n```\n\n#### 补丁分支\n\n> \n分支来源：`master`\n合并目标：`develop`和`master`\n命名惯例：`hotfix-*`\n\n![Hoxfix branches](http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png)\n\n这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的`master`分支上拉出一个补丁分支。\n\n在某一位或者几位开发者修复线上问题的同时，`develop`分支可以继续进行。\n\n*创建一个补丁分支*\n\n补丁分支在`master`上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前`develop`分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：\n\n```bash\n$ git checkout -b hotfix-1.2.1 master\nSwitched to a new branch \"hotfix-1.2.1\"\n$ ./bump-version.sh 1.2.1\nFiles modified successfully, version bumped to 1.2.1.\n$ git commit -a -m \"Bumped version number to 1.2.1\"\n[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1\n1 files changed, 1 insertions(+), 1 deletions(-)\n```\n\n不要忘记增加版本号。\n\n然后，修复bug并提交变更。\n\n```bash\n$ git commit -m \"Fixed severe production problem\"\n[hotfix-1.2.1 abbe5d6] Fixed severe production problem\n5 files changed, 32 insertions(+), 17 deletions(-)\n```\n\n*结束使用一个补丁分支*\n\n修复bug之后，补丁分支必须合并到`master`，同时，也需要合并到`develop`，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。\n\n首先，更新`master`并且标注版本：\n\n```bash\n$ git checkout master\nSwitched to branch 'master'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n$ git tag -a 1.2.1\n```\n\n接着，合并到`develop`：\n\n```bash\n$ git checkout develop\nSwitched to branch 'develop'\n$ git merge --no-ff hotfix-1.2.1\nMerge made by recursive.\n(Summary of changes)\n```\n\n**这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是`develop`**，因为该发布用分支最终会合并到`develop`（如果`develop`分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的`develop`分支上）。\n\n最后，移除这个临时分支：\n\n```bash\n$ git branch -d hotfix-1.2.1\nDeleted branch hotfix-1.2.1 (was abbe5d6).\n```\n\n## 结语\n\n这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题[What does Bump Version stand for?](http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for)中，有解答者提到了该文，并十分推荐。\n\n\n>原文作者Twitter：[@nvie](http://twitter.com/nvie) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"一个成功的Git分支模型","published":1,"updated":"2016-03-25T07:38:33.684Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajj0007gghltzf335dw","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\" target=\"_blank\" rel=\"external\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\" target=\"_blank\" rel=\"external\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>\n<a id=\"more\"></a>\n<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch <span class=\"_\">-d</span> myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\" target=\"_blank\" rel=\"external\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\" target=\"_blank\" rel=\"external\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\" target=\"_blank\" rel=\"external\">@nvie</a> </p>\n</blockquote>\n","excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>从大公司跳到了小团队，版本控制软件从Git换到了SVN，然而前段时间，头儿让我研究下如何搭建私有Git服务器，如何“优雅”地使用Git。</p>\n<p>针对如何搭建私有Git服务器，我选用的是<a href=\"https://about.gitlab.com/\">GitLab</a>，有一键安装包，也有很多Step by Step的教程，可自行Google。本文就上面提出的后两个问题，参考文章<a href=\"http://nvie.com/posts/a-successful-git-branching-model/\">《A successful Git branching model》</a>讲述如何合理的使用Git branch进行开发和版本管理。</p>","more":"<p>先来张图：<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/git-model%402x.png\" alt=\"分支模型全貌\"></p>\n<h2 id=\"详细展开\"><a href=\"#详细展开\" class=\"headerlink\" title=\"详细展开\"></a>详细展开</h2><h3 id=\"主要分支\"><a href=\"#主要分支\" class=\"headerlink\" title=\"主要分支\"></a>主要分支</h3><p>在这个模型中，中央仓库持有两个生命周期无限长的主要分支：</p>\n<ul>\n<li><code>master</code></li>\n<li><code>develop</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/main-branches%402x.png\" alt=\"主要分支\"></p>\n<p>我们认为，<code>origin/master</code>这个主要分支上，源码的<code>HEAD</code>永远保持生产就绪的状态。<code>origin/develop</code>这个主要分支的源码<code>HEAD</code>则永远代表了最新提交的开发变更，所以也被称为是“集成分支”。该分支可以用于每晚的自动化构建所使用。</p>\n<p>当<code>develop</code>分支的代码能够到达一个稳定点，并且已经准备好进行版本发布，所以的变更应当合并到<code>master</code>上，并且用版本号标注。具体操作后详细谈到。</p>\n<p>因此，每当变更最终合并到<code>master</code>分支，这就是一个新的生产版本。对待这个分支，要极其严格，所以理论上来讲，可以使用一个Git hook脚本来进行自动化构建，每当有新内容提交到<code>master</code>，脚本自动将软件发布到成产环境。</p>\n<h3 id=\"支持性分支\"><a href=\"#支持性分支\" class=\"headerlink\" title=\"支持性分支\"></a>支持性分支</h3><p>在这个模型中，有各类支持性分支来协助团队成员的并行开发，方便跟踪功能特性，准备生产版本和快速修复生产问题。与主要分支不同的是，这三个支持性分支是有有限生命周期的，最终会被移除。</p>\n<p>这里使用的三类分支分别是：</p>\n<ul>\n<li>功能特性分支（<code>Feature branches</code>）</li>\n<li>发布用分支（<code>Release branches</code>）</li>\n<li>补丁分支（<code>Hotfix branches</code>）</li>\n</ul>\n<p>这三类分支目的明确，所以对于这些分支的源分支和合并的目标分支具有十分严格的规则。当然，这三类分支也仅仅是分支而已，并没有特别的地方。</p>\n<h4 id=\"功能特性分支\"><a href=\"#功能特性分支\" class=\"headerlink\" title=\"功能特性分支\"></a>功能特性分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code><br>命名惯例：除<code>master</code>、<code>develop</code>、<code>release-*</code>或者<code>hotfix-*</code>之外的任何名字均可</p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/fb%402x.png\" alt=\"\"></p>\n<p>功能特性分支（或者有时被称作专题分支）被用于开发接下来或者将来版本的新功能、新特性。当开始开发一项功能时，目标发布用分支并未明确，但只要功能在开发中，这个分支就存在，最终会合并回<code>develop</code>（意味着即将发布的版本中一定会包含该功能）或者被废弃（这当然是一种令人十分失望的情况）。</p>\n<p>功能特性分支仅存在与开发的代码仓库，并不在<code>origin</code>。</p>\n<p><em>创建一个功能特性分支</em></p>\n<p>当着手开发新功能时，先在开发分支上检出新分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b myfeature develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"myfeature\"</span></span><br></pre></td></tr></table></figure>\n<p><em>将完成的功能合并到开发分支上</em></p>\n<p>完成的功能特性被合并到<code>develop</code>分支上，表示该功能要添加到即将发布的版本中：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff myfeature</span><br><span class=\"line\">Updating ea1b82a..05e9557</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git branch <span class=\"_\">-d</span> myfeature</span><br><span class=\"line\">Deleted branch myfeature (was 05e9557).</span><br><span class=\"line\">$ git push origin develop</span><br></pre></td></tr></table></figure>\n<p><code>--no-ff</code>表示合并总是创建新的提交对象，这样可以避免在合并分支时丢失历史信息，对比图如下：</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/merge-without-ff%402x.png\" alt=\"\"></p>\n<p>显而易见，这就是证据啊，证据！:joy:</p>\n<h4 id=\"发布用分支\"><a href=\"#发布用分支\" class=\"headerlink\" title=\"发布用分支\"></a>发布用分支</h4><blockquote>\n<p>分支来源：<code>develop</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>release-*</code></p>\n</blockquote>\n<p>发布用分支用于支持生产环境新版本，如修改少数的缺陷，准备版本发布的元数据（如版本号，构建日期等）。做完这些操作之后，<code>develop</code>分支便可以为了下个大版本接受这些新功能了。</p>\n<p>将发布用分支从<code>develop</code>分支上检出的关键时刻是在开发几乎完全可以反映新功能理想状态的时候。此时，至少下个版本要发布的功能所在的功能分支要合并到<code>develop</code>上，而功能发布在将来的版本中则可以暂时不合并，等待下一次发布用分支的检出。</p>\n<p>在发布用分支拉出时，就需要给其分配一个版本号。而此后的<code>develop</code>分支上的变更都将反映这个版本。</p>\n<p><em>创建一个发布用分支</em></p>\n<p>发布用分支在<code>develop</code>分支上检出。举例来讲，目前我们的生产环境版本是1.1.5，马上就要发布一个大版本。<code>develop</code>分支已经准备就绪，我们决定将下一个版本的版本号为1.2.所以我们拉出一个发布用分支，命名需要反映新的版本号：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b release-1.2 develop</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"release-1.2\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2\"</span></span><br><span class=\"line\">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>创建完新分支之后，变更版本号（这里的<a href=\"https://gist.github.com/pete-otaqui/4188238\"><code>bump-version.sh</code></a>脚本用于修改文件版本号，当然，针对不同的场景，也可手动变更版本号）。</p>\n<p>该分支会存在一段时间，这段时间内，该分支允许修改缺陷（而不是在<code>develop</code>上面）。在该分支上禁止添加新特性。最终，该分支必须合并到<code>develop</code>、</p>\n<p><em>完成一个发布用分支</em></p>\n<p>当发布用分支已经准备就绪可以发布一个现实的版本，我们仍然有很多工作要做。首先，将发布用分支合并到<code>master</code>（切记，所以提交到<code>master</code>内容一定是一新版本）。接着，提交到<code>master</code>上的变更必须添加标记（如使用版本号等进行标记），用于将来参考。最后，在这个发布用分支上进行的更改需要合并回<code>develop</code>，以保证将来的版本包含缺陷的修复。</p>\n<p>在Git中的前两步：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2</span><br></pre></td></tr></table></figure>\n<p>此时，版本已发布，并且已标记。</p>\n<blockquote>\n<p>Tips: 你可以使用<code>-s</code>或者<code>-u &lt;key&gt;</code>来加密标记。</p>\n</blockquote>\n<p>为了保留发布用分支的变更，需要合并回<code>develop</code>分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff release-1.2</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p>这一步可能也会产生冲突，所以，解决冲突并且提交。</p>\n<p>此时，我们可以移除该发布用分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> release-1.2</span><br><span class=\"line\">Deleted branch release-1.2 (was ff452fe)</span><br></pre></td></tr></table></figure>\n<h4 id=\"补丁分支\"><a href=\"#补丁分支\" class=\"headerlink\" title=\"补丁分支\"></a>补丁分支</h4><blockquote>\n<p>分支来源：<code>master</code><br>合并目标：<code>develop</code>和<code>master</code><br>命名惯例：<code>hotfix-*</code></p>\n</blockquote>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/hotfix-branches%402x.png\" alt=\"Hoxfix branches\"></p>\n<p>这类分支与发布用分支很类似，不过补丁分支的产生是为了快速响应生产环境中的紧急问题。当线上遭遇紧急缺陷需要立刻解决，则需要在对应标记的<code>master</code>分支上拉出一个补丁分支。</p>\n<p>在某一位或者几位开发者修复线上问题的同时，<code>develop</code>分支可以继续进行。</p>\n<p><em>创建一个补丁分支</em></p>\n<p>补丁分支在<code>master</code>上拉出，举例来说，1.2版本是目前的线上版本，由于一个严重bug造成宕机的情况出现，但是目前<code>develop</code>分支上的变更还不够稳定，此时，我们可以使用补丁分支，先来解决紧急问题：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout -b hotfix-1.2.1 master</span><br><span class=\"line\">Switched to a new branch <span class=\"string\">\"hotfix-1.2.1\"</span></span><br><span class=\"line\">$ ./bump-version.sh 1.2.1</span><br><span class=\"line\">Files modified successfully, version bumped to 1.2.1.</span><br><span class=\"line\">$ git commit <span class=\"_\">-a</span> -m <span class=\"string\">\"Bumped version number to 1.2.1\"</span></span><br><span class=\"line\">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class=\"line\">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>\n<p>不要忘记增加版本号。</p>\n<p>然后，修复bug并提交变更。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git commit -m <span class=\"string\">\"Fixed severe production problem\"</span></span><br><span class=\"line\">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class=\"line\">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>\n<p><em>结束使用一个补丁分支</em></p>\n<p>修复bug之后，补丁分支必须合并到<code>master</code>，同时，也需要合并到<code>develop</code>，确保在下一个版本中包含bug的修复。此时的操作与发布用分支完全一致。</p>\n<p>首先，更新<code>master</code>并且标注版本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">Switched to branch <span class=\"string\">'master'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br><span class=\"line\">$ git tag <span class=\"_\">-a</span> 1.2.1</span><br></pre></td></tr></table></figure>\n<p>接着，合并到<code>develop</code>：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git checkout develop</span><br><span class=\"line\">Switched to branch <span class=\"string\">'develop'</span></span><br><span class=\"line\">$ git merge --no-ff hotfix-1.2.1</span><br><span class=\"line\">Merge made by recursive.</span><br><span class=\"line\">(Summary of changes)</span><br></pre></td></tr></table></figure>\n<p><strong>这个规则存在一个例外情况：如果发布用分支当前存在，则需要将补丁分支合并到发布用分支，而不是<code>develop</code></strong>，因为该发布用分支最终会合并到<code>develop</code>（如果<code>develop</code>分支立刻需要这个bug得到修复，而等不到发布用分支结束，则你需要小心谨慎的将修正合并到未准备就绪的<code>develop</code>分支上）。</p>\n<p>最后，移除这个临时分支：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git branch <span class=\"_\">-d</span> hotfix-1.2.1</span><br><span class=\"line\">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>这个模型看起来并没有什么特别令人震惊的地方，但是却十分合理。在StackOverflow上问题<a href=\"http://stackoverflow.com/questions/4181185/what-does-bump-version-stand-for\">What does Bump Version stand for?</a>中，有解答者提到了该文，并十分推荐。</p>\n<blockquote>\n<p>原文作者Twitter：<a href=\"http://twitter.com/nvie\">@nvie</a> </p>\n</blockquote>"},{"title":"基于Redis的Tomcat集群Session共享","date":"2016-03-10T08:18:06.000Z","_content":"\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","source":"_posts/基于Redis的Tomcat集群Session共享.md","raw":"---\ntitle: 基于Redis的Tomcat集群Session共享\ndate: 2016-03-10 16:18:06\ntags: [Reids, Tomcat]\n---\n\n\n目前的web应用集群，使用Nginx做负载均衡，将upstream配置成`ip_hash`的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<!--more-->\n\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n\n但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。\n\n## 从Nginx upstream配置说起\n首先，来看一下Nginx upstream的几种负载均衡策略：\n\n1）轮询\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080 weight=2;\n    server 192.168.8.17:8080 weight=3;\n}\n```\n3）ip_hash\n```\nupstream YOUR_NAME {\n\tip_hash;\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n}\n```\n4）fair：需要安装[Upstream Fair Balancer](http://wiki.nginx.org/HttpUpstreamFairModule) Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配\n```\nupstream YOUR_NAME {\n    server 192.168.8.15:8080;\n    server 192.168.8.17:8080;\n\tfair;\n}\n```\n5）一致性Hash：需要安装[Upstream Consistent Hash](https://www.nginx.com/resources/wiki/modules/consistent_hash/) Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。\n\n\n由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。\n\n## Session共享机制\n\n在集群系统下实现Session共享机制一般有如下两种方案：\n* 应用服务器间的Session复制共享（如Tomcat自带的Session共享）\n* 基于缓存数据库的Session共享（如使用Memcached、Redis）\n\n### 应用服务器间的Session复制共享\n\nSession复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。\n\n此方案的不足之处：\n\n* 技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).\n* Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。\n* Session内容序列化（Serialize），会消耗系统性能。\n* Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。\n\n\n### 基于缓存数据库的Session共享\n\n基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。\n\n我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——\n\n在GitHub有这样一个开源工具[tomcat-redis-session-manager](https://github.com/jcoleman/tomcat-redis-session-manager)，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到[这里](https://github.com/2hf/customized-tomcat-redis-session-manager)，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：\n\n```xml\n<Context docBase=\"/root/YOUR_WEB_APP\" \n\tpath=\"\" \n\treloadable=\"true\" \n\tsessionCookieName=\"YOURJSessionID\" />\n```\n\n闲话少说，下面开始讲解如何使用：\n1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）\n2）在Tomcat的conf目录下，编辑`context.xml`。如果你是用Redis单点，则可以仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n         host=\"192.168.8.38\" \n         port=\"6379\" \n         database=\"1\" \n         maxInactiveInterval=\"60\" />\n```\n如果是Redis集群环境，则可仿照如下配置：\n```xml\n<Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n<Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    database=\"1\"    \n\tmaxInactiveInterval=\"60\" \n    sentinelMaster=\"mymaster\"\n    sentinels=\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"/>\n```\n参数均可选，详见上面`tomcat-redis-session-manager`Github中的说明。\n\n<p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p>\n>即使在这里配置的`maxInactiveInterval`是60s，如果`web.xml`配置了session的失效时间，则以`web.xml`为准。\n>另，\n>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:\n* TOMCAT_HOME/conf/web.xml\n* WebApplication/webapp/WEB-INF/web.xml\n* 写在代码中的值 : HttpSession.setMaxInactiveInterval(int)\n\n>即实际生效顺序是:\nHttpSession.setMaxInactiveInterval(int) > $WebApplication/webapp/WEB-INF/web.xml > $TOMCAT_HOME/conf/web.xml\n\n\n启动Tomcat，访问应用，即可在Redis中看到效果。\n\n关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。\n\n\n## 参考\n\nnginx upstream的几种配置方式：[http://alwaysyunwei.blog.51cto.com/3224143/1239182](http://alwaysyunwei.blog.51cto.com/3224143/1239182)\nLoad Balancing via Nginx Upstream :[http://nginx.org/en/docs/http/load_balancing.html](http://nginx.org/en/docs/http/load_balancing.html)\nTomcat7基于Redis的Session共享：[https://yq.aliyun.com/articles/1298](https://yq.aliyun.com/articles/1298)\nTomcat Session Timeout Web.xml: [http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml](http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml)\n\n\n\n\n\n\n\n\n\n","slug":"基于Redis的Tomcat集群Session共享","published":1,"updated":"2016-03-25T07:38:34.237Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajm0009gghlh5u75n5y","content":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。<a id=\"more\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\" target=\"_blank\" rel=\"external\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\" target=\"_blank\" rel=\"external\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\" target=\"_blank\" rel=\"external\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\" target=\"_blank\" rel=\"external\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</context></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span><br><span class=\"line\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span><br><span class=\"line\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span><br><span class=\"line\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span><br><span class=\"line\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span><br><span class=\"line\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span><br><span class=\"line\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p></p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p><p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\" target=\"_blank\" rel=\"external\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\" target=\"_blank\" rel=\"external\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\" target=\"_blank\" rel=\"external\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>\n","excerpt":"<p>目前的web应用集群，使用Nginx做负载均衡，将upstream配置成<code>ip_hash</code>的方式，这种模式下，Nginx会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端。","more":"</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是，由于固定某个IP只能访问单独的一个后端，如果宕机或者需要升级程序时做停机重启，正在操作的用户就会退出到登录页面，不仅用户体验很差，而且正在做的操作不能保证成功，容易产生脏数据等。</p>\n<h2 id=\"从Nginx-upstream配置说起\"><a href=\"#从Nginx-upstream配置说起\" class=\"headerlink\" title=\"从Nginx upstream配置说起\"></a>从Nginx upstream配置说起</h2><p>首先，来看一下Nginx upstream的几种负载均衡策略：</p>\n<p>1）轮询<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>2）权重：该策略可解决服务器性能不等的情况下轮询比率的调配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080 weight=2;</span><br><span class=\"line\">    server 192.168.8.17:8080 weight=3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>3）ip_hash<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">\tip_hash;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4）fair：需要安装<a href=\"http://wiki.nginx.org/HttpUpstreamFairModule\">Upstream Fair Balancer</a> Module。该策略根据后端服务的响应时间来分配，响应时间短的后端优先分配<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream YOUR_NAME &#123;</span><br><span class=\"line\">    server 192.168.8.15:8080;</span><br><span class=\"line\">    server 192.168.8.17:8080;</span><br><span class=\"line\">\tfair;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>5）一致性Hash：需要安装<a href=\"https://www.nginx.com/resources/wiki/modules/consistent_hash/\">Upstream Consistent Hash</a> Module，该策略可以根据给定的字符串进行Hash分配，具体参见官方Wiki。</p>\n<p>由此可见，我们迫切的需要使用轮训的方式来做负载均衡，那对于大规模集群部署的web应用来讲，轮训的方式就要Session必须进行共享。</p>\n<h2 id=\"Session共享机制\"><a href=\"#Session共享机制\" class=\"headerlink\" title=\"Session共享机制\"></a>Session共享机制</h2><p>在集群系统下实现Session共享机制一般有如下两种方案：</p>\n<ul>\n<li>应用服务器间的Session复制共享（如Tomcat自带的Session共享）</li>\n<li>基于缓存数据库的Session共享（如使用Memcached、Redis）</li>\n</ul>\n<h3 id=\"应用服务器间的Session复制共享\"><a href=\"#应用服务器间的Session复制共享\" class=\"headerlink\" title=\"应用服务器间的Session复制共享\"></a>应用服务器间的Session复制共享</h3><p>Session复制共享，主要是指集群环境下，多台应用服务器之间同步Session，使其保持一致，对外透明。如果其中一台服务器发生故障，根据负载均衡的原理，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，由于Session已同步，故能保证用户的Session信息不会丢失。</p>\n<p>此方案的不足之处：</p>\n<ul>\n<li>技术复杂,必须在同一种中间件之间完成(如Tomcat-Tomcat之间).</li>\n<li>Session复制带来的性能损失会快速增加.特别是当Session中保存了较大的对象,而且对象变化较快时, 性能下降更加显著. 这种特性使得Web应用的水平扩展受到了限制。</li>\n<li>Session内容序列化（Serialize），会消耗系统性能。</li>\n<li>Session内容通过广播同步给成员，会造成网络流量瓶颈，即便是内网瓶颈。</li>\n</ul>\n<h3 id=\"基于缓存数据库的Session共享\"><a href=\"#基于缓存数据库的Session共享\" class=\"headerlink\" title=\"基于缓存数据库的Session共享\"></a>基于缓存数据库的Session共享</h3><p>基于缓存数据库的Session共享是指使用如Memcached、Redis等Cache DB来存取Session信息：应用服务器接受新请求将Session信息保存到Cache DB中，当应用服务器发生故障，Web服务器（Apache/Nginx）会遍历寻找可用节点，分发请求，当应用服务器发现Session不在本机内存，则会去Cache DB中查找，如果找到，则复制到本机，这样就实现了Session的共享和高可用。</p>\n<p>我选用的是Redis而不是Memcached，是因为Redis具有更丰富的数据结构，比如可以为Key指定过期时间，从而不需要我们定期的刷新缓存。而Memcached做不到，所有就有了这样一个合理的方案——</p>\n<p>在GitHub有这样一个开源工具<a href=\"https://github.com/jcoleman/tomcat-redis-session-manager\">tomcat-redis-session-manager</a>，可以帮我们实现基于Redis的Session共享，然而直接拿来用的话，Session的key直接就是SessionID，没有一个统一的前缀，所以经过一些小改造，代码已托管到<a href=\"https://github.com/2hf/customized-tomcat-redis-session-manager\">这里</a>，可以通过Tomcat/conf/server.xml的最下面的<Context>中增加sessionCookieName配置你想要的Redis中key的前缀，如下所示：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Context</span> <span class=\"attr\">docBase</span>=<span class=\"string\">\"/root/YOUR_WEB_APP\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">path</span>=<span class=\"string\">\"\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">reloadable</span>=<span class=\"string\">\"true\"</span> </span><br><span class=\"line\">\t<span class=\"attr\">sessionCookieName</span>=<span class=\"string\">\"YOURJSessionID\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>闲话少说，下面开始讲解如何使用：<br>1）下载源码编译成Jar包，讲 tomcat-redis-session-manager-1.2.jar 、jedis-2.6.1.jar、commons-pool2-2.2.jar拷贝到Tomcat目录下的lib中（Jedis、commons-pool2版本任意）<br>2）在Tomcat的conf目录下，编辑<code>context.xml</code>。如果你是用Redis单点，则可以仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">         <span class=\"attr\">host</span>=<span class=\"string\">\"192.168.8.38\"</span> </span><br><span class=\"line\">         <span class=\"attr\">port</span>=<span class=\"string\">\"6379\"</span> </span><br><span class=\"line\">         <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span> </span><br><span class=\"line\">         <span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>如果是Redis集群环境，则可仿照如下配置：<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Valve</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Manager</span> <span class=\"attr\">className</span>=<span class=\"string\">\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"</span></span><br><span class=\"line\">    <span class=\"attr\">database</span>=<span class=\"string\">\"1\"</span>    </span><br><span class=\"line\">\t<span class=\"attr\">maxInactiveInterval</span>=<span class=\"string\">\"60\"</span> </span><br><span class=\"line\">    <span class=\"attr\">sentinelMaster</span>=<span class=\"string\">\"mymaster\"</span></span><br><span class=\"line\">    <span class=\"attr\">sentinels</span>=<span class=\"string\">\"192.168.8.43:26379,192.168.8.45:26379,192.168.8.47:26379\"</span>/&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>参数均可选，详见上面<code>tomcat-redis-session-manager</code>Github中的说明。</p>\n<p><p style=\"color:red\"><strong>关于maxInactiveInterval，即失效时间，这里做一些说明：</strong></p></p>\n<blockquote>\n<p>即使在这里配置的<code>maxInactiveInterval</code>是60s，如果<code>web.xml</code>配置了session的失效时间，则以<code>web.xml</code>为准。<br>另，<br>如果有一下三处配置了Session的失效时间，则下面的配置覆盖上面的配置:</p>\n<ul>\n<li>TOMCAT_HOME/conf/web.xml</li>\n<li>WebApplication/webapp/WEB-INF/web.xml</li>\n<li>写在代码中的值 : HttpSession.setMaxInactiveInterval(int)</li>\n</ul>\n<p>即实际生效顺序是:<br>HttpSession.setMaxInactiveInterval(int) &gt; $WebApplication/webapp/WEB-INF/web.xml &gt; $TOMCAT_HOME/conf/web.xml</p>\n</blockquote>\n<p>启动Tomcat，访问应用，即可在Redis中看到效果。</p>\n<p>关于测试，可以将Nginx Upstream配置为轮询后，仅留一台应用服务器启动，登陆操作，然后启动另外一台，停止第一台服务，继续操作，发现并未受任何影响，即可。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>nginx upstream的几种配置方式：<a href=\"http://alwaysyunwei.blog.51cto.com/3224143/1239182\">http://alwaysyunwei.blog.51cto.com/3224143/1239182</a><br>Load Balancing via Nginx Upstream :<a href=\"http://nginx.org/en/docs/http/load_balancing.html\">http://nginx.org/en/docs/http/load_balancing.html</a><br>Tomcat7基于Redis的Session共享：<a href=\"https://yq.aliyun.com/articles/1298\">https://yq.aliyun.com/articles/1298</a><br>Tomcat Session Timeout Web.xml: <a href=\"http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml\">http://stackoverflow.com/questions/13463036/tomcat-session-timeout-web-xml</a></p>"},{"title":"如何在CentOS7上安装和配置VNCServer","date":"2016-03-09T09:22:56.000Z","_content":"\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","source":"_posts/如何在CentOS7上安装和配置VNCServer.md","raw":"---\ntitle: 如何在CentOS7上安装和配置VNCServer\ndate: 2016-03-09 17:22:56\ntags: [Linux, CentOS7]\n---\n\n>原文地址：[传送门](http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/)\n>转载自：[Linux.cn](https://linux.cn/article-5335-1.html)\n\n这是一个关于怎样在你的 CentOS 7 上安装配置 [VNC](http://en.wikipedia.org/wiki/Virtual_Network_Computing) 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 [VNC 服务器](http://en.wikipedia.org/wiki/Virtual_Network_Computing)。\n\n<!--more-->\n\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\n\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png)\n\n一些 VNC 服务器的优点：\n\n* 远程的图形管理方式让工作变得简单方便。\n* 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。\n* CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。\n* 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。\n* 比 ssh 图形转发和 RDP 连接更可靠。\n\n那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。\n\n\n### 安装 X-Window\n\n首先我们需要安装 [X-Window](http://en.wikipedia.org/wiki/X_Window_System)，在终端中运行下面的命令，安装会花费一点时间。\n\n```shell\n# yum check-update\n# yum groupinstall \"X Window System\"\n```\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png)\n\n```shell\n# yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png)\n\n```shell\n### 设置默认启动图形界面\n# unlink /etc/systemd/system/default.target\n# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png)\n\n```shell\n# reboot\n```\n\n在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n\n现在，我们要在服务器上安装 VNC 服务器了。\n\n### 安装 VNC 服务器\n\n现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n\n```shell\n# yum install tigervnc-server -y\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png)\n\n### 配置 VNC\n\n然后，我们需要在 `/etc/systemd/system/` 目录里创建一个配置文件。我们可以将 `/lib/systemd/sytem/vncserver@.service` 拷贝一份配置文件范例过来。\n\n```shell\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png)\n\n接着我们用自己最喜欢的编辑器打开 `/etc/systemd/system/vncserver@:1.service` ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 `linoxide` 所以我用 `linoxide` 来替换掉 ：\n\n```shell\nExecStart=/sbin/runuser -l <USER> -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/<USER>/.vnc/%H%i.pid\n```\n\n替换成\n\n```shell\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"\nPIDFile=/home/linoxide/.vnc/%H%i.pid\n```\n\n如果是 root 用户则\n\n```shell\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"\nPIDFile=/root/.vnc/%H%i.pid\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png)\n\n好了，下面重启 `systemd`.\n\n```shell\n# systemctl daemon-reload\n``` \n\n最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。\n\n```shell\n# su linoxide\n$ sudo vncpasswd\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png)\n\n<strong style=\"color:red\">确保你输入的密码多于6个字符。</strong>\n\n### 开启服务\n\n用下面的命令（永久地）开启服务：\n\n```shell\n$ sudo systemctl enable vncserver@:1.service\n```\n\n启动服务。\n\n```shell\n$ sudo systemctl start vncserver@:1.service\n```\n\n### 防火墙设置\n\n我们需要配置防火墙来让 VNC 服务正常工作。\n\n```shell\n$ sudo firewall-cmd --permanent --add-service vnc-server\n$ sudo systemctl restart firewalld.service\n```\n\n![](https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png)\n\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。\n\n### 用 VNC 客户端连接服务器\n\n好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\n\n你可以用像 [Tightvnc viewer](http://www.tightvnc.com/) 和 [Realvnc viewer](https://www.realvnc.com/) 的客户端来连接到服务器。\n\n要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 `vncserver@:2.service` 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong>\n\nVNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 `vncserver@:x.service` 里面的 x 。\n\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。\n\n执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n\n```shell\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'\n```\n\n### 总结\n\n好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。\n\n关闭 VNC 服务。\n\n```shell\n# systemctl stop vncserver@:1.service\n```\n禁止 VNC 服务开机启动。\n\n```shell\n# systemctl disable vncserver@:1.service\n```\n关闭防火墙。\n\n```shell\n# systemctl stop firewalld.service\n```\n\n\n\n\n\n\n","slug":"如何在CentOS7上安装和配置VNCServer","published":1,"updated":"2016-03-25T07:38:34.329Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajp000bgghlaf0qebww","content":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\" target=\"_blank\" rel=\"external\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\" target=\"_blank\" rel=\"external\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"external\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\" target=\"_blank\" rel=\"external\">VNC 服务器</a>。</p>\n<a id=\"more\"></a>\n<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\" target=\"_blank\" rel=\"external\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum check-update</span><br><span class=\"line\"># yum groupinstall &quot;X Window System&quot;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">### 设置默认启动图形界面</span><br><span class=\"line\"># unlink /etc/systemd/system/default.target</span><br><span class=\"line\"># ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># reboot</span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install tigervnc-server -y</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl daemon-reload</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"># su linoxide</span><br><span class=\"line\">$ sudo vncpasswd</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl enable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl start vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo firewall-cmd --permanent --add-service vnc-server</span><br><span class=\"line\">$ sudo systemctl restart firewalld.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\" target=\"_blank\" rel=\"external\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\" target=\"_blank\" rel=\"external\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># curl -s checkip.dyndns.org|sed -e &apos;s/.*Current IP Address: //&apos; -e &apos;s/&lt;.*$//&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl disable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>\n","excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://linoxide.com/linux-how-to/install-configure-vnc-server-centos-7-0/\">传送门</a><br>转载自：<a href=\"https://linux.cn/article-5335-1.html\">Linux.cn</a></p>\n</blockquote>\n<p>这是一个关于怎样在你的 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\">VNC</a> 服务的教程。当然这个教程也适合 RHEL 7 。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 <a href=\"http://en.wikipedia.org/wiki/Virtual_Network_Computing\">VNC 服务器</a>。</p>","more":"<p>我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。</p>\n<p>VNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。</p>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112812oz6l6tnr6trnmluc.png\" alt=\"\"></p>\n<p>一些 VNC 服务器的优点：</p>\n<ul>\n<li>远程的图形管理方式让工作变得简单方便。</li>\n<li>剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。</li>\n<li>CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。</li>\n<li>只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。</li>\n<li>比 ssh 图形转发和 RDP 连接更可靠。</li>\n</ul>\n<p>那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。</p>\n<p>首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。</p>\n<p style=\"color:red\"><strong>注意：以下命令必须以 root 权限运行。要切换到 root ，请在终端下运行“sudo -s”，当然不包括双引号（“”）</strong></p>\n\n<blockquote>\n<p>这里我操作时，运维给准备了一台CentOS 7的环境已经安装了桌面。所以第一步我直接跳过，而是SSH到服务器，直接进行VNC的安装，不过还是保留原文的全部步骤吧。</p>\n</blockquote>\n<h3 id=\"安装-X-Window\"><a href=\"#安装-X-Window\" class=\"headerlink\" title=\"安装 X-Window\"></a>安装 X-Window</h3><p>首先我们需要安装 <a href=\"http://en.wikipedia.org/wiki/X_Window_System\">X-Window</a>，在终端中运行下面的命令，安装会花费一点时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum check-update</span><br><span class=\"line\"># yum groupinstall &quot;X Window System&quot;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815zz6kgdkqznknnqqf.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112815pgyhigy0ycpccz0c.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">### 设置默认启动图形界面</span><br><span class=\"line\"># unlink /etc/systemd/system/default.target</span><br><span class=\"line\"># ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112816e4dvx6zui4z9ugz4.png\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># reboot</span><br></pre></td></tr></table></figure>\n<p>在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。</p>\n<p>现在，我们要在服务器上安装 VNC 服务器了。</p>\n<h3 id=\"安装-VNC-服务器\"><a href=\"#安装-VNC-服务器\" class=\"headerlink\" title=\"安装 VNC 服务器\"></a>安装 VNC 服务器</h3><p>现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># yum install tigervnc-server -y</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817b0m2tj40jjs0120l.png\" alt=\"\"></p>\n<h3 id=\"配置-VNC\"><a href=\"#配置-VNC\" class=\"headerlink\" title=\"配置 VNC\"></a>配置 VNC</h3><p>然后，我们需要在 <code>/etc/systemd/system/</code> 目录里创建一个配置文件。我们可以将 <code>/lib/systemd/sytem/vncserver@.service</code> 拷贝一份配置文件范例过来。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112817khh66mhmndtlg1h6.png\" alt=\"\"></p>\n<p>接着我们用自己最喜欢的编辑器打开 <code>/etc/systemd/system/vncserver@:1.service</code> ，找到下面这几行，用自己的用户名替换掉 。举例来说，我的用户名是 <code>linoxide</code> 所以我用 <code>linoxide</code> 来替换掉 ：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>替换成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l linoxide -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/home/linoxide/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p>如果是 root 用户则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ExecStart=/sbin/runuser -l root -c &quot;/usr/bin/vncserver %i&quot;</span><br><span class=\"line\">PIDFile=/root/.vnc/%H%i.pid</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818a5s5i5pdok2g5dyr.png\" alt=\"\"></p>\n<p>好了，下面重启 <code>systemd</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl daemon-reload</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 `linoxide` 的权限，执行`su linoxide`就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\">```shell</span><br><span class=\"line\"># su linoxide</span><br><span class=\"line\">$ sudo vncpasswd</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112818f4rw9i46yt9carg9.png\" alt=\"\"></p>\n<p><strong style=\"color:red\">确保你输入的密码多于6个字符。</strong></p>\n<h3 id=\"开启服务\"><a href=\"#开启服务\" class=\"headerlink\" title=\"开启服务\"></a>开启服务</h3><p>用下面的命令（永久地）开启服务：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl enable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>启动服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl start vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h3><p>我们需要配置防火墙来让 VNC 服务正常工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sudo firewall-cmd --permanent --add-service vnc-server</span><br><span class=\"line\">$ sudo systemctl restart firewalld.service</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://dn-linuxcn.qbox.me/data/attachment/album/201504/26/112819xd57amrcrqdvrdrj.png\" alt=\"\"></p>\n<p>现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1 ，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从1开始排序）来连接 VNC 服务器了。</p>\n<h3 id=\"用-VNC-客户端连接服务器\"><a href=\"#用-VNC-客户端连接服务器\" class=\"headerlink\" title=\"用 VNC 客户端连接服务器\"></a>用 VNC 客户端连接服务器</h3><p>好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。</p>\n<p>你可以用像 <a href=\"http://www.tightvnc.com/\">Tightvnc viewer</a> 和 <a href=\"https://www.realvnc.com/\">Realvnc viewer</a> 的客户端来连接到服务器。</p>\n<p>要用更多的用户连接，需要创建配置文件和端口，请回到第3步，添加一个新的用户和端口。你需要创建 <code>vncserver@:2.service</code> 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。<strong style=\"color:red\">请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。</strong></p>\n<p>VNC 服务本身使用的是5900端口。鉴于有不同的用户使用 VNC ，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在5900的子端口上。在我们这个例子里，第一个 VNC 服务会运行在5901（5900 + 1）端口上，之后的依次增加，运行在5900 + x 号端口上。其中 x 是指之后用户的配置文件名 <code>vncserver@:x.service</code> 里面的 x 。</p>\n<p>在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是96.126.120.92，VNC 用户端口是1。</p>\n<p>执行下面的命令可以获得服务器的公网 IP 地址（译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># curl -s checkip.dyndns.org|sed -e &apos;s/.*Current IP Address: //&apos; -e &apos;s/&lt;.*$//&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。</p>\n<p>关闭 VNC 服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>禁止 VNC 服务开机启动。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl disable vncserver@:1.service</span><br></pre></td></tr></table></figure>\n<p>关闭防火墙。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>"},{"title":"简述StringBuilder和StringBuffer的区别","date":"2016-09-05T06:36:37.000Z","_content":"\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/difference-between-stringbuilder-and-stringbuffer.md","raw":"---\ntitle: 简述StringBuilder和StringBuffer的区别\ndate: 2016-09-05 14:36:37\ntags: [Java]\n---\n\n### 从StringBuilder和StringBuffer的不同说起\n\n最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：[国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低](https://www.zhihu.com/question/50211894)，果然这在面试中只是一道预热筛选题嘛<!-- more -->，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在[StringBuilder](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html)和[StringBuffer](http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html)的API(JDK1.7)里找到了答案。下面就做一下简述——\n\n首先，`StringBuffer`和`StringBuilder`都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了`synchronized`关键字：\n```java\n...\npublic synchronized StringBuffer append(String str) {\n        super.append(str);\n        return this;\n}\n...\n```\n\n而在StringBuilder的源码中，我们看到的是这样的：\n```java\npublic StringBuilder append(String str) {\n        super.append(str);\n        return this;\n    }\n```\n\n上面仅截取部分代码，更多的代码大家可自行查看。\n\n在`StringBuffer`的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用`synchronized`、性能更好的类`StringBuilder`，在`StringBuilder`API说明中，有提到这么一句话：\n\n>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.\n\n即只有在同步是必要的情况下，才建议使用`StringBuffer`。\n\n\n### 再论拼接字符串的不同方法和效率\n\n至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——\n\n>问：常见的拼接字符串的方法有哪些？\n\n答案是：String的`concat`方法、`+`操作符；`StringBuffer`和`StringBuilder`的`append`方法。\n\n>再问：上面几种方法效率如何？\n\n答案也很简单，当然是`StringBuilder>StringBuffer>concat或+操作符`。\n\n回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比`concat`或者`+`效率搞呢？于是又Google一下，找到了这个[讨论](http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do)（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用\"+\"操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：\n```java\nString one = \"abc\";\nString two = \"xyz\";\nString three = one + two;\n```\n在编译的时候，`String three`会被编译成：\n```java\nString three = new StringBuilder().append(one).append(two).toString();\n```\n乍一看，是效率了很多，但是如果在循环中这样干：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000 ; i++ ) {\n    out = out + i;\n}\nreturn out;\n```\n那么在编译时，可能得到的内容就是这样子的：\n```java\nString out = \"\";\nfor( int i = 0; i < 10000; i++ ) {\n    out = new StringBuilder().append(out).append(i).toString();\n}\nreturn out;\n```\n此时，我们其实都知道应该这样写：\n```java\nStringBuilder out = new StringBuilder();\nfor( int i = 0 ; i < 10000; i++ ) {\n    out.append(i);\n}\nreturn out.toString();\n```\n这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。\n\n### 另一个角度较真儿的验证\n\n上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见[Java StringBuilder myth debunked](https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html)，最终得到了下面的图表：\n\n* 使用`+`操作符\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png)\n\n* 使用`StringBuilder`\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png)\n\n* 使用`StringBuilder`的基准\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png)\n\n这位童鞋贴心的把测试用的代码托管在[Github](https://github.com/skuro/stringbuilder)上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用`StringBuilder`是可以提高性能的。文章开篇还提到这么一句话——\n\n>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev\n\n与大家共勉。\n\n\n\n\n\n\n\n\n\n\n","slug":"difference-between-stringbuilder-and-stringbuffer","published":1,"updated":"2016-09-05T08:29:51.499Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajr000cgghl4ozctlaq","content":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\" target=\"_blank\" rel=\"external\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛<a id=\"more\"></a>，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\" target=\"_blank\" rel=\"external\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\" target=\"_blank\" rel=\"external\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\" target=\"_blank\" rel=\"external\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\" target=\"_blank\" rel=\"external\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\" target=\"_blank\" rel=\"external\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>\n","excerpt":"<h3 id=\"从StringBuilder和StringBuffer的不同说起\"><a href=\"#从StringBuilder和StringBuffer的不同说起\" class=\"headerlink\" title=\"从StringBuilder和StringBuffer的不同说起\"></a>从StringBuilder和StringBuffer的不同说起</h3><p>最近在搬砖的时候，发现在拼接字符串的时候，有人习惯使用StringBuffer，有人习惯使用StringBuilder，于是想到了之前在知乎上看到的这个讨论：<a href=\"https://www.zhihu.com/question/50211894\">国内Java面试总是问StringBuffer，StringBuilder区别是啥？档次为什么这么低</a>，果然这在面试中只是一道预热筛选题嘛","more":"，不过一下子让我答，却并不能立刻回答上来区别，于是顺手Google了一下，在<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html\">StringBuilder</a>和<a href=\"http://docs.oracle.com/javase/7/docs/api/java/lang/StringBuffer.html\">StringBuffer</a>的API(JDK1.7)里找到了答案。下面就做一下简述——</p>\n<p>首先，<code>StringBuffer</code>和<code>StringBuilder</code>都是可变字符串，但是前者是线程安全的，因为在调用StringBuffer的操作时是同步的，在源代码中看到的就是方法上加了<code>synchronized</code>关键字：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> StringBuffer <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>而在StringBuilder的源码中，我们看到的是这样的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> StringBuilder <span class=\"title\">append</span><span class=\"params\">(String str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>.append(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面仅截取部分代码，更多的代码大家可自行查看。</p>\n<p>在<code>StringBuffer</code>的API说明中，提到，在JDK5中，开始提供了功能相同，但是非线程安全、不使用<code>synchronized</code>、性能更好的类<code>StringBuilder</code>，在<code>StringBuilder</code>API说明中，有提到这么一句话：</p>\n<blockquote>\n<p>Instances of StringBuilder are not safe for use by multiple threads. If such synchronization is required then it is recommended that StringBuffer be used.</p>\n</blockquote>\n<p>即只有在同步是必要的情况下，才建议使用<code>StringBuffer</code>。</p>\n<h3 id=\"再论拼接字符串的不同方法和效率\"><a href=\"#再论拼接字符串的不同方法和效率\" class=\"headerlink\" title=\"再论拼接字符串的不同方法和效率\"></a>再论拼接字符串的不同方法和效率</h3><p>至此，区别就简述完了。什么，这就完了？摔……按照面试套路，理论上应该是进入下一话题了，不过这里我们还是要继续，现在就抛出一个非常基础常见的套路问题——</p>\n<blockquote>\n<p>问：常见的拼接字符串的方法有哪些？</p>\n</blockquote>\n<p>答案是：String的<code>concat</code>方法、<code>+</code>操作符；<code>StringBuffer</code>和<code>StringBuilder</code>的<code>append</code>方法。</p>\n<blockquote>\n<p>再问：上面几种方法效率如何？</p>\n</blockquote>\n<p>答案也很简单，当然是<code>StringBuilder&gt;StringBuffer&gt;concat或+操作符</code>。</p>\n<p>回答完是什么之后，我们再问问为什么。首先，StringBuffer的每个append操作都是同步的，所以比StringBuilder要慢，那么为什么都比<code>concat</code>或者<code>+</code>效率搞呢？于是又Google一下，找到了这个<a href=\"http://stackoverflow.com/questions/14927630/java-string-concat-vs-stringbuilder-optimised-so-what-should-i-do\">讨论</a>（Google大法好！Stackoverflow大法好！Orz..），里面提到，在JDK1.6之后，使用”+”操作符时，编译器会自动使用StringBuilder将两个字符append到一起，比如我们代码里是这样写的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String one = <span class=\"string\">\"abc\"</span>;</span><br><span class=\"line\">String two = <span class=\"string\">\"xyz\"</span>;</span><br><span class=\"line\">String three = one + two;</span><br></pre></td></tr></table></figure></p>\n<p>在编译的时候，<code>String three</code>会被编译成：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String three = <span class=\"keyword\">new</span> StringBuilder().append(one).append(two).toString();</span><br></pre></td></tr></table></figure></p>\n<p>乍一看，是效率了很多，但是如果在循环中这样干：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span> ; i++ ) &#123;</span><br><span class=\"line\">    out = out + i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>那么在编译时，可能得到的内容就是这样子的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">String out = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out = <span class=\"keyword\">new</span> StringBuilder().append(out).append(i).toString();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out;</span><br></pre></td></tr></table></figure></p>\n<p>此时，我们其实都知道应该这样写：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">StringBuilder out = <span class=\"keyword\">new</span> StringBuilder();</span><br><span class=\"line\"><span class=\"keyword\">for</span>( <span class=\"keyword\">int</span> i = <span class=\"number\">0</span> ; i &lt; <span class=\"number\">10000</span>; i++ ) &#123;</span><br><span class=\"line\">    out.append(i);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> out.toString();</span><br></pre></td></tr></table></figure></p>\n<p>这也反映了，编译器一定程度上可以帮助我们优化，但是写出高效的代码，还需要我们自己。</p>\n<h3 id=\"另一个角度较真儿的验证\"><a href=\"#另一个角度较真儿的验证\" class=\"headerlink\" title=\"另一个角度较真儿的验证\"></a>另一个角度较真儿的验证</h3><p>上面的代码是13年答主在JDK1.6中测试的结果，又有一位较真儿的朋友，在不同的JDK版本中进行了测试，全文见<a href=\"https://www.javacodegeeks.com/2013/03/java-stringbuilder-myth-debunked.html\">Java StringBuilder myth debunked</a>，最终得到了下面的图表：</p>\n<ul>\n<li>使用<code>+</code>操作符</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catplus.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code></li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb.png\" alt=\"\"></p>\n<ul>\n<li>使用<code>StringBuilder</code>的基准</li>\n</ul>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/catsb2.png\" alt=\"\"></p>\n<p>这位童鞋贴心的把测试用的代码托管在<a href=\"https://github.com/skuro/stringbuilder\">Github</a>上，有兴趣的可以去看一下。最终这篇文章得出的结论就是——通过对字节码的分析，我们得到了答案，显而易见的是，使用<code>StringBuilder</code>是可以提高性能的。文章开篇还提到这么一句话——</p>\n<blockquote>\n<p>Concatenating two Strings with the plus operator is the source of all evil — Anonymous Java dev</p>\n</blockquote>\n<p>与大家共勉。</p>"},{"title":"开山第一篇","date":"2016-03-03T01:30:24.000Z","_content":"\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","source":"_posts/开山第一篇.md","raw":"---\ntitle: 开山第一篇\ndate: 2016-03-03 09:30:24\ntags: 杂\n---\n\n## 关于博客\n\n用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习[gizak](https://github.com/gizak)搞了一个[介个](https://2hf.github.io/)。后来，在[郭师哥](https://guojianxiang.com/)的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了[Hexo](http://hexo.io/)来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。\n<!--more-->\n\nHexo的主题十分丰富，官方的主题向[这里(自备梯子)](https://hexo.io/themes/)看齐。至于我，选用的是[indigo](https://github.com/yscoder/hexo-theme-indigo)，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……_(:3 」∠)_）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看[这个项目](https://github.com/2hf/elbarco.cn/tree/dev)，`dev`分支是备份，`master`分支是第一次生成的博客内容。Feel free to build your own blog based on that.\n\n## 关于我\n\n90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。\n\n## 关于域名\n\n目前域名为`0x4b5.top`，数字表示了我的生日，无他。正在备案的域名`elbarco.cn`，通过后将正式启用。`El barco`（音译：埃尔巴科），西班牙语`船`的意思，朋友们喊我`小船`，估计是因为我是`张帆`。家人取的这名重名率极高，选个域名无从下手，所以才想到了用`El barco`，BTW，本域名与什么`elbarco.com`毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。\n\n最后，感谢各位看官老爷。\n\n","slug":"开山第一篇","published":1,"updated":"2016-03-25T07:38:34.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriajs000egghl4xua35kc","content":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\" target=\"_blank\" rel=\"external\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\" target=\"_blank\" rel=\"external\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\" target=\"_blank\" rel=\"external\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br><a id=\"more\"></a></p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"external\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\" target=\"_blank\" rel=\"external\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\" target=\"_blank\" rel=\"external\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>\n","excerpt":"<h2 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h2><p>用过好多博客，如Cnblog、CSDN、ITeye等等，后来觉得用Github更Geek一点，于是学习<a href=\"https://github.com/gizak\">gizak</a>搞了一个<a href=\"https://2hf.github.io/\">介个</a>。后来，在<a href=\"https://guojianxiang.com/\">郭师哥</a>的怂恿下，搞了台阿里云主机把玩，因为有之前的经验，所以比较愉快选择了<a href=\"http://hexo.io/\">Hexo</a>来搭建自己的博客。拖延了好久，上周末终于下定决心好好弄一弄。<br>","more":"</p>\n<p>Hexo的主题十分丰富，官方的主题向<a href=\"https://hexo.io/themes/\">这里(自备梯子)</a>看齐。至于我，选用的是<a href=\"https://github.com/yscoder/hexo-theme-indigo\">indigo</a>，因为Material Design的风格很舒服，而且移动设备适配也很好，功能基本满足，个性化定制也方便（主要是修改起来方便……<em>(:3 」∠)</em>）。刚搭建完成的时候，我将整个博客的源码都放在了GitHub上面，看<a href=\"https://github.com/2hf/elbarco.cn/tree/dev\">这个项目</a>，<code>dev</code>分支是备份，<code>master</code>分支是第一次生成的博客内容。Feel free to build your own blog based on that.</p>\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>90后，男，单身狗，程序猿。目前帝都某创业型互联网公司就职，云计算相关的Java攻城狮，所以到底是🐶还是🦁️，傻傻分不清楚。喜欢做技术，热爱互联网，拥抱开源。一个人惯了，也爱宅。爱好十分广泛，美剧、电影、音乐、旅行、折腾。其他关键字，强迫症（尽管我是射手座不是处女座）、轻微人格分裂、偶尔犯二……各位看官，随便感受下就好。这里的我，无关紧要。</p>\n<h2 id=\"关于域名\"><a href=\"#关于域名\" class=\"headerlink\" title=\"关于域名\"></a>关于域名</h2><p>目前域名为<code>0x4b5.top</code>，数字表示了我的生日，无他。正在备案的域名<code>elbarco.cn</code>，通过后将正式启用。<code>El barco</code>（音译：埃尔巴科），西班牙语<code>船</code>的意思，朋友们喊我<code>小船</code>，估计是因为我是<code>张帆</code>。家人取的这名重名率极高，选个域名无从下手，所以才想到了用<code>El barco</code>，BTW，本域名与什么<code>elbarco.com</code>毫无关系，特此声明。也希望在这里，我能做那沉舟侧畔千帆中的一员，有所分享，有所进步。</p>\n<p>最后，感谢各位看官老爷。</p>"},{"title":"使用Logrotate管理MongoDB日志-后记","date":"2016-07-01T07:23:11.000Z","_content":"\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/使用Logrotate管理MongoDB日志-后记.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志-后记\ndate: 2016-07-01 15:23:11\ntags: [Logrotate, MongoDB]\n---\n\n## 发现问题\n\n昨天完成了[Logrotate管理MongoDB日志的配置](http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/)工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<!-- more -->\n\n## 分析\n\n### 确定执行情况\n\n为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看`/var/log/cron`，下面是截取了部分内容：\n\n```shell\n...\nJul  1 03:01:02 localhost anacron[19152]: Will run job 'cron.daily' in 49 min.\nJul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially\n...\nJul  1 03:50:02 localhost anacron[19152]: Job 'cron.daily' started\n...\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate\nJul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate\n...\nJul  1 03:53:49 localhost anacron[19152]: Job 'cron.daily' terminated\nJul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)\n\n```\n\n可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且`cron.daily`正常退出。但是Logrotate有没有出错还要继续分析。\n\n查看`/var/log/message`，在同样的时间段，发现了这样一条错误信息：\n```\nJul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]\n```\n而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：\n```shell\n[root@localhost ~]# cat /etc/cron.daily/logrotate \n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf >/dev/null 2>&1\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n### 原因探究\n\n原因探究的过程非常简单——Google，所以略。\n\n>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧\n\n回到正题。\n\n引起该问题的原因与SELinux有关。使用`getenforce`查询SELinux状态：\n```shell\n[root@localhost ~]# getenforce\nEnforcing\n```\n\n可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，**使用了除了`/var/log/`之外的路径**，那么：\n>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. \"/var/log\" directory has \"var_log_t\" file context, and logrotate was able to do the needful. \n\n即，`/var/log`目录具有`var_log_t`文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：\n```shell\nsemanage fcontext -a -t var_log_t <directory/logfile>\nrestorecon -v <directory/logfile>\n```\n第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。\n\n## 解决过程\n\n### 检查安装情况\n\n执行`man semanage`或`semanage -h`检查是否安装`semanage`:\n```shell\n[root@localhost ~]# man semanage\nNo manual entry for semanage\n\n[root@localhost ~]# semanage -h\n-bash: semanage: command not found\n```\n这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。\n\n### 安装\n\n找到是什么软件提供了`semanage`命令：\n```shell\n[root@localhost ~]#  yum provides */semanage\nLoaded plugins: fastestmirror, refresh-packagekit, security\nLoading mirror speeds from cached hostfile\n * base: mirrors.yun-idc.com\n * extras: mirrors.yun-idc.com\n * updates: mirrors.yun-idc.com\nlibsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\nlibsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools\nRepo        : base\nMatched from:\nFilename    : /usr/include/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : base\nMatched from:\nFilename    : /usr/sbin/semanage\n\n\n\npolicycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities\nRepo        : installed\nMatched from:\nFilename    : /usr/sbin/semanage\n\n```\n\n这里，我们手动安装一下`policycoreutils-python`即可：\n```shell\n[root@localhost ~]# yum -y install policycoreutils-python\n```\n\n### 执行命令\n\n安装完毕，执行命令:\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n设置完file context之后，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`中，我们可以检查一下：\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n\n此时，补锅工作结束。\n\n更多详细内容，点击这里查看[参考文章](https://access.redhat.com/solutions/39006)\n\n\n\n\n\n\n\n\n\n\n","slug":"使用Logrotate管理MongoDB日志-后记","published":1,"updated":"2016-07-01T08:01:27.447Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriak9000zgghlnpg8f0yr","content":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！<a id=\"more\"></a></p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job &apos;cron.daily&apos; in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job &apos;cron.daily&apos; started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job &apos;cron.daily&apos; terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"external\">参考文章</a></p>\n","excerpt":"<h2 id=\"发现问题\"><a href=\"#发现问题\" class=\"headerlink\" title=\"发现问题\"></a>发现问题</h2><p>昨天完成了<a href=\"http://elbarco.cn/2016/06/30/%E4%BD%BF%E7%94%A8Logrotate%E7%AE%A1%E7%90%86MongoDB%E6%97%A5%E5%BF%97/\">Logrotate管理MongoDB日志的配置</a>工作，手动执行验证通过，但是今天查看日志切换情况，却没有如期待的一般——在日志目录下仅有一个mongodb.log文件——日志没有切换？！","more":"</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><h3 id=\"确定执行情况\"><a href=\"#确定执行情况\" class=\"headerlink\" title=\"确定执行情况\"></a>确定执行情况</h3><p>为了确定配置的每天执行的MongoDB日至切换是否执行过，我们首先查看<code>/var/log/cron</code>，下面是截取了部分内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Will run job &apos;cron.daily&apos; in 49 min.</span><br><span class=\"line\">Jul  1 03:01:02 localhost anacron[19152]: Jobs will be executed sequentially</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost anacron[19152]: Job &apos;cron.daily&apos; started</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19251]: starting logrotate</span><br><span class=\"line\">Jul  1 03:50:02 localhost run-parts(/etc/cron.daily)[19267]: finished logrotate</span><br><span class=\"line\">...</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Job &apos;cron.daily&apos; terminated</span><br><span class=\"line\">Jul  1 03:53:49 localhost anacron[19152]: Normal exit (1 job run)</span><br></pre></td></tr></table></figure>\n<p>可以看到，在7月1日凌晨3点50左右确实执行了每日的计划任务，并且<code>cron.daily</code>正常退出。但是Logrotate有没有出错还要继续分析。</p>\n<p>查看<code>/var/log/message</code>，在同样的时间段，发现了这样一条错误信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Jul  1 03:50:02 localhost logrotate: ALERT exited abnormally with [1]</span><br></pre></td></tr></table></figure></p>\n<p>而这段错误信息，正是Logrotate每日执行的计划任务脚本中执行异常退出的提示信息：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/cron.daily/logrotate </span><br><span class=\"line\">#!/bin/sh</span><br><span class=\"line\"></span><br><span class=\"line\">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">EXITVALUE=$?</span><br><span class=\"line\">if [ $EXITVALUE != 0 ]; then</span><br><span class=\"line\">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"原因探究\"><a href=\"#原因探究\" class=\"headerlink\" title=\"原因探究\"></a>原因探究</h3><p>原因探究的过程非常简单——Google，所以略。</p>\n<blockquote>\n<p>噗……友谊的小船说翻就翻！（╯－_－）╯╧╧</p>\n</blockquote>\n<p>回到正题。</p>\n<p>引起该问题的原因与SELinux有关。使用<code>getenforce</code>查询SELinux状态：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# getenforce</span><br><span class=\"line\">Enforcing</span><br></pre></td></tr></table></figure></p>\n<p>可以看到，我们当前的SELinux处于Enforcing模式下，此时，因为我们在之前MongoDB轮换配置文件中，<strong>使用了除了<code>/var/log/</code>之外的路径</strong>，那么：</p>\n<blockquote>\n<p>SELinux was restricting the access to logrotate on log files in directories which does not have the required SELinux file context type. “/var/log” directory has “var_log_t” file context, and logrotate was able to do the needful. </p>\n</blockquote>\n<p>即，<code>/var/log</code>目录具有<code>var_log_t</code>文件上下文，如果要使用Logrotate，我们的日志目录也应该具备这个向下问。所以解决方案就是为配置文件中使用的日志目录设置文件上下文，可以通过下面两个命令做到：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">semanage fcontext -a -t var_log_t &lt;directory/logfile&gt;</span><br><span class=\"line\">restorecon -v &lt;directory/logfile&gt;</span><br></pre></td></tr></table></figure></p>\n<p>第一个命令，用于设置上下文，第二个命令用于对于需要设置上下文的目录活文件，递归的设置。</p>\n<h2 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h2><h3 id=\"检查安装情况\"><a href=\"#检查安装情况\" class=\"headerlink\" title=\"检查安装情况\"></a>检查安装情况</h3><p>执行<code>man semanage</code>或<code>semanage -h</code>检查是否安装<code>semanage</code>:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# man semanage</span><br><span class=\"line\">No manual entry for semanage</span><br><span class=\"line\"></span><br><span class=\"line\">[root@localhost ~]# semanage -h</span><br><span class=\"line\">-bash: semanage: command not found</span><br></pre></td></tr></table></figure></p>\n<p>这里我们并没有找到这个命令，所以需要安装相关软件，如果已安装，则跳过这一步。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找到是什么软件提供了<code>semanage</code>命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]#  yum provides */semanage</span><br><span class=\"line\">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\"> * base: mirrors.yun-idc.com</span><br><span class=\"line\"> * extras: mirrors.yun-idc.com</span><br><span class=\"line\"> * updates: mirrors.yun-idc.com</span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.x86_64 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">libsemanage-devel-2.0.43-5.1.el6.i686 : Header files and libraries used to build policy manipulation tools</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/include/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : base</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">policycoreutils-python-2.0.83-29.el6.x86_64 : SELinux policy core python utilities</span><br><span class=\"line\">Repo        : installed</span><br><span class=\"line\">Matched from:</span><br><span class=\"line\">Filename    : /usr/sbin/semanage</span><br></pre></td></tr></table></figure></p>\n<p>这里，我们手动安装一下<code>policycoreutils-python</code>即可：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# yum -y install policycoreutils-python</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><p>安装完毕，执行命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>设置完file context之后，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>中，我们可以检查一下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>此时，补锅工作结束。</p>\n<p>更多详细内容，点击这里查看<a href=\"https://access.redhat.com/solutions/39006\">参考文章</a></p>"},{"title":"英雄联盟中的随机行为优化","date":"2016-03-07T05:48:24.000Z","_content":"> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","source":"_posts/英雄联盟中的随机行为优化.md","raw":"---\ntitle: 英雄联盟中的随机行为优化\ndate: 2016-03-07 13:48:24\ntags: 翻译\n---\n> 原文地址：[传送门](http://engineering.riotgames.com/news/random-acts-optimization)\n> 原创翻译，转载请注明出处\n\n\n对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。\n<!--more-->\n![](http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png)\n\n我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。\n\n这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。\n\n![GIF图](http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif)\n\n上图是在英雄联盟游戏中高粒子密度的一个例子。\n\n优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。\n\n优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。\n\n*步骤一：鉴别*\n\n在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。\n\n*步骤二：理解*\n\n一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。\n\n*步骤三：迭代*\n\n当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。\n\n现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。\n\n## 步骤1:鉴别\n\n拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png)\nWaffles截图\n\nWaffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。\n\n我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png)\nChrome Tracing\n\n在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击[这里](https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started)，你可以在自己的Chrome浏览器中通过在地址栏敲入\"chrome://tracing/\"进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。\n\n让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png)\nChrome Tracing放大效果图\n\n让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。\n\n既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储[程序计数器](https://en.wikipedia.org/wiki/Program_counter)和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的[Very Sleepy](http://www.codersnotes.com/sleepy)到更多特性支持的商业软件，如Intel的[VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe)。\n\n通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG)\n\nVTune中的Hot Functions\n\n上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor<>中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。\n\n## 步骤2:理解\n\n现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。\n\n这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png)\n\n动画变量曲线的查询表\n\n在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。\n\n下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png)\n\nVTune中的分析样本\n\n对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。\n\n如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？\n\n答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg)\n\n图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau\n\n缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。\n\n最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。\n\n为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：\n\n* 37500个是线性插值；100个是一级，400个是二级\n* 31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值\n\n所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。\n\n通常来讲，代码成为瓶颈一半有四个原因：\n\n* 调用频率过高\n* 算法选择不佳：如O(n^2)vsO(n)\n* 做了不必要的工作或者太频繁的执行必要的操作\n* 数据较差：或者是数据量太大，或者是数据分布和访问模式较差\n\n这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。\n\n顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg)\n\n来自：[http://codesoftly.com/2010/03/ha-code-entropy-explained.html](http://codesoftly.com/2010/03/ha-code-entropy-explained.html)\n\n## 步骤3:迭代\n\n现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。\n\n在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。\n\n之前的代码看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    std::vector<float> mTimes;\n    std::vector<T>     mValues;\n};\n\ntemplate <typename T>\nclass AnimatedVariablePrecomputed\n{\n    // <snip>\nprivate:\n    std::vector<T> mPrecomutedValues;\n};\n\n```\nAnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。\n\n我们修改了一下AnimatedVariable类，现在看起来是这个样子的：\n\n```c++\ntemplate <typename T>\nclass AnimatedVariable\n{\n    // <snip>\nprivate:\n    int mNumValues;\n    T mSingleValue;\n\n    struct Key\n    {\n        float mTime;\n        T     mvalue;\n    };\n    std::vector<Key> mKeys;\n    AnimatedVariablePrecomputed<T> *mPrecomputed;\n};\n\n```\n我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。\n\n指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector<>的大小也会不同）。\n\nEvaluate()之前的代码看起来是这样子的：\n\n```c++\ntemplate <typename T>\nT AnimatedVariablePrecomputed<T>::Evaluate(float time) const\n{\n    in numValues = mPrecomputedValues.size();\n    RIOT_ASSERT(numValues > 1);\n\n    int index = static_cast<int>(time * numValues);\n    // clamp to valid table entry to handle the 1.0 boundary or out of bounds input\n    index = Clamp(index, 0, numValues - 1);\n    return mPrecomputedValues[index];\n}\n```\n\n修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。\n\n![](http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG)\n\n在VTune中展示的优化过的代码片段\n\n修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。\n\n这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。\n\n## 总结\n\n本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。\n\n当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：\n\n1. 鉴别：分析应用并找出性能最差的部分\n2. 理解：理解代码的本意和执行缓慢的原因\n3. 迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。\n\n上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。\n\n本文作者：Tony Albrecht\n\n\n\n\n\n\n\n","slug":"英雄联盟中的随机行为优化","published":1,"updated":"2016-10-20T06:06:17.761Z","_id":"ciugriapl0013gghlvj6ed7wl","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\" target=\"_blank\" rel=\"external\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br><a id=\"more\"></a><br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\" target=\"_blank\" rel=\"external\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\" target=\"_blank\" rel=\"external\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\" target=\"_blank\" rel=\"external\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\" target=\"_blank\" rel=\"external\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\" target=\"_blank\" rel=\"external\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariablePrecomputed</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">struct</span> Key</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>\n","excerpt":"<blockquote>\n<p>原文地址：<a href=\"http://engineering.riotgames.com/news/random-acts-optimization\">传送门</a><br>原创翻译，转载请注明出处</p>\n</blockquote>\n<p>对于像英雄联盟这样不断演进的产品的开发者而言，需要不断的致力于与系统的熵作斗争，因为他们将越来越多的内容添加到资源有限的服务器中。新的内容带了新的隐性成本——不仅是更多的实施成本，同时也包括由于创造了更多的纹理、仿真和处理造成的内存和性能成本。如果我们忽略（或者错误估算）了这些成本，则整体游戏性能不佳，可玩性减少。故障使人厌恶，延迟使人愤怒，帧率下降让人沮丧。<br>","more":"<br><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/particlesheader2.png\" alt=\"\"></p>\n<p>我是致力于提高英雄联盟性能团队中的一员。我们为客户端和服务器做快照，发现问题 (性能相关和其他)，然后修复问题。同时，我们将在这个过程中学到的东西反馈其他团队，并且给他们提供工具，使他们在影响用户之前来检测并定位他们自己的性能问题。我们不断的提高英雄联盟的性能为艺术家和设计师添加新的东西提供了空间：当他们使游戏更庞大更优秀的同时，我们使之更快。</p>\n<p>这是关于我们团队如何优化英雄联盟性能系列的第一篇文章，后续我们将不断持续更新。这是一项回报丰厚的挑战，这篇文章将深入介绍我们在粒子系统中遇到的一些有趣的挑战——正如在下图中，你可以看到粒子系统在游戏中扮演了十分重要的角色。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/TeamParticles.gif\" alt=\"GIF图\"></p>\n<p>上图是在英雄联盟游戏中高粒子密度的一个例子。</p>\n<p>优化，并不是在程序集中重写大量的代码——尽管有些时候是这样的。我们仅变更那些不仅能够提高性能，而且维护正确性的代码，如果有可能的话，还会提高代码质量。最后一项略显挑剔：任何不易读、不易维护的代码都会产生技术债务，这个我们稍后再谈。</p>\n<p>优化已有的代码库，我们采用了三个基本步骤：鉴别、理解和迭代。</p>\n<p><em>步骤一：鉴别</em></p>\n<p>在开始之前，我们首先需要确认哪些代码需要进行优化。即使有些代码看起来明显性能较差，但是由于其对整体性能影响极小，优化这类代码收益极少（尤其当花费在上面的时间和精力在其他方面可以做到更好的收益）。我们使用代码检测工具和采样分析器来帮助识别非性能部分的基本代码。</p>\n<p><em>步骤二：理解</em></p>\n<p>一旦我们得知代码库的哪部分代码性能较差，我们便会详细的查看这部分代码以求完全理解代码。理解代码意味着理解这些代码的含义及原本的目的。接着，我们就能知悉为何这些代码产生瓶颈了。</p>\n<p><em>步骤三：迭代</em></p>\n<p>当我们理解了为何特定部分代码执行较慢及代码本意要执行的内容，我们就有了足够的信息来设计和开发一套可行的解决方案。使用鉴别步骤中的工具和得到的快照数据，我们将新代码和旧代码的性能做了比较。如果解决方案效果出众，我们会彻底的进行测试以确保不引入来新的bug，那么接下来就可以击掌庆贺了，因为我们已经为其他内部测试做好了充分的准备。在大多数情况下，新的代码不见的足够快，所以我们不断迭代解决方案，知道新的代码能达到优化的目的。</p>\n<p>现在，让我们看下在英雄联盟代码库中这几个步骤的实施细节，并以最近优化的粒子系统逐步介绍。</p>\n<h2 id=\"步骤1-鉴别\"><a href=\"#步骤1-鉴别\" class=\"headerlink\" title=\"步骤1:鉴别\"></a>步骤1:鉴别</h2><p>拳头的工程师使用大量的分析工具来检查游戏客户端和服务器的性能。我们先查看来客户端的帧率和通过Waffles得到的高级分析信息（通过工具的特定函数获得的输出信息），这个内部工具可以让我们在内部构建的客户端与服务器保持联通。此外，Waffles还具备其他功能，如在测试过程中触发调试、检查游戏内部数据如导航分格和暂停或者减缓游戏过程。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/Waffles.png\" alt=\"\"><br>Waffles截图</p>\n<p>Waffles提供了一个实时展示界面，并提供详细的性能信息。上图是Waffles如何展现客户端性能表现的经典例子，上边图形（绿色柱状图）以毫秒为单位表示了帧率——越高的柱状图表示越低的帧率。非常慢的帧率在游戏中是可以感受得到的。柱状图下面是重要功能的分层视图，通过点击任何绿色柱状图，工程师都会看到影响该帧率的详细信息。通过这里，我们可以看出些端倪，即哪部分代码运行时导致性能较差的关键。</p>\n<p>我们使用一个简单的宏在代码库内手工检测一些重要函数来提供这份性能相关的信息。在对外发布的游戏版本中，这个宏并没有被打包编译，但在测试版本打包中，这个宏作为一个很小的class存在，它创建了一个事件，存放于配置文件缓冲区。该事件包含一个字符串识别码、一个线程ID、一个时间戳和其他必要的信息（比如它还可以存储在其生命周期内所有发生的内存配置数）。当对象超出范围后，析构器会在配置缓冲区中更新该事件自构造以来的运行时间。在随后的时间，可以输出和解析此配置文件缓冲区——理想的情况是在另一个进程进行以尽量减少对游戏本身的影响。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing1.png\" alt=\"\"><br>Chrome Tracing</p>\n<p>在这个例子中，我们将分析缓冲区输出到文件，并且读入到构建在Chrome浏览中可视化工具中（关于跟踪工具的更多信息，可以点击<a href=\"https://github.com/catapult-project/catapult/wiki/Trace-Viewer-Getting-Started\">这里</a>，你可以在自己的Chrome浏览器中通过在地址栏敲入”chrome://tracing/“进行尝试。这个扩展程序被设计用来进行网页性能分析，输入格式时JSON，所以你可以轻松的根据你自己的数据构造输入）。通过图形化后的结果，我们可以看到哪些是执行较慢的函数，或者在那里不断有大量的小函数被调用：这些都是次优代码的迹象。</p>\n<p>让我来展示详细操作：上面的视图是Chrome Tracing的视图，图中展示了客户端上两个运行的线程。上部分的是主线程，执行大多数的处理工作，底部的是粒子线程，用来执行粒子处理。每一个着色的横条均对应一个函数，横条的长度指示了其执行时间。被调用的函数由竖直栈结构展示，父函数在子函数之上。这个工具提供给我们一种非常神奇方式来可视化执行复杂度以及帧的签名时间。当我们发现一个次优代码区域，我们可以放大粒子区域以求查看更多细节。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/ChromeTracing2.png\" alt=\"\"><br>Chrome Tracing放大效果图</p>\n<p>让我们放大图形中间部分。从上面的线程中我可以看到一个非常场的等待，只有当下面的粒子模拟函数执行完毕才结束。模拟功能包含大量不同函数（着色的横条）的调用。每一类都是粒子系统的更新功能，用于将位置、 方向和每个粒子在该系统中其他可见性状态进行更新。一个明显的优化方式是将模拟函数改造成多线程方式，即可运行在主线程中，也可以在粒子线程中执行，对于本例，我们仅关注与优化模拟代码本身。</p>\n<p>既然现在我们知道去何处查看性能问题，我们可以切换到样本分析。这类分析周期性的读取和存储<a href=\"https://en.wikipedia.org/wiki/Program_counter\">程序计数器</a>和运行中的进程的栈信息（可选）。一段时间后，这个信息可以给出一个随机概述，概述中描述了代码库内的耗时。较慢的函数会得到更多的样本，更有用的是，用时最长的单个函数会累积更多的样本。在这里，我们不仅可以看到哪些函数执行最慢，同时可以看到哪几行代码执行最慢。如今有很多不错的样本分析工具可供选择，从免费的<a href=\"http://www.codersnotes.com/sleepy\">Very Sleepy</a>到更多特性支持的商业软件，如Intel的<a href=\"https://software.intel.com/en-us/intel-vtune-amplifier-xe\">VTune</a>。</p>\n<p>通过在游戏客户端上运行VTune来检查粒子线程，我们可以看到如下列表中运行最慢的函数。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune.PNG\" alt=\"\"></p>\n<p>VTune中的Hot Functions</p>\n<p>上面的表格展现了一些粒子相关的函数。作为参考，最上面两个较大的函数用于为每个粒子更新矩阵和位置、方向相关的状态。举例来说，我们来看在第三和第九项AnimatedVariableWithRandomFactor&lt;&gt;中的Evaluate函数，函数很小（并且容易理解），但是相对而言比较耗时。</p>\n<h2 id=\"步骤2-理解\"><a href=\"#步骤2-理解\" class=\"headerlink\" title=\"步骤2:理解\"></a>步骤2:理解</h2><p>现在，我们选择了一个需要优化的函数，则需要理解这个函数要做的事情和为什么这么做的原因。在本例中，AnimatedVariables被英雄联盟美术师用来定义粒子特征是如何随着时间变化。一旦一个美术师为一个特定的粒子可见性指定关键帧值后，代码中便会插入这些数据来产生一条曲线。插值方法是线性插值或一阶或二次集成。动画曲线被大量的使用——尽在召唤师峡谷（译者注：英雄联盟的地图之一，也是最热门的地图）中就有接近40000的动画曲线——涵盖了从粒子颜色扩展到旋转速度方方面面。Evaluate函数在每场游戏中会被调用数以亿计次。此外，LOL中的粒子系统是游戏体验中很重要的一部分，所以它们的行为不能做出任何改变。</p>\n<p>这个类其实已经做过了优化，通过查表的方式，对每个timestep所需要的值都预先计算过并存储在一个数组中，所以在读取这些数值时不必再次计算，所以减少了计算的耗时。这是一个明智的选择，因为曲线的一阶和二次集成是一个昂贵的进程。为每个系统中的每个粒子上的动画变量进行这个操作会使得处理过程大大减少。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/graphpointgraphsmaller.png\" alt=\"\"></p>\n<p>动画变量曲线的查询表</p>\n<p>在查询性能问题时，通过找到最坏的场景来放大问题往往是一个十分有用的技巧。为了模拟粒子处理减缓，我开始了一场单个玩家的游戏，游戏中有9个中期级别的电脑，并且在下路挑起了一场混乱的团战。接着，我在团战期间在客户端上运行了VTune，记录了大量的数据用于分析。这些数据给出了在Evaluate代码中的归因样本（如下图所示）。</p>\n<p>下图中我截取了第91-95行代码，为了更好的说明第90行调用Evaluate的情形。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune2.png\" alt=\"\"></p>\n<p>VTune中的分析样本</p>\n<p>对于不熟悉VTune的人来说，其实这个试图展示的就是解析期间所收集的代码。右侧的红色横条指示了命中次数，横条越长就意味着命中次数越多，而命中次数越多表示这一行执行越慢。挨着横条的时间是处理这行代码所用的预估时间。你也可以就某个特定函数的到一个准确视图来查看是什么因素“贡献”了执行缓慢。</p>\n<p>如果就红色的横条来看，第95行代码就是问题所在。但是这段代码所做的仅仅是在Vector3f中复制出拼写错误的查询表，为什么这个函数成为最慢的部分呢？为什么12字节的复制这么慢？</p>\n<p>答案在于现代CPU访问内存的方式中。CPU非常忠实的遵循了摩尔定律，每年都会提速60%，而内存速度每年的增速只有可怜的10%。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/processor_memory_gap.jpg\" alt=\"\"></p>\n<p>图出自《计算机体系结构：量化研究方法》By John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau</p>\n<p>缓存可以减小性能差距，运行英雄联盟的大多数CPU都有3级缓存，一级缓存最快但容量最小，三级缓存最慢但容量相对最大。从一级缓存读取数据只需要4个周期，而读取主内存却需要大约300个周期甚至更多。你可以在300个周期内做大量处理工作。</p>\n<p>最初查询表的解决方案的问题在于，虽然从查询表中的顺序读取值的操作是非常快的(由于硬件预取)，但是我们正在处理的颗粒并不是按照时间顺序存储，所以实际查找顺序是随机的。这通常会导致CPU等待从主存储设备读取数据时产生延迟。虽然300个周期比一级或者二级集成代价更低，但我们还是需要知道这个函数在游戏中的使用频率如何，因为毕竟这个函数在游戏中被大量的使用。</p>\n<p>为了探求真相，我们在代码中添加一些额外的内容来收集AnimatedVariables的数量和类型。结果表示，在38000个AnimatedVariables中：</p>\n<ul>\n<li>37500个是线性插值；100个是一级，400个是二级</li>\n<li>31500个仅有一个关键值；2500个有3个关键值；1500有2个或者4个关键值</li>\n</ul>\n<p>所以最常见的途径是针对单键值。因为代码总是生成查询表，这就产生了一个不需要传播的单数值表。也就意味着每次查询（总是返回相同值）一般会产生缓存丢失，进而导致大量的内存和CPU周期浪费。</p>\n<p>通常来讲，代码成为瓶颈一半有四个原因：</p>\n<ul>\n<li>调用频率过高</li>\n<li>算法选择不佳：如O(n^2)vsO(n)</li>\n<li>做了不必要的工作或者太频繁的执行必要的操作</li>\n<li>数据较差：或者是数据量太大，或者是数据分布和访问模式较差</li>\n</ul>\n<p>这里产生的问题原因不是由于代码设计不好或者开发质量导致。解决方案是好的，但是在被美术师大量使用之后，普通路径是针对单值的，而这些简单的问题在使用过程中是很不明显的。</p>\n<p>顺便说一句，我学会了作为一名程序员最重要的事情之一便是尊重你正在处理的代码。代码有可能看起很疯狂，但是这样写的目的可能是基于一个好的出发点。在没有完全理解代码如何使用和其为何设计之前不要错误的认为这些代码是丑陋愚蠢的。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/codesoftly_comic.jpg\" alt=\"\"></p>\n<p>来自：<a href=\"http://codesoftly.com/2010/03/ha-code-entropy-explained.html\">http://codesoftly.com/2010/03/ha-code-entropy-explained.html</a></p>\n<h2 id=\"步骤3-迭代\"><a href=\"#步骤3-迭代\" class=\"headerlink\" title=\"步骤3:迭代\"></a>步骤3:迭代</h2><p>现在我们了解了哪部分代码执行较慢、这部分代码本意是什么和为何执行较慢，是时候开始构想解决方案了。每个常见的执行路径都是为单独变量设计，我们还知道数量少的键的线性插值非常快（在少量高速缓存中作简单的计算），所以我们需要在考虑这种情况的基础上进行重新设计。最后，我们可以回到前面罕见集成曲线的预计算查询表上。</p>\n<p>在某些情况下，当我们不使用查询表时，首先构造这些表是没有意义的，所以会释放大量意义非凡的内存（大多数表具有256个条目或者更多，每个条目可达12字节的大小，这相当于大约每张表3kb）。所以现在，我们可以使用额外的一些内存来添加缓存的条目和存储的单值的数量。</p>\n<p>之前的代码看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">float</span>&gt; mTimes;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt;     mValues;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariablePrecomputed</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;T&gt; mPrecomutedValues;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>AnimatedVariablePrecomputed对象在AnimatedVariable中进行构造，从它的指定大小插值和构建一个表。Evaluate()仅在预计算对象中被调用。</p>\n<p>我们修改了一下AnimatedVariable类，现在看起来是这个样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> AnimatedVariable</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// &lt;snip&gt;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> mNumValues;</span><br><span class=\"line\">    T mSingleValue;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">struct</span> Key</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">float</span> mTime;</span><br><span class=\"line\">        T     mvalue;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;Key&gt; mKeys;</span><br><span class=\"line\">    AnimatedVariablePrecomputed&lt;T&gt; *mPrecomputed;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>我们添加了一个缓存值mSingleValue，和一个整数mNumValues，用于告诉我们何时才使用mSingleValue。如果mNumValues是1（即对应单值的情况），Evaluate()会直接返回mSingleValue的值——不需要其他多余的处理。你还可以注意到插入时间和值构造的Key能够减少缓存未命中的情况。</p>\n<p>指向此类的数据向量大小现在范围从24到36个字节不等，具体取决于模板类型（同时也依赖与平台，std::vector&lt;&gt;的大小也会不同）。</p>\n<p>Evaluate()之前的代码看起来是这样子的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T AnimatedVariablePrecomputed&lt;T&gt;::Evaluate(<span class=\"keyword\">float</span> time) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    in numValues = mPrecomputedValues.size();</span><br><span class=\"line\">    RIOT_ASSERT(numValues &gt; <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> index = <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">int</span>&gt;(time * numValues);</span><br><span class=\"line\">    <span class=\"comment\">// clamp to valid table entry to handle the 1.0 boundary or out of bounds input</span></span><br><span class=\"line\">    index = Clamp(index, <span class=\"number\">0</span>, numValues - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mPrecomputedValues[index];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>修改后的Evaluate()方法代码如下，这是在VTune中展示的。你可以看到三个可能的执行case：单值（红色部分），线性插值（蓝色部分）和预计算查询（绿色部分）。</p>\n<p><img src=\"http://7xrgsx.com1.z0.glb.clouddn.com/VTune3.PNG\" alt=\"\"></p>\n<p>在VTune中展示的优化过的代码片段</p>\n<p>修改后的代码执行速度大约快了3倍：在最慢的函数列表中该函数从第三位降到了第22位！不仅执行更快，同时还降低了内存的使用，大约减少了750kb。这还不算完，不仅函数执行更快，占内存更少，同时提高了线性插值的准确度。可谓一石三鸟。</p>\n<p>这里并没有提到的内容（尽管文章已经足够长了）是我如何通过不断迭代找到了这个解决方案。我最初的尝试减少在粒子生命周期内样本表的大小。这个方案几乎有效——但有些移动较快的粒子由于样本表的减少，变的参差不齐。幸运的是，这个现象很快就被发现了，使得我依然能够将方案更换为本文中提到的方法。当然还有一些其他的代码修改，但是对于性能提高并没有直接效果，也有些代码的修改甚至造成了代码执行更慢。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文中介绍的是英雄联盟游戏代码库中代码优化的一个典型案例。虽然变动更小，但是这个改动使得内存节约了750kb，粒子线程比较之前运行快了1到2毫秒，这使得主线程执行的更快。</p>\n<p>当程序员寻求优化的时候，虽然看似显而易见，但这里提到的三个阶段都常常会被忽视。这里只是为了强调一下：</p>\n<ol>\n<li>鉴别：分析应用并找出性能最差的部分</li>\n<li>理解：理解代码的本意和执行缓慢的原因</li>\n<li>迭代：基于上面两个阶段的到的成果进行代码的修改、迭代，并重新分析。重复这三个步骤直到足够快。</li>\n</ol>\n<p>上面提到的解决方案不见得是最快的解决方案，但至少方向是正确的——性能提升的安全路径是通过迭代改进。</p>\n<p>本文作者：Tony Albrecht</p>"},{"title":"使用Logrotate管理MongoDB日志","date":"2016-06-30T07:26:03.000Z","_content":"\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","source":"_posts/使用Logrotate管理MongoDB日志.md","raw":"---\ntitle: 使用Logrotate管理MongoDB日志\ndate: 2016-06-30 15:26:03\ntags: [Logrotate, MongoDB]\n---\n\n## 痛点\n\n前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<!-- more -->\n\n## 选型\n\n通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见[这里](https://docs.mongodb.com/manual/tutorial/rotate-log-files/)（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的[`logRotate`](https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate)命令或者通过向`mongod`进程发送`SIGUSR1`信号来实现。\n\n然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式`mongodb.log.2016-10-22T17-44-44`不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。\n\n被广泛认可的方案是通过[Logrotate](http://linux.die.net/man/8/logrotate)进行日志管理，其中可以执行脚本实现向`mongod`进程发送`SIGUSR1`信号。\n\n## Logrotate\n\n### 简介\n\nLogrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。\n\n通常来讲，默认的Logrotate会作为`/etc/cron.daily/`中的一个计划任务每天执行一次。\n```shell\n[root@localhost etc]# ls /etc/cron.daily/\ncups  logrotate  makewhatis.cron  mlocate.cron  \n```\n\n### 配置说明\n\n配置Logrotate通过编辑两处配置文件来完成：\n* /etc/logrotate.conf\n* /etc/logrotate.d/下面的不同服务特定的配置\n\n`logrotate.conf`包含了通用的配置，下面是一个默认配置：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# use date as a suffix of the rotated file\ndateext\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    create 0664 root utmp\n        minsize 1M\n    rotate 1\n}\n\n/var/log/btmp {\n    missingok\n    monthly\n    create 0600 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录`/etc/logrotate.d/`下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：\n\n```shell\n[root@localhost ~]# cd /etc/logrotate.d/\n[root@localhost logrotate.d]# ll\ntotal 44\n-rw-r--r--. 1 root root 185 Aug  2  2013 httpd\n-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld\n-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx\n-rw-r--r--. 1 root root 219 Nov 23  2013 sssd\n-rw-r--r--. 1 root root 210 Aug 15  2013 syslog\n-rw-r--r--. 1 root root 100 Feb 22  2013 yum\n[root@localhost logrotate.d]# cat nginx \n/var/log/nginx/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 640 nginx adm\n        sharedscripts\n        postrotate\n                [ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\n        endscript\n}\n```\n首先第一行，配置了要自动轮换的日志文件的路径`/var/log/nginx/*.log`，即针对在`/var/log/nginx`下的`*.log`文件进行轮换。\n\n* daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly\n* missingok：找不到*.log文件也是ok的，不要方……\n* rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）\n* compress：压缩日志文件（默认gzip格式）\n\t* delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件\n\t* compresscmd：设置使用什么命令来进行压缩，默认是gzip\n\t* uncompresscmd：设置解压的命令，默认是gunzip。\n* notifempty：不轮转空文件\n* create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。\n* sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。\n* postrotate：轮换日志完成后运行的脚本。\n\n更多的选项，参见[这里](http://linux.die.net/man/8/logrotate)。\n\n## 使用Logrotate管理MongoDB日志\n\n经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。\n\n### 找到日志文件及PID记录文件\n首先，我们的MongoDB启动配置中，指定了`logpath`和`pidfilepath`：\n\n```\nlogpath=/mongoData/mongodb_log/mongodb.log \npidfilepath=/mongoData/mongodb.pid \n```\n`mongod.pid`和文件`/mongoData/mongodb_data/mongod.lock`中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。\n\n\n### 编写配置文件\n\n通过`man logrotate`查看详细参数，结合业务需求，编写的配置文件如下：\n\n```\n/mongoData/mongodb_log/mongodb.log  {\n\tdaily\n    missingok\n    rotate 30\n    copytruncate \n    dateext  \n    compress\n    notifempty\n    create 644 root root \n    sharedscripts\n    postrotate\n    \t/bin/kill -SIGUSR1 'cat /mongoData/mongodb.pid 2> /dev/null' 2> /dev/null || true\n    endscript\n}\n\n```\n\n这里做一下简单说明：\n* `copytruncate` 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。\n* `dateext` 用于切换日志文件时命名成为`mongodb.log-YYYYMMDD`格式。 \n* `create 644 root root` 644权限，即`-rw-r--r--`与之前的日志文件保持一直的权限即可。\n\n### 验证\n\n编写完配置文件之后，我们将文件拷贝到`/etc/logrotate.d/`下，执行命令`logrotate -f -v /etc/logrotate.d/<YOUR_CONFIG_FILE_NAME>`来验证日志是否被轮换了，示例执行结果如下：\n\n```shell\nroot@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate\nreading config file /etc/logrotate.d/mongologrotate\nreading config info for /mongoData/mongodb_log/mongodb.log\n\nHandling 1 logs\n\nrotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)\nempty log files are not rotated, old logs are removed\nconsidering log /mongoData/mongodb_log/mongodb.log\n  log needs rotating\nrotating log /mongoData/mongodb_log/mongodb.log, log->rotateCount is 30\ndateext suffix '-20160630'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nglob finding old rotated logs failed\ncopying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630\nset default create context\ntruncating /mongoData/mongodb_log/mongodb.log\nrunning postrotate script\ncompressing log with: /bin/gzip\n[root@localhost mongodb_log]# ll\ntotal 69604\n-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log\n-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz\n```\n### 特别指出\n\n由于我们的服务期开启了SELinux，并且是`Enforcing`模式下，会造成非`/var/log/`目录下的logrotate操作失败，所以需要执行下面的命令：\n```shell\n[root@localhost ~]# semanage fcontext -a -t var_log_t '/mongoData/mongodb_log/mongodb.log'\n[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log\n```\n上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到`/etc/selinux/targeted/contexts/files/file_contexts.local`里，我们可以验证一下。\n```shell\n[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local\n# This file is auto-generated by libsemanage\n# Do not edit directly.\n\n/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0\n```\n上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。\n\n关于这个问题的说明，可以[点击这里](https://access.redhat.com/solutions/39006)查看更多说明和解释。\n\n## 结语\n\n至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过`man logrotate`查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。\n","slug":"使用Logrotate管理MongoDB日志","published":1,"updated":"2016-07-01T06:12:13.332Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciugriapp0014gghl76bm1a6e","content":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。<a id=\"more\"></a></p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\" target=\"_blank\" rel=\"external\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\" target=\"_blank\" rel=\"external\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"external\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix &apos;-20160630&apos;</span><br><span class=\"line\">glob pattern &apos;-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]&apos;</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\" target=\"_blank\" rel=\"external\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>\n","excerpt":"<h2 id=\"痛点\"><a href=\"#痛点\" class=\"headerlink\" title=\"痛点\"></a>痛点</h2><p>前段时间需要查询MongoDB日志，惊觉MongoDB的日志并没有配置自动切换轮转，这会导致在繁忙的业务下，日志增长量惊人。面对海量的MongoDB日志，开发和运维人员查看日志变的十分不方便，所以需要寻求使日志自动切换轮转的方式。","more":"</p>\n<h2 id=\"选型\"><a href=\"#选型\" class=\"headerlink\" title=\"选型\"></a>选型</h2><p>通过查看MongoDB官方文档，知悉MongoDB提供了几种轮转日志文件的策略，详见<a href=\"https://docs.mongodb.com/manual/tutorial/rotate-log-files/\">这里</a>（据说新版本的MongoDB已经完成了自动的日志轮转功能？）。其中，可以使用MongoDB提供的<a href=\"https://docs.mongodb.com/manual/reference/command/logRotate/#dbcmd.logRotate\"><code>logRotate</code></a>命令或者通过向<code>mongod</code>进程发送<code>SIGUSR1</code>信号来实现。</p>\n<p>然而看很多文章中均表示，MongoDB本身提供的logRotate机制存在很多问题，比如由于其不稳定性，会造成日志轮换中mongodb进程终止，不提供旧日志的压缩，即使轮转切换日志，还是占用了很多磁盘空间；日志文件重命名格式<code>mongodb.log.2016-10-22T17-44-44</code>不友好等等。所以我们在选择时就会变得很小心，尽量避免使用其内置logRotate。</p>\n<p>被广泛认可的方案是通过<a href=\"http://linux.die.net/man/8/logrotate\">Logrotate</a>进行日志管理，其中可以执行脚本实现向<code>mongod</code>进程发送<code>SIGUSR1</code>信号。</p>\n<h2 id=\"Logrotate\"><a href=\"#Logrotate\" class=\"headerlink\" title=\"Logrotate\"></a>Logrotate</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Logrotate可以帮助我们管理日志文件。比如周期性的读取日志、压缩日志、备份日志、创建新的日志文件等，基本上你希望做的，都能实现。通常来讲，常被用于来避免单个日志文件增长为难以处理的大小。也常被用于删除旧的日志文件来释放磁盘空间。</p>\n<p>通常来讲，默认的Logrotate会作为<code>/etc/cron.daily/</code>中的一个计划任务每天执行一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost etc]# ls /etc/cron.daily/</span><br><span class=\"line\">cups  logrotate  makewhatis.cron  mlocate.cron</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置说明\"><a href=\"#配置说明\" class=\"headerlink\" title=\"配置说明\"></a>配置说明</h3><p>配置Logrotate通过编辑两处配置文件来完成：</p>\n<ul>\n<li>/etc/logrotate.conf</li>\n<li>/etc/logrotate.d/下面的不同服务特定的配置</li>\n</ul>\n<p><code>logrotate.conf</code>包含了通用的配置，下面是一个默认配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># see &quot;man logrotate&quot; for details</span><br><span class=\"line\"># rotate log files weekly</span><br><span class=\"line\">weekly</span><br><span class=\"line\"></span><br><span class=\"line\"># keep 4 weeks worth of backlogs</span><br><span class=\"line\">rotate 4</span><br><span class=\"line\"></span><br><span class=\"line\"># create new (empty) log files after rotating old ones</span><br><span class=\"line\">create</span><br><span class=\"line\"></span><br><span class=\"line\"># use date as a suffix of the rotated file</span><br><span class=\"line\">dateext</span><br><span class=\"line\"></span><br><span class=\"line\"># uncomment this if you want your log files compressed</span><br><span class=\"line\">#compress</span><br><span class=\"line\"></span><br><span class=\"line\"># RPM packages drop log rotation information into this directory</span><br><span class=\"line\">include /etc/logrotate.d</span><br><span class=\"line\"></span><br><span class=\"line\"># no packages own wtmp and btmp -- we&apos;ll rotate them here</span><br><span class=\"line\">/var/log/wtmp &#123;</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0664 root utmp</span><br><span class=\"line\">        minsize 1M</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log/btmp &#123;</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    monthly</span><br><span class=\"line\">    create 0600 root utmp</span><br><span class=\"line\">    rotate 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure>\n<p>上面的通用配置我们不用过多关心，因为我们具体服务的具体配置在目录<code>/etc/logrotate.d/</code>下。在这个目录里，许多应用在安装后已经设置了Logrotate，比如httpd，nginx等。下面，我们拿nginx的配置做一个简要的说明：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cd /etc/logrotate.d/</span><br><span class=\"line\">[root@localhost logrotate.d]# ll</span><br><span class=\"line\">total 44</span><br><span class=\"line\">-rw-r--r--. 1 root root 185 Aug  2  2013 httpd</span><br><span class=\"line\">-rw-r--r--. 1 root root 871 Jun 22  2015 mysqld</span><br><span class=\"line\">-rw-r--r--. 1 root root 302 Apr 26 23:10 nginx</span><br><span class=\"line\">-rw-r--r--. 1 root root 219 Nov 23  2013 sssd</span><br><span class=\"line\">-rw-r--r--. 1 root root 210 Aug 15  2013 syslog</span><br><span class=\"line\">-rw-r--r--. 1 root root 100 Feb 22  2013 yum</span><br><span class=\"line\">[root@localhost logrotate.d]# cat nginx </span><br><span class=\"line\">/var/log/nginx/*.log &#123;</span><br><span class=\"line\">        daily</span><br><span class=\"line\">        missingok</span><br><span class=\"line\">        rotate 52</span><br><span class=\"line\">        compress</span><br><span class=\"line\">        delaycompress</span><br><span class=\"line\">        notifempty</span><br><span class=\"line\">        create 640 nginx adm</span><br><span class=\"line\">        sharedscripts</span><br><span class=\"line\">        postrotate</span><br><span class=\"line\">                [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class=\"line\">        endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先第一行，配置了要自动轮换的日志文件的路径<code>/var/log/nginx/*.log</code>，即针对在<code>/var/log/nginx</code>下的<code>*.log</code>文件进行轮换。</p>\n<ul>\n<li>daily：每天轮换日志。可选选项有daily，weekly，monthly和yearly</li>\n<li>missingok：找不到*.log文件也是ok的，不要方……</li>\n<li>rotate 52：保留52个日志文件，其他更老旧的日志文件删掉（在这里要配合daily使用，即保留52天的日志文件）</li>\n<li>compress：压缩日志文件（默认gzip格式）<ul>\n<li>delaycompress：延迟压缩任务直到第二次轮换日志才进行。结果会导致你会有当前的日志文件，一个较旧的没有被压缩过的日志文件和一些压缩过的日志文件</li>\n<li>compresscmd：设置使用什么命令来进行压缩，默认是gzip</li>\n<li>uncompresscmd：设置解压的命令，默认是gunzip。</li>\n</ul>\n</li>\n<li>notifempty：不轮转空文件</li>\n<li>create 640 nginx adm：创建一个新的日志文件，并设置权限permissions/owner/group。本例中，使用用户ngxin和用户组adm创建了一个日志文件，文件权限为640.在很多系统中，owner和group一般都会是root。</li>\n<li>sharedscripts：在所有的日志轮换完毕后执行postrotate脚本。如果该项没有设置，则会在每个匹配的文件轮换后执行postrotate脚本。</li>\n<li>postrotate：轮换日志完成后运行的脚本。</li>\n</ul>\n<p>更多的选项，参见<a href=\"http://linux.die.net/man/8/logrotate\">这里</a>。</p>\n<h2 id=\"使用Logrotate管理MongoDB日志\"><a href=\"#使用Logrotate管理MongoDB日志\" class=\"headerlink\" title=\"使用Logrotate管理MongoDB日志\"></a>使用Logrotate管理MongoDB日志</h2><p>经过上面对Logrotate的简单说明，这是我们就可以开始使用它来管理MongoDB日志了。</p>\n<h3 id=\"找到日志文件及PID记录文件\"><a href=\"#找到日志文件及PID记录文件\" class=\"headerlink\" title=\"找到日志文件及PID记录文件\"></a>找到日志文件及PID记录文件</h3><p>首先，我们的MongoDB启动配置中，指定了<code>logpath</code>和<code>pidfilepath</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">logpath=/mongoData/mongodb_log/mongodb.log </span><br><span class=\"line\">pidfilepath=/mongoData/mongodb.pid</span><br></pre></td></tr></table></figure>\n<p><code>mongod.pid</code>和文件<code>/mongoData/mongodb_data/mongod.lock</code>中都存有mongod的PID，用这两个文件都可以获取PID，任选其一即可。</p>\n<h3 id=\"编写配置文件\"><a href=\"#编写配置文件\" class=\"headerlink\" title=\"编写配置文件\"></a>编写配置文件</h3><p>通过<code>man logrotate</code>查看详细参数，结合业务需求，编写的配置文件如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/mongoData/mongodb_log/mongodb.log  &#123;</span><br><span class=\"line\">\tdaily</span><br><span class=\"line\">    missingok</span><br><span class=\"line\">    rotate 30</span><br><span class=\"line\">    copytruncate </span><br><span class=\"line\">    dateext  </span><br><span class=\"line\">    compress</span><br><span class=\"line\">    notifempty</span><br><span class=\"line\">    create 644 root root </span><br><span class=\"line\">    sharedscripts</span><br><span class=\"line\">    postrotate</span><br><span class=\"line\">    \t/bin/kill -SIGUSR1 &apos;cat /mongoData/mongodb.pid 2&gt; /dev/null&apos; 2&gt; /dev/null || true</span><br><span class=\"line\">    endscript</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里做一下简单说明：</p>\n<ul>\n<li><code>copytruncate</code> 这个命令很重要，意思是在创建副本后，将原文件清空，而不是将原文件重命名并创建新的日志文件。这样可以避免有些应用继续向原日志文件中输出，而不是新的日志文件。在没有配置这个命令之前，mongodb一直向轮换后的带时间戳的旧文件中输出日志。</li>\n<li><code>dateext</code> 用于切换日志文件时命名成为<code>mongodb.log-YYYYMMDD</code>格式。 </li>\n<li><code>create 644 root root</code> 644权限，即<code>-rw-r--r--</code>与之前的日志文件保持一直的权限即可。</li>\n</ul>\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><p>编写完配置文件之后，我们将文件拷贝到<code>/etc/logrotate.d/</code>下，执行命令<code>logrotate -f -v /etc/logrotate.d/&lt;YOUR_CONFIG_FILE_NAME&gt;</code>来验证日志是否被轮换了，示例执行结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost mongodb_log]# logrotate -f -v /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config file /etc/logrotate.d/mongologrotate</span><br><span class=\"line\">reading config info for /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\"></span><br><span class=\"line\">Handling 1 logs</span><br><span class=\"line\"></span><br><span class=\"line\">rotating pattern: /mongoData/mongodb_log/mongodb.log  forced from command line (30 rotations)</span><br><span class=\"line\">empty log files are not rotated, old logs are removed</span><br><span class=\"line\">considering log /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">  log needs rotating</span><br><span class=\"line\">rotating log /mongoData/mongodb_log/mongodb.log, log-&gt;rotateCount is 30</span><br><span class=\"line\">dateext suffix &apos;-20160630&apos;</span><br><span class=\"line\">glob pattern &apos;-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]&apos;</span><br><span class=\"line\">glob finding old rotated logs failed</span><br><span class=\"line\">copying /mongoData/mongodb_log/mongodb.log to /mongoData/mongodb_log/mongodb.log-20160630</span><br><span class=\"line\">set default create context</span><br><span class=\"line\">truncating /mongoData/mongodb_log/mongodb.log</span><br><span class=\"line\">running postrotate script</span><br><span class=\"line\">compressing log with: /bin/gzip</span><br><span class=\"line\">[root@localhost mongodb_log]# ll</span><br><span class=\"line\">total 69604</span><br><span class=\"line\">-rw-r--r--. 1 root root    37092 Jun 30 13:24 mongodb.log</span><br><span class=\"line\">-rw-r--r--. 1 root root  1047190 Jun 30 13:24 mongodb.log-20160630.gz</span><br></pre></td></tr></table></figure>\n<h3 id=\"特别指出\"><a href=\"#特别指出\" class=\"headerlink\" title=\"特别指出\"></a>特别指出</h3><p>由于我们的服务期开启了SELinux，并且是<code>Enforcing</code>模式下，会造成非<code>/var/log/</code>目录下的logrotate操作失败，所以需要执行下面的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# semanage fcontext -a -t var_log_t &apos;/mongoData/mongodb_log/mongodb.log&apos;</span><br><span class=\"line\">[root@localhost ~]# restorecon -Frvv /mongoData/mongodb_log/mongodb.log</span><br></pre></td></tr></table></figure></p>\n<p>上面的第一条命令用来定义mongodb.log这个文件的上下文，记录会被持久化到<code>/etc/selinux/targeted/contexts/files/file_contexts.local</code>里，我们可以验证一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost ~]# cat /etc/selinux/targeted/contexts/files/file_contexts.local</span><br><span class=\"line\"># This file is auto-generated by libsemanage</span><br><span class=\"line\"># Do not edit directly.</span><br><span class=\"line\"></span><br><span class=\"line\">/mongoData/mongodb_log/mongodb.log    system_u:object_r:var_log_t:s0</span><br></pre></td></tr></table></figure></p>\n<p>上面的第二条命令，可以递归的设置上下文，如果我们传入的是一个目录，则目录下的所有子目录及文件都会被递归的统一设置。</p>\n<p>关于这个问题的说明，可以<a href=\"https://access.redhat.com/solutions/39006\">点击这里</a>查看更多说明和解释。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>至此，我们边完成了使用Logrotate来管理MongoDB日志了。可以看到，Logrotate十分强大，在使用时，可以通过<code>man logrotate</code>查看一下具体参数，知其然并知其所以然，让其更好地为我们所用。</p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ciugriaj60000gghlox3q5gql","tag_id":"ciugriajf0004gghl0tqexcfe","_id":"ciugriajp000agghl4oqy0oen"},{"post_id":"ciugriajg0005gghl8n35whsn","tag_id":"ciugriajt000fgghl1dh42w45","_id":"ciugriajv000kgghl59c3ax4y"},{"post_id":"ciugriajg0005gghl8n35whsn","tag_id":"ciugriaju000igghlfm282ouh","_id":"ciugriajv000lgghlbfldo3gu"},{"post_id":"ciugriajj0007gghltzf335dw","tag_id":"ciugriaju000jgghlsva7yiww","_id":"ciugriajw000ngghlv5aticot"},{"post_id":"ciugriajm0009gghlh5u75n5y","tag_id":"ciugriajv000mgghlskj3zxve","_id":"ciugriajy000qgghl2nes6x0s"},{"post_id":"ciugriajm0009gghlh5u75n5y","tag_id":"ciugriajw000ogghlz5d8spx5","_id":"ciugriajy000rgghlq837w2fm"},{"post_id":"ciugriajp000bgghlaf0qebww","tag_id":"ciugriajt000fgghl1dh42w45","_id":"ciugriak0000ugghl0brjq0fx"},{"post_id":"ciugriajp000bgghlaf0qebww","tag_id":"ciugriajy000sgghluv7ylxbq","_id":"ciugriak1000vgghlmumgbjpr"},{"post_id":"ciugriajr000cgghl4ozctlaq","tag_id":"ciugriajs000dgghlpqwhwahh","_id":"ciugriak2000xgghli74u1p2t"},{"post_id":"ciugriajs000egghl4xua35kc","tag_id":"ciugriak1000wgghlht2ar6dp","_id":"ciugriak2000ygghlkjtxn9h7"},{"post_id":"ciugriak9000zgghlnpg8f0yr","tag_id":"ciugriaka0010gghl9qfwk2kd","_id":"ciugriakb0011gghlj9xn7nsi"},{"post_id":"ciugriak9000zgghlnpg8f0yr","tag_id":"ciugriajf0004gghl0tqexcfe","_id":"ciugriakb0012gghlx39b674j"},{"post_id":"ciugriapp0014gghl76bm1a6e","tag_id":"ciugriaka0010gghl9qfwk2kd","_id":"ciugriapt0016gghlwqr5ugr0"},{"post_id":"ciugriapp0014gghl76bm1a6e","tag_id":"ciugriajf0004gghl0tqexcfe","_id":"ciugriapt0017gghljtbwxgtj"},{"post_id":"ciugriapl0013gghlvj6ed7wl","tag_id":"ciugriaps0015gghl4ek1givz","_id":"ciugriapy0018gghlzwmrrys7"}],"Tag":[{"name":"MongoDB","_id":"ciugriajf0004gghl0tqexcfe"},{"name":"Quartz","_id":"ciugriajl0008gghl0onsagfv"},{"name":"Java","_id":"ciugriajs000dgghlpqwhwahh"},{"name":"Linux","_id":"ciugriajt000fgghl1dh42w45"},{"name":"CentOS6.5","_id":"ciugriaju000igghlfm282ouh"},{"name":"Git","_id":"ciugriaju000jgghlsva7yiww"},{"name":"Reids","_id":"ciugriajv000mgghlskj3zxve"},{"name":"Tomcat","_id":"ciugriajw000ogghlz5d8spx5"},{"name":"CentOS7","_id":"ciugriajy000sgghluv7ylxbq"},{"name":"杂","_id":"ciugriak1000wgghlht2ar6dp"},{"name":"Logrotate","_id":"ciugriaka0010gghl9qfwk2kd"},{"name":"翻译","_id":"ciugriaps0015gghl4ek1givz"}]}}